# Рекомендация тарифов
## Описание проекта
Оператор мобильной связи «Мегалайн» выяснил: многие клиенты пользуются архивными тарифами. Они хотят построить систему, способную проанализировать поведение клиентов и предложить пользователям новый тариф: «Смарт» или «Ультра».
В вашем распоряжении данные о поведении клиентов, которые уже перешли на эти тарифы. Нужно построить модель для задачи классификации, которая выберет подходящий тариф. Предобработка данных не понадобится — вы её уже сделали.
Постройте модель с максимально большим значением accuracy. Чтобы сдать проект успешно, нужно довести долю правильных ответов по крайней мере до 0.75. Проверьте accuracy на тестовой выборке самостоятельно.
## Инструкция по выполнению проекта
1. Откройте файл с данными и изучите его. Путь к файлу: `/datasets/users_behavior.csv`.
2. Разделите исходные данные на обучающую, валидационную и тестовую выборки.
3. Исследуйте качество разных моделей, меняя гиперпараметры. Кратко напишите выводы исследования.
4. Проверьте качество модели на тестовой выборке.
5. Дополнительное задание: проверьте модели на вменяемость. Ничего страшного, если не получится: эти данные сложнее тех, с которыми вы работали раньше. В следующем курсе подробнее об этом расскажем.
## Описание данных
Каждый объект в наборе данных — это информация о поведении одного пользователя за месяц. Известно:
* `сalls` — количество звонков,
* `minutes` — суммарная длительность звонков в минутах,
* `messages` — количество sms-сообщений,
* `mb_used` — израсходованный интернет-трафик в Мб,
* `is_ultra` — каким тарифом пользовался в течение месяца («Ультра» — 1, «Смарт» — 0).

## Вывод
В ходе исследования были проверены все распространенные алгоритмы машинного обучения,
так же была проверка нейросетевого классификатора. Ожидаемо наилучшие результаты показали
алгоритмы связанные с деревьями:
1) `CatBoost` (респект Яндексу)
2) `BaggingClassifier`, model = `catboosting`
3) Решающие деревья
4) `Optuna` Решающие деревья

У всех перечисленных выше моделей accuracy на тестовой выборке было 0.81, что по моему мнению является хорошим
результатом с учетов маленького объема данных 3тысячи строк и несбалансированных классов (70 на 30).
Нейросетевой классификатор показал плохой результат, я считаю что это связано с недостатком данных.