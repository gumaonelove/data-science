{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nНапример, можно извлечь дополнительные признаки из текста программы, такие как \\n1) частоты конструкций языка,\\n2) длину символов в названиях, \\n3) степени вложенности циклов и условий. \\nК полученным признакам можно применить модель классификации (линейные, деревья или любые другие).\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Например, можно извлечь дополнительные признаки из текста программы, такие как \n",
    "1) частоты конструкций языка,\n",
    "2) длину символов в названиях, \n",
    "3) степени вложенности циклов и условий. \n",
    "К полученным признакам можно применить модель классификации (линейные, деревья или любые другие).\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_vector(text): \n",
    "    X_train_counts = count_vect.fit_transform(text)\n",
    "    tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\n",
    "    X_train_tf = tf_transformer.transform(X_train_counts)\n",
    "    return X_train_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FuncLister(ast.NodeVisitor):\n",
    "    def __init__(self):\n",
    "        # длина слов в названиях\n",
    "        self.stats = {\n",
    "            'FunctionDef': [],\n",
    "            'ClassDef': [],\n",
    "            'AsyncFunctionDef': [],\n",
    "            'String': [],\n",
    "            'from': [],\n",
    "            'import': []\n",
    "        }\n",
    "\n",
    "    def visit_FunctionDef(self, node):\n",
    "        self.stats['FunctionDef'].append(node.name)\n",
    "        self.generic_visit(node)\n",
    "\n",
    "    def visit_ClassDef(self, node):\n",
    "        self.stats['ClassDef'].append(node.name)\n",
    "        self.generic_visit(node)\n",
    "\n",
    "    def visit_AsyncFunctionDef(self, node):\n",
    "        self.stats['AsyncFunctionDef'].append(node.name)\n",
    "        self.generic_visit(node)\n",
    "\n",
    "    def visit_Str(self, node):\n",
    "        self.stats['String'].append(node.s)\n",
    "    \n",
    "    def node_visitFrom(self, node): \n",
    "        for alias in node.names: \n",
    "            self.stats['from'].append(alias.name) \n",
    "        self.generic_visit(node) \n",
    "    \n",
    "    def node_visit(self, node): \n",
    "        for alias in node.names: \n",
    "            self.stats['import'].append(alias.name) \n",
    "        self.generic_visit(node) \n",
    "\n",
    "    def get_stats(self):\n",
    "        try: \n",
    "            for stat in self.stats:\n",
    "                self.stats[stat] = to_vector(self.stats[stat])\n",
    "        except ValueError:\n",
    "            print(self.stats)\n",
    "            pass\n",
    "        return self.stats\n",
    "        \n",
    "    def report(self):\n",
    "        print(self.stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(a, b):\n",
    "    '''Алгоритм Левинштейна'''\n",
    "    n, m = len(a), len(b)\n",
    "    if n > m:\n",
    "        # убедимся что n <= m, чтобы использовать минимум памяти O(min(n, m))\n",
    "        a, b = b, a\n",
    "        n, m = m, n\n",
    "\n",
    "    current_row = range(n + 1)  # 0 ряд - просто восходящая последовательность (одни вставки)\n",
    "    for i in range(1, m + 1):\n",
    "        previous_row, current_row = current_row, [i] + [0] * n\n",
    "        for j in range(1, n + 1):\n",
    "            add, delete, change = previous_row[j] + 1, current_row[j - 1] + 1, previous_row[j - 1]\n",
    "            if a[j - 1] != b[i - 1]:\n",
    "                change += 1\n",
    "            current_row[j] = min(add, delete, change)\n",
    "\n",
    "    return current_row[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(text):\n",
    "    '''парсим и чистим файл'''\n",
    "    text = re.sub(r'\\s+', r' ', text)  # убираем лишние пробелы\n",
    "    text = text.lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_paths = ['./plagiat/files/', './plagiat/plagiat1/', './plagiat/plagiat2/']\n",
    "keywords = {  # словарь частот конструкций языка\n",
    "    'False': 0,\n",
    "    'class': 0,\n",
    "    'from': 0,\n",
    "    'or': 0,\n",
    "    'None': 0,\n",
    "    'continue': 0,\n",
    "    'global': 0,\n",
    "    'pass': 0,\n",
    "    'True': 0,\n",
    "    'def': 0,\n",
    "    'if': 0,\n",
    "    'raise': 0,\n",
    "    'and': 0,\n",
    "    'del': 0,\n",
    "    'import': 0,\n",
    "    'return': 0,\n",
    "    'as': 0,\n",
    "    'elif': 0,\n",
    "    'in': 0,\n",
    "    'try': 0,\n",
    "    'assert': 0,\n",
    "    'else': 0,\n",
    "    'is': 0,\n",
    "    'while': 0,\n",
    "    'async': 0,\n",
    "    'except': 0,\n",
    "    'lambda': 0,\n",
    "    'with': 0,\n",
    "    'await': 0,\n",
    "    'finally': 0,\n",
    "    'nonlocal': 0,\n",
    "    'yield': 0,\n",
    "    'break': 0,\n",
    "    'for': 0,\n",
    "    'not': 0\n",
    "}\n",
    "files = {}\n",
    "distances = {}  # livinstein\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dir_path in dir_paths:\n",
    "    for f in listdir(dir_path):\n",
    "        if isfile(join(dir_path, f)):\n",
    "            files[dir_path + f] = {\n",
    "                'X_train_tf': None\n",
    "            }\n",
    "            files[dir_path + f] |= keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'FunctionDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Implementation of the Multi-similarity loss with custom scorer.\\n\\n    For details see original paper:\\n    https://openaccess.thecvf.com/content_CVPR_2019/papers/Wang_Multi-Similarity_Loss_With_General_Pair_Weighting_for_Deep_Metric_Learning_CVPR_2019_paper.pdf\\n\\n    Implementation was largely motivited by:\\n    https://github.com/msight-tech/research-ms-loss/blob/master/ret_benchmark/losses/multi_similarity_loss.py\\n    ', 'Get default config.', 'threshold', 'margin', 'positive_scale', 'negative_scale', 'mean', 'Embeddings and labels shape mismatch', 'margin', 'margin', 'positive_scale', 'positive_scale', 'threshold', 'negative_scale', 'negative_scale', 'threshold', 'none', 'mean', 'Unknown aggregation: {}'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['cmd', 'data', 'name', 'logger', 'config', 'train_root', 'checkpoint', 'no_strict_init', 'from_stage', 'from_seed', 'dataset_params', 'model_params', 'trainer_params', 'num_evaluation_seeds', 'stages', 'name', 'batch_size', 'num_workers', 'num_validation_folds', 'debug-openset', 'distribution_type', 'distribution_params', 'embedder_params', 'classifier_type', 'vmf', 'k', 'separate', 'pretrained', 'model_type', 'extra_head_dim', 'resnet18', 'loglike', 'num_epochs', 'model_params', 'embedder_params', 'freeze_extra_head', 'resume_prefixes', 'model_params', '_embedder.,_classifier.', 'freeze_classifier', 'embedder_params', 'freeze_stem', 'freeze_head', 'freeze_normalizer', 'config.yaml', 'w', 'train', 'tensorboard', 'model', 'checkpoints', 'train-0.', 'model_model_state_dict', 'checkpoints', 'train-1.', 'model_model_state_dict', '_embedder._extra_head.', '_embedder._stem.', '_embedder._head.', '_embedder._normalizer.', '_classifier.', '_embedder._extra_head.', '_embedder._stem.', '_embedder._head.', '_classifier.', '_embedder._normalizer.', 'Keys mismatch', 'trainer_params', 'num_epochs', '.pth', 'cpu', 'No checkpoint for prefix {}.', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <9x9 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 9 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['Generate dataset with non-positive target.', 'timestamp', '2020-01-01', 'segment', 'segment_1', 'target', 'timestamp', '2020-01-01', 'segment', 'segment_2', 'target', 'timestamp', 'segment', 'segment', 'feature', 'Generate dataset with positive target.', 'timestamp', '2020-01-01', 'segment', 'segment_1', 'target', 'expected', 'target', 'timestamp', '2020-01-01', 'segment', 'segment_2', 'target', 'expected', 'target', 'timestamp', 'segment', 'segment', 'feature', 'Check LogTransform behavior in case of negative-value series.', 'target', 'Check the value of transform result.', 'target', 'segment_1', 'segment_2', 'target', 'expected', 'Check the column name after non inplace transform.', 'target', 'segment_1', 'segment_2', 'out_column', 'log_transform', 'Check the value of transform result in case of given out column.', 'target_log_10', 'target', 'segment_1', 'segment_2', 'expected', 'Check that inverse_transform rolls back transform result.', 'target', 'segment_1', 'segment_2', 'target', 'target', 'base', 'Check that inverse_transform rolls back transform result in case of given out_column.', 'target_log_10', 'target', 'segment_1', 'segment_2', 'target', 'target'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <8x8 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 8 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['1d', 'target', 'catboostmodel', 'regressor_exog', 'feature', '1d', 'all', 'target', 'regressor_exog', 'catboostmodel', '2020-01-03', 'D', 'timestamp', 'target', 'segment', 'segment_', 'D', 'target', 'target', 'target', 'Can not get the dict with base models, the model is not fitted!', 'target', '2021-01-01', 'D', 'date_flag', 'encoder', 'date_flag_day_number_in_month', 'date_flag_day_number_in_month'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['features_to_use, expected_features', 'all', 'regressor_1', 'regressor_2', 'exog', 'regressor_1', 'regressor_1', 'regressor_1', 'unknown_column', 'regressor_1', 'regressor_1', 'unknown_column', 'Columns from feature_to_use which are out of dataframe columns will be dropped!', 'feature', 'features_to_use, selected_features, expected_columns', 'all', 'regressor_1', 'regressor_1', 'target', 'regressor_1', 'regressor_2', 'regressor_1', 'regressor_1', 'exog', 'target', 'feature', 'return_features', 'features_to_use, selected_features, expected_columns', 'all', 'regressor_1', 'exog', 'regressor_2', 'regressor_1', 'regressor_2', 'regressor_1', 'regressor_2', 'feature', 'features_to_use, expected_columns, return_features', 'all', 'exog', 'regressor_1', 'regressor_2', 'target', 'regressor_1', 'regressor_2', 'regressor_2', 'regressor_1', 'exog', 'target', 'all', 'regressor_2', 'exog', 'target', 'regressor_1', 'regressor_2', 'regressor_2', 'regressor_1', 'exog', 'target'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Enum for different optimization modes.', 'pen', 'epsilon', ' is not a valid ', '. Only ', ', ', ' modes allowed', 'Get number of change points, detected with given params.\\n\\n    Parameters\\n    ----------\\n    series:\\n        series to detect change points\\n    change_point_model:\\n        model to get trend change points\\n\\n    Returns\\n    -------\\n    :\\n        number of change points\\n    ', 'Give next value according to binary search.\\n\\n    Parameters\\n    ----------\\n    now_value:\\n        current value\\n    lower_bound:\\n        lower bound for search\\n    upper_bound:\\n        upper bound for search\\n    need_greater:\\n        True if we need greater value for n_bkps than previous time\\n\\n    Returns\\n    -------\\n    :\\n        next value and its bounds\\n    ', 'Run binary search for optimal regularizations.\\n\\n    Parameters\\n    ----------\\n    series:\\n        series for search\\n    change_point_model:\\n        model to get trend change points\\n    n_bkps:\\n        target numbers of changepoints\\n    opt_param:\\n        parameter for optimization\\n    max_value:\\n        maximum possible value, the upper bound for search\\n    max_iters:\\n        maximum iterations; in case if the required number of points is unattainable, values will be selected after max_iters iterations\\n\\n    Returns\\n    -------\\n    :\\n        regularization parameters value\\n\\n    Raises\\n    ______\\n    ValueError:\\n        If max_value is too low for needed n_bkps\\n    ValueError:\\n        If n_bkps is too high for this series\\n    ', 'Impossible number of changepoints. Please, decrease n_bkps value.', 'Impossible number of changepoints. Please, increase max_value or increase n_bkps value.', 'Get regularization parameter values for given number of changepoints.\\n\\n    It is assumed that as the regularization being selected increases, the number of change points decreases.\\n\\n    Parameters\\n    ----------\\n    ts:\\n        Dataset with timeseries data\\n    in_column:\\n        name of processed column\\n    change_point_model:\\n        model to get trend change points\\n    n_bkps:\\n        target numbers of changepoints\\n    mode:\\n        optimization mode\\n    max_value:\\n        maximum possible value, the upper bound for search\\n    max_iters:\\n        maximum iterations; in case if the required number of points is unattainable, values will be selected after max_iters iterations\\n\\n    Returns\\n    -------\\n    :\\n        regularization parameters values in dictionary format {segment: {mode: value}}.\\n\\n    Raises\\n    ______\\n    ValueError:\\n        If max_value is too low for needed n_bkps\\n    ValueError:\\n        If n_bkps is too high for this series\\n    '], 'from': [], 'import': []}\n",
      "{'FunctionDef': <6x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Convert dataset to mxnet format', 'src', 'Source dataset root', 'dst', 'Target dataset root', '--dataset', 'Type of the dataset (like in training config)', '--batch-size', 'Batch size', '--num-workers', 'Number of loader workers', 'jpeg', 'w', 'classification', 'num_classes', 'num_samples', 'name', 'validation_fold', 'add_verification_testsets', 'add_lossy_testsets', 'train_repeat', 'Datasets:', 'Skip verification dataset', 'Serialize', '.yaml', '.labels', '.idx', '.rec', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Run forward for default model.', 'logits', 'Run scoring for default model.', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <9x9 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 9 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Get distance between two samples for dtw distance.\\n\\n    Parameters\\n    ----------\\n    x1:\\n        first value\\n    x2:\\n        second value\\n\\n    Returns\\n    -------\\n    float:\\n        distance between x1 and x2\\n    ', 'DTW distance handler.', \"Init DTWDistance.\\n\\n        Parameters\\n        ----------\\n        points_distance:\\n            function to be used for computation of distance between two series' points\\n        trim_series:\\n            True if it is necessary to trim series, default False.\\n\\n        Notes\\n        -----\\n        Specifying manual ``points_distance`` might slow down the clustering algorithm.\\n        \", 'Build dtw-distance matrix for series x1 and x2.', 'Build a warping path with given matrix of dtw-distance.', 'Compute distance between x1 and x2.', 'Run DBA iteration.\\n        * for each series from series list build a dtw matrix and warping path\\n        * update values of centroid with values from series according to path\\n        ', 'TSDataset', 'Get the longest series from the list.', 'target', 'TSDataset', 'Get series from the TSDataset.', 'target', 'TSDataset', 'Get series that minimizes squared distance to given ones according to the dtw distance.\\n\\n        Parameters\\n        ----------\\n        ts:\\n            TSDataset with series to be averaged\\n        n_iters:\\n            number of DBA iterations to adjust centroid with series\\n\\n        Returns\\n        -------\\n        pd.Dataframe:\\n            dataframe with columns \"timestamp\" and \"target\" that contains the series\\n        ', 'timestamp', 'target', 'DTWDistance', 'simple_dist'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['adaptive', 'params', 'params', 'params', 'adaptive', 'params', 'adaptive_bias_and_bn', 'params', 'params', 'params', 'params', 'adaptive_bias_and_bn', 'params', 'params', 'params', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <16x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 16 stored elements in Compressed Sparse Row format>, 'ClassDef': <8x8 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 8 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Mean absolute error metric with multi-segment computation support.\\n\\n    .. math::\\n        MAE(y\\\\_true, y\\\\_pred) = \\\\frac{\\\\sum_{i=0}^{n-1}{\\\\mid y\\\\_true_i - y\\\\_pred_i \\\\mid}}{n}\\n\\n    Notes\\n    -----\\n    You can read more about logic of multi-segment metrics in Metric docs.\\n    ', \"Init metric.\\n\\n        Parameters\\n        ----------\\n        mode: 'macro' or 'per-segment'\\n            metrics aggregation mode\\n        kwargs:\\n            metric's computation arguments\\n        \", 'Whether higher metric value is better.', 'Mean squared error metric with multi-segment computation support.\\n\\n    .. math::\\n        MSE(y\\\\_true, y\\\\_pred) = \\\\frac{\\\\sum_{i=0}^{n-1}{(y\\\\_true_i - y\\\\_pred_i)^2}}{n}\\n\\n    Notes\\n    -----\\n    You can read more about logic of multi-segment metrics in Metric docs.\\n    ', \"Init metric.\\n\\n        Parameters\\n        ----------\\n        mode: 'macro' or 'per-segment'\\n            metrics aggregation mode\\n        kwargs:\\n            metric's computation arguments\\n        \", 'Whether higher metric value is better.', 'Coefficient of determination metric with multi-segment computation support.\\n\\n    .. math::\\n        R^2(y\\\\_true, y\\\\_pred) = 1 - \\\\frac{\\\\sum_{i=0}^{n-1}{(y\\\\_true_i - y\\\\_pred_i)^2}}{\\\\sum_{i=0}^{n-1}{(y\\\\_true_i - \\\\overline{y\\\\_true})^2}}\\n    Notes\\n    -----\\n    You can read more about logic of multi-segment metrics in Metric docs.\\n    ', \"Init metric.\\n\\n        Parameters\\n        ----------\\n        mode: 'macro' or 'per-segment'\\n            metrics aggregation mode\\n        kwargs:\\n            metric's computation arguments\\n        \", 'Whether higher metric value is better.', 'Mean absolute percentage error metric with multi-segment computation support.\\n\\n    .. math::\\n       MAPE(y\\\\_true, y\\\\_pred) = \\\\frac{1}{n}\\\\cdot\\\\frac{\\\\sum_{i=0}^{n-1}{\\\\mid y\\\\_true_i - y\\\\_pred_i\\\\mid}}{\\\\mid y\\\\_true_i \\\\mid + \\\\epsilon}\\n\\n    Notes\\n    -----\\n    You can read more about logic of multi-segment metrics in Metric docs.\\n    ', \"Init metric.\\n\\n        Parameters\\n        ----------\\n        mode: 'macro' or 'per-segment'\\n            metrics aggregation mode\\n        kwargs:\\n            metric's computation arguments\\n        \", 'Whether higher metric value is better.', 'Symmetric mean absolute percentage error metric with multi-segment computation support.\\n\\n    .. math::\\n       SMAPE(y\\\\_true, y\\\\_pred) = \\\\frac{2 \\\\cdot 100 \\\\%}{n}\\\\cdot\\\\frac{\\\\sum_{i=0}^{n-1}{\\\\mid y\\\\_true_i - y\\\\_pred_i\\\\mid}}{\\\\mid y\\\\_true_i \\\\mid + \\\\mid y\\\\_pred_i \\\\mid}\\n\\n    Notes\\n    -----\\n    You can read more about logic of multi-segment metrics in Metric docs.\\n    ', \"Init metric.\\n\\n        Parameters\\n        ----------\\n        mode: 'macro' or 'per-segment'\\n            metrics aggregation mode\\n        kwargs:\\n            metric's computation arguments\\n        \", 'Whether higher metric value is better.', 'Median absolute error metric with multi-segment computation support.\\n\\n    .. math::\\n       MedAE(y\\\\_true, y\\\\_pred) = median(\\\\mid y\\\\_true_1 - y\\\\_pred_1 \\\\mid, \\\\cdots, \\\\mid y\\\\_true_n - y\\\\_pred_n \\\\mid)\\n\\n    Notes\\n    -----\\n    You can read more about logic of multi-segment metrics in Metric docs.\\n    ', \"Init metric.\\n\\n        Parameters\\n        ----------\\n        mode: 'macro' or 'per-segment'\\n            metrics aggregation mode\\n        kwargs:\\n            metric's computation arguments\\n        \", 'Whether higher metric value is better.', 'Mean squared logarithmic error metric with multi-segment computation support.\\n\\n    .. math::\\n       MSLE(y\\\\_true, y\\\\_pred) = \\\\frac{1}{n}\\\\cdot\\\\sum_{i=0}^{n - 1}{(ln(1 + y\\\\_true_i) - ln(1 + y\\\\_pred_i))^2}\\n\\n    Notes\\n    -----\\n    You can read more about logic of multi-segment metrics in Metric docs.\\n    ', \"Init metric.\\n\\n        Parameters\\n        ----------\\n        mode: 'macro' or 'per-segment'\\n            metrics aggregation mode\\n        kwargs:\\n            metric's computation arguments\\n\\n        \", 'Whether higher metric value is better.', 'Sign error metric with multi-segment computation support.\\n\\n    .. math::\\n        Sign(y\\\\_true, y\\\\_pred) = \\\\frac{1}{n}\\\\cdot\\\\sum_{i=0}^{n - 1}{sign(y\\\\_true_i - y\\\\_pred_i)}\\n\\n    Notes\\n    -----\\n    You can read more about logic of multi-segment metrics in Metric docs.\\n    ', \"Init metric.\\n\\n        Parameters\\n        ----------\\n        mode: 'macro' or 'per-segment'\\n            metrics aggregation mode\\n        kwargs:\\n            metric's computation arguments\\n        \", 'Whether higher metric value is better.', 'MAE', 'MSE', 'R2', 'MSLE', 'MAPE', 'SMAPE', 'MedAE', 'Sign'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <9x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 9 stored elements in Compressed Sparse Row format>, 'ClassDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Enum for different imputation strategy.', 'new_value', 'mean', 'none', \"The strategy '\", \"' doesn't exist\", 'Encode categorical feature with value between 0 and n_classes-1.', '\\n        Init LabelEncoderTransform.\\n\\n        Parameters\\n        ----------\\n        in_column:\\n            Name of column to be transformed\\n        out_column:\\n            Name of added column. If not given, use ``self.__repr__()``\\n        strategy:\\n            Filling encoding in not fitted values:\\n\\n            - If \"new_value\", then replace missing values with \\'-1\\'\\n\\n            - If \"mean\", then replace missing values using the mean in encoded column\\n\\n            - If \"none\", then replace missing values with None\\n\\n        ', '\\n        Fit Label encoder.\\n\\n        Parameters\\n        ----------\\n        df:\\n            Dataframe with data to fit the transform\\n        Returns\\n        -------\\n        :\\n            Fitted transform\\n        ', 'LabelEncoderTransform', '\\n        Encode the ``in_column`` by fitted Label encoder.\\n\\n        Parameters\\n        ----------\\n        df\\n            Dataframe with data to transform\\n\\n        Returns\\n        -------\\n        :\\n            Dataframe with column with encoded values\\n        ', 'category', \"Get the ``out_column`` depending on the transform's parameters.\", 'Encode categorical feature as a one-hot numeric features.\\n\\n    If unknown category is encountered during transform, the resulting one-hot\\n    encoded columns for this feature will be all zeros.\\n    ', '\\n        Init OneHotEncoderTransform.\\n\\n        Parameters\\n        ----------\\n        in_column:\\n            Name of column to be encoded\\n        out_column:\\n            Prefix of names of added columns. If not given, use ``self.__repr__()``\\n        ', 'ignore', '\\n        Fit One Hot encoder.\\n\\n        Parameters\\n        ----------\\n        df:\\n            Dataframe with data to fit the transform\\n        Returns\\n        -------\\n        :\\n            Fitted transform\\n        ', 'OneHotEncoderTransform', '\\n        Encode the `in_column` by fitted One Hot encoder.\\n\\n        Parameters\\n        ----------\\n        df\\n            Dataframe with data to transform\\n\\n        Returns\\n        -------\\n        :\\n            Dataframe with column with encoded values\\n        ', '_', 'category', \"Get the ``out_column`` depending on the transform's parameters.\"], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['expected_global_means', 'timestamp', '2021-06-01', '2021-07-01', 'D', 'timestamp', '2021-06-01', '2021-07-01', 'D', 'segment', 'Moscow', 'target', 'segment', 'Omsk', 'target', 'D', 'Test that MeanSegmentEncoderTransform works correctly in forecast pipeline\\n    and helps to correctly forecast almost constant series.', 'macro'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <6x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['2000-01-01', 'D', '2000-01-04', 'D', 'All the pipelines should have pairwise different horizons.'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['Trace model embedder to output checkpoint.', 'Input checkpoint path must be provided', 'Output checkpoint path must be provided', 'tensorboard', 'embedder'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <11x11 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 11 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['2020-01-01', 'D', 'timestamp', 'exog_1', 'exog_2', 'exog_3', 'Test that `duplicate_data` fails on empty list of segments.', \"Parameter segments shouldn't be empty\", 'Test that `duplicate_data` fails on wrong given format.', \"'wrong_format' is not a valid DataFrameFormat\", 'segment_1', 'segment_2', 'wrong_format', 'Test that `duplicate_data` fails on wrong df.', \"There should be 'timestamp' column\", 'timestamp', 'segment_1', 'segment_2', 'Test that `duplicate_data` makes duplication in long format.', 'segment_1', 'segment_2', 'long', 'segment', 'segment', 'Test that `duplicate_data` makes duplication in wide format.', 'segment_1', 'segment_2', 'wide', 'timestamp', 'segment', 'timestamp', 'timestamp', 'Unit test for `_TorchDataset` class.', 'decoder_target', 'encoder_target', '2020-01-01', 'target', 'exog_0', 'exog_0', 'exog_0', 'exog_1', 'exog_0', 'exog_2', 'exog_1', 'D', 'segment_2', 'segment_0', 'segment_1', 'target', 'exog_2', 'exog_1', 'exog_0', 'segment', 'segment', 'feature', 'feature', 'features_left, features_right', 'exog_0', 'exog_0', 'exog_0', 'exog_1', 'exog_0', 'exog_1', 'exog_0', 'exog_1', 'exog_1', 'exog_2', 'segments_left, segment_right', 'segment_0', 'segment_0', 'segment_0', 'segment_1', 'segment_0', 'segment_1', 'segment_0', 'segment_1', 'segment_1', 'segment_2', 'timestamps_idx_left, timestamps_idx_right'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['.hydra', 'config.yaml', '2021-06-01', '2021-06-01', 'target', 'regressor_0', 'regressor_', 'pipeline', 'backtest'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <26x26 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 26 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['Example dataset with NaNs at the beginning.', 'segment_1', 'target', 'segment_1', 'target', 'segment_2', 'target', 'segment_2', 'target', 'Check that imputer for one segment fails to init with wrong imputing strategy.', 'target', 'wrong_strategy', 'Check that imputer for two segments fails to fit_transform with wrong imputing strategy.', 'wrong_strategy', 'Check that imputer does nothing with series without gaps.', 'target', 'target', 'target', 'fill_strategy', 'mean', 'constant', 'running_mean', 'forward_fill', 'seasonal', 'Check that imputer does nothing with series without gaps.', 'segment', 'target', 'target', 'fill_strategy', 'mean', 'constant', 'running_mean', 'forward_fill', 'seasonal', \"Check that imputer can't fill nans if all values are nans.\", 'target', \"Series hasn't non NaN values which means it is empty and can't be filled\", 'fill_strategy', 'constant', 'mean', 'running_mean', 'forward_fill', 'seasonal', \"Check that imputer can't fill nans if all values are nans.\", \"Series hasn't non NaN values which means it is empty and can't be filled\", 'fill_strategy', 'mean', 'running_mean', 'forward_fill', 'seasonal', 'Check that imputer with constant-strategy works correctly in case of one missing value in data.', 'target', 'constant', 'target', 'constant_value', 'Check that imputer with constant-strategy works correctly in case of range of missing values in data.', 'target', 'constant', 'target', 'target', 'constant_value', 'target', 'constant', 'target', 'target', 'Check that imputer with mean-strategy works correctly in case of one missing value in data.', 'target', 'mean', 'target', 'target', 'Check that imputer with mean-strategy works correctly in case of range of missing values in data.', 'target', 'mean', 'target', 'target', 'target', 'Check that imputer with forward-fill-strategy works correctly in case of one missing value in data.', 'target', 'forward_fill', 'target', 'target', 'Check that imputer with forward-fill-strategy works correctly in case of range of missing values in data.', 'target', 'forward_fill', 'target', 'target', 'target', 'Check that imputer with running-mean-strategy works correctly in case of one missing value in data.', 'target', 'running_mean', 'target', 'target', 'target', 'window', 'Check that imputer with running-mean-strategy works correctly in case of range of missing values in data.', 'target', 'running_mean', 'target', 'window', '2020-01-01', '2020-01-11', 'D', 'timestamp', 'segment', 'segment_1', 'target', 'timestamp', 'segment', 'segment_2', 'target', 'D', 'TSDataset with nans to fill with imputer.', '2020-01-01', '2020-01-03', '2020-01-08', '2020-01-09', 'target', 'target', 'seasonal', 'target', 'window, seasonality, expected', 'target', 'seasonal', 'target', 'window, seasonality, default_value, expected', \"Check that transform + inverse_transform don't change original df for one segment.\", 'target', 'fill_strategy', 'mean', 'constant', 'running_mean', 'forward_fill', 'seasonal', \"Check that transform + inverse_transform don't change original df for two segments.\", 'fill_strategy', 'mean', 'constant', 'running_mean', 'forward_fill', 'seasonal', \"Check that inverse_transform doesn't change anything in forecast.\", 'target', 'target', 'target', 'fill_strategy', 'mean', 'constant', 'running_mean', 'forward_fill', 'seasonal', \"Check that transform doesn't fill NaNs at the beginning.\", 'target', 'target', 'target', 'fill_strategy', 'mean', 'constant', 'running_mean', 'forward_fill', 'seasonal', 'Check that transform correctly works with NaNs at the end.', 'target', 'target', 'fill_strategy', 'mean', 'constant', 'running_mean', 'forward_fill', 'seasonal', 'target', 'constant', 'segment_1', 'segment_2', 'target', 'constant_value'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <24x10 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 24 stored elements in Compressed Sparse Row format>, 'ClassDef': <7x7 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Base class for model mixins.', \"Mixin for models that don't support prediction intervals and don't need context for prediction.\", 'Make predictions.\\n\\n        Parameters\\n        ----------\\n        ts:\\n            Dataset with features\\n\\n        Returns\\n        -------\\n        :\\n            Dataset with predictions\\n        ', 'Make predictions with using true values as autoregression context if possible (teacher forcing).\\n\\n        Parameters\\n        ----------\\n        ts:\\n            Dataset with features\\n\\n        Returns\\n        -------\\n        :\\n            Dataset with predictions\\n        ', \"Mixin for models that don't support prediction intervals and need context for prediction.\", 'Make predictions.\\n\\n        Parameters\\n        ----------\\n        ts:\\n            Dataset with features\\n        prediction_size:\\n            Number of last timestamps to leave after making prediction.\\n            Previous timestamps will be used as a context for models that require it.\\n\\n        Returns\\n        -------\\n        :\\n            Dataset with predictions\\n        ', 'Make predictions with using true values as autoregression context if possible (teacher forcing).\\n\\n        Parameters\\n        ----------\\n        ts:\\n            Dataset with features\\n        prediction_size:\\n            Number of last timestamps to leave after making prediction.\\n            Previous timestamps will be used as a context for models that require it.\\n\\n        Returns\\n        -------\\n        :\\n            Dataset with predictions\\n        ', \"Mixin for models that support prediction intervals and don't need context for prediction.\", 'Make predictions.\\n\\n        Parameters\\n        ----------\\n        ts:\\n            Dataset with features\\n        prediction_interval:\\n            If True returns prediction interval for forecast\\n        quantiles:\\n            Levels of prediction distribution. By default 2.5% and 97.5% are taken to form a 95% prediction interval\\n\\n        Returns\\n        -------\\n        :\\n            Dataset with predictions\\n        ', 'Make predictions with using true values as autoregression context if possible (teacher forcing).\\n\\n        Parameters\\n        ----------\\n        ts:\\n            Dataset with features\\n        prediction_interval:\\n            If True returns prediction interval for forecast\\n        quantiles:\\n            Levels of prediction distribution. By default 2.5% and 97.5% are taken to form a 95% prediction interval\\n\\n        Returns\\n        -------\\n        :\\n            Dataset with predictions\\n        ', 'Mixin for models that support prediction intervals and need context for prediction.', 'Make predictions.\\n\\n        Parameters\\n        ----------\\n        ts:\\n            Dataset with features\\n        prediction_size:\\n            Number of last timestamps to leave after making prediction.\\n            Previous timestamps will be used as a context for models that require it.\\n        prediction_interval:\\n            If True returns prediction interval for forecast\\n        quantiles:\\n            Levels of prediction distribution. By default 2.5% and 97.5% are taken to form a 95% prediction interval\\n\\n        Returns\\n        -------\\n        :\\n            Dataset with predictions\\n        ', 'Make predictions with using true values as autoregression context if possible (teacher forcing).\\n\\n        Parameters\\n        ----------\\n        ts:\\n            Dataset with features\\n        prediction_size:\\n            Number of last timestamps to leave after making prediction.\\n            Previous timestamps will be used as a context for models that require it.\\n        prediction_interval:\\n            If True returns prediction interval for forecast\\n        quantiles:\\n            Levels of prediction distribution. By default 2.5% and 97.5% are taken to form a 95% prediction interval\\n\\n        Returns\\n        -------\\n        :\\n            Dataset with predictions\\n        ', 'Mixin for holding methods for per-segment prediction.', '\\n        Init PerSegmentModelMixin.\\n\\n        Parameters\\n        ----------\\n        base_model:\\n            Internal model which will be used to forecast segments, expected to have fit/predict interface\\n        ', 'Fit model.\\n\\n        Parameters\\n        ----------\\n        ts:\\n            Dataset with features\\n\\n        Returns\\n        -------\\n        :\\n            Model after fit\\n        ', 'segment', 'PerSegmentModelMixin', 'Get internal etna base models that are used inside etna class.\\n\\n        Returns\\n        -------\\n        :\\n           dictionary where key is segment and value is internal model\\n        ', 'Can not get the dict with base models, the model is not fitted!', 'Get internal models that are used inside etna class.\\n\\n        Internal model is a model that is used inside etna to forecast segments,\\n        e.g. :py:class:`catboost.CatBoostRegressor` or :py:class:`sklearn.linear_model.Ridge`.\\n\\n        Returns\\n        -------\\n        :\\n           dictionary where key is segment and value is internal model\\n        ', 'get_model', 'get_model method is not implemented for ', 'Make predictions for one segment.', 'timestamp', 'target', 'segment', 'prediction_size', 'timestamp', 'timestamp', 'Make predictions.\\n\\n        Parameters\\n        ----------\\n        ts:\\n            Dataframe with features\\n        prediction_method:\\n            Method for making predictions\\n\\n        Returns\\n        -------\\n        :\\n            Dataset with predictions\\n        ', 'timestamp', 'segment', 'timestamp', 'segment', 'prediction_size', 'forecast', \"Mixin for holding methods for multi-segment prediction.\\n\\n    It currently isn't working with prediction intervals and context.\\n    \", '\\n        Init MultiSegmentModel.\\n\\n        Parameters\\n        ----------\\n        base_model:\\n            Internal model which will be used to forecast segments, expected to have fit/predict interface\\n        ', 'Fit model.\\n\\n        Parameters\\n        ----------\\n        ts:\\n            Dataset with features\\n\\n        Returns\\n        -------\\n        :\\n            Model after fit\\n        ', 'segment', 'MultiSegmentModelMixin', 'Make predictions.\\n\\n        Parameters\\n        ----------\\n        ts:\\n            Dataset with features\\n        prediction_method:\\n            Method for making predictions\\n\\n        Returns\\n        -------\\n        :\\n            Dataset with predictions\\n        ', 'segment', 'target', 'forecast', 'Get internal model that is used inside etna class.\\n\\n        Internal model is a model that is used inside etna to forecast segments,\\n        e.g. :py:class:`catboost.CatBoostRegressor` or :py:class:`sklearn.linear_model.Ridge`.\\n\\n        Returns\\n        -------\\n        :\\n           Internal model\\n        ', 'get_model', 'get_model method is not implemented for '], 'from': [], 'import': []}\n",
      "{'FunctionDef': <35x32 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 35 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['TSDataset', 'Get start and end parameters according to given TSDataset.', \"Parameter 'end' must be greater than 'start'!\", 'TSDataset', 'Get quantiles that are present inside the TSDataset.', 'feature', 'target_0.', 'target_', 'TSDataset', 'Select quantiles from the forecast results.\\n\\n    Selected quantiles exist in each forecast.\\n    ', 'Quantiles ', ' do not exist in each forecast dataset. They will be dropped.', 'TSDataset', 'TSDataset', 'TSDataset', 'Prepare dictionary with forecasts results.', '1', 'Unknown type of `forecast_ts`', 'TSDataset', 'TSDataset', 'TSDataset', 'TSDataset', 'TSDataset', 'TSDataset', \"\\n    Plot of prediction for forecast pipeline.\\n\\n    Parameters\\n    ----------\\n    forecast_ts:\\n        there are several options:\\n\\n        #. Forecasted TSDataset with timeseries data, single-forecast mode\\n\\n        #. List of forecasted TSDatasets, multi-forecast mode\\n\\n        #. Dictionary with forecasted TSDatasets, multi-forecast mode\\n\\n    test_ts:\\n        TSDataset with timeseries data\\n    train_ts:\\n        TSDataset with timeseries data\\n    segments:\\n        segments to plot; if not given plot all the segments from ``forecast_df``\\n    n_train_samples:\\n        length of history of train to plot\\n    columns_num:\\n        number of graphics columns\\n    figsize:\\n        size of the figure per subplot with one segment in inches\\n    prediction_intervals:\\n        if True prediction intervals will be drawn\\n    quantiles:\\n        List of quantiles to draw, if isn't set then quantiles from a given dataset will be used.\\n        In multi-forecast mode, only quantiles present in each forecast will be used.\\n\\n    Raises\\n    ------\\n    ValueError:\\n        if the format of ``forecast_ts`` is unknown\\n    \", 'timestamp', 'timestamp', 'timestamp', 'target', 'segment', 'timestamp', 'target', 'segment', 'timestamp', 'target', 'segment', 'train', 'purple', 'test', 'target_', ': ', '', 'timestamp', 'forecast', '-', '-', '--', 'x', 'upper left', \"Validate if segments aren't intersecting.\", 'fold_start', 'fold_end', 'fold_start', 'fold_start', 'fold_end', 'Folds are intersecting', 'TSDataset', 'all', 'Plot targets and forecast for backtest pipeline.\\n\\n    This function doesn\\'t support intersecting folds.\\n\\n    Parameters\\n    ----------\\n    forecast_df:\\n        forecasted dataframe with timeseries data\\n    ts:\\n        dataframe of timeseries that was used for backtest\\n    segments:\\n        segments to plot\\n    columns_num:\\n        number of subplots columns\\n    history_len:\\n        length of pre-backtest history to plot, if value is \"all\" then plot all the history\\n    figsize:\\n        size of the figure per subplot with one segment in inches\\n\\n    Raises\\n    ------\\n    ValueError:\\n        if ``history_len`` is negative\\n    ValueError:\\n        if folds are intersecting\\n    ', 'all', \"Parameter history_len should be non-negative or 'all'\", 'fold_number', 'axes.prop_cycle', 'color', 'history', 'test', 'forecast', 'all', 'history', 'test', 'forecast', 'test', 'forecast', 'skyblue', 'o', 'x', 'TSDataset', 'all', 'Plot targets and forecast for backtest pipeline using plotly.\\n\\n    Parameters\\n    ----------\\n    forecast_df:\\n        forecasted dataframe with timeseries data\\n    ts:\\n        dataframe of timeseries that was used for backtest\\n    segments:\\n        segments to plot\\n    history_len:\\n        length of pre-backtest history to plot, if value is \"all\" then plot all the history\\n    figsize:\\n        size of the figure in pixels\\n\\n    Returns\\n    -------\\n    go.Figure:\\n        result of plotting\\n\\n    Raises\\n    ------\\n    ValueError:\\n        if ``history_len`` is negative\\n    ValueError:\\n        if folds are intersecting\\n    ', 'all', \"Parameter history_len should be non-negative or 'all'\", 'fold_number', 'all', 'lines', 'dash', 'Test: ', 'lines', 'solid', 'Forecast: ', 'lines', 'dot', 'Test: ', 'markers', 'Forecast: ', 'markers', 'blue', 'Backtest for all segments', 'timestamp', 'target', 'trace', 'Segments', 'buttons', 'left', 'left', 'top', 'restyle', 'visible', 'all', 'show all', 'restyle', 'visible', 'legendonly', 'hide all', 'Show segments:', 'paper', 'paper', 'left', 'TSDataset', 'target', 'Plot a time series with indicated anomalies.\\n\\n    Parameters\\n    ----------\\n    ts:\\n        TSDataset of timeseries that was used for detect anomalies\\n    anomaly_dict:\\n        dictionary derived from anomaly detection function,\\n        e.g. :py:func:`~etna.analysis.outliers.density_outliers.get_anomalies_density`\\n    in_column:\\n        column to plot\\n    segments:\\n        segments to plot\\n    columns_num:\\n        number of subplots columns\\n    figsize:\\n        size of the figure per subplot with one segment in inches\\n    start:\\n        start timestamp for plot\\n    end:\\n        end timestamp for plot\\n    ', 'r', 'x', 'TSDataset', 'pearson', 'Compute pairwise correlation of timeseries for selected segments.\\n\\n    Parameters\\n    ----------\\n    ts:\\n        TSDataset with timeseries data\\n    columns:\\n        Columns to use, if None use all columns\\n    segments:\\n        Segments to use\\n    method:\\n        Method of correlation:\\n\\n        * pearson: standard correlation coefficient\\n\\n        * kendall: Kendall Tau correlation coefficient\\n\\n        * spearman: Spearman rank correlation\\n\\n    Returns\\n    -------\\n    np.ndarray\\n        Correlation matrix\\n    ', 'pearson', 'kendall', 'spearman', \"'\", \"' is not a valid method of correlation.\", 'feature', 'TSDataset', 'pearson', 'macro', \"Plot pairwise correlation heatmap for selected segments.\\n\\n    Parameters\\n    ----------\\n    ts:\\n        TSDataset with timeseries data\\n    columns:\\n        Columns to use, if None use all columns\\n    segments:\\n        Segments to use\\n    method:\\n        Method of correlation:\\n\\n        * pearson: standard correlation coefficient\\n\\n        * kendall: Kendall Tau correlation coefficient\\n\\n        * spearman: Spearman rank correlation\\n\\n    mode: 'macro' or 'per-segment'\\n        Aggregation mode\\n    columns_num:\\n        Number of subplots columns\\n    figsize:\\n        size of the figure in inches\\n    \", 'feature', 'vmin', 'vmin', 'vmax', 'vmax', 'macro', 'per-segment', \"'\", \"' is not a valid method of mode.\", 'macro', '.1g', 'right', 'anchor', 'right', 'anchor', 'Correlation Heatmap', 'per-segment', '.1g', 'right', 'anchor', 'right', 'anchor', 'Correlation Heatmap', ' ', 'TSDataset', 'target', 'Plot a time series with indicated anomalies.\\n\\n    Anomalies are obtained using the specified method. The method parameters values\\n    can be changed using the corresponding sliders.\\n\\n    Parameters\\n    ----------\\n    ts:\\n        TSDataset with timeseries data\\n    segment:\\n        Segment to plot\\n    method:\\n        Method for outliers detection, e.g. :py:func:`~etna.analysis.outliers.density_outliers.get_anomalies_density`\\n    params_bounds:\\n        Parameters ranges of the outliers detection method. Bounds for the parameter are (min,max,step)\\n    in_column:\\n        column to plot\\n    figsize:\\n        size of the figure in inches\\n    start:\\n        start timestamp for plot\\n    end:\\n        end timestamp for plot\\n\\n    Notes\\n    -----\\n    Jupyter notebook might display the results incorrectly,\\n    in this case try to use ``!jupyter nbextension enable --py widgetsnbextension``.\\n\\n    Examples\\n    --------\\n    >>> from etna.datasets import TSDataset\\n    >>> from etna.datasets import generate_ar_df\\n    >>> from etna.analysis import plot_anomalies_interactive, get_anomalies_density\\n    >>> classic_df = generate_ar_df(periods=1000, start_time=\"2021-08-01\", n_segments=2)\\n    >>> df = TSDataset.to_dataset(classic_df)\\n    >>> ts = TSDataset(df, \"D\")\\n    >>> params_bounds = {\"window_size\": (5, 20, 1), \"distance_coef\": (0.1, 3, 0.25)}\\n    >>> method = get_anomalies_density\\n    >>> plot_anomalies_interactive(ts=ts, segment=\"segment_1\", method=method, params_bounds=params_bounds, figsize=(20, 10)) # doctest: +SKIP\\n    ', 'description_width', 'initial', '_', 'r', 'TSDataset', 'Plot clusters [with centroids].\\n\\n    Parameters\\n    ----------\\n    ts:\\n        TSDataset with timeseries\\n    segment2cluster:\\n        mapping from segment to cluster in format {segment: cluster}\\n    centroids_df:\\n        dataframe with centroids\\n    columns_num:\\n        number of columns in subplots\\n    figsize:\\n        size of the figure per subplot with one segment in inches\\n    ', 'axes.prop_cycle', 'color', 'target', 'cluster=', '\\n', ' segments in cluster', 'target', 'red', 'centroid', 'TSDataset', 'Plot segments with their trend change points.\\n\\n    Parameters\\n    ----------\\n    ts:\\n        TSDataset with timeseries\\n    change_points:\\n        dictionary with trend change points for each segment,\\n        can be obtained from :py:func:`~etna.analysis.change_points_trend.search.find_change_points`\\n    segments:\\n        segments to use\\n    columns_num:\\n        number of subplots columns\\n    figsize:\\n        size of the figure per subplot with one segment in inches\\n    start:\\n        start timestamp for plot\\n    end:\\n        end timestamp for plot\\n    ', 'target', 'dashed', 'grey', 'x', 'TSDataset', \"Get residuals for further analysis.\\n\\n    Parameters\\n    ----------\\n    forecast_df:\\n        forecasted dataframe with timeseries data\\n    ts:\\n        dataset of timeseries that has answers to forecast\\n\\n    Returns\\n    -------\\n    new_ts: TSDataset\\n        TSDataset with residuals in forecasts\\n\\n    Raises\\n    ------\\n    KeyError:\\n        if segments of ``forecast_df`` and ``ts`` aren't the same\\n\\n    Notes\\n    -----\\n    Transforms are taken as is from ``ts``.\\n    \", 'segment', 'Segments of `ts` and `forecast_df` should be the same', 'target', 'target', 'TSDataset', 'TSDataset', 'timestamp', 'timestamp', 'Plot residuals for predictions from backtest against some feature.\\n\\n    Parameters\\n    ----------\\n    forecast_df:\\n        forecasted dataframe with timeseries data\\n    ts:\\n        dataframe of timeseries that was used for backtest\\n    feature:\\n        feature name to draw against residuals, if \"timestamp\" plot residuals against the timestamp\\n    transforms:\\n        sequence of transforms to get feature column\\n    segments:\\n        segments to use\\n    columns_num:\\n        number of columns in subplots\\n    figsize:\\n        size of the figure per subplot with one segment in inches\\n\\n    Raises\\n    ------\\n    ValueError:\\n        if feature isn\\'t present in the dataset after applying transformations\\n\\n    Notes\\n    -----\\n    Parameter ``transforms`` is necessary because some pipelines doesn\\'t save features in their forecasts,\\n    e.g. :py:mod:`etna.ensembles` pipelines.\\n    ', 'timestamp', 'feature', \"Given feature isn't present in the dataset after applying transformations\", 'target', 'timestamp', 'fold_number', 'fold_number', 'timestamp', 'timestamp', 'fold_number', 'skyblue', 'b', 'x', 'ChangePointsTrendTransform', 'LinearTrendTransform', 'TheilSenTrendTransform', 'STLTransform', 'If only unique transform classes are used then show their short names (without parameters). Otherwise show their full repr as label.', '(', '', ', k=', 'g', 'TSDataset', 'TrendTransformType', 'TrendTransformType', 'Plot series and trend from trend transform for this series.\\n\\n    If only unique transform classes are used then show their short names (without parameters).\\n    Otherwise show their full repr as label\\n\\n    Parameters\\n    ----------\\n    ts:\\n        dataframe of timeseries that was used for trend plot\\n    trend_transform:\\n        trend transform or list of trend transforms to apply\\n    segments:\\n        segments to use\\n    columns_num:\\n        number of columns in subplots\\n    figsize:\\n        size of the figure per subplot with one segment in inches\\n    ', 'target', 'Initial series', 'target', 'target', 'x', '\\n    Convert p-values into fictitious variables, with function f(x) = 1 - x.\\n\\n    Also converts alpha into fictitious variable.\\n\\n    Parameters\\n    ----------\\n    pvalues:\\n        dataFrame with pvalues\\n    alpha:\\n        significance level, default alpha = 0.05\\n\\n    Returns\\n    -------\\n    pvalues:\\n        array with fictitious relevances\\n    new_alpha:\\n        adjusted significance level\\n    ', 'TSDataset', 'per-segment', '\\n    Plot relevance of the features.\\n\\n    The most important features are at the top, the least important are at the bottom.\\n\\n    For :py:class:`~etna.analysis.feature_relevance.relevance.StatisticsRelevanceTable` also plot vertical line: transformed significance level.\\n\\n    * Values that lie to the right of this line have p-value < alpha.\\n\\n    * And the values that lie to the left have p-value > alpha.\\n\\n    Parameters\\n    ----------\\n    ts:\\n        TSDataset with timeseries data\\n    relevance_table:\\n        method to evaluate the feature relevance;\\n\\n        * if :py:class:`~etna.analysis.feature_relevance.relevance.StatisticsRelevanceTable` table is used then relevances are normalized p-values\\n\\n        * if :py:class:`~etna.analysis.feature_relevance.relevance.ModelRelevanceTable` table is used then relevances are importances from some model\\n\\n    normalized:\\n        whether obtained relevances should be normalized to sum up to 1\\n    relevance_aggregation_mode:\\n        aggregation strategy for obtained feature relevance table;\\n        all the strategies can be examined\\n        at :py:class:`~etna.analysis.feature_selection.mrmr_selection.AggregationMode`\\n    relevance_params:\\n        additional keyword arguments for the ``__call__`` method of\\n        :py:class:`~etna.analysis.feature_relevance.relevance.RelevanceTable`\\n    top_k:\\n        number of best features to plot, if None plot all the features\\n    alpha:\\n        significance level, default alpha = 0.05, only for :py:class:`~etna.analysis.feature_relevance.relevance.StatisticsRelevanceTable`\\n    segments:\\n        segments to use\\n    columns_num:\\n        if ``relevance_aggregation_mode=\"per-segment\"`` number of columns in subplots, otherwise the value is ignored\\n    figsize:\\n        size of the figure per subplot with one segment in inches\\n    ', 'feature', 'target', 'target', 'per-segment', 'Relevances on segment: ', ' of features: ', \" can't be calculated.\", 'h', 'Feature relevance: ', 'Relevances of features: ', \" can't be calculated.\", 'h', 'Feature relevance', 'TSDataset', 'TimeSeriesImputerTransform', 'Plot the result of imputation by a given imputer.\\n\\n    Parameters\\n    ----------\\n    ts:\\n        TSDataset with timeseries data\\n    imputer:\\n        transform to make imputation of NaNs\\n    segments:\\n        segments to use\\n    columns_num:\\n        number of columns in subplots\\n    figsize:\\n        size of the figure per subplot with one segment in inches\\n    start:\\n        start timestamp for plot\\n    end:\\n        end timestamp for plot\\n    ', 'red', 'x', 'TSDataset', 'per-segment', 'Plot the periodogram using :py:func:`scipy.signal.periodogram`.\\n\\n    It is useful to determine the optimal ``order`` parameter\\n    for :py:class:`~etna.transforms.timestamp.fourier.FourierTransform`.\\n\\n    Parameters\\n    ----------\\n    ts:\\n        TSDataset with timeseries data\\n    period:\\n        the period of the seasonality to capture in frequency units of time series, it should be >= 2;\\n        it is translated to the ``fs`` parameter of :py:func:`scipy.signal.periodogram`\\n    amplitude_aggregation_mode:\\n        aggregation strategy for obtained per segment periodograms;\\n        all the strategies can be examined\\n        at :py:class:`~etna.analysis.feature_selection.mrmr_selection.AggregationMode`\\n    periodogram_params:\\n        additional keyword arguments for periodogram, :py:func:`scipy.signal.periodogram` is used\\n    segments:\\n        segments to use\\n    xticks:\\n        list of tick locations of the x-axis, useful to highlight specific reference periodicities\\n    columns_num:\\n        if ``amplitude_aggregation_mode=\"per-segment\"`` number of columns in subplots, otherwise the value is ignored\\n    figsize:\\n        size of the figure per subplot with one segment in inches\\n\\n    Raises\\n    ------\\n    ValueError:\\n        if period < 2\\n    ValueError:\\n        if periodogram can\\'t be calculated on segment because of the NaNs inside it\\n\\n    Notes\\n    -----\\n    In non per-segment mode all segments are cut to be the same length, the last values are taken.\\n    ', 'Period should be at least 2', 'per-segment', 'target', \"Periodogram can't be calculated on segment with NaNs inside: \", 'log', 'Frequency', 'Power spectral density', 'Periodogram: ', 'target', \"Periodogram can't be calculated on segment with NaNs inside: \", 'target', 'log', 'Frequency', 'Power spectral density', 'Periodogram', 'Parameter holidays is expected as str or pd.DataFrame', 'Parameter `as_is` should be used with `holiday`: pd.DataFrame, not string.', '', 'Got empty `holiday` pd.DataFrame.', 'holiday', 'holiday', 'holiday', 'ds', 'upper_window', 'holiday', 'upper_window', 'Upper windows should be non-negative.', 'lower_window', 'holiday', 'lower_window', 'Lower windows should be non-positive.', 'TSDataset', \"Plot holidays for segments.\\n\\n    Sequence of timestamps with one holiday is drawn as a colored region.\\n    Individual holiday is drawn like a colored point.\\n\\n    It is not possible to distinguish points plotted at one timestamp, but this case is considered rare.\\n    This the problem isn't relevant for region drawing because they are partially transparent.\\n\\n    Parameters\\n    ----------\\n    ts:\\n        TSDataset with timeseries data\\n    holidays:\\n        there are several options:\\n\\n        * if str, then this is code of the country in `holidays <https://pypi.org/project/holidays/>`_ library;\\n\\n        * if DataFrame, then dataframe is expected to be in prophet`s holiday format;\\n\\n    segments:\\n        segments to use\\n    columns_num:\\n        number of columns in subplots\\n    figsize:\\n        size of the figure per subplot with one segment in inches\\n    as_is:\\n        * | Use this option if DataFrame is represented as a dataframe with a timestamp index and holiday names columns.\\n          | In a holiday column values 0 represent absence of holiday in that timestamp, 1 represent the presence.\\n    start:\\n        start timestamp for plot\\n    end:\\n        end timestamp for plot\\n\\n    Raises\\n    ------\\n    ValueError:\\n        * Holiday nor pd.DataFrame or String.\\n        * Holiday is an empty pd.DataFrame.\\n        * `as_is=True` while holiday is String.\\n        * If upper_window is negative.\\n        * If lower_window is positive.\\n\\n    \", 'target', 'axes.prop_cycle', 'color', 'dashed', 'dashed', 'x', 'o', 'Enum for types of aggregation in a metric per-segment plot.', 'mean', 'median', ' is not a valid ', '. Only ', ', ', ' aggregations are allowed', 'Get aggregation function.', 'mean', 'median', \"Plot barplot with per-segment metrics.\\n\\n    Parameters\\n    ----------\\n    metrics_df:\\n        dataframe with metrics calculated on the backtest\\n    metric_name:\\n        name of the metric to visualize\\n    ascending:\\n\\n        * If True, small values at the top;\\n\\n        * If False, big values at the top.\\n\\n    per_fold_aggregation_mode:\\n        how to aggregate metrics over the folds if they aren't already aggregated\\n        (see :py:class:`~etna.analysis.plotters.PerFoldAggregation`)\\n    top_k:\\n        number segments to show after ordering according to ``ascending``\\n    barplot_params:\\n        dictionary with parameters for plotting, :py:func:`seaborn.barplot` is used\\n    figsize:\\n        size of the figure per subplot with one segment in inches\\n\\n    Raises\\n    ------\\n    ValueError:\\n        if ``metric_name`` isn't present in ``metrics_df``\\n    NotImplementedError:\\n        unknown ``per_fold_aggregation_mode`` is given\\n    \", \"Given metric_name isn't present in metrics_df\", 'fold_number', 'segment', 'segment', 'h', 'Metric per-segment plot', 'Segment', 'Enum for types of plot in :py:func:`~etna.analysis.plotters.metric_per_segment_distribution_plot`.\\n\\n    Attributes\\n    ----------\\n    hist:\\n        Histogram plot, :py:func:`seaborn.histplot` is used\\n    box:\\n        Boxplot, :py:func:`seaborn.boxplot` is used\\n    violin:\\n        Violin plot, :py:func:`seaborn.violinplot` is used\\n    ', 'hist', 'box', 'violin', ' is not a valid ', '. Only ', ', ', ' plots are allowed', 'Get aggregation function.', 'hist', 'box', 'violin', 'hist', 'box', 'violin', 'hist', \"Plot per-segment metrics distribution.\\n\\n    Parameters\\n    ----------\\n    metrics_df:\\n        dataframe with metrics calculated on the backtest\\n    metric_name:\\n        name of the metric to visualize\\n    per_fold_aggregation_mode:\\n\\n        * If None, separate distributions for each fold will be drawn\\n\\n        * If str, determines how to aggregate metrics over the folds if they aren't already aggregated\\n        (see :py:class:`~etna.analysis.plotters.PerFoldAggregation`)\\n\\n    plot_type:\\n        type of plot (see :py:class:`~etna.analysis.plotters.MetricPlotType`)\\n    seaborn_params:\\n        dictionary with parameters for plotting\\n    figsize:\\n        size of the figure per subplot with one segment in inches\\n\\n    Raises\\n    ------\\n    ValueError:\\n        if ``metric_name`` isn't present in ``metrics_df``\\n    NotImplementedError:\\n        unknown ``per_fold_aggregation_mode`` is given\\n    \", \"Given metric_name isn't present in metrics_df\", 'fold_number', 'fold_number', 'fold_number', 'Fold', 'fold_number', 'segment', 'Metric per-segment distribution plot', 'target', 'Plot a time series with indicated change points.\\n\\n    Change points are obtained using the specified method. The method parameters values\\n    can be changed using the corresponding sliders.\\n\\n    Parameters\\n    ----------\\n    ts:\\n        TSDataset with timeseries data\\n    change_point_model:\\n        model to get trend change points\\n    model:\\n        binseg segment model, [\"l1\", \"l2\", \"rbf\",...]. Not used if \\'custom_cost\\' is not None\\n    params_bounds:\\n        Parameters ranges of the change points detection. Bounds for the parameter are (min,max,step)\\n    model_params:\\n        List of iterable parameters for initialize the model\\n    predict_params:\\n        List of iterable parameters for predict method\\n    in_column:\\n        column to plot\\n    segments:\\n        segments to use\\n    columns_num:\\n        number of subplots columns\\n    figsize:\\n        size of the figure in inches\\n    start:\\n        start timestamp for plot\\n    end:\\n        end timestamp for plot\\n\\n    Notes\\n    -----\\n    Jupyter notebook might display the results incorrectly,\\n    in this case try to use ``!jupyter nbextension enable --py widgetsnbextension``.\\n\\n    Examples\\n    --------\\n    >>> from etna.datasets import TSDataset\\n    >>> from etna.datasets import generate_ar_df\\n    >>> from etna.analysis import plot_change_points_interactive\\n    >>> from ruptures.detection import Binseg\\n    >>> classic_df = generate_ar_df(periods=1000, start_time=\"2021-08-01\", n_segments=2)\\n    >>> df = TSDataset.to_dataset(classic_df)\\n    >>> ts = TSDataset(df, \"D\")\\n    >>> params_bounds = {\"n_bkps\": [0, 5, 1], \"min_size\":[1,10,3]}\\n    >>> plot_change_points_interactive(ts=ts, change_point_model=Binseg, model=\"l2\", params_bounds=params_bounds, model_params=[\"min_size\"], predict_params=[\"n_bkps\"], figsize=(20, 10)) # doctest: +SKIP\\n    ', 'description_width', 'initial', '_', 'dashed', 'grey', 'facecolor', 'edgecolor', 'boxstyle', 'grey', 'red', 'round', 'Parameters\\nError', 'center', 'white', 'x'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['2020-01-01', '2020-01-01', 'target', 'exog', '2019-12-01', 'target', 'regressor_1', '2019-12-01', 'target', 'regressor_2', 'timestamp', 'segment', 'right', 'timestamp', 'segment', 'D', 'regressor_1', 'regressor_2'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Original Stanford Online Products dataset. Train and test are splitted by sample.\\n\\n    See: https://cvgl.stanford.edu/projects/lifted_struct/\\n\\n    Args:\\n        root: Dataset root.\\n        train: Whether to use train or test part of the dataset.\\n\\n    ', 'Ebay_train.txt', 'Ebay_test.txt', 'image_id class_id super_class_id path', 'Whether dataset is classification or matching.', 'Whether dataset is for open-set or closed-set classification.', 'Get dataset labels array.\\n\\n        Labels are integers in the range [0, N-1].\\n\\n        ', 'Get element of the dataset.\\n\\n        Returns tuple (image, label).\\n\\n        '], 'from': [], 'import': []}\n",
      "{'FunctionDef': <28x28 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 28 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Parse logger specification.\\n\\n    Returns:\\n        Tuple of logger_type, project, experiment, group.\\n    ', 'tensorboard', ':', 'tensorboard', 'Bad tensorboard spec: {}.', 'wandb', 'Bad wandb spec: {}', 'Bad logger spec: {}.', 'Configurable runner class for training and evaluation.\\n\\n    Args:\\n        root: Training folder (checkpoints, logs, etc.).\\n        data_root: Dataset root folder.\\n        config: Runner config dictionary or None to use default.\\n        logger: Logger to use (\"tensorboard\" or \"wandb:<project-name>\").\\n        initial_checkpoint: Path to checkpoint to resume training.\\n        no_strict_init: Skip checkpoint mismatch errors.\\n        from_stage: Start training from specified stage index.\\n    ', 'train', 'test', 'best', 'wandb-bayes', 'Get runner parameters.\\n\\n        Args:\\n            dataset_params: Parameters of :class:`DatasetCollection`.\\n            model_params: Parameters of :class:`Model`.\\n            initializer_params: Parameters of :class:`Initializer`.\\n            criterion_params: Parameters of the loss function.\\n            trainer_params: Parameters of :class:`Trainer`.\\n            metrics_params: Parameters of :class:`Metrics`.\\n            stages: List of config patches for each stage. Train single stage by default.\\n            stage_resume: Type of model preloading between stages (one of \"best\", \"last\").\\n            resume_prefixes: Coma-separated list of parameter name prefixes for model preloading.\\n            fp16: Whether to use FP16 training or not.\\n            amp_head: Whether to use FP16 for classifier and criterion or not (when fp16=True).\\n            initial_grad_scale: Initial grad scale used for FP16 training.\\n            grad_scale_growth_interval: Number of batches without overflow before gradient scale growth.\\n            seed: Random seed.\\n            num_evaluation_seeds: Number of different seeds used for evaluation.\\n            num_hopt_trials: Number of runs used for hyperparameter tuning.\\n            hopt_backend: Type of hyperparameter search algorithm (\"wandb-bayes\", \"wandb-random\", \"optuna-tpe\").\\n            hopt_params: Config patch used during hyper-parameter tuning.\\n        ', 'dataset_params', 'model_params', 'initializer_params', 'criterion_params', 'trainer_params', 'metrics_params', 'stages', 'stage_resume', 'resume_prefixes', 'fp16', 'amp_head', 'initial_grad_scale', 'grad_scale_growth_interval', 'seed', 'num_evaluation_seeds', 'num_hopt_trials', 'hopt_backend', 'hopt_params', 'tensorboard', 'stages', 'stages', 'fp16', 'initial_grad_scale', 'num_hopt_trials', 'hopt_backend', \"Can't overwrite {} in a stage\", 'stages', '-', 'stages', 'Initialize config and base structures for the stage.', 'dataset_params', 'metrics_params', '-', 'stages', \"Can't start from stage {}. Total number of stages is {}.\", '_epoch_', 'model_hash', 'model', '_epoch_', 'stage', '-', 'seed', 'fp16', 'init_scale', 'growth_interval', 'initial_grad_scale', 'grad_scale_growth_interval', 'amp_head', 'model_params', 'Total model parameters:', 'initializer_params', 'train', 'stage_resume', 'stage_resume', 'best', 'last', 'Unexpected resume type: {}.', 'stage_resume', 'checkpoints', 'stage_resume', '.pth', \"Can't find checkpoint {}.\", 'Load', 'cpu', 'model_model_state_dict', 'resume_prefixes', 'resume_prefixes', ',', 'Empty resume prefix.', 'Unknown prefix {}.', 'Unexpected state dict keys: {}.', 'model', 'embedder', 'scorer', 'criterion_params', 'model', 'tensorboard', 'wandb', 'group', 'git_commit', 'Unknown logger: {}.', '_console', '_csv', 'main', 'verbose', 'model', 'embeddings', 'embeddings', 'labels', 'labels', 'logits', 'logits', 'final_weights', 'final_weights', 'target_embeddings', 'target_embeddings', 'final_bias', 'final_bias', 'final_variance', 'final_variance', 'criterion', 'amp_head', 'loss', 'train', 'checkpoints', 'loss', 'train', '_', '', 'train', 'labels', 'embeddings', 'target_embeddings', 'logits', 'confidences', 'quality', 'confidences_key', 'confidences', 'train', 'labels', 'scores', '_', 'train', '', '_', 'labels', 'quality', 'images', 'images1', 'images2', 'trainer_params', 'train', 'model', 'images', 'labels', 'embeddings', 'distributions', 'model', 'logits', 'logits', 'final_weights', 'target_embeddings', 'labels', 'final_bias', 'final_variance', 'confidences', 'embeddings', 'infnans', 'embeddings', 'embeddings1', 'embedder', 'images1', 'embeddings2', 'embedder', 'images2', 'scores', 'scorer', 'embeddings1', 'embeddings2', 'model', 'embeddings1', 'embeddings2', 'confidences'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['minimize', 'maximize', 'Class for encapsulate work with Optuna.', \"Init wrapper for Optuna.\\n\\n        Parameters\\n        ----------\\n        direction:\\n            optuna direction\\n        study_name:\\n            name of study\\n        sampler:\\n            optuna sampler to use\\n        storage:\\n            storage to use\\n        pruner:\\n            optuna pruner\\n        directions:\\n            directions to optimize in case of multi-objective optimization\\n        load_if_exists:\\n            load study from storage if it exists or raise exception if it doesn't\\n        \", 'Call optuna ``optimize`` for chosen Runner.\\n\\n        Parameters\\n        ----------\\n        objective:\\n            objective function to optimize in optuna style\\n        n_trials:\\n            number of trials to run. N.B. in case of parallel runner, this is number of trials per worker\\n        timeout:\\n            timeout for optimization. N.B. in case of parallel runner, this is timeout per worker\\n        kwargs:\\n            additional arguments to pass to :py:meth:`optuna.study.Study.optimize`\\n        ', 'Get optuna study.'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['path to yaml config with desired pipeline', 'path to csv with data to forecast', 'frequency of timestamp in files in pandas format', 'where to save forecast', 'path to csv with exog data', 'path to yaml config with forecast params', 'by default we return only forecast without features', 'list of all known_future columns (regressor columns). If not specified then all exog_columns considered known_future.', 'Command to make forecast with etna without coding.\\n\\n    Expected format of csv with target timeseries:\\n\\n    \\x08\\n    =============  ===========  ==========\\n      timestamp      segment      target\\n    =============  ===========  ==========\\n    2020-01-01     segment_1         1\\n    2020-01-02     segment_1         2\\n    2020-01-03     segment_1         3\\n    2020-01-04     segment_1         4\\n    ...\\n    2020-01-10     segment_2        10\\n    2020-01-11     segment_2        20\\n    =============  ===========  ==========\\n\\n    Expected format of csv with exogenous timeseries:\\n\\n    \\x08\\n    =============  ===========  ===============  ===============\\n      timestamp      segment      regressor_1      regressor_2\\n    =============  ===========  ===============  ===============\\n    2020-01-01     segment_1          11               12\\n    2020-01-02     segment_1          22               13\\n    2020-01-03     segment_1          31               14\\n    2020-01-04     segment_1          42               15\\n    ...\\n    2020-02-10     segment_2         101               61\\n    2020-02-11     segment_2         205               54\\n    =============  ===========  ===============  ===============\\n    ', 'timestamp', 'all', 'timestamp', 'all', 'target_0.', 'timestamp', 'segment', 'target', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <18x17 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 17 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['int', 'timestamp', 'segment', 'regressor_0', 'target', '2021-01-01', '2021-01-03', 'segment_0', 'segment_1', 'regressor_0', 'regressor_0', 'timestamp', 'segment', 'regressor_0', 'target', '2021-01-01', '2021-01-03', 'segment_0', 'segment_1', 'regressor_0', 'regressor_0', 'int', '2021-01-01', 'timestamp', 'regressor_0', 'regressor_1', 'regressor_2', '2021-01-01', '2021-01-12', 'regressor_0', 'regressor_1', 'regressor_2', 'segment', 'segment_0', 'D', 'segment_0', 'test_0', 'regressor_0', 'test_1', 'regressor_0', 'test_0', 'test_0', 'category', 'test_1', 'test_1', 'category', 'segment_0', 'test_0', 'regressor_1', 'test_1', 'regressor_1', 'test_0', 'test_0', 'category', 'test_1', 'test_1', 'category', 'segment_0', 'test_0', 'regressor_2', 'test_0', 'test_0', 'category', 'int', '2021-01-01', 'timestamp', 'regressor_0', 'regressor_1', 'regressor_2', '2021-01-01', '2021-01-12', 'regressor_0', 'regressor_1', 'regressor_2', 'segment', 'segment_0', 'D', 'segment_0', 'test', 'regressor_0', 'test', 'test', 'category', 'segment_0', 'test', 'regressor_1', 'test', 'test', 'category', 'segment_0', 'test', 'regressor_2', 'test', 'test', 'category', '2021-01-01', '2021-01-01', 'timestamp', 'segment', 'timestamp', 'regressor_1', '2', 'segment', 'segment_0', 'D', 'Test that LabelEncoderTransform works correct in a simple cases.', 'regressor_', 'test', 'segment_0', 'segment_0', 'dtype', 'float', 'int', 'str', 'category', 'Test that OneHotEncoderTransform works correct in a simple case.', 'regressor_', 'test', 'segment_0', 'segment_0', 'dtype', 'float', 'int', 'str', 'category', 'Test LabelEncoderTransform with wrong strategy.', 'The strategy', 'target', 'new_vlue', 'Test LabelEncoderTransform correct works with unknown values.', 'segment', 'regressor_0', 'encoded_regressor_0', 'encoded_regressor_0', 'strategy, expected_values', 'new_value', 'segment_0', 'segment_1', 'none', 'segment_0', 'segment_1', 'mean', 'segment_0', 'segment_1', 'dtype', 'float', 'int', 'str', 'category', 'Test OneHotEncoderTransform correct works with unknown values.', 'segment', 'targets_0', 'targets_1', 'targets_2', 'regressor_0', 'targets', 'expected_values', 'segment_0', 'segment_1', 'dtype', 'float', 'int', 'str', 'category', 'Test OneHotEncoderTransform gives the correct columns.', 'regressor_0', 'targets', 'segment_0', 'segment_1', 'target', 'targets_0', 'targets_1', 'targets_2', 'regressor_0', 'Test OneHotEncoderTransform gives the correct columns with no out_column.', 'segment_0', '_0', '_1', 'segment_0', 'in_column', '2', 'regressor_1', 'Test LabelEncoderTransform gives the correct columns with no out_column.', 'segment_0', 'segment_0', 'in_column', '2', 'regressor_1', '2021-01-01', '2021-01-01', 'timestamp', 'segment', 'timestamp', 'regressor_', 'segment', 'segment_0', 'segment_0', 'target', 'segment_0', 'regressor_0', 'D', 'all', 'Test for correct work in the full forecasting pipeline.', 'regressor_0', 'regressor_0', 'segment_0'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <13x13 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 13 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['label', 'label', 'range', 'Unknown features type: {}', 'range', 'center_crop_range', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Check auto_matmul result equal to torch.matmul.', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <9x9 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 9 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Optuna based sampler for greedy search over different configurations.', 'Init Config sampler.\\n\\n        Parameters\\n        ----------\\n        configs:\\n            pool of configs to sample from\\n        random_generator:\\n            numpy generator to get reproducible samples\\n        retries:\\n            number of retries to get new sample from storage. It could be useful if storage is not reliable.\\n        ', 'Sample independent. Not used.', 'Infer relative search space. Not used.', 'Sample configuration to test.\\n\\n        Parameters\\n        ----------\\n        study:\\n            current optuna study\\n        trial:\\n            optuna trial to use\\n\\n        Return\\n        ------\\n        :\\n            sampled configuration to run objective on\\n        ', 'hash', 'pipeline', 'Stop study if all configs have been tested.\\n\\n        Parameters\\n        ----------\\n        study:\\n            current optuna study\\n        ', 'hash', 'Get unfinished config hashes.\\n\\n        Parameters\\n        ----------\\n        study:\\n            current optuna study\\n\\n        Returns\\n        -------\\n        :\\n            hashes to run\\n        ', 'hash', 'hash', 'Get config by hash.\\n\\n        Parameters\\n        ----------\\n        hash:\\n            hash to get config for\\n        '], 'from': [], 'import': []}\n",
      "{'FunctionDef': <10x9 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 10 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Compute risk-coverage curve.\\n\\n    Returns:\\n      risk: Mean loss for each confidence threshold.\\n      coverage: Coverage for each confidence threshold.\\n      thresholds: Decreasing thresholds.\\n    ', 'Size mismatch.', 'Empty data.', 'Losses must be non-negative.', 'Compute verification metrics.\\n\\n    Available metrics:\\n      - pr: Fraction of positives in the dataset.\\n      - max_accuracy: Verification accuracy with best threshold.\\n      - auc: ROC AUC.\\n      - tpr: TPR for the requested FPR.\\n      - fpr: Actual FPR of the found threshold.\\n      - eer: Equal error rate.\\n    ', 'Get config.\\n\\n        Args:\\n            fpr: Required FPR for TPR computation.\\n            roc_curve_dump_dir: If not None, saves ROC curve to `roc_curve_dump_dir`.\\n        ', 'fpr', 'roc_curve_dump_dir', 'fpr', 'roc_curve_dump_dir', '', 'Resets all fields', 'Updates metric value with statistics for new data.\\n\\n        Args:\\n            scores: Tensor with scores.\\n            targets: Tensor with targets.\\n        ', 'Computes the AUC metric based on saved statistics.', '', '_', 'tprs', 'fprs', 'Computes the binary AUC metric based on saved statistics and returns key-value results.', 'pr', 'max_accuracy', 'auc', 'tpr', 'fpr', 'eer', 'confidence_auroc', 'confidence_aupr', 'confidence_aurcc', 'Expected boolean targets or {0, 1} targets.', 'Callback for verification metrics computation.\\n\\n    Args:\\n        input_key: Pairwise scores key.\\n        target_key: Labels key.\\n    ', 'scores', 'confidences', 'targets'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['https://github.com/tinkoff-ai/etna', 'prerelease', 'prepatch', 'preminor', 'patch', 'minor', 'gh auth status', 'Please, auth with command:\\n', 'gh auth login --web', 'poetry version --short', 'poetry version', ' ', '\\nYou should use \"', '\" command to update unstable releases', '', 'PRE-', 'poetry version ', 'poetry version --short', '\\nDo you really want to ', 'yellow', 'release ', '==', 'Ok...\\n', 'poetry version ', ':bomb: ', 'release ', 'git checkout -b release/', 'git commit -am', 'git push -u origin release/', 'gh pr create --title', '--body', 'Great!\\nPlease visit ', '/releases/edit/', ' to describe **release notes!**\\n\\nAlso you can find publishing task here ', '/actions/workflows/publish.yml', 'git rev-parse --abbrev-ref HEAD', '--prerelease', 'gh release create ', '--title', '--notes', 'In progress...', '--target', 'gh pr view --web', 'Done!', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['_OneSegmentChangePointsSegmentationTransform make label encoder to change points.', 'Init _OneSegmentChangePointsSegmentationTransform.\\n        Parameters\\n        ----------\\n        in_column:\\n            name of column to apply transform to\\n        out_column:\\n            result column name. If not given use ``self.__repr__()``\\n        change_point_model:\\n            model to get change points\\n        ', 'Fill values in resulting series.', 'Transform is not fitted! Fit the Transform before calling transform method.', 'category', 'Fit _OneSegmentChangePointsSegmentationTransform: find change points in ``df`` and build intervals.\\n\\n        Parameters\\n        ----------\\n        df:\\n            one segment dataframe indexed with timestamp\\n\\n        Returns\\n        -------\\n        :\\n            instance with trained change points\\n\\n        Raises\\n        ------\\n        ValueError\\n            If series contains NaNs in the middle\\n        ', '_OneSegmentChangePointsSegmentationTransform', 'Split df to intervals.\\n\\n        Parameters\\n        ----------\\n        df:\\n            one segment dataframe\\n\\n        Returns\\n        -------\\n        df:\\n            df with new column\\n        ', 'ChangePointsSegmentationTransform make label encoder to change points.\\n\\n    Warning\\n    -------\\n    This transform can suffer from look-ahead bias. For transforming data at some timestamp\\n    it uses information from the whole train part.\\n    ', 'Init ChangePointsSegmentationTransform.\\n\\n        Parameterss\\n        ----------\\n        in_column:\\n            name of column to fit change point model\\n        out_column:\\n            result column name. If not given use ``self.__repr__()``\\n        change_point_model:\\n            model to get change points\\n        '], 'from': [], 'import': []}\n",
      "{'FunctionDef': <70x21 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 70 stored elements in Compressed Sparse Row format>, 'ClassDef': <7x7 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Create new log priors tensor.\\n\\n    Args:\\n        num_classes: Numder of classes.\\n        priors: Initial value for priors.\\n\\n    Returns:\\n        Parameter if trainable is True and Tensor otherwise.\\n    ', 'Expected initial priors with shape ({},), got: {}.', 'Add margin if labels are provided.', 'Simple classification head based on linear layer.\\n\\n    Args:\\n        distribution: Distribution used in the model.\\n        num_classes: Number of output classes.\\n        priors (unused): Precomputed class priors. Priors can be learned on-line if not provided.\\n\\n    Inputs:\\n        - parameters: Distribution parameters with shape (..., K).\\n        - labels: Unused.\\n        - scorer: Unused.\\n\\n    Outputs:\\n        - logits: Class logits with shape (..., C).\\n\\n    ', 'exp', 'Get classifier config.\\n\\n        Args:\\n            sample: If True, sample from distribution. Use distribution mean otherwise.\\n            use_bias: Whether to use bias in linear layer or not.\\n            initial_scale: Scale parameters during initialization.\\n            normalize_weights: Normalize weights before applying.\\n            use_variance: Whether to add trainable embeddings variance or not.\\n            initial_variance: Initial value of the variance.\\n            variance_parametrization: Type of variance coding (\"exp\" or \"invlin\").\\n            freeze_variance: Don\\'t train variance parameter.\\n            variance_center: Parametrization center.\\n            variance_scale: Parametrization scale.\\n        ', 'sample', 'use_bias', 'initial_scale', 'normalize_weights', 'use_variance', 'initial_variance', 'variance_parametrization', 'freeze_variance', 'variance_center', 'variance_scale', 'use_bias', 'initial_scale', 'initial_scale', 'use_bias', 'initial_scale', 'use_variance', 'variance_parametrization', 'variance_center', 'variance_scale', 'initial_variance', 'freeze_variance', 'use_bias', 'use_variance', 'sample', 'normalize_weights', 'Compute useful statistics for logging.\\n\\n        Returns:\\n            Dictionary with floating-point statistics values.\\n        ', 'distribution={}, num_classes={}, config={}', 'ArcFace classification head with trainable target classes centers.\\n\\n    Args:\\n        distribution: Distribution used in the model.\\n        num_classes: Number of output classes.\\n        priors (unused): Precomputed class priors. Priors can be learned on-line if not provided.\\n\\n    Inputs:\\n        - parameters: Distribution parameters with shape (..., K).\\n        - labels: If provided, used for ArcFace logit correction. Compute cosine otherwise.\\n        - scorer: Unused.\\n\\n    Outputs:\\n        - logits: Class logits with shape (..., C).\\n\\n    ', 'Get classifier config.\\n\\n        Args:\\n            sample: If True, sample from distribution. Use distribution mean otherwise.\\n            scale: Output scale (number or \"trainable\").\\n            margin: ArcFace margin.\\n        ', 'sample', 'scale', 'margin', 'Spherical distrubution is expected.', 'scale', 'trainable', 'scale', 'margin', 'sample', 'Compute useful statistics for logging.\\n\\n        Returns:\\n            Dictionary with floating-point statistics values.\\n        ', 'scale', 'trainable', 'scale', 'distribution={}, num_classes={}, config={}', 'CosFace classification head with trainable target classes centers.\\n\\n    Args:\\n        distribution: Distribution used in the model.\\n        num_classes: Number of output classes.\\n        priors (unused): Precomputed class priors. Priors can be learned on-line if not provided.\\n\\n    Inputs:\\n        - parameters: Distribution parameters with shape (..., K).\\n        - labels: If provided, used for logit correction. Compute cosine otherwise.\\n        - scorer: Unused.\\n\\n    Outputs:\\n        - logits: Class logits with shape (..., C).\\n\\n    ', 'Get classifier config.\\n\\n        Args:\\n            scale: Output scale.\\n            margin: CosFace margin.\\n            symmetric: If true, add margin to negatives (useful for Proxy-Anchor loss).\\n        ', 'scale', 'margin', 'symmetric', 'Spherical distrubution is expected.', 'margin', 'scale', 'symmetric', 'margin', 'scale', 'Compute useful statistics for logging.\\n\\n        Returns:\\n            Dictionary with floating-point statistics values.\\n        ', 'distribution={}, num_classes={}, config={}', 'Contains target centroids and performs log likelihood estimation.\\n\\n    Layer can add prior correction in different forms. If \"pretrained\"\\n    is used, log priors from training set are added to logits. If\\n    \"trainable\" is used, bias vector is trained for output logits. By\\n    default prior correction is turned off.\\n\\n    Args:\\n        distribution: Distribution used in the model.\\n        num_classes: Number of output classes.\\n        priors: Precomputed class priors. Priors can be learned on-line if not provided.\\n\\n    Inputs:\\n        - parameters: Distribution parameters with shape (..., K).\\n        - labels: Positive labels used for margin with shape (...).\\n        - scorer: Unused.\\n\\n    Outputs:\\n        - logits: Class logits with shape (..., C).\\n\\n    ', 'gmm', 'vmf', 'Get classifier config.\\n\\n        Args:\\n            priors: Type of prior correction used (one of `pretrained`, `trainable` and `none`).\\n              See description above. By default turned off.\\n            margin: Log probability subtracted from positive logit.\\n            target_distribution: Compute likelihood of the prediction using target distributions.\\n              Default is to compute likelihood of the target using predicted distribution.\\n        ', 'priors', 'margin', 'target_distribution', 'target_distribution_params', 'target_distribution', 'target_distribution', 'target_distribution_params', 'Predicted and target embeddings size mismatch: {} != {}.', 'Predicted and target embeddings normalization mismatch', 'priors', 'none', 'priors', 'pretrained', 'Need dataset priors for pretrained mode', 'priors', 'trainable', 'Unknown priors mode: {}.', 'priors', 'Parameters and labels shape mismatch: {}, {}', 'target_distribution', 'margin', 'Compute useful statistics for logging.\\n\\n        Returns:\\n            Dictionary with floating-point statistics values.\\n        ', 'target_distribution', 'target_confidence/mean', 'target_confidence/std', 'distribution={}, num_classes={}, config={}', 'Contains target centroids distribution and evaluates expected log likelihood.\\n\\n    Implementation is based on \"Von Mises–Fisher Loss:An Exploration of Embedding Geometries for Supervised Learning.\" (2021).\\n\\n    Args:\\n        distribution: Distribution used in the model.\\n        num_classes: Number of output classes.\\n\\n    Inputs:\\n        - parameters: Distribution parameters with shape (..., K).\\n        - labels: Positive labels used for margin with shape (...).\\n        - scorer: Unused.\\n\\n    Outputs:\\n        - logits: Class logits with shape (..., C).\\n\\n    ', 'trainable', 'Get classifier config.\\n\\n        Args:\\n            scale: Output scale (number or \"trainable\").\\n            initial_log_scale: Initial logarithm of scale value when scale is trainable.\\n            kappa_confidence: Hyperparameter used for initialization and scoring.\\n            sample_size: Number of samples for probability estimation.\\n            approximate_logc: Use approximation from the paper to speedup training.\\n            deterministic_target: Use a variation of vMF-loss with deterministic target embeddings.\\n        ', 'scale', 'initial_log_scale', 'kappa_confidence', 'sample_size', 'approximate_logc', 'deterministic_target', 'Expected vMF distribution for vMF loss.', 'kappa_confidence', 'deterministic_target', 'scale', 'trainable', 'initial_log_scale', 'scale', 'Get lambda parameter of vMF-loss.', 'kappa_confidence', 'Parameters and labels shape mismatch: {}, {}', 'sample_size', 'deterministic_target', 'deterministic_target', 'deterministic_target', 'Compute useful statistics for logging.\\n\\n        Returns:\\n            Dictionary with floating-point statistics values.\\n        ', 'scale', 'deterministic_target', 'target_sqrt_inv_k/mean', 'target_sqrt_inv_k/std', 'distribution={}, num_classes={}, config={}', 'scale', 'trainable', 'Compute Log MLS for unimodal distributions.', 'approximate_logc', 'Extracts target centroids from elements of the same batch and computes Stochastic Prototype Embeddings logits.\\n\\n    See \"Stochastic Prototype Embeddings.\" (2019) for details.\\n\\n    Args:\\n        distribution: Distribution used in the model.\\n        num_classes: Number of output classes.\\n\\n    Inputs:\\n        - parameters: Distribution parameters with shape (..., K).\\n        - labels: Positive labels used for margin with shape (...).\\n        - scorer: Unused.\\n\\n    Outputs:\\n        - logits: Class logits with shape (..., C).\\n\\n    ', 'Get classifier config.\\n\\n        Args:\\n            train_epsilon: Whether to use trainable addition to the variance or not.\\n            sample_size: Number of samples used for integral evaluation. Zero to disable sampling and use distribution mean.\\n        ', 'train_epsilon', 'sample_size', 'Expected GMM distribution for SPE loss.', 'train_epsilon', 'train_epsilon', 'train_epsilon', 'Expected embeddings with shape (B, N), got: {}', 'Parameters and labels shape mismatch: {}, {}', 'Group embeddings into batch by label.\\n\\n        Returns:\\n           A tuple of\\n               - grouped_embeddings with shape (B // L, L, P), where second dimension encodes label.\\n               - label_map with shape (L) which stores original label indices.\\n        ', 'Expected tensor with shape (B, P).', 'Need uniform balanced sampling: {}.', 'Expected grouped embeddings with shape (B, L, P).', \"Compute SPE logits.\\n\\n        Args:\\n            - query: Queries with shape (B, L, P) to compute logits for.\\n            - support: Embeddings used for prototype computation with shape (B', L, P).\\n        Returns:\\n            SPE logits with shape (B, L).\\n        \", 'sample_size', 'sample_size', 'Compute useful statistics for logging.\\n\\n        Returns:\\n            Dictionary with floating-point statistics values.\\n        ', 'distribution={}, num_classes={}, config={}', 'Classify using scores.\\n\\n    Args:\\n        distribution: Distribution used in the model.\\n        num_classes: Number of output classes.\\n        priors (unused): Precomputed class priors. Priors can be learned on-line if not provided.\\n\\n    Inputs:\\n        - parameters: Distribution parameters with shape (..., K).\\n        - labels: Unused.\\n        - scorer: Scorer used for logits computation.\\n\\n    Outputs:\\n        - logits: Class logits with shape (..., C).\\n\\n    ', 'Get classifier config.', 'use_bias', 'use_bias', 'use_bias', 'Compute useful statistics for logging.\\n\\n        Returns:\\n            Dictionary with floating-point statistics values.\\n        ', 'covariance', 'std', 'covariance', 'k', 'vmf_sqrt_inv_k', 'k', 'target_{}/mean', 'target_{}/std', 'distribution={}, num_classes={}, config={}'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <15x15 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 15 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['Test that AutoRegressivePipeline pipeline makes fit without failing.', 'target', 'target', 'make_future', 'model_class', 'make_future', 'model_class', 'Test that AutoRegressivePipeline generates all the columns.', 'target', 'regressor_exog_weekend', 'regressor_exog_weekend', 'Test that AutoRegressivePipeline gets predictions one by one if step is equal to 1.', 'target', 'target', 'target', 'Test that AutoRegressivePipeline gets correct number of predictions if step is more than 1.', 'target', 'horizon, step', 'Test the forecast interface with prediction intervals.', 'target', 'target_0.025', 'target_0.975', 'target', 'target_0.975', 'target_0.025', 'Test that AutoRegressivePipeline can work with transforms that need fitting.', 'target', 'target', 'Test that AutoRegressivePipeline raise error when calling forecast without being fit.', 'AutoRegressivePipeline is not fitted!', 'Check that AutoRegressivePipeline.backtest gives the same results in case of single and multiple jobs modes.', 'target', 'regressor_lag_feature', 'Check that AutoRegressivePipeline.backtest gives correct forecasts according to the simple case.', 'target', 'model, transforms', 'target', 'target'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['Generate configs for reality check from templates.', 'templates', 'Templates root.', 'dst', 'Target configs root.', '--best', 'Best hopts root.', '--embeddings-dims', 'Coma-separated list of required embeddings dimensions.', '128,512', \"Load best hyperparameters from wandb config.\\n\\n    If file doesn't exists, returns empty dictionary.\\n    \", 'Load best parameters from {}.', 'value', 'wandb', '_', 'dataset_params', 'metrics_params', 'git_commit', 'Unknown parameter: {}.', 'reality-*.yaml', 'reality-base.yaml', 'reality-datasets.yaml', 'Need {} template.', 'reality-base.yaml', 'reality-datasets.yaml', ',', '-', '{}-{}-{}.yaml', 'model_params', 'distribution_params', 'dim', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <10x10 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 10 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Tools for configuration using default config.\\n\\nAll configurable classes must have :meth:`get_default_config` static method\\nwhich returns dictionary of default values. Than you can use\\n:func:`prepare_config` function to construct actual config. Actual config\\ncan be ``None``, ``dict`` or ``str`` containing path to the file.\\n\\n**Example**::\\n\\n    from collections import OrderedDict\\n    from mdn_metric.config import prepare_config\\n\\n    class Configurable:\\n        @staticmethod\\n        def get_default_config():\\n            return OrderedDict([\\n                (\"arg1\", 10),\\n                (\"arg2\", None)\\n            ])\\n\\n        def __init__(self, *args, config=None):\\n            config = prepare_config(self, config)\\n            self.arg1 = config[\"arg1\"]\\n            self.arg2 = config[\"arg2\"]\\n\\n    obj = Configurable(config={\"arg1\": 5})\\n    print(obj.arg1)  # 5\\n    print(obj.arg2)  # None\\n\\nConfig files use YAML syntax. The special key `_type` can be used in configs to specify\\ntarget class. If types are provided, they are checked during initialization.\\n\\n**Example**::\\n\\n    system:\\n        subsystem:\\n            _type: SubsystemClass\\n            arg1: [5.0, 2.0]\\n\\nConfig can contain hyperparameters for optimization in WandB format like:\\n\\n**Example**::\\n\\n    system:\\n        subsystem:\\n            arg1: [5.0, 2.0]\\n            _hopt:\\n              arg2:\\n                min: 1\\n                max: 5\\n\\nIf _hopt dictionary contains some values instead of dictionaries,\\nthese values will used in config as parameters when needed.\\n\\n', '_type', '_hopt', 'Exception class for errors in config.', 'Load config from file if string is provided. Return empty dictionary if input is None.', 'Config dictionary expected, got {}', 'Set defaults and check fields.\\n\\n    Config is a dictionary of values. Method creates new config using\\n    default class config. Result config keys are the same as default config keys.\\n\\n    Args:\\n        cls_or_default: Class with get_default_config method or default config dictionary.\\n        config: User-provided config.\\n\\n    Returns:\\n        Config dictionary with defaults set.\\n    ', 'Type mismatch: expected {}, got {}', 'Unknown parameter {}', '.', 'Convert nested config to flat config.', 'Expected dictionary, got {}.', '.', 'Convert flat config to nested config.', \"Can't use hopts for list values.\", \"Can't mix dict and list configs: some keys are indices and some are strings.\", 'Merge patch into config recursively.'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <16x16 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 16 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['Lengths of arrays should be equal', 'Parameter maxlags should', 'max_lags', 'max_lags', 'full', 'random_state', 'maxlags', 'full', 'random_state', 'maxlags', 'a, b, expected_result', 'a, b, normed, expected_result', 'cycle_name', 'in_cycle_num', 'in_cycle_name', 'timestamp, cycle, expected_cycle_names, expected_in_cycle_nums, expected_in_cycle_names', '2020-01-01', 'D', '1', '1', '1', '2', '2', '0', '1', '2', '0', '1', '2020-01-01', '15T', 'hour', '2020-01-01 00', '2020-01-01 01', '0', '1', '2', '3', '0', '1', '2020-01-01', 'H', 'day', '2020-01-01', '2020-01-02', '2020-01-01', 'D', 'week', '2020-00', '2020-01', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun', 'Mon', 'Tue', 'Wed', 'Thu', 'Fri', '2020-01-03', 'D', 'month', '2020-Jan', '2020-Feb', '2020-01-01', 'M', 'quarter', '2020-1', '2020-2', '2020-3', '2020-4', '2021-1', '2020-01-01', 'M', 'year', '2020', '2021', 'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec', 'Jan', 'Feb', 'timestamp', 'target', 'segment', 'segment_0', 'segment_0', 'target', 'timestamp, values, resample_freq, aggregation, expected_timestamp, expected_values', '2020-01-01', 'Q', 'Y', 'sum', '2020-01-01', 'Y', '2020-01-01', 'Q', 'Y', 'mean', '2020-01-01', 'Y', 'freq, cycle, additional_params', 'D', 'first', 'D', 'last', 'D', 'week', 'D', 'month', 'D', 'year', 'M', 'year', 'sum', 'M', 'year', 'mean', 'DeprecationWarning: This function is deprecated and will be removed in etna=2.0; Please use acf_plot instead.', 'segment_1', 'target', 'segment_2', 'target', 'H', 'H'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['TSDataset', 'Create TSDataset based on original ts with selecting only column in each segment and setting it to target.\\n\\n    Parameters\\n    ----------\\n    ts:\\n        dataset with timeseries data\\n    column:\\n        column to select in each.\\n\\n    Returns\\n    -------\\n    result: TSDataset\\n        dataset with selected column.\\n    ', 'target', 'TSDataset', 'TSDataset', 'ProphetModel', 'SARIMAXModel', 'target', '\\n    Get point outliers in time series using prediction intervals (estimation model-based method).\\n\\n    Outliers are all points out of the prediction interval predicted with the model.\\n\\n    Parameters\\n    ----------\\n    ts:\\n        dataset with timeseries data(should contains all the necessary features).\\n    model:\\n        model for prediction interval estimation.\\n    interval_width:\\n        the significance level for the prediction interval. By default a 95% prediction interval is taken.\\n    in_column:\\n        column to analyze\\n\\n        * If it is set to \"target\", then all data will be used for prediction.\\n\\n        * Otherwise, only column data will be used.\\n\\n    Returns\\n    -------\\n    :\\n        dict of outliers in format {segment: [outliers_timestamps]}.\\n\\n    Notes\\n    -----\\n    For not \"target\" column only column data will be used for learning.\\n    ', 'target', 'target', 'target_', '.4g', 'target', 'target_', '.4g'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <41x27 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 41 stored elements in Compressed Sparse Row format>, 'ClassDef': <9x9 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 9 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['cuda', 'halfcheetah-medium-expert-v2', '', 'CORL', 'IQL-D4RL', 'IQL', '-', '-', 'cpu', 'Trying to load data into non-empty replay buffer', 'observations', 'Replay buffer is smaller than the dataset you are trying to load!', 'observations', 'actions', 'rewards', 'next_observations', 'terminals', 'Dataset size: ', 'PYTHONHASHSEED', 'project', 'group', 'name', 'rewards', 'terminals', 'rewards', 'halfcheetah', 'hopper', 'walker2d', 'rewards', 'rewards', 'antmaze', 'rewards', 'MLP requires at least two dims (input and output)', 'Last dim must be 1 when squeezing', 'cpu', 'cpu', 'cpu', 'value_loss', 'q_loss', 'Actions shape missmatch', 'actor_loss', 'qf', 'q_optimizer', 'vf', 'v_optimizer', 'actor', 'actor_optimizer', 'actor_lr_schedule', 'total_it', 'qf', 'q_optimizer', 'vf', 'v_optimizer', 'actor', 'actor_optimizer', 'actor_lr_schedule', 'total_it', 'observations', 'observations', 'observations', 'next_observations', 'next_observations', 'Checkpoints path: ', 'config.yaml', 'w', 'max_action', 'actor', 'actor_optimizer', 'q_network', 'q_optimizer', 'v_network', 'v_optimizer', 'discount', 'tau', 'device', 'beta', 'iql_tau', 'max_steps', '---------------------------------------', 'Training IQL, Env: ', ', Seed: ', '---------------------------------------', '', 'Time steps: ', '---------------------------------------', 'Evaluation over ', ' episodes: ', '.3f', ' , D4RL score: ', '.3f', '---------------------------------------', 'checkpoint_', '.pt', 'd4rl_normalized_score', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <31x25 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 31 stored elements in Compressed Sparse Row format>, 'ClassDef': <6x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['CORL', 'SAC-N', 'SAC-N', 'halfcheetah-medium-v2', 'cpu', '-', '-', 'project', 'group', 'name', 'PYTHONHASHSEED', 'cpu', 'Trying to load data into non-empty replay buffer', 'observations', 'Replay buffer is smaller than the dataset you are trying to load!', 'observations', 'actions', 'rewards', 'next_observations', 'terminals', 'Dataset size: ', 'cpu', 'alpha_loss', 'critic_loss', 'actor_loss', 'batch_entropy', 'alpha', 'q_policy_std', 'q_random_std', 'actor', 'critic', 'target_critic', 'log_alpha', 'actor_optim', 'critic_optim', 'alpha_optim', 'actor', 'critic', 'target_critic', 'actor_optim', 'critic_optim', 'alpha_optim', 'log_alpha', 'rewards', 'terminals', 'rewards', 'halfcheetah', 'hopper', 'walker2d', 'rewards', 'rewards', 'antmaze', 'rewards', 'Checkpoints path: ', 'config.yaml', 'w', 'Training', 'Epoch', 'epoch', 'eval/reward_mean', 'eval/reward_std', 'epoch', 'get_normalized_score', 'eval/normalized_score_mean', 'eval/normalized_score_std', '.pt', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <11x9 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 11 stored elements in Compressed Sparse Row format>, 'ClassDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Enum for seasonality mode for DeadlineMovingAverageModel.', 'month', 'year', ' is not a valid ', '. Only ', ', ', ' seasonality allowed', 'Moving average model that uses exact previous dates to predict.', 'month', '\\n        Initialize deadline moving average model.\\n\\n        Length of the context is equal to the number of ``window`` months or years, depending on the ``seasonality``.\\n\\n        Parameters\\n        ----------\\n        window: int\\n            Number of values taken for forecast for each point.\\n        seasonality: str\\n            Only allowed monthly or annual seasonality.\\n        ', 'target', 'H', 'D', '\\n        Fit DeadlineMovingAverageModel model.\\n\\n        Parameters\\n        ----------\\n        df: pd.DataFrame\\n            Data to fit on\\n        regressors:\\n            List of the columns with regressors(ignored in this model)\\n\\n        Raises\\n        ------\\n        ValueError\\n            If freq of dataframe is not supported\\n        ValueError\\n            If series is too short for chosen shift value\\n\\n        Returns\\n        -------\\n        :\\n            Fitted model\\n        ', 'timestamp', ' is not supported! Use daily or hourly frequency!', 'timestamp', 'target', ' does not work with any exogenous series or features. It uses only target series for predict/\\n ', '_DeadlineMovingAverageModel', \"\\n        Get timestamp where context begins.\\n\\n        Parameters\\n        ----------\\n        df:\\n            Time series in a long format.\\n        prediction_size:\\n            Number of last timestamps to leave after making prediction.\\n            Previous timestamps will be used as a context for models that require it.\\n        seasonality:\\n            Seasonality.\\n        window:\\n            Number of values taken for forecast of each point.\\n\\n        Returns\\n        -------\\n        :\\n            Timestamp with beginning of the context.\\n\\n        Raises\\n        ------\\n        ValueError:\\n            if context isn't big enough\\n        \", 'timestamp', 'timestamp', \"Given context isn't big enough, try to decrease context_size, prediction_size of increase length of given dataframe!\", \"Given context isn't big enough, try to decrease context_size, prediction_size of increase length of given dataframe!\", 'Make predictions using ``result_template`` as a base and ``context`` as a context.', \"Compute autoregressive forecasts.\\n\\n        Parameters\\n        ----------\\n        df:\\n            Features dataframe.\\n        prediction_size:\\n            Number of last timestamps to leave after making prediction.\\n            Previous timestamps will be used as a context for models that require it.\\n\\n        Returns\\n        -------\\n        :\\n            Array with predictions.\\n\\n        Raises\\n        ------\\n        ValueError:\\n            if context isn't big enough\\n        ValueError:\\n            if forecast context contains NaNs\\n        \", 'timestamp', 'target', 'There are NaNs in a forecast context, forecast method required context to filled!', \"Compute predictions using true target data as context.\\n\\n        Parameters\\n        ----------\\n        df:\\n            Features dataframe.\\n        prediction_size:\\n            Number of last timestamps to leave after making prediction.\\n            Previous timestamps will be used as a context for models that require it.\\n\\n        Returns\\n        -------\\n        :\\n            Array with predictions.\\n\\n        Raises\\n        ------\\n        ValueError:\\n            if context isn't big enough\\n        ValueError:\\n            if there are NaNs in a target column on timestamps that are required to make predictions\\n        \", 'timestamp', 'target', 'There are NaNs in a target column, predict method requires target to be filled!', 'Upper bound to context size of the model.', 'Model is not fitted! Fit the model before trying the find out context size!', 'H', 'Moving average model that uses exact previous dates to predict.', 'month', '\\n        Initialize deadline moving average model.\\n\\n        Length of the context is equal to the number of ``window`` months or years, depending on the ``seasonality``.\\n\\n        Parameters\\n        ----------\\n        window: int\\n            Number of values taken for forecast for each point.\\n        seasonality: str\\n            Only allowed monthly or annual seasonality.\\n        ', 'Upper bound to context size of the model.', 'Get internal model.\\n\\n        Returns\\n        -------\\n        :\\n           Internal model\\n        ', 'DeadlineMovingAverageModel', 'DeadlineMovingAverageModel'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <6x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['_OneSegmentResampleWithDistributionTransform resamples the given column using the distribution of the other column.', '\\n        Init _OneSegmentResampleWithDistributionTransform.\\n\\n        Parameters\\n        ----------\\n        in_column:\\n            name of column to be resampled\\n        distribution_column:\\n            name of column to obtain the distribution from\\n        inplace:\\n\\n            * if True, apply resampling inplace to in_column,\\n\\n            * if False, add transformed column to dataset\\n\\n        out_column:\\n            name of added column. If not given, use ``self.__repr__()``\\n        ', '\\n        Generate fold number for each timestamp of the dataframe.\\n\\n        Here the ``in_column`` frequency gap is divided into the folds with the size of dataset frequency gap.\\n        ', 'Can not infer in_column frequency!Check that in_column frequency is compatible with dataset frequency.', '\\n        Obtain the resampling frequency and distribution from ``distribution_column``.\\n\\n        Parameters\\n        ----------\\n        df:\\n            dataframe with data to fit the transform.\\n\\n        Returns\\n        -------\\n        :\\n        ', 'fold', 'fold', 'fold', 'distribution', '_OneSegmentResampleWithDistributionTransform', '\\n        Resample the `in_column` using the distribution of `distribution_column`.\\n\\n        Parameters\\n        ----------\\n        df\\n            dataframe with data to transform.\\n\\n        Returns\\n        -------\\n        :\\n            result dataframe\\n        ', 'fold', 'fold', 'timestamp', 'distribution', 'fold', 'distribution', 'ResampleWithDistributionTransform resamples the given column using the distribution of the other column.\\n\\n    Warning\\n    -------\\n    This transform can suffer from look-ahead bias. For transforming data at some timestamp\\n    it uses information from the whole train part.\\n    ', '\\n        Init ResampleWithDistributionTransform.\\n\\n        Parameters\\n        ----------\\n        in_column:\\n            name of column to be resampled\\n        distribution_column:\\n            name of column to obtain the distribution from\\n        inplace:\\n\\n            * if True, apply resampling inplace to in_column,\\n\\n            * if False, add transformed column to dataset\\n\\n        out_column:\\n            name of added column. If not given, use ``self.__repr__()``\\n        ', \"Get the `out_column` depending on the transform's parameters.\", 'Transformation will be applied inplace, out_column param will be ignored'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <20x10 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 20 stored elements in Compressed Sparse Row format>, 'ClassDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['lfw', 'cfp_fp', 'cfp_ff', 'calfw', 'cplfw', 'agedb_30', 'lfw', 'cfp_fp', 'cfp_ff', 'calfw', 'cplfw', 'agedb_30', 'vgg2_fp', 'lfw', 'cfp_fp', 'cfp_ff', 'calfw', 'cplfw', 'agedb_30', 'vgg2_fp', 'PyTorch interface to MXNet serialized training dataset.\\n\\n    Args:\\n        root: Path to the dataset root with images and annotations.\\n    ', 'train.idx', 'train.rec', 'property', 'labels.yaml', ',', 'r', 'Whether dataset is classification or matching.', 'Whether dataset is for open-set or closed-set classification.', 'Get dataset labels array.\\n\\n        Labels are integers in the range [0, N-1].\\n        ', 'Get element of the dataset.\\n\\n        Returns:\\n            Tuple (image, label).\\n\\n        ', 'Dump labels to dataset folder.', 'PyTorch interface to MXNet pairs validation dataset.\\n\\n    Args:\\n        filename: Path to the binary.\\n    ', 'rb', 'bytes', 'Whether dataset is classification or matching.', 'Whether dataset is for open-set or closed-set classification.', 'Get dataset labels array.\\n\\n        Labels are integers in the range [0, N-1].\\n        ', 'Get element of the dataset.\\n\\n        Returns:\\n            Tuple ((image1, image2), label).\\n\\n        ', 'MXNet-serialized dataset.', '.yaml', '.labels', '.idx', '.rec', 'r', 'Whether dataset is classification or verification.', 'classification', 'Whether dataset is for open-set or closed-set classification.', 'Get dataset labels array.\\n\\n        Labels are integers in the range [0, N-1].\\n\\n        ', '.idx', '.labels', '.yaml', '.rec', '.rec', 'train', \"Can't find trainset in {}.\", '.idx'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <7x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['\\n    Seasonal moving average.\\n\\n    .. math::\\n        y_{t} = \\\\frac{\\\\sum_{i=1}^{n} y_{t-is} }{n},\\n\\n    where :math:`s` is seasonality, :math:`n` is window size (how many history values are taken for forecast).\\n    ', '\\n        Initialize seasonal moving average model.\\n\\n        Length of the context is ``window * seasonality``.\\n\\n        Parameters\\n        ----------\\n        window: int\\n            Number of values taken for forecast for each point.\\n        seasonality: int\\n            Lag between values taken for forecast.\\n        ', 'target', '\\n        Fit SeasonalMovingAverage model.\\n\\n        Parameters\\n        ----------\\n        df:\\n            Data to fit on\\n        regressors:\\n            List of the columns with regressors(ignored in this model)\\n\\n        Returns\\n        -------\\n        :\\n            Fitted model\\n        ', 'timestamp', 'target', ' does not work with any exogenous series or features. It uses only target series for predict/\\n ', '_SeasonalMovingAverageModel', \"Compute autoregressive forecasts.\\n\\n        Parameters\\n        ----------\\n        df:\\n            Features dataframe.\\n        prediction_size:\\n            Number of last timestamps to leave after making prediction.\\n            Previous timestamps will be used as a context for models that require it.\\n\\n        Returns\\n        -------\\n        :\\n            Array with predictions.\\n\\n        Raises\\n        ------\\n        ValueError:\\n            if context isn't big enough\\n        ValueError:\\n            if forecast context contains NaNs\\n        \", \"Given context isn't big enough, try to decrease context_size, prediction_size of increase length of given dataframe!\", 'target', 'There are NaNs in a forecast context, forecast method required context to filled!', \"Compute predictions using true target data as context.\\n\\n        Parameters\\n        ----------\\n        df:\\n            Features dataframe.\\n        prediction_size:\\n            Number of last timestamps to leave after making prediction.\\n            Previous timestamps will be used as a context for models that require it.\\n\\n        Returns\\n        -------\\n        :\\n            Array with predictions.\\n\\n        Raises\\n        ------\\n        ValueError:\\n            if context isn't big enough\\n        ValueError:\\n            if there are NaNs in a target column on timestamps that are required to make predictions\\n        \", \"Given context isn't big enough, try to decrease context_size, prediction_size of increase length of given dataframe!\", 'target', 'There are NaNs in a target column, predict method requires target to be filled!', '\\n    Seasonal moving average.\\n\\n    .. math::\\n        y_{t} = \\\\frac{\\\\sum_{i=1}^{n} y_{t-is} }{n},\\n\\n    where :math:`s` is seasonality, :math:`n` is window size (how many history values are taken for forecast).\\n    ', '\\n        Initialize seasonal moving average model.\\n\\n        Length of the context is ``window * seasonality``.\\n\\n        Parameters\\n        ----------\\n        window: int\\n            Number of values taken for forecast for each point.\\n        seasonality: int\\n            Lag between values taken for forecast.\\n        ', 'Context size of the model.', 'Get internal model.\\n\\n        Returns\\n        -------\\n        :\\n           Internal model\\n        ', 'SeasonalMovingAverageModel', 'SeasonalMovingAverageModel'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <8x8 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 8 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['metric, right_metrics_value', 'metric, right_metrics_value'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <8x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 8 stored elements in Compressed Sparse Row format>, 'ClassDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['LinearTrendBaseTransform is a base class that implements trend subtraction and reconstruction feature.', '\\n        Create instance of _OneSegmentLinearTrendBaseTransform.\\n\\n        Parameters\\n        ----------\\n        in_column:\\n            name of processed column\\n        regressor:\\n            instance of sklearn :py:class`sklearn.base.RegressorMixin` to predict trend\\n        poly_degree:\\n            degree of polynomial to fit trend on\\n        ', 'polynomial', 'regressor', 'Your timestamp column has wrong format. Need np.datetime64 or datetime.datetime', '\\n        Fit regression detrend_model with data from df.\\n\\n        Parameters\\n        ----------\\n        df:\\n            data that regressor should be trained with\\n\\n        Returns\\n        -------\\n        _OneSegmentLinearTrendBaseTransform\\n            instance with trained regressor\\n        ', '_OneSegmentLinearTrendBaseTransform', '\\n        Transform data from df: subtract linear trend found by regressor.\\n\\n        Parameters\\n        ----------\\n        df:\\n            data to subtract trend from\\n\\n        Returns\\n        -------\\n        pd.DataFrame\\n            residue after trend subtraction\\n        ', '\\n        Fit regression detrend_model with data from df and subtract the trend from df.\\n\\n        Parameters\\n        ----------\\n        df:\\n            data to train regressor and transform\\n\\n        Returns\\n        -------\\n        pd.DataFrame\\n            residue after trend subtraction\\n        ', '\\n        Inverse transformation for trend subtraction: add trend to prediction.\\n\\n        Parameters\\n        ----------\\n        df:\\n            data to transform\\n\\n        Returns\\n        -------\\n        pd.DataFrame\\n            data with reconstructed trend\\n        ', 'target', '\\n    Transform that uses :py:class:`sklearn.linear_model.LinearRegression` to find linear or polynomial trend in data.\\n\\n    Warning\\n    -------\\n    This transform can suffer from look-ahead bias. For transforming data at some timestamp\\n    it uses information from the whole train part.\\n    ', 'Create instance of LinearTrendTransform.\\n\\n        Parameters\\n        ----------\\n        in_column:\\n            name of processed column\\n        poly_degree:\\n            degree of polynomial to fit trend on\\n        regression_params:\\n            params that should be used to init :py:class:`sklearn.linear_model.LinearRegression`\\n        ', '\\n    Transform that uses :py:class:`sklearn.linear_model.TheilSenRegressor` to find linear or polynomial trend in data.\\n\\n    Warning\\n    -------\\n    This transform can suffer from look-ahead bias. For transforming data at some timestamp\\n    it uses information from the whole train part.\\n\\n    Notes\\n    -----\\n    Setting parameter ``n_subsamples`` manually might cause the error. It should be at least the number\\n    of features (plus 1 if ``fit_intercept=True``) and the number of samples in the shortest segment as a maximum.\\n    ', 'Create instance of TheilSenTrendTransform.\\n\\n        Parameters\\n        ----------\\n        in_column:\\n            name of processed column\\n        poly_degree:\\n            degree of polynomial to fit trend on\\n        regression_params:\\n            params that should be used to init :py:class:`sklearn.linear_model.TheilSenRegressor`\\n        '], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['BaseChangePointsModelAdapter is the base class for change point models adapters.', 'Find change points within one segment.\\n\\n        Parameters\\n        ----------\\n        df:\\n            dataframe indexed with timestamp\\n        in_column:\\n            name of column to get change points\\n\\n        Returns\\n        -------\\n        change points:\\n            change point timestamps\\n        ', 'Create list of stable intervals from list of change points.', 'Find change point intervals in given dataframe and column.\\n\\n        Parameters\\n        ----------\\n        df:\\n            dataframe indexed with timestamp\\n        in_column:\\n            name of column to get change points\\n\\n        Returns\\n        -------\\n        :\\n            change points intervals\\n        ', 'RupturesChangePointsModel is ruptures change point models adapter.', 'Init RupturesChangePointsModel.\\n\\n        Parameters\\n        ----------\\n        change_point_model:\\n            model to get change points\\n        change_point_model_predict_params:\\n            params for ``change_point_model.predict`` method\\n        ', 'Find change points within one segment.\\n\\n        Parameters\\n        ----------\\n        df:\\n            dataframe indexed with timestamp\\n        in_column:\\n            name of column to get change points\\n\\n        Returns\\n        -------\\n        change points:\\n            change point timestamps\\n        ', 'The input column contains NaNs in the middle of the series! Try to use the imputer.'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <12x12 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 12 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['Check metrics __repr__ method', 'per-segment', 'kwarg_1', 'kwarg_2', 'value_1', 'value_2', \"kwarg_1 = 'value_1', kwarg_2 = 'value_2'\", \"(mode = '\", \"', \", ', )', 'metric_class, metric_class_repr, metric_params, param_repr', 'MAE', '', 'MSE', '', 'MedAE', '', 'MSLE', '', 'MAPE', '', 'SMAPE', '', 'R2', '', 'Sign', '', 'DummyMetric', 'alpha', 'alpha = 1.0, ', 'Check metrics name property without changing its during inheritance', 'per-segment', 'metric_class', 'Check metrics name property with changing its during inheritance to repr', 'per-segment', 'metric_class', \"Check metrics interface in 'macro' mode\", 'metric_class', \"Check metrics interface in 'per-segment' mode\", 'segment', 'metric_class', 'Check metrics behavior in case of invalid aggregation mode', 'a', 'metric_class', 'Check metrics behavior in case of invalid timeranges', 'metric_class', 'Check metrics behavior in case of invalid segments sets', 'metric_class', 'Check metrics behavior in case of no target column in segment', 'segment_1', 'target', 'metric_class', \"\\n    Check that all the segments' metrics values in per-segments mode are equal to the same\\n    metric for segments' series.\\n    \", 'per-segment', 'target', 'target', 'metric_class, metric_fn', 'metric, greater_is_better', 'Check that metric works correctly in case of multiple call.', 'timestamp', '2020-01-01', '1D', 'segment', 'A', 'B', 'segment', 'C', 'B', 'target', 'target', 'target', 'target', 'timestamp', 'segment', 'segment', 'feature', 'timestamp', 'segment', 'segment', 'feature', 'timestamp', 'segment', 'segment', 'feature', 'timestamp', 'segment', 'segment', 'feature', '1D', '1D', '1D', '1D', 'per-segment', 'A', 'B', 'A', 'B', 'B', 'C', 'C', 'B'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <10x10 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 10 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['segment_1', 'segment', 'timestamp', '\\n    Test that fit_transform interface works correctly for one segment.\\n    ', 'regressor_result', 'target', 'target', 'segment', 'target', 'target', 'target', '\\n    Test that inverse_transform interface works correctly for one segment.\\n    ', 'target', 'test', '\\n    Test that fit_transform interface works correctly for many segment.\\n    ', 'regressor_result', 'target', 'target', 'target', 'target', 'target', '\\n    Test that inverse_transform interface works correctly for many segment.\\n    ', 'target', 'test', '\\n    Test inverse transform of TrendTransform.\\n    ', 'target', 'rbf', 'Test transform interface with out_column param', 'regressor_test', 'target', 'rbf', 'Test transform interface without out_column param', 'target', 'rbf', 'target', 'rbf', 'regressor_result', 'segment', 'target', 'regressor_result', 'model', 'target', 'rbf', 'The input column contains NaNs in the middle of the series!', 'model'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['Test that `create_ts_column` produces correct columns.', 'feature', 'target', 'column', 'exog', 'Test that `create_ts_column` selects correct data in selected columns.', 'target', 'column', 'exog', 'Test that `get_anomalies_prediction_interval` produces correct columns.', 'in_column', 'target', 'exog', 'model', 'Test that `get_anomalies_prediction_interval` generates correct values.', 'in_column', 'target', 'exog', 'model, interval_width, true_anomalies', '1', '2', '2021-01-11', '2021-01-09', '2021-01-27', '1', '2', '2021-01-27'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['Drop nan values from dataframes for the segment.', 'target', 'Exogenous or target data contains None! It will be dropped for calculating relevance.', 'Calculate relevance table with p-values from tsfresh.\\n\\n    Parameters\\n    ----------\\n    df:\\n        dataframe with timeseries\\n    df_exog:\\n        dataframe with exogenous data\\n\\n    Returns\\n    -------\\n    pd.DataFrame\\n        dataframe with p-values.\\n    ', 'feature', 'segment', 'category', ' column cannot be cast to float type! Please, use encoders.', 'Exogenous data contains columns with category type! It will be converted to float. If this is not desired behavior, use encoders.', 'feature', 'p_value', 'Calculate relevance table with feature importance from model.\\n\\n    Parameters\\n    ----------\\n    df:\\n        dataframe with timeseries\\n    df_exog:\\n        dataframe with exogenous data\\n    model:\\n        model to obtain feature importance, should have ``feature_importances_`` property\\n\\n    Returns\\n    -------\\n    pd.DataFrame\\n        dataframe with feature importance values.\\n    ', 'feature', 'segment'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <9x9 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 9 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['Check that transforms are logged into the file.', 'r', 'Check working of logging inside `TSDataset.transform`.', 'target', 'target', 'Check working of logging inside `TSDataset.fit_transform`.', 'target', 'target', 'Check working of logging inside `TSDataset.make_future`.', 'target', 'target', 'Check working of logging inside `TSDataset.inverse_transform`.', 'target', 'target', 'Check working of logging inside `Metric.__call__`.', 'r', 'metric', 'macro', 'Check working of logging inside backtest.', 'MAE', 'MSE', 'SMAPE', 'r', 'backtest', 'Check working of logging inside backtest with `table=False`.', 'r', 'backtest', 'Check working of logging in fit/forecast of model.', 'target', 'r', 'fit', 'forecast', 'model'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Class for holding time series binary classification.', 'Init TimeSeriesClassifier with given parameters.\\n\\n        Parameters\\n        ----------\\n        feature_extractor:\\n            Instance of time series feature extractor.\\n        classifier:\\n            Instance of classifier with sklearn interface.\\n        threshold:\\n            Positive class probability threshold.\\n        ', 'Fit the classifier.\\n\\n        Parameters\\n        ----------\\n        x:\\n            Array with time series.\\n        y:\\n            Array of class labels.\\n\\n        Returns\\n        -------\\n        :\\n            Fitted instance of classifier.\\n        ', 'Only the 0 - negative and 1 - positive are possible values for the class labels!', 'TimeSeriesBinaryClassifier', 'Predict classes with threshold.\\n\\n        Parameters\\n        ----------\\n        x:\\n           Array with time series.\\n\\n        Returns\\n        -------\\n        :\\n            Array with predicted labels.\\n        ', 'Predict probabilities of the positive class.\\n\\n        Parameters\\n        ----------\\n        x:\\n            Array with time series.\\n\\n        Returns\\n        -------\\n        :\\n            Probabilities for classes.\\n        ', 'Classifier is not fitted!', 'Calculate classification metrics on cross-validation.\\n\\n        Parameters\\n        ----------\\n        x:\\n            Array with time series.\\n        y:\\n            Array of class labels.\\n        mask:\\n            Fold mask (array where for each element there is a label of its fold)\\n\\n        Returns\\n        -------\\n        :\\n            Classification metrics for each fold\\n        ', 'macro', 'precision', 'recall', 'fscore', 'precision', 'recall', 'fscore', 'AUC', 'metrics', 'all'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <14x14 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 14 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['auto', 'Check that VotingEnsemble._validate_weights validate weights correctly in case of valid args sets.', 'weights', 'auto', 'Check that VotingEnsemble._validate_weights validate weights correctly in case of invalid args sets.', 'Weights size should be equal to pipelines number.', 'Check that _process_weights processes weights correctly.', 'weights,pipelines_number,expected', 'Check that _process_weights processes weights correctly in \"auto\" mode.', 'auto', 'auto', 'Check that fit saves processes weights.', 'weights', 'auto', 'Check that VotingEnsemble.forecast returns TSDataset of correct length.', 'Test the forecast interface with prediction intervals.', 'target_0.025', 'target_0.975', 'target', 'target_0.975', 'target_0.025', 'Check that VotingEnsemble.predict returns TSDataset of correct length.', 'Check that VotingEnsemble gets average during vote.', 'multiprocessing', 'A', 'target', 'B', 'target', 'Check that VotingEnsemble gets average during vote.', 'multiprocessing', 'A', 'target', 'B', 'target', 'Check that VotingEnsemble works the same in case of multi and single jobs modes.', 'Check that backtest works with VotingEnsemble.', 'n_jobs'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['x', 'y', 'x', 'y', 'x', 'y', 'minimize', 'maximize'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['LogTransform applies logarithm transformation for given series.', 'Init LogTransform.\\n\\n        Parameters\\n        ----------\\n        in_column:\\n            column to apply transform\\n        base:\\n            base of logarithm to apply to series\\n        inplace:\\n\\n            * if True, apply logarithm transformation inplace to in_column,\\n\\n            * if False, add column add transformed column to dataset\\n\\n        out_column:\\n            name of added column. If not given, use ``self.__repr__()``\\n        ', 'Transformation will be applied inplace, out_column param will be ignored', 'Fit method does nothing and is kept for compatibility.\\n\\n        Parameters\\n        ----------\\n        df:\\n            dataframe with data.\\n\\n        Returns\\n        -------\\n        result: LogTransform\\n        ', 'LogTransform', 'Apply log transformation to the dataset.\\n\\n        Parameters\\n        ----------\\n        df:\\n            dataframe with data to transform.\\n\\n        Returns\\n        -------\\n        result: pd.Dataframe\\n            transformed dataframe\\n        ', 'segment', 'LogPreprocess can be applied only to non-negative series', 'Apply inverse transformation to the dataset.\\n\\n        Parameters\\n        ----------\\n        df:\\n            dataframe with data to transform.\\n\\n        Returns\\n        -------\\n        result: pd.DataFrame\\n            transformed series\\n        ', 'target', 'feature', 'LogTransform'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <8x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 8 stored elements in Compressed Sparse Row format>, 'ClassDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': [\"\\n    Class for holding Holt-Winters' exponential smoothing model.\\n\\n    Notes\\n    -----\\n    We use :py:class:`statsmodels.tsa.holtwinters.ExponentialSmoothing` model from statsmodels package.\\n    \", 'estimated', 'none', '\\n        Init Holt-Winters\\' model with given params.\\n\\n        Parameters\\n        ----------\\n        trend:\\n            Type of trend component. One of:\\n\\n            * \\'add\\'\\n\\n            * \\'mul\\'\\n\\n            * \\'additive\\'\\n\\n            * \\'multiplicative\\'\\n\\n            * None\\n\\n        damped_trend:\\n            Should the trend component be damped.\\n        seasonal:\\n            Type of seasonal component. One of:\\n\\n            * \\'add\\'\\n\\n            * \\'mul\\'\\n\\n            * \\'additive\\'\\n\\n            * \\'multiplicative\\'\\n\\n            * None\\n\\n        seasonal_periods:\\n            The number of periods in a complete seasonal cycle, e.g., 4 for\\n            quarterly data or 7 for daily data with a weekly cycle.\\n        initialization_method:\\n            Method for initialize the recursions. One of:\\n\\n            * None\\n\\n            * \\'estimated\\'\\n\\n            * \\'heuristic\\'\\n\\n            * \\'legacy-heuristic\\'\\n\\n            * \\'known\\'\\n\\n            None defaults to the pre-0.12 behavior where initial values\\n            are passed as part of ``fit``. If any of the other values are\\n            passed, then the initial values must also be set when constructing\\n            the model. If \\'known\\' initialization is used, then ``initial_level``\\n            must be passed, as well as ``initial_trend`` and ``initial_seasonal`` if\\n            applicable. Default is \\'estimated\\'. \"legacy-heuristic\" uses the same\\n            values that were used in statsmodels 0.11 and earlier.\\n        initial_level:\\n            The initial level component. Required if estimation method is \"known\".\\n            If set using either \"estimated\" or \"heuristic\" this value is used.\\n            This allows one or more of the initial values to be set while\\n            deferring to the heuristic for others or estimating the unset\\n            parameters.\\n        initial_trend:\\n            The initial trend component. Required if estimation method is \"known\".\\n            If set using either \"estimated\" or \"heuristic\" this value is used.\\n            This allows one or more of the initial values to be set while\\n            deferring to the heuristic for others or estimating the unset\\n            parameters.\\n        initial_seasonal:\\n            The initial seasonal component. An array of length `seasonal`\\n            or length ``seasonal - 1`` (in which case the last initial value\\n            is computed to make the average effect zero). Only used if\\n            initialization is \\'known\\'. Required if estimation method is \"known\".\\n            If set using either \"estimated\" or \"heuristic\" this value is used.\\n            This allows one or more of the initial values to be set while\\n            deferring to the heuristic for others or estimating the unset\\n            parameters.\\n        use_boxcox: {True, False, \\'log\\', float}, optional\\n            Should the Box-Cox transform be applied to the data first? One of:\\n\\n            * True\\n\\n            * False\\n\\n            * \\'log\\': apply log\\n\\n            * float: lambda value\\n\\n        bounds:\\n            An dictionary containing bounds for the parameters in the model,\\n            excluding the initial values if estimated. The keys of the dictionary\\n            are the variable names, e.g., smoothing_level or initial_slope.\\n            The initial seasonal variables are labeled initial_seasonal.<j>\\n            for j=0,...,m-1 where m is the number of period in a full season.\\n            Use None to indicate a non-binding constraint, e.g., (0, None)\\n            constrains a parameter to be non-negative.\\n        dates:\\n            An array-like object of datetime objects. If a Pandas object is given\\n            for endog, it is assumed to have a DateIndex.\\n        freq:\\n            The frequency of the time-series. A Pandas offset or \\'B\\', \\'D\\', \\'W\\',\\n            \\'M\\', \\'A\\', or \\'Q\\'. This is optional if dates are given.\\n        missing:\\n            Available options are \\'none\\', \\'drop\\', and \\'raise\\'. If \\'none\\', no nan\\n            checking is done. If \\'drop\\', any observations with nans are dropped.\\n            If \\'raise\\', an error is raised. Default is \\'none\\'.\\n        smoothing_level:\\n            The alpha value of the simple exponential smoothing, if the value\\n            is set then this value will be used as the value.\\n        smoothing_trend:\\n            The beta value of the Holt\\'s trend method, if the value is\\n            set then this value will be used as the value.\\n        smoothing_seasonal:\\n            The gamma value of the holt winters seasonal method, if the value\\n            is set then this value will be used as the value.\\n        damping_trend:\\n            The phi value of the damped method, if the value is\\n            set then this value will be used as the value.\\n        fit_kwargs:\\n            Additional parameters for calling :py:meth:`statsmodels.tsa.holtwinters.ExponentialSmoothing.fit`.\\n        ', \"\\n        Fit Holt-Winters' model.\\n\\n        Parameters\\n        ----------\\n        df:\\n            Features dataframe\\n        regressors:\\n            List of the columns with regressors(ignored in this model)\\n        Returns\\n        -------\\n        :\\n            Fitted model\\n        \", 'target', 'timestamp', '_HoltWintersAdapter', \"\\n        Compute predictions from a Holt-Winters' model.\\n\\n        Parameters\\n        ----------\\n        df:\\n            Features dataframe\\n\\n        Returns\\n        -------\\n        :\\n            Array with predictions\\n        \", 'This model is not fitted! Fit the model before calling predict method!', 'timestamp', 'timestamp', 'target', 'timestamp', 'This model does not work with exogenous features and regressors.\\n ', ' will be dropped', 'Get :py:class:`statsmodels.tsa.holtwinters.results.HoltWintersResultsWrapper` model that was fitted inside etna class.\\n\\n        Returns\\n        -------\\n        :\\n           Internal model\\n        ', \"\\n    Holt-Winters' etna model.\\n\\n    Notes\\n    -----\\n    We use :py:class:`statsmodels.tsa.holtwinters.ExponentialSmoothing` model from statsmodels package.\\n    \", 'estimated', 'none', '\\n        Init Holt-Winters\\' model with given params.\\n\\n        Parameters\\n        ----------\\n        trend:\\n            Type of trend component. One of:\\n\\n            * \\'add\\'\\n\\n            * \\'mul\\'\\n\\n            * \\'additive\\'\\n\\n            * \\'multiplicative\\'\\n\\n            * None\\n\\n        damped_trend:\\n            Should the trend component be damped.\\n        seasonal:\\n            Type of seasonal component. One of:\\n\\n            * \\'add\\'\\n\\n            * \\'mul\\'\\n\\n            * \\'additive\\'\\n\\n            * \\'multiplicative\\'\\n\\n            * None\\n\\n        seasonal_periods:\\n            The number of periods in a complete seasonal cycle, e.g., 4 for\\n            quarterly data or 7 for daily data with a weekly cycle.\\n        initialization_method:\\n            Method for initialize the recursions. One of:\\n\\n            * None\\n\\n            * \\'estimated\\'\\n\\n            * \\'heuristic\\'\\n\\n            * \\'legacy-heuristic\\'\\n\\n            * \\'known\\'\\n\\n            None defaults to the pre-0.12 behavior where initial values\\n            are passed as part of ``fit``. If any of the other values are\\n            passed, then the initial values must also be set when constructing\\n            the model. If \\'known\\' initialization is used, then ``initial_level``\\n            must be passed, as well as ``initial_trend`` and ``initial_seasonal`` if\\n            applicable. Default is \\'estimated\\'. \"legacy-heuristic\" uses the same\\n            values that were used in statsmodels 0.11 and earlier.\\n        initial_level:\\n            The initial level component. Required if estimation method is \"known\".\\n            If set using either \"estimated\" or \"heuristic\" this value is used.\\n            This allows one or more of the initial values to be set while\\n            deferring to the heuristic for others or estimating the unset\\n            parameters.\\n        initial_trend:\\n            The initial trend component. Required if estimation method is \"known\".\\n            If set using either \"estimated\" or \"heuristic\" this value is used.\\n            This allows one or more of the initial values to be set while\\n            deferring to the heuristic for others or estimating the unset\\n            parameters.\\n        initial_seasonal:\\n            The initial seasonal component. An array of length `seasonal`\\n            or length ``seasonal - 1`` (in which case the last initial value\\n            is computed to make the average effect zero). Only used if\\n            initialization is \\'known\\'. Required if estimation method is \"known\".\\n            If set using either \"estimated\" or \"heuristic\" this value is used.\\n            This allows one or more of the initial values to be set while\\n            deferring to the heuristic for others or estimating the unset\\n            parameters.\\n        use_boxcox: {True, False, \\'log\\', float}, optional\\n            Should the Box-Cox transform be applied to the data first? One of:\\n\\n            * True\\n\\n            * False\\n\\n            * \\'log\\': apply log\\n\\n            * float: lambda value\\n\\n        bounds:\\n            An dictionary containing bounds for the parameters in the model,\\n            excluding the initial values if estimated. The keys of the dictionary\\n            are the variable names, e.g., smoothing_level or initial_slope.\\n            The initial seasonal variables are labeled initial_seasonal.<j>\\n            for j=0,...,m-1 where m is the number of period in a full season.\\n            Use None to indicate a non-binding constraint, e.g., (0, None)\\n            constrains a parameter to be non-negative.\\n        dates:\\n            An array-like object of datetime objects. If a Pandas object is given\\n            for endog, it is assumed to have a DateIndex.\\n        freq:\\n            The frequency of the time-series. A Pandas offset or \\'B\\', \\'D\\', \\'W\\',\\n            \\'M\\', \\'A\\', or \\'Q\\'. This is optional if dates are given.\\n        missing:\\n            Available options are \\'none\\', \\'drop\\', and \\'raise\\'. If \\'none\\', no nan\\n            checking is done. If \\'drop\\', any observations with nans are dropped.\\n            If \\'raise\\', an error is raised. Default is \\'none\\'.\\n        smoothing_level:\\n            The alpha value of the simple exponential smoothing, if the value\\n            is set then this value will be used as the value.\\n        smoothing_trend:\\n            The beta value of the Holt\\'s trend method, if the value is\\n            set then this value will be used as the value.\\n        smoothing_seasonal:\\n            The gamma value of the holt winters seasonal method, if the value\\n            is set then this value will be used as the value.\\n        damping_trend:\\n            The phi value of the damped method, if the value is\\n            set then this value will be used as the value.\\n        fit_kwargs:\\n            Additional parameters for calling :py:meth:`statsmodels.tsa.holtwinters.ExponentialSmoothing.fit`.\\n        ', '\\n    Holt etna model.\\n\\n    Restricted version of HoltWinters model.\\n\\n    Notes\\n    -----\\n    We use :py:class:`statsmodels.tsa.holtwinters.ExponentialSmoothing` model from statsmodels package.\\n    They implement :py:class:`statsmodels.tsa.holtwinters.Holt` model\\n    as a restricted version of :py:class:`~statsmodels.tsa.holtwinters.ExponentialSmoothing` model.\\n    ', 'estimated', '\\n        Init Holt model with given params.\\n\\n        Parameters\\n        ----------\\n        exponential:\\n            Type of trend component. One of:\\n\\n            * False: additive trend\\n\\n            * True: multiplicative trend\\n\\n        damped_trend:\\n            Should the trend component be damped.\\n        initialization_method:\\n            Method for initialize the recursions. One of:\\n\\n            * None\\n\\n            * \\'estimated\\'\\n\\n            * \\'heuristic\\'\\n\\n            * \\'legacy-heuristic\\'\\n\\n            * \\'known\\'\\n\\n            None defaults to the pre-0.12 behavior where initial values\\n            are passed as part of ``fit``. If any of the other values are\\n            passed, then the initial values must also be set when constructing\\n            the model. If \\'known\\' initialization is used, then ``initial_level``\\n            must be passed, as well as ``initial_trend`` and ``initial_seasonal`` if\\n            applicable. Default is \\'estimated\\'. \"legacy-heuristic\" uses the same\\n            values that were used in statsmodels 0.11 and earlier.\\n        initial_level:\\n            The initial level component. Required if estimation method is \"known\".\\n            If set using either \"estimated\" or \"heuristic\" this value is used.\\n            This allows one or more of the initial values to be set while\\n            deferring to the heuristic for others or estimating the unset\\n            parameters.\\n        initial_trend:\\n            The initial trend component. Required if estimation method is \"known\".\\n            If set using either \"estimated\" or \"heuristic\" this value is used.\\n            This allows one or more of the initial values to be set while\\n            deferring to the heuristic for others or estimating the unset\\n            parameters.\\n        smoothing_level:\\n            The alpha value of the simple exponential smoothing, if the value\\n            is set then this value will be used as the value.\\n        smoothing_trend:\\n            The beta value of the Holt\\'s trend method, if the value is\\n            set then this value will be used as the value.\\n        damping_trend:\\n            The phi value of the damped method, if the value is\\n            set then this value will be used as the value.\\n        fit_kwargs:\\n            Additional parameters for calling :py:meth:`statsmodels.tsa.holtwinters.ExponentialSmoothing.fit`.\\n        ', 'mul', 'add', '\\n    Exponential smoothing etna model.\\n\\n    Restricted version of HoltWinters model.\\n\\n    Notes\\n    -----\\n    We use :py:class:`statsmodels.tsa.holtwinters.ExponentialSmoothing` model from statsmodels package.\\n    They implement :py:class:`statsmodels.tsa.holtwinters.SimpleExpSmoothing` model\\n    as a restricted version of :py:class:`~statsmodels.tsa.holtwinters.ExponentialSmoothing` model.\\n    ', 'estimated', '\\n        Init Exponential smoothing model with given params.\\n\\n        Parameters\\n        ----------\\n        initialization_method:\\n            Method for initialize the recursions. One of:\\n\\n            * None\\n\\n            * \\'estimated\\'\\n\\n            * \\'heuristic\\'\\n\\n            * \\'legacy-heuristic\\'\\n\\n            * \\'known\\'\\n\\n            None defaults to the pre-0.12 behavior where initial values\\n            are passed as part of ``fit``. If any of the other values are\\n            passed, then the initial values must also be set when constructing\\n            the model. If \\'known\\' initialization is used, then ``initial_level``\\n            must be passed, as well as ``initial_trend`` and ``initial_seasonal`` if\\n            applicable. Default is \\'estimated\\'. \"legacy-heuristic\" uses the same\\n            values that were used in statsmodels 0.11 and earlier.\\n        initial_level:\\n            The initial level component. Required if estimation method is \"known\".\\n            If set using either \"estimated\" or \"heuristic\" this value is used.\\n            This allows one or more of the initial values to be set while\\n            deferring to the heuristic for others or estimating the unset\\n            parameters.\\n        smoothing_level:\\n            The alpha value of the simple exponential smoothing, if the value\\n            is set then this value will be used as the value.\\n        fit_kwargs:\\n            Additional parameters for calling :py:meth:`statsmodels.tsa.holtwinters.ExponentialSmoothing.fit`.\\n        '], 'from': [], 'import': []}\n",
      "{'FunctionDef': <8x8 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 8 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['StackingEnsemble is a pipeline that forecast future using the metamodel to combine the forecasts of the base models.\\n\\n    Examples\\n    --------\\n    >>> from etna.datasets import generate_ar_df\\n    >>> from etna.datasets import TSDataset\\n    >>> from etna.ensembles import VotingEnsemble\\n    >>> from etna.models import NaiveModel\\n    >>> from etna.models import MovingAverageModel\\n    >>> from etna.pipeline import Pipeline\\n    >>> import pandas as pd\\n    >>> pd.options.display.float_format = \\'{:,.2f}\\'.format\\n    >>> df = generate_ar_df(periods=100, start_time=\"2021-06-01\", ar_coef=[0.8], n_segments=3)\\n    >>> df_ts_format = TSDataset.to_dataset(df)\\n    >>> ts = TSDataset(df_ts_format, \"D\")\\n    >>> ma_pipeline = Pipeline(model=MovingAverageModel(window=5), transforms=[], horizon=7)\\n    >>> naive_pipeline = Pipeline(model=NaiveModel(lag=10), transforms=[], horizon=7)\\n    >>> ensemble = StackingEnsemble(pipelines=[ma_pipeline, naive_pipeline])\\n    >>> _ = ensemble.fit(ts=ts)\\n    >>> forecast = ensemble.forecast()\\n    >>> forecast[:,:,\"target\"]\\n    segment    segment_0 segment_1 segment_2\\n    feature       target    target    target\\n    timestamp\\n    2021-09-09      0.70      1.47      0.20\\n    2021-09-10      0.62      1.53      0.26\\n    2021-09-11      0.50      1.78      0.36\\n    2021-09-12      0.37      1.88      0.21\\n    2021-09-13      0.46      1.87      0.25\\n    2021-09-14      0.44      1.49      0.21\\n    2021-09-15      0.36      1.56      0.30\\n    ', 'all', 'Init StackingEnsemble.\\n\\n        Parameters\\n        ----------\\n        pipelines:\\n            List of pipelines that should be used in ensemble.\\n        final_model:\\n            Regression model with fit/predict interface which will be used to combine the base estimators.\\n        n_folds:\\n            Number of folds to use in the backtest. Backtest is not used for model evaluation but for prediction.\\n        features_to_use:\\n            Features except the forecasts of the base models to use in the ``final_model``.\\n        n_jobs:\\n            Number of jobs to run in parallel.\\n        joblib_params:\\n            Additional parameters for :py:class:`joblib.Parallel`.\\n\\n        Raises\\n        ------\\n        ValueError:\\n            If the number of the pipelines is less than 2 or pipelines have different horizons.\\n        ', 'multiprocessing', 'c', \"Return all the features from ``features_to_use`` which can be obtained from base models' forecasts.\", 'feature', 'fold_number', 'all', 'target', 'Features ', ' are not found and will be dropped!', \"Feature list is passed in the wrong format.Only the base models' forecasts will be used for the final forecast.\", 'Get forecasts from backtest for given pipeline.', 'Fit the ensemble.\\n\\n        Parameters\\n        ----------\\n        ts:\\n            TSDataset to fit ensemble.\\n\\n        Returns\\n        -------\\n        self:\\n            Fitted ensemble.\\n        ', 'StackingEnsemble', 'Prepare features for the ``final_model``.', 'StackingEnsemble is not fitted! Fit the StackingEnsemble before calling forecast method.', 'target', 'target', 'regressor_target_', 'feature', 'target', 'segment', 'timestamp', 'target', 'target', 'target', \"Make predictions.\\n\\n        Compute the combination of pipelines' forecasts using ``final_model``\\n        \", 'Something went wrong, ts is None!', 'Ensemble ', \" doesn't support prediction intervals!\"], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['target', 'target', 'macro', 'horizon', 'D', '1', 'decoder_real', 'decoder_target', 'segment', '1', 'segment', '1', 'decoder_real', 'decoder_target', 'decoder_target', 'decoder_target', 'decoder_real', 'decoder_real', 'segment', 'segment', 'target', 'decoder_target', 'target', 'decoder_target', 'decoder_real', 'decoder_target', 'segment', 'A', 'decoder_target'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['In-shop clothes retrieval dataset.\\n\\n    Test part of the dataset is obtained by joining gallery and query samples.\\n\\n    See: https://mmlab.ie.cuhk.edu.hk/projects/DeepFashion/InShopRetrieval.html\\n\\n    Args:\\n        root: Dataset root (with img subfolder and list_eval_partition.txt).\\n        train: Whether to use train or test part of the dataset.\\n\\n    ', 'img', 'list_eval_partition.txt', '52712', 'Unexpected labels file. Make sure you use original labels file.', 'image_name item_id evaluation_status', 'Unexpected labels file. Make sure you use original labels file.', 'train', 'train', 'Whether dataset is classification or matching.', 'Whether dataset is for open-set or closed-set classification.', 'Get dataset labels array.\\n\\n        Labels are integers in the range [0, N-1].\\n\\n        ', 'Get element of the dataset.\\n\\n        Returns tuple (image, label).\\n\\n        '], 'from': [], 'import': []}\n",
      "{'FunctionDef': <22x22 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 22 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Normal distribution.\\n\\n    Variances are parametrized as input of :meth:`positive` function.\\n    ', 'spherical', 'invlin', 'Get Normal distribution parameters.\\n\\n        Args:\\n            dim: Point dimension.\\n            spherical: Whether distribution is on sphere or R^n.\\n            covariance: Type of covariance matrix (`diagonal`, `spherical` or number).\\n            parametrization: Type of parametrization (`exp` or `invlin`).\\n            min_logivar: Minimum value of log inverse variance (log concentration).\\n            max_logivar: Maximum value of log inverse variance (log concentration).\\n        ', 'dim', 'spherical', 'covariance', 'parametrization', 'min_logivar', 'max_logivar', 'covariance', 'diagonal', 'spherical', 'covariance', 'Unknown covariance type: {}', 'covariance', 'max_logivar', 'max_logivar', 'min_logivar', 'min_logivar', 'parametrization', 'Point dimension.', 'dim', 'Whether distribution is on sphere or R^n.', 'spherical', 'Whether distribution has builtin confidence estimation or not.', 'Number of distribution parameters.', 'dim', 'covariance', 'covariance', 'spherical', 'covariance', 'diagonal', 'dim', 'Returns dict with distribution parameters.', 'log_probs', 'mean', 'covariance', 'Returns vector from parameters dict.', 'log_probs', 'mean', 'covariance', 'Expected dict with keys {}.', 'covariance', 'log_probs', 'mean', 'Create and return normalization layer.', 'dim', 'Extract component log probs, means and hidden variances from parameters.', 'Wrong number of parameters: {} != {}.', 'dim', 'covariance', 'covariance', 'Join different GMM parameters into vectors.', 'covariance', 'covariance', 'Covariance value changed: {} != {}.', 'Sample from distributions.\\n\\n        Args:\\n            parameters: Distribution parameters with shape (..., K).\\n            size: Sample size (output shape without dimension). Parameters must be broadcastable to the given size.\\n              If not provided, output shape will be consistent with parameters.\\n\\n        Returns:\\n            Tuple of:\\n                - Samples with shape (..., D).\\n                - Choosen components with shape (...).\\n        ', 'Extract mean for each distribution.\\n\\n        Args:\\n            parameters: Distribution parameters with shape (..., K).\\n\\n        Returns:\\n            Distribution means with shape (..., D).\\n        ', 'Get modes of distributions.\\n\\n        Args:\\n            parameters: Distribution parameters with shape (..., K).\\n\\n        Returns:\\n            Tuple of mode log probabilities with shape (..., C) and modes with shape (..., C, D).\\n        ', 'Get confidence score for each element of the batch.\\n\\n        Args:\\n            parameters: Distribution parameters with shape (..., K).\\n\\n        Returns:\\n            Confidences with shape (...).\\n        ', 'Get KL-divergence between distributions and standard normal distribution.\\n\\n        Args:\\n            parameters: Distribution parameters with shape (..., K).\\n\\n        Returns:\\n            KL-divergence of each distribution with shape (...).\\n        ', 'covariance', 'spherical', 'covariance', 'diagonal', 'Compute log density for all points.\\n\\n        Args:\\n            parameters: Distribution parameters with shape (..., K).\\n            points: Points for density evaluation with shape (..., D).\\n\\n        Returns:\\n            Log probabilities with shape (...).\\n        ', 'dim', 'covariance', 'spherical', 'covariance', 'covariance', 'diagonal', 'Compute Log Mutual Likelihood Score (MLS) for pairs of distributions.\\n\\n\\n        Args:\\n            parameters1: Distribution parameters with shape (..., K).\\n            parameters2: Distribution parameters with shape (..., K).\\n\\n        Returns:\\n            MLS scores with shape (...).\\n        ', \"Compute product of two densities.\\n\\n        Returns:\\n            Tuple of new distribution class and it's parameters.\\n        \", 'covariance', 'covariance', 'spherical', 'covariance', 'covariance', 'spherical', 'Compute useful statistics for logging.\\n\\n        Args:\\n            parameters: Distribution parameters with shape (..., K).\\n\\n        Returns:\\n            Dictionary with floating-point statistics values.\\n        ', 'gmm_std/mean', 'gmm_std/std', 'Compute Log MLS for unimodal distributions.\\n\\n        For implementation details see \"Probabilistic Face Embeddings\":\\n        https://openaccess.thecvf.com/content_ICCV_2019/papers/Shi_Probabilistic_Face_Embeddings_ICCV_2019_paper.pdf\\n        ', 'dim'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <6x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['Create a constant dataset with little noise.', '2020-01-01', 'D', 'target', 'D', \"Test that Holt-Winters' models make predictions in simple case.\", 'model', \"Test that Holt-Winters' models make predictions with exog with warning.\", 'This model does not work with exogenous features and regressors', 'model', \"Test that Holt-Winters' models works good with almost constant dataset.\", 'macro', 'model', 'Check that get_model method throws an error if per-segment model is not fitted yet.', 'Can not get the dict with base models, the model is not fitted!', 'etna_model_class', 'Check that get_model method returns dict of objects of SARIMAX class.', 'etna_model_class,expected_class'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Generates series of lags from given dataframe.', \"Create instance of LagTransform.\\n\\n        Parameters\\n        ----------\\n        in_column:\\n            name of processed column\\n        lags:\\n            int value or list of values for lags computation; if int, generate range of lags from 1 to given value\\n        out_column:\\n            base for the name of created columns;\\n\\n            * if set the final name is '{out_column}_{lag_number}';\\n\\n            * if don't set, name will be ``transform.__repr__()``,\\n              repr will be made for transform that creates exactly this column\\n\\n        Raises\\n        ------\\n        ValueError:\\n            if lags value contains non-positive values\\n        \", ' works only with positive lags values, ', ' given', ' works only with positive lags values', '_', 'Fit method does nothing and is kept for compatibility.\\n\\n        Parameters\\n        ----------\\n        df:\\n            dataframe with data.\\n\\n        Returns\\n        -------\\n        result: LagTransform\\n        ', 'LagTransform', 'Add lags to the dataset.\\n\\n        Parameters\\n        ----------\\n        df:\\n            dataframe with data to transform.\\n\\n        Returns\\n        -------\\n        result: pd.Dataframe\\n            transformed dataframe\\n        ', 'segment'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['Shift values for steps_number steps.', 'Multiply arguments.'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['_OneSegmentTrendTransform adds trend as a feature.', 'Init _OneSegmentTrendTransform.\\n\\n        Parameters\\n        ----------\\n        in_column:\\n            name of column to apply transform to\\n        out_column:\\n            name of added column\\n        change_point_model:\\n            model to get trend change points\\n        detrend_model:\\n            model to get trend from data\\n        change_point_model_predict_params:\\n            params for ``change_point_model.predict`` method\\n        ', 'Add column with trend, got from the detrend_model.\\n\\n        Parameters\\n        ----------\\n        df:\\n            data to get trend from\\n\\n        Returns\\n        -------\\n        pd.DataFrame:\\n            df with trend column\\n        ', 'Inverse transform dataframe.\\n\\n        Parameters\\n        ----------\\n        df:\\n            one segment dataframe\\n\\n        Returns\\n        -------\\n        pd.DataFrame:\\n            given dataframe\\n        ', \"_TrendTransform adds trend as a feature. Creates column '<in_column>_trend'.\", 'Init _TrendTransform.\\n\\n        Parameters\\n        ----------\\n        in_column:\\n            name of column to apply transform to\\n        out_column:\\n            name of added column\\n        change_point_model:\\n            model to get trend change points\\n        detrend_model:\\n            model to get trend in data\\n        change_point_model_predict_params:\\n            params for ``change_point_model.predict`` method\\n        ', 'TrendTransform adds trend as a feature.\\n\\n    TrendTransform uses uses :py:class:`ruptures.detection.Binseg` model as a change point detection model\\n    in _TrendTransform.\\n\\n    Warning\\n    -------\\n    This transform can suffer from look-ahead bias. For transforming data at some timestamp\\n    it uses information from the whole train part.\\n    ', 'ar', 'Init TrendTransform.\\n\\n        Parameters\\n        ----------\\n        in_column:\\n            name of column to apply transform to\\n        out_column:\\n            name of added column.\\n            If not given, use ``self.__repr__()``\\n        detrend_model:\\n            model to get trend in data\\n        model:\\n            binseg segment model, [\"l1\", \"l2\", \"rbf\",...]. Not used if \\'custom_cost\\' is not None.\\n        custom_cost:\\n            binseg custom cost function\\n        min_size:\\n            minimum segment length necessary to decide it is a stable trend segment\\n        jump:\\n            jump value can speed up computations: if ``jump==k``,\\n            the algo will use every k-th value for change points search.\\n        n_bkps:\\n            number of change points to find\\n        pen:\\n            penalty value (>0)\\n        epsilon:\\n            reconstruction budget (>0)\\n        '], 'from': [], 'import': []}\n",
      "{'FunctionDef': <7x7 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['segment_0', 'segment_1', 'x, y, expected', 'Check that outliers in one series computation works correctly.', 'window_size,n_neighbors,distance_threshold,expected', '1', '2', 'Check if get_anomalies_density works correctly.', '1', '2', '2021-01-11', '2021-01-09', '2021-01-27', 'feature', '1', '2', '2021-01-08', '2021-01-26'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <13x13 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 13 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['2020-01-01', 'D', 'timestamp', 'segment', 'target', 'segment_1', 'timestamp', 'segment', 'target', 'segment_2', 'timestamp', 'segment', 'exog_1', 'exog_2', 'segment_1', 'timestamp', 'segment', 'exog_1', 'exog_2', 'segment_2', 'D', 'Test that transform is created with include.', 'exog_1', 'exog_2', 'Test that transform is created with exclude.', 'exog_1', 'exog_2', 'Test that transform is not created with include and exclude.', 'There should be exactly one option set: include or exclude', 'exog_1', 'exog_2', 'Test that transform is not created without include and exclude.', 'There should be exactly one option set: include or exclude', 'Test that transform remains only features in include.', 'feature', 'include', 'target', 'exog_1', 'exog_1', 'exog_2', 'target', 'Test that transform removes only features in exclude.', 'feature', 'exclude, expected_columns', 'target', 'exog_1', 'exog_2', 'target', 'exog_1', 'exog_2', 'exog_1', 'exog_2', 'target', 'target', 'exog_1', 'exog_2', 'Test that transform raises error with non-existent column in include.', 'non-existent-column', 'Features {.*} are not present in the dataset', 'Test that transform raises error with non-existent column in exclude.', 'non-existent-column', 'Features {.*} are not present in the dataset', 'feature', 'return_features', 'columns, saved_columns', 'target', 'target', 'exog_1', 'exog_2', 'exog_1', 'exog_2', 'target', 'exog_1', 'exog_2', 'target', 'exog_1', 'exog_2', 'feature', 'return_features', 'columns, saved_columns', 'target', 'exog_1', 'exog_2', 'target', 'exog_1', 'exog_2', 'exog_1', 'exog_2', 'target', 'target', 'exog_1', 'exog_2', 'feature', 'columns, return_features, expected_columns', 'exog_1', 'target', 'exog_2', 'target', 'exog_1', 'exog_2', 'target', 'exog_1', 'target', 'exog_2', 'target', 'exog_2', 'exog_1', 'exog_1', 'exog_2', 'exog_1', 'target', 'exog_2', 'exog_1', 'exog_2', 'target', 'target', 'exog_1', 'exog_2', 'exog_1', 'target', 'exog_2', 'target', 'exog_1', 'exog_2', 'feature', 'columns, return_features, expected_columns', 'exog_1', 'target', 'exog_2', 'target', 'exog_1', 'target', 'exog_2', 'target', 'target', 'exog_1', 'exog_2', 'exog_1', 'target', 'exog_2', 'exog_1', 'exog_2', 'exog_1', 'exog_2', 'target', 'exog_1', 'exog_2', 'exog_1', 'target', 'exog_2', 'target', 'exog_1', 'exog_2', 'exog_1', 'target', 'exog_2'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Standardize features by removing the mean and scaling to unit variance.\\n\\n    Uses :py:class:`sklearn.preprocessing.StandardScaler` inside.\\n\\n    Warning\\n    -------\\n    This transform can suffer from look-ahead bias. For transforming data at some timestamp\\n    it uses information from the whole train part.\\n    ', 'per-segment', '\\n        Init StandardScalerPreprocess.\\n\\n        Parameters\\n        ----------\\n        in_column:\\n            columns to be scaled, if None - all columns will be scaled.\\n        inplace:\\n            features are changed by scaled.\\n        out_column:\\n            base for the names of generated columns, uses ``self.__repr__()`` if not given.\\n        with_mean:\\n            if True, center the data before scaling.\\n        with_std:\\n            if True, scale the data to unit standard deviation.\\n        mode:\\n            \"macro\" or \"per-segment\", way to transform features over segments.\\n\\n            * If \"macro\", transforms features globally, gluing the corresponding ones for all segments.\\n\\n            * If \"per-segment\", transforms features for each segment separately.\\n\\n        Raises\\n        ------\\n        ValueError:\\n            if incorrect mode given\\n        ', 'Scale features using statistics that are robust to outliers.\\n\\n    Uses :py:class:`sklearn.preprocessing.RobustScaler` inside.\\n\\n    Warning\\n    -------\\n    This transform can suffer from look-ahead bias. For transforming data at some timestamp\\n    it uses information from the whole train part.\\n    ', 'per-segment', '\\n        Init RobustScalerPreprocess.\\n\\n        Parameters\\n        ----------\\n        in_column:\\n            columns to be scaled, if None - all columns will be scaled.\\n        inplace:\\n            features are changed by scaled.\\n        out_column:\\n            base for the names of generated columns, uses ``self.__repr__()`` if not given.\\n        with_centering:\\n            if True, center the data before scaling.\\n        with_scaling:\\n            if True, scale the data to interquartile range.\\n        quantile_range:\\n            quantile range.\\n        unit_variance:\\n            If True, scale data so that normally distributed features have a variance of 1.\\n\\n            In general, if the difference between the x-values of q_max and q_min for a standard normal\\n            distribution is greater than 1, the dataset will be scaled down. If less than 1,\\n            the dataset will be scaled up.\\n        mode:\\n            \"macro\" or \"per-segment\", way to transform features over segments.\\n\\n            * If \"macro\", transforms features globally, gluing the corresponding ones for all segments.\\n\\n            * If \"per-segment\", transforms features for each segment separately.\\n\\n        Raises\\n        ------\\n        ValueError:\\n            if incorrect mode given\\n        ', 'Transform features by scaling each feature to a given range.\\n\\n    Uses :py:class:`sklearn.preprocessing.MinMaxScaler` inside.\\n\\n    Warning\\n    -------\\n    This transform can suffer from look-ahead bias. For transforming data at some timestamp\\n    it uses information from the whole train part.\\n    ', 'per-segment', '\\n        Init MinMaxScalerPreprocess.\\n\\n        Parameters\\n        ----------\\n        in_column:\\n            columns to be scaled, if None - all columns will be scaled.\\n        inplace:\\n            features are changed by scaled.\\n        out_column:\\n            base for the names of generated columns, uses ``self.__repr__()`` if not given.\\n        feature_range:\\n            desired range of transformed data.\\n        clip:\\n            set to True to clip transformed values of held-out data to provided feature range.\\n        mode:\\n            \"macro\" or \"per-segment\", way to transform features over segments.\\n\\n            * If \"macro\", transforms features globally, gluing the corresponding ones for all segments.\\n\\n            * If \"per-segment\", transforms features for each segment separately.\\n\\n        Raises\\n        ------\\n        ValueError:\\n            if incorrect mode given\\n        ', 'Scale each feature by its maximum absolute value.\\n\\n    Uses :py:class:`sklearn.preprocessing.MaxAbsScaler` inside.\\n\\n    Warning\\n    -------\\n    This transform can suffer from look-ahead bias. For transforming data at some timestamp\\n    it uses information from the whole train part.\\n    ', 'per-segment', 'Init MinMaxScalerPreprocess.\\n\\n        Parameters\\n        ----------\\n        in_column:\\n            columns to be scaled, if None - all columns will be scaled.\\n        inplace:\\n            features are changed by scaled.\\n        out_column:\\n            base for the names of generated columns, uses ``self.__repr__()`` if not given.\\n        mode:\\n            \"macro\" or \"per-segment\", way to transform features over segments.\\n\\n            * If \"macro\", transforms features globally, gluing the corresponding ones for all segments.\\n\\n            * If \"per-segment\", transforms features for each segment separately.\\n\\n        Raises\\n        ------\\n        ValueError:\\n            if incorrect mode given\\n        ', 'MaxAbsScalerTransform', 'MinMaxScalerTransform', 'RobustScalerTransform', 'StandardScalerTransform'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <19x16 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 19 stored elements in Compressed Sparse Row format>, 'ClassDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['CORL', 'DT-D4RL', 'DT', 'halfcheetah-medium-v2', 'cuda', '-', '-', 'PYTHONHASHSEED', 'project', 'group', 'name', 'constant', 'rewards', 'Processing trajectories', 'observations', 'observations', 'actions', 'actions', 'rewards', 'rewards', 'terminals', 'timeouts', 'returns', 'rewards', 'obs_mean', 'obs_std', 'traj_lens', 'observations', 'observations', 'obs_mean', 'obs_std', 'traj_lens', 'traj_lens', 'observations', 'actions', 'returns', 'rewards', 'causal_mask', 'cpu', 'Checkpoints path: ', 'config.yaml', 'w', 'Total parameters: ', 'Training', 'none', 'train_loss', 'learning_rate', 'Evaluation', 'eval/', '_return_mean', 'eval/', '_return_std', 'eval/', '_normalized_score_mean', 'eval/', '_normalized_score_std', 'model_state', 'state_mean', 'state_std', 'dt_checkpoint.pt', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <3x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['T', 'LocalRunner for one threaded run.', 'Call given ``func`` with ``*args`` and ``**kwargs``.', 'ParallelLocalRunner for multiple parallel runs with joblib.\\n\\n    Notes\\n    -----\\n    Global objects behavior could be different while parallel usage because platform dependent new process start.\\n    Be sure that new process is started with ``fork`` via ``multiprocessing.set_start_method``.\\n    If it\\'s not possible you should try define all globals before ``if __name__ == \"__main__\"`` scope.\\n    ', 'multiprocessing', 'c', 'Init ParallelLocalRunner.\\n\\n        Parameters\\n        ----------\\n        n_jobs:\\n            number of parallel jobs to use\\n        backend:\\n            joblib backend to use\\n        mmap_mode:\\n            joblib mmap mode\\n        joblib_params:\\n            joblib additional params\\n        ', 'Call given ``func`` with Joblib and ``*args`` and ``**kwargs``.'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <9x9 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 9 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Verification dataset based on dataset with labels.\\n\\n    Args:\\n        dataset: Classification dataset to sample pairs from.\\n        size_factor: The number of pairs in verification dataset is\\n            `2 * N * size_factor`, where N is the number of images.\\n        seed: Random seed.\\n    ', 'Whether dataset is classification or verification.', 'Whether dataset is for open-set or closed-set classification.', 'Whether dataset assigns quality score to each sample or not.', 'Get dataset labels array.\\n\\n        Labels are 0/1 integers.\\n\\n        ', 'Get element of the dataset.\\n\\n        Returns ((image1, image2), label).\\n\\n        ', 'Generate random permutation such that p[i] != i.', 'Sample pairs of samples with the same label.\\n\\n        Output number of pairs is len(labels) * size_factor.\\n        ', 'Sample pairs with different labels.\\n\\n        Output number of pairs is len(labels) * size_factor.\\n        '], 'from': [], 'import': []}\n",
      "{'FunctionDef': <7x7 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['segment', 'timestamp', 'target', '1/1/2018', 'segment', 'timestamp', 'target', '1/1/2018', 'D', 'use_box_cox', 'box_cox_bounds', 'use_trend', 'use_damped_trend', 'seasonal_periods', 'use_arma_errors', 'show_warnings', 'n_jobs', 'multiprocessing_start_method', 'context', 'use_box_cox = None, ', 'box_cox_bounds = None, ', 'use_trend = None, ', 'use_damped_trend = None, ', 'seasonal_periods = None, ', 'use_arma_errors = None, ', 'show_warnings = None, ', 'n_jobs = None, ', 'multiprocessing_start_method = None, ', 'context = None', '(', ', )', 'model_class, model_class_repr', 'TBATSModel', 'BATSModel', 'model is not fitted!', 'model', '1d', 'target', 'model', 'macro', 'model', 'target_0.025', 'target_0.975', 'target', 'target_0.975', 'target_0.025', 'model'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Normalize gradient value using running gradient norm mean.\\n\\n    Outputs:\\n        Normalized gradient norm.\\n    ', 'is_first', 'moving_norm'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['TSDataset', 'target', '\\n    Get point outliers in time series using median model (estimation model-based method).\\n\\n    Outliers are all points deviating from the median by more than alpha * std,\\n    where std is the sample variance in the window.\\n\\n    Parameters\\n    ----------\\n    ts:\\n        TSDataset with timeseries data\\n    in_column:\\n        name of the column in which the anomaly is searching\\n    window_size:\\n        number of points in the window\\n    alpha:\\n        coefficient for determining the threshold\\n\\n    Returns\\n    -------\\n    :\\n        dict of outliers in format {segment: [outliers_timestamps]}\\n    ', 'timestamp'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <16x16 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 16 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['2020-01-01', '2020-01-01', 'target', 'regressor_a', 'D', 'timestamp', '2020-01-01', '2020-01-15', 'D', 'target', 'timestamp', 'segment', 'segment_1', 'segment', 'segment_2', 'timestamp', '2020-01-08 22:15', '2020-01-10', 'H', 'target', 'timestamp', 'segment', 'segment_1', 'segment', 'segment_2', 'timestamp', '2020-11-25 22:30', '2020-11-26 02:15', '15MIN', 'target', 'timestamp', 'segment', 'segment_1', 'segment', 'segment_2', 'holiday', 'holiday', 'segment', 'regressor_holidays', 'segment', 'regressor_holidays', 'regressor_holidays', 'category', 'regressor_holidays', 'segment', 'regressor_holidays', 'regressor_holidays', 'category', 'regressor_holidays', 'segment', 'regressor_holidays', 'regressor_holidays', 'category', 'regressor_holidays', 'segment', 'regressor_holidays', 'iso_code,answer', 'RUS', 'US', 'regressor_holidays', 'segment', 'regressor_holidays', 'iso_code,answer', 'RUS', 'US', 'regressor_holidays', 'segment', 'regressor_holidays', 'iso_code,answer', 'RUS', 'US', 'Frequency of data should be no more than daily.', 'index', '2020-11-25 22:30', '2020-12-11', '1D 15MIN', '2019-11-25', '2021-02-25', 'M', 'regressor_holidays', 'expected_regressors', 'regressor_holidays'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['.jpg', '.jpeg', '.png', '.JPEG', 'Scale dataset images', 'src', 'Images root', 'dst', 'Target root', '--center-crop', 'Crop output images to center', 'store_true', '--size', 'Size of the minimal side or coma-separated width and height', '--num-workers', 'Number of workers', ',', ',', '*', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <9x9 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 9 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Weights&Biases logger.', '', \"\\n        Create instance of WandbLogger.\\n\\n        Parameters\\n        ----------\\n        name:\\n            Wandb run name.\\n        entity:\\n            An entity is a username or team name where you're sending runs.\\n        project:\\n            The name of the project where you're sending the new run\\n        job_type:\\n            Specify the type of run, which is useful when you're grouping runs together\\n            into larger experiments using group.\\n        group:\\n            Specify a group to organize individual runs into a larger experiment.\\n        tags:\\n            A list of strings, which will populate the list of tags on this run in the UI.\\n        plot:\\n            Indicator for making and sending plots.\\n        table:\\n            Indicator for making and sending tables.\\n        name_prefix:\\n            Prefix for the name field.\\n        config:\\n            This sets `wandb.config`, a dictionary-like object for saving inputs to your job,\\n            like hyperparameters for a model or settings for a data preprocessing job.\\n        \", 'utf8', '=\\n', 'PLWandbLogger', '\\n        Log any event.\\n\\n        e.g. \"Fitted segment segment_name\" to stderr output.\\n\\n        Parameters\\n        ----------\\n        msg:\\n            Message or dict to log\\n        kwargs:\\n            Parameters for changing additional info in log message\\n\\n        Notes\\n        -----\\n        We log dictionary to wandb only.\\n        ', 'TSDataset', '\\n        Write metrics to logger.\\n\\n        Parameters\\n        ----------\\n        ts:\\n            TSDataset to with backtest data\\n        metrics_df:\\n            Dataframe produced with :py:meth:`etna.pipeline.Pipeline._get_backtest_metrics`\\n        forecast_df:\\n            Forecast from backtest\\n        fold_info_df:\\n            Fold information from backtest\\n        ', 'metrics', 'forecast', 'fold_info', 'backtest', '\\n        Backtest metrics from one fold to logger.\\n\\n        Parameters\\n        ----------\\n        metrics:\\n            Dataframe with metrics from backtest fold\\n        forecast:\\n            Dataframe with forecast\\n        test:\\n            Dataframe with ground truth\\n        ', 'segment', 'metrics', 'forecast', 'test', \"Start experiment.\\n\\n        Complete logger initialization or reinitialize it before the next experiment with the same name.\\n\\n        Parameters\\n        ----------\\n        job_type:\\n            Specify the type of run, which is useful when you're grouping runs together\\n            into larger experiments using group.\\n        group:\\n            Specify a group to organize individual runs into a larger experiment.\\n        \", 'Reinit experiment.', 'thread', 'Finish experiment.', 'Pytorch lightning loggers.', 'Init experiment.'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['examples', 'mape,hist', 'r', 'source', 'cells', 'w', '\\n', 'poetry run codespell -L ', ' ', '*.ipynb', 'Skipping ', 'Running ', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Class holding per segment :py:class:`sklearn.linear_model.LinearRegression`.', '\\n        Create instance of LinearModel with given parameters.\\n\\n        Parameters\\n        ----------\\n        fit_intercept:\\n            Whether to calculate the intercept for this model. If set to False, no intercept will be used in\\n            calculations (i.e. data is expected to be centered).\\n        ', 'Class holding per segment :py:class:`sklearn.linear_model.ElasticNet`.', '\\n        Create instance of ElasticNet with given parameters.\\n\\n        Parameters\\n        ----------\\n        alpha:\\n            Constant that multiplies the penalty terms. Defaults to 1.0.\\n            ``alpha = 0`` is equivalent to an ordinary least square, solved by the LinearRegression object.\\n            For numerical reasons, using ``alpha = 0`` with the Lasso object is not advised.\\n            Given this, you should use the :py:class:`~etna.models.linear.LinearPerSegmentModel` object.\\n        l1_ratio:\\n            The ElasticNet mixing parameter, with ``0 <= l1_ratio <= 1``.\\n\\n            * For ``l1_ratio = 0`` the penalty is an L2 penalty.\\n\\n            * For ``l1_ratio = 1`` it is an L1 penalty.\\n\\n            * For ``0 < l1_ratio < 1``, the penalty is a combination of L1 and L2.\\n\\n        fit_intercept:\\n            Whether to calculate the intercept for this model. If set to False, no intercept will be used in\\n            calculations (i.e. data is expected to be centered).\\n        ', 'Class holding :py:class:`sklearn.linear_model.LinearRegression` for all segments.', '\\n        Create instance of LinearModel with given parameters.\\n\\n        Parameters\\n        ----------\\n        fit_intercept:\\n            Whether to calculate the intercept for this model. If set to False, no intercept will be used in\\n            calculations (i.e. data is expected to be centered).\\n        ', 'Class holding :py:class:`sklearn.linear_model.ElasticNet` for all segments.', '\\n        Create instance of ElasticNet with given parameters.\\n\\n        Parameters\\n        ----------\\n        alpha:\\n            Constant that multiplies the penalty terms. Defaults to 1.0.\\n            ``alpha = 0`` is equivalent to an ordinary least square, solved by the LinearRegression object.\\n            For numerical reasons, using ``alpha = 0`` with the Lasso object is not advised.\\n            Given this, you should use the :py:class:`~etna.models.linear.LinearMultiSegmentModel` object.\\n        l1_ratio:\\n            The ElasticNet mixing parameter, with ``0 <= l1_ratio <= 1``.\\n\\n            * For ``l1_ratio = 0`` the penalty is an L2 penalty.\\n\\n            * For ``l1_ratio = 1`` it is an L1 penalty.\\n\\n            * For ``0 < l1_ratio < 1``, the penalty is a combination of L1 and L2.\\n\\n        fit_intercept:\\n            Whether to calculate the intercept for this model. If set to False, no intercept will be used in\\n            calculations (i.e. data is expected to be centered).\\n        '], 'from': [], 'import': []}\n",
      "{'FunctionDef': <9x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 9 stored elements in Compressed Sparse Row format>, 'ClassDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Silent', 'category', '\\n        Fit Catboost model.\\n\\n        Parameters\\n        ----------\\n        df:\\n            Features dataframe\\n        regressors:\\n            List of the columns with regressors(ignored in this model)\\n\\n        Returns\\n        -------\\n        :\\n            Fitted model\\n        ', 'timestamp', 'target', 'target', 'category', '_CatBoostAdapter', '\\n        Compute predictions from a Catboost model.\\n\\n        Parameters\\n        ----------\\n        df:\\n            Features dataframe\\n\\n        Returns\\n        -------\\n        :\\n            Array with predictions\\n        ', 'timestamp', 'target', 'Get internal catboost.CatBoostRegressor model that is used inside etna class.\\n\\n        Returns\\n        -------\\n        result:\\n           Internal model\\n        ', 'Class for holding per segment Catboost model.\\n\\n    Examples\\n    --------\\n    >>> from etna.datasets import generate_periodic_df\\n    >>> from etna.datasets import TSDataset\\n    >>> from etna.models import CatBoostPerSegmentModel\\n    >>> from etna.transforms import LagTransform\\n    >>> classic_df = generate_periodic_df(\\n    ...     periods=100,\\n    ...     start_time=\"2020-01-01\",\\n    ...     n_segments=4,\\n    ...     period=7,\\n    ...     sigma=3\\n    ... )\\n    >>> df = TSDataset.to_dataset(df=classic_df)\\n    >>> ts = TSDataset(df, freq=\"D\")\\n    >>> horizon = 7\\n    >>> transforms = [\\n    ...     LagTransform(in_column=\"target\", lags=[horizon, horizon+1, horizon+2])\\n    ... ]\\n    >>> ts.fit_transform(transforms=transforms)\\n    >>> future = ts.make_future(horizon)\\n    >>> model = CatBoostPerSegmentModel()\\n    >>> model.fit(ts=ts)\\n    CatBoostPerSegmentModel(iterations = None, depth = None, learning_rate = None,\\n    logging_level = \\'Silent\\', l2_leaf_reg = None, thread_count = None, )\\n    >>> forecast = model.forecast(future)\\n    >>> pd.options.display.float_format = \\'{:,.2f}\\'.format\\n    >>> forecast[:, :, \"target\"]\\n    segment    segment_0 segment_1 segment_2 segment_3\\n    feature       target    target    target    target\\n    timestamp\\n    2020-04-10      9.00      9.00      4.00      6.00\\n    2020-04-11      5.00      2.00      7.00      9.00\\n    2020-04-12      0.00      4.00      7.00      9.00\\n    2020-04-13      0.00      5.00      9.00      7.00\\n    2020-04-14      1.00      2.00      1.00      6.00\\n    2020-04-15      5.00      7.00      4.00      7.00\\n    2020-04-16      8.00      6.00      2.00      0.00\\n    ', 'Silent', \"Create instance of CatBoostPerSegmentModel with given parameters.\\n\\n        Parameters\\n        ----------\\n        iterations:\\n            The maximum number of trees that can be built when solving\\n            machine learning problems. When using other parameters that\\n            limit the number of iterations, the final number of trees\\n            may be less than the number specified in this parameter.\\n        depth:\\n            Depth of the tree. The range of supported values depends\\n            on the processing unit type and the type of the selected loss function:\\n\\n            * CPU — Any integer up to 16.\\n\\n            * GPU — Any integer up to 8 pairwise modes (YetiRank, PairLogitPairwise and\\n              QueryCrossEntropy) and up to 16 for all other loss functions.\\n        learning_rate:\\n            The learning rate. Used for reducing the gradient step.\\n            If None the value is defined automatically depending on the number of iterations.\\n        logging_level:\\n            The logging level to output to stdout.\\n            Possible values:\\n\\n            * Silent — Do not output any logging information to stdout.\\n\\n            * Verbose — Output the following data to stdout:\\n\\n                * optimized metric\\n\\n                * elapsed time of training\\n\\n                * remaining time of training\\n\\n            * Info — Output additional information and the number of trees.\\n\\n            * Debug — Output debugging information.\\n\\n        l2_leaf_reg:\\n            Coefficient at the L2 regularization term of the cost function.\\n            Any positive value is allowed.\\n        thread_count:\\n            The number of threads to use during the training.\\n\\n            * For CPU. Optimizes the speed of execution. This parameter doesn't affect results.\\n            * For GPU. The given value is used for reading the data from the hard drive and does\\n              not affect the training.\\n              During the training one main thread and one thread for each GPU are used.\\n        \", 'Class for holding Catboost model for all segments.\\n\\n    Examples\\n    --------\\n    >>> from etna.datasets import generate_periodic_df\\n    >>> from etna.datasets import TSDataset\\n    >>> from etna.models import CatBoostMultiSegmentModel\\n    >>> from etna.transforms import LagTransform\\n    >>> classic_df = generate_periodic_df(\\n    ...     periods=100,\\n    ...     start_time=\"2020-01-01\",\\n    ...     n_segments=4,\\n    ...     period=7,\\n    ...     sigma=3\\n    ... )\\n    >>> df = TSDataset.to_dataset(df=classic_df)\\n    >>> ts = TSDataset(df, freq=\"D\")\\n    >>> horizon = 7\\n    >>> transforms = [\\n    ...     LagTransform(in_column=\"target\", lags=[horizon, horizon+1, horizon+2])\\n    ... ]\\n    >>> ts.fit_transform(transforms=transforms)\\n    >>> future = ts.make_future(horizon)\\n    >>> model = CatBoostMultiSegmentModel()\\n    >>> model.fit(ts=ts)\\n    CatBoostMultiSegmentModel(iterations = None, depth = None, learning_rate = None,\\n    logging_level = \\'Silent\\', l2_leaf_reg = None, thread_count = None, )\\n    >>> forecast = model.forecast(future)\\n    >>> pd.options.display.float_format = \\'{:,.2f}\\'.format\\n    >>> forecast[:, :, \"target\"].round()\\n    segment    segment_0 segment_1 segment_2 segment_3\\n    feature       target    target    target    target\\n    timestamp\\n    2020-04-10      9.00      9.00      4.00      6.00\\n    2020-04-11      5.00      2.00      7.00      9.00\\n    2020-04-12     -0.00      4.00      7.00      9.00\\n    2020-04-13      0.00      5.00      9.00      7.00\\n    2020-04-14      1.00      2.00      1.00      6.00\\n    2020-04-15      5.00      7.00      4.00      7.00\\n    2020-04-16      8.00      6.00      2.00      0.00\\n    ', 'Silent', \"Create instance of CatBoostMultiSegmentModel with given parameters.\\n\\n        Parameters\\n        ----------\\n        iterations:\\n            The maximum number of trees that can be built when solving\\n            machine learning problems. When using other parameters that\\n            limit the number of iterations, the final number of trees\\n            may be less than the number specified in this parameter.\\n        depth:\\n            Depth of the tree. The range of supported values depends\\n            on the processing unit type and the type of the selected loss function:\\n\\n            * CPU — Any integer up to 16.\\n\\n            * GPU — Any integer up to 8 pairwise modes (YetiRank, PairLogitPairwise and\\n              QueryCrossEntropy) and up to 16 for all other loss functions.\\n        learning_rate:\\n            The learning rate. Used for reducing the gradient step.\\n            If None the value is defined automatically depending on the number of iterations.\\n        logging_level:\\n            The logging level to output to stdout.\\n            Possible values:\\n\\n            * Silent — Do not output any logging information to stdout.\\n\\n            * Verbose — Output the following data to stdout:\\n\\n                * optimized metric\\n\\n                * elapsed time of training\\n\\n                * remaining time of training\\n\\n            * Info — Output additional information and the number of trees.\\n\\n            * Debug — Output debugging information.\\n\\n        l2_leaf_reg:\\n            Coefficient at the L2 regularization term of the cost function.\\n            Any positive value is allowed.\\n        thread_count:\\n            The number of threads to use during the training.\\n\\n            * For CPU. Optimizes the speed of execution. This parameter doesn't affect results.\\n            * For GPU. The given value is used for reading the data from the hard drive and does\\n              not affect the training.\\n              During the training one main thread and one thread for each GPU are used.\\n        \", 'Class for holding per segment Catboost model.\\n\\n    Warnings\\n    --------\\n    CatBoostModelPerSegment is deprecated; will be deleted in etna==2.0.\\n    Use etna.models.CatBoostPerSegmentModel instead.\\n\\n    Examples\\n    --------\\n    >>> from etna.datasets import generate_periodic_df\\n    >>> from etna.datasets import TSDataset\\n    >>> from etna.models import CatBoostModelPerSegment\\n    >>> from etna.transforms import LagTransform\\n    >>> classic_df = generate_periodic_df(\\n    ...     periods=100,\\n    ...     start_time=\"2020-01-01\",\\n    ...     n_segments=4,\\n    ...     period=7,\\n    ...     sigma=3\\n    ... )\\n    >>> df = TSDataset.to_dataset(df=classic_df)\\n    >>> ts = TSDataset(df, freq=\"D\")\\n    >>> horizon = 7\\n    >>> transforms = [\\n    ...     LagTransform(in_column=\"target\", lags=[horizon, horizon+1, horizon+2])\\n    ... ]\\n    >>> ts.fit_transform(transforms=transforms)\\n    >>> future = ts.make_future(horizon)\\n    >>> model = CatBoostModelPerSegment()\\n    >>> model.fit(ts=ts)\\n    CatBoostModelPerSegment(iterations = None, depth = None, learning_rate = None,\\n    logging_level = \\'Silent\\', l2_leaf_reg = None, thread_count = None, )\\n    >>> forecast = model.forecast(future)\\n    >>> pd.options.display.float_format = \\'{:,.2f}\\'.format\\n    >>> forecast[:, :, \"target\"]\\n    segment    segment_0 segment_1 segment_2 segment_3\\n    feature       target    target    target    target\\n    timestamp\\n    2020-04-10      9.00      9.00      4.00      6.00\\n    2020-04-11      5.00      2.00      7.00      9.00\\n    2020-04-12      0.00      4.00      7.00      9.00\\n    2020-04-13      0.00      5.00      9.00      7.00\\n    2020-04-14      1.00      2.00      1.00      6.00\\n    2020-04-15      5.00      7.00      4.00      7.00\\n    2020-04-16      8.00      6.00      2.00      0.00\\n    ', 'Silent', \"Create instance of CatBoostModelPerSegment with given parameters.\\n\\n        Parameters\\n        ----------\\n        iterations:\\n            The maximum number of trees that can be built when solving\\n            machine learning problems. When using other parameters that\\n            limit the number of iterations, the final number of trees\\n            may be less than the number specified in this parameter.\\n        depth:\\n            Depth of the tree. The range of supported values depends\\n            on the processing unit type and the type of the selected loss function:\\n\\n            * CPU — Any integer up to 16.\\n\\n            * GPU — Any integer up to 8 pairwise modes (YetiRank, PairLogitPairwise and\\n              QueryCrossEntropy) and up to 16 for all other loss functions.\\n        learning_rate:\\n            The learning rate. Used for reducing the gradient step.\\n            If None the value is defined automatically depending on the number of iterations.\\n        logging_level:\\n            The logging level to output to stdout.\\n            Possible values:\\n\\n            * Silent — Do not output any logging information to stdout.\\n\\n            * Verbose — Output the following data to stdout:\\n\\n                * optimized metric\\n\\n                * elapsed time of training\\n\\n                * remaining time of training\\n\\n            * Info — Output additional information and the number of trees.\\n\\n            * Debug — Output debugging information.\\n\\n        l2_leaf_reg:\\n            Coefficient at the L2 regularization term of the cost function.\\n            Any positive value is allowed.\\n        thread_count:\\n            The number of threads to use during the training.\\n\\n            * For CPU. Optimizes the speed of execution. This parameter doesn't affect results.\\n            * For GPU. The given value is used for reading the data from the hard drive and does\\n              not affect the training.\\n              During the training one main thread and one thread for each GPU are used.\\n        \", 'CatBoostModelPerSegment is deprecated; will be deleted in etna==2.0. Use CatBoostPerSegmentModel instead.', 'Class for holding Catboost model for all segments.\\n\\n    Warnings\\n    --------\\n    CatBoostModelMultiSegment is deprecated; will be deleted in etna==2.0.\\n    Use etna.models.CatBoostMultiSegmentModel instead.\\n\\n    Examples\\n    --------\\n    >>> from etna.datasets import generate_periodic_df\\n    >>> from etna.datasets import TSDataset\\n    >>> from etna.models import CatBoostModelMultiSegment\\n    >>> from etna.transforms import LagTransform\\n    >>> classic_df = generate_periodic_df(\\n    ...     periods=100,\\n    ...     start_time=\"2020-01-01\",\\n    ...     n_segments=4,\\n    ...     period=7,\\n    ...     sigma=3\\n    ... )\\n    >>> df = TSDataset.to_dataset(df=classic_df)\\n    >>> ts = TSDataset(df, freq=\"D\")\\n    >>> horizon = 7\\n    >>> transforms = [\\n    ...     LagTransform(in_column=\"target\", lags=[horizon, horizon+1, horizon+2])\\n    ... ]\\n    >>> ts.fit_transform(transforms=transforms)\\n    >>> future = ts.make_future(horizon)\\n    >>> model = CatBoostModelMultiSegment()\\n    >>> model.fit(ts=ts)\\n    CatBoostModelMultiSegment(iterations = None, depth = None, learning_rate = None,\\n    logging_level = \\'Silent\\', l2_leaf_reg = None, thread_count = None, )\\n    >>> forecast = model.forecast(future)\\n    >>> pd.options.display.float_format = \\'{:,.2f}\\'.format\\n    >>> forecast[:, :, \"target\"].round()\\n    segment    segment_0 segment_1 segment_2 segment_3\\n    feature       target    target    target    target\\n    timestamp\\n    2020-04-10      9.00      9.00      4.00      6.00\\n    2020-04-11      5.00      2.00      7.00      9.00\\n    2020-04-12     -0.00      4.00      7.00      9.00\\n    2020-04-13      0.00      5.00      9.00      7.00\\n    2020-04-14      1.00      2.00      1.00      6.00\\n    2020-04-15      5.00      7.00      4.00      7.00\\n    2020-04-16      8.00      6.00      2.00      0.00\\n    ', 'Silent', \"Create instance of CatBoostModelMultiSegment with given parameters.\\n\\n        Parameters\\n        ----------\\n        iterations:\\n            The maximum number of trees that can be built when solving\\n            machine learning problems. When using other parameters that\\n            limit the number of iterations, the final number of trees\\n            may be less than the number specified in this parameter.\\n        depth:\\n            Depth of the tree. The range of supported values depends\\n            on the processing unit type and the type of the selected loss function:\\n\\n            * CPU — Any integer up to 16.\\n\\n            * GPU — Any integer up to 8 pairwise modes (YetiRank, PairLogitPairwise and\\n              QueryCrossEntropy) and up to 16 for all other loss functions.\\n        learning_rate:\\n            The learning rate. Used for reducing the gradient step.\\n            If None the value is defined automatically depending on the number of iterations.\\n        logging_level:\\n            The logging level to output to stdout.\\n            Possible values:\\n\\n            * Silent — Do not output any logging information to stdout.\\n\\n            * Verbose — Output the following data to stdout:\\n\\n                * optimized metric\\n\\n                * elapsed time of training\\n\\n                * remaining time of training\\n\\n            * Info — Output additional information and the number of trees.\\n\\n            * Debug — Output debugging information.\\n\\n        l2_leaf_reg:\\n            Coefficient at the L2 regularization term of the cost function.\\n            Any positive value is allowed.\\n        thread_count:\\n            The number of threads to use during the training.\\n\\n            * For CPU. Optimizes the speed of execution. This parameter doesn't affect results.\\n            * For GPU. The given value is used for reading the data from the hard drive and does\\n              not affect the training.\\n              During the training one main thread and one thread for each GPU are used.\\n        \", 'CatBoostModelMultiSegment is deprecated; will be deleted in etna==2.0. Use CatBoostMultiSegmentModel instead.'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['Test StackingEnsemble behavior in case of invalid pipelines number.', 'At least two pipelines are expected.', 'Check that StackingEnsemble._get horizon works correctly in case of valid pipelines list.', 'Check that StackingEnsemble._get horizon works correctly in case of invalid pipelines list.', 'All the pipelines should have the same horizon.'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['dim', 'none', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['regressor_1', '1', 'regressor_2', '1', 'regressor_1', '2', 'regressor_2', '2', 'greater_is_better,answer'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <13x10 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 13 stored elements in Compressed Sparse Row format>, 'ClassDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['No frequency information was provided, so inferred frequency .* will be used', 'ignore', 'statsmodels.tsa.base.tsa_model', 'Base class for adapters based on :py:class:`statsmodels.tsa.statespace.sarimax.SARIMAX`.', '\\n        Fits a SARIMAX model.\\n\\n        Parameters\\n        ----------\\n        df:\\n            Features dataframe\\n        regressors:\\n            List of the columns with regressors\\n\\n        Returns\\n        -------\\n        :\\n            Fitted model\\n        ', 'target', 'timestamp', \"Can't determine frequency of a given dataframe\", 'timestamp', '_SARIMAXBaseAdapter', 'Make predictions taking into account ``dynamic`` parameter.', 'Model is not fitted! Fit the model before calling predict method!', 'timestamp', 'timestamp', 'mean', 'mean_', '.4g', 'mean', 'mean', 'target', 'mean', '\\n        Compute autoregressive predictions from a SARIMAX model.\\n\\n        Parameters\\n        ----------\\n        df:\\n            Features dataframe\\n        prediction_interval:\\n             If True returns prediction interval for forecast\\n        quantiles:\\n            Levels of prediction distribution\\n\\n        Returns\\n        -------\\n        :\\n            DataFrame with predictions\\n        ', '\\n        Compute predictions from a SARIMAX model and use true in-sample data as lags if possible.\\n\\n        Parameters\\n        ----------\\n        df:\\n            Features dataframe\\n        prediction_interval:\\n            If True returns prediction interval for forecast\\n        quantiles:\\n            Levels of prediction distribution\\n\\n        Returns\\n        -------\\n        :\\n            DataFrame with predictions\\n        ', 'Something went wrong, regressor_columns is None!', 'target', 'timestamp', 'SARIMAX model does not work with exogenous features (features unknown in future).\\n ', ' will be dropped', 'Regressors ', ' are too short for chosen horizon value.\\n Try lower horizon value, or drop this regressors.', 'timestamp', 'category', 'Categorical columns ', ' can not been converted to int.\\n Try to encode this columns manually.', 'Get :py:class:`statsmodels.tsa.statespace.sarimax.SARIMAXResultsWrapper` that is used inside etna class.\\n\\n        Returns\\n        -------\\n        :\\n           Internal model\\n        ', '\\n    Class for holding Sarimax model.\\n\\n    Notes\\n    -----\\n    We use SARIMAX [1] model from statsmodels package. Statsmodels package uses `exog` attribute for\\n    `exogenous regressors` which should be known in future, however we use exogenous for\\n    additional features what is not known in future, and regressors for features we do know in\\n    future.\\n\\n    .. `SARIMAX: <https://www.statsmodels.org/stable/generated/statsmodels.tsa.statespace.sarimax.SARIMAX.html>_`\\n\\n    ', 'c', 'none', \"\\n        Init SARIMAX model with given params.\\n\\n        Parameters\\n        ----------\\n        order:\\n            The (p,d,q) order of the model for the number of AR parameters,\\n            differences, and MA parameters. `d` must be an integer\\n            indicating the integration order of the process, while\\n            `p` and `q` may either be an integers indicating the AR and MA\\n            orders (so that all lags up to those orders are included) or else\\n            iterables giving specific AR and / or MA lags to include. Default is\\n            an AR(1) model: (1,0,0).\\n        seasonal_order:\\n            The (P,D,Q,s) order of the seasonal component of the model for the\\n            AR parameters, differences, MA parameters, and periodicity.\\n            `D` must be an integer indicating the integration order of the process,\\n            while `P` and `Q` may either be an integers indicating the AR and MA\\n            orders (so that all lags up to those orders are included) or else\\n            iterables giving specific AR and / or MA lags to include. `s` is an\\n            integer giving the periodicity (number of periods in season), often it\\n            is 4 for quarterly data or 12 for monthly data. Default is no seasonal\\n            effect.\\n        trend:\\n            Parameter controlling the deterministic trend polynomial :math:`A(t)`.\\n            Can be specified as a string where 'c' indicates a constant (i.e. a\\n            degree zero component of the trend polynomial), 't' indicates a\\n            linear trend with time, and 'ct' is both. Can also be specified as an\\n            iterable defining the non-zero polynomial exponents to include, in\\n            increasing order. For example, `[1,1,0,1]` denotes\\n            :math:`a + bt + ct^3`. Default is to not include a trend component.\\n        measurement_error:\\n            Whether or not to assume the endogenous observations `endog` were\\n            measured with error. Default is False.\\n        time_varying_regression:\\n            Used when an explanatory variables, `exog`, are provided provided\\n            to select whether or not coefficients on the exogenous regressors are\\n            allowed to vary over time. Default is False.\\n        mle_regression:\\n            Whether or not to use estimate the regression coefficients for the\\n            exogenous variables as part of maximum likelihood estimation or through\\n            the Kalman filter (i.e. recursive least squares). If\\n            `time_varying_regression` is True, this must be set to False. Default\\n            is True.\\n        simple_differencing:\\n            Whether or not to use partially conditional maximum likelihood\\n            estimation. If True, differencing is performed prior to estimation,\\n            which discards the first :math:`s D + d` initial rows but results in a\\n            smaller state-space formulation. See the Notes section for important\\n            details about interpreting results when this option is used. If False,\\n            the full SARIMAX model is put in state-space form so that all\\n            datapoints can be used in estimation. Default is False.\\n        enforce_stationarity:\\n            Whether or not to transform the AR parameters to enforce stationarity\\n            in the autoregressive component of the model. Default is True.\\n        enforce_invertibility:\\n            Whether or not to transform the MA parameters to enforce invertibility\\n            in the moving average component of the model. Default is True.\\n        hamilton_representation:\\n            Whether or not to use the Hamilton representation of an ARMA process\\n            (if True) or the Harvey representation (if False). Default is False.\\n        concentrate_scale:\\n            Whether or not to concentrate the scale (variance of the error term)\\n            out of the likelihood. This reduces the number of parameters estimated\\n            by maximum likelihood by one, but standard errors will then not\\n            be available for the scale parameter.\\n        trend_offset:\\n            The offset at which to start time trend values. Default is 1, so that\\n            if `trend='t'` the trend is equal to 1, 2, ..., nobs. Typically is only\\n            set when the model created by extending a previous dataset.\\n        use_exact_diffuse:\\n            Whether or not to use exact diffuse initialization for non-stationary\\n            states. Default is False (in which case approximate diffuse\\n            initialization is used).\\n        dates:\\n            If no index is given by `endog` or `exog`, an array-like object of\\n            datetime objects can be provided.\\n        freq:\\n            If no index is given by `endog` or `exog`, the frequency of the\\n            time-series may be specified here as a Pandas offset or offset string.\\n        missing:\\n            Available options are 'none', 'drop', and 'raise'. If 'none', no nan\\n            checking is done. If 'drop', any observations with nans are dropped.\\n            If 'raise', an error is raised. Default is 'none'.\\n        validate_specification:\\n            If True, validation of hyperparameters is performed.\\n        \", '\\n    Class for holding Sarimax model.\\n\\n    Method ``predict`` can use true target values only on train data on future data autoregression\\n    forecasting will be made even if targets are known.\\n\\n    Notes\\n    -----\\n    We use :py:class:`statsmodels.tsa.sarimax.SARIMAX`. Statsmodels package uses `exog` attribute for\\n    `exogenous regressors` which should be known in future, however we use exogenous for\\n    additional features what is not known in future, and regressors for features we do know in\\n    future.\\n    ', 'c', 'none', \"\\n        Init SARIMAX model with given params.\\n\\n        Parameters\\n        ----------\\n        order:\\n            The (p,d,q) order of the model for the number of AR parameters,\\n            differences, and MA parameters. `d` must be an integer\\n            indicating the integration order of the process, while\\n            `p` and `q` may either be an integers indicating the AR and MA\\n            orders (so that all lags up to those orders are included) or else\\n            iterables giving specific AR and / or MA lags to include. Default is\\n            an AR(1) model: (1,0,0).\\n        seasonal_order:\\n            The (P,D,Q,s) order of the seasonal component of the model for the\\n            AR parameters, differences, MA parameters, and periodicity.\\n            `D` must be an integer indicating the integration order of the process,\\n            while `P` and `Q` may either be an integers indicating the AR and MA\\n            orders (so that all lags up to those orders are included) or else\\n            iterables giving specific AR and / or MA lags to include. `s` is an\\n            integer giving the periodicity (number of periods in season), often it\\n            is 4 for quarterly data or 12 for monthly data. Default is no seasonal\\n            effect.\\n        trend:\\n            Parameter controlling the deterministic trend polynomial :math:`A(t)`.\\n            Can be specified as a string where 'c' indicates a constant (i.e. a\\n            degree zero component of the trend polynomial), 't' indicates a\\n            linear trend with time, and 'ct' is both. Can also be specified as an\\n            iterable defining the non-zero polynomial exponents to include, in\\n            increasing order. For example, `[1,1,0,1]` denotes\\n            :math:`a + bt + ct^3`. Default is to not include a trend component.\\n        measurement_error:\\n            Whether or not to assume the endogenous observations `endog` were\\n            measured with error. Default is False.\\n        time_varying_regression:\\n            Used when an explanatory variables, `exog`, are provided provided\\n            to select whether or not coefficients on the exogenous regressors are\\n            allowed to vary over time. Default is False.\\n        mle_regression:\\n            Whether or not to use estimate the regression coefficients for the\\n            exogenous variables as part of maximum likelihood estimation or through\\n            the Kalman filter (i.e. recursive least squares). If\\n            `time_varying_regression` is True, this must be set to False. Default\\n            is True.\\n        simple_differencing:\\n            Whether or not to use partially conditional maximum likelihood\\n            estimation. If True, differencing is performed prior to estimation,\\n            which discards the first :math:`s D + d` initial rows but results in a\\n            smaller state-space formulation. See the Notes section for important\\n            details about interpreting results when this option is used. If False,\\n            the full SARIMAX model is put in state-space form so that all\\n            datapoints can be used in estimation. Default is False.\\n        enforce_stationarity:\\n            Whether or not to transform the AR parameters to enforce stationarity\\n            in the autoregressive component of the model. Default is True.\\n        enforce_invertibility:\\n            Whether or not to transform the MA parameters to enforce invertibility\\n            in the moving average component of the model. Default is True.\\n        hamilton_representation:\\n            Whether or not to use the Hamilton representation of an ARMA process\\n            (if True) or the Harvey representation (if False). Default is False.\\n        concentrate_scale:\\n            Whether or not to concentrate the scale (variance of the error term)\\n            out of the likelihood. This reduces the number of parameters estimated\\n            by maximum likelihood by one, but standard errors will then not\\n            be available for the scale parameter.\\n        trend_offset:\\n            The offset at which to start time trend values. Default is 1, so that\\n            if `trend='t'` the trend is equal to 1, 2, ..., nobs. Typically is only\\n            set when the model created by extending a previous dataset.\\n        use_exact_diffuse:\\n            Whether or not to use exact diffuse initialization for non-stationary\\n            states. Default is False (in which case approximate diffuse\\n            initialization is used).\\n        dates:\\n            If no index is given by `endog` or `exog`, an array-like object of\\n            datetime objects can be provided.\\n        freq:\\n            If no index is given by `endog` or `exog`, the frequency of the\\n            time-series may be specified here as a Pandas offset or offset string.\\n        missing:\\n            Available options are 'none', 'drop', and 'raise'. If 'none', no nan\\n            checking is done. If 'drop', any observations with nans are dropped.\\n            If 'raise', an error is raised. Default is 'none'.\\n        validate_specification:\\n            If True, validation of hyperparameters is performed.\\n        \"], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Helper transform for preloading.\\n\\n    Returns padded image and original shape.\\n\\n    For classification dataset:\\n      image, label -> (image, shape), label\\n    For verification dataset:\\n      (image1, image2), label -> ((image1, shape1), (image2, shape2)), label\\n\\n    ', 'Load full dataset to memory.\\n\\n    Useful for experiments with small datasets and large images.\\n    ', \"Can't preload datasets with sample quality available.\"], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Pipeline that make regressive models autoregressive.\\n\\n    Examples\\n    --------\\n    >>> from etna.datasets import generate_periodic_df\\n    >>> from etna.datasets import TSDataset\\n    >>> from etna.models import LinearPerSegmentModel\\n    >>> from etna.transforms import LagTransform\\n    >>> classic_df = generate_periodic_df(\\n    ...     periods=100,\\n    ...     start_time=\"2020-01-01\",\\n    ...     n_segments=4,\\n    ...     period=7,\\n    ...     sigma=3\\n    ... )\\n    >>> df = TSDataset.to_dataset(df=classic_df)\\n    >>> ts = TSDataset(df, freq=\"D\")\\n    >>> horizon = 7\\n    >>> transforms = [\\n    ...     LagTransform(in_column=\"target\", lags=list(range(1, horizon+1)))\\n    ... ]\\n    >>> model = LinearPerSegmentModel()\\n    >>> pipeline = AutoRegressivePipeline(model, horizon, transforms, step=1)\\n    >>> _ = pipeline.fit(ts=ts)\\n    >>> forecast = pipeline.forecast()\\n    >>> pd.options.display.float_format = \\'{:,.2f}\\'.format\\n    >>> forecast[:, :, \"target\"]\\n    segment    segment_0 segment_1 segment_2 segment_3\\n    feature       target    target    target    target\\n    timestamp\\n    2020-04-10      9.00      9.00      4.00      6.00\\n    2020-04-11      5.00      2.00      7.00      9.00\\n    2020-04-12      0.00      4.00      7.00      9.00\\n    2020-04-13      0.00      5.00      9.00      7.00\\n    2020-04-14      1.00      2.00      1.00      6.00\\n    2020-04-15      5.00      7.00      4.00      7.00\\n    2020-04-16      8.00      6.00      2.00      0.00\\n    ', '\\n        Create instance of AutoRegressivePipeline with given parameters.\\n\\n        Parameters\\n        ----------\\n        model:\\n            Instance of the etna Model\\n        horizon:\\n            Number of timestamps in the future for forecasting\\n        transforms:\\n            Sequence of the transforms\\n        step:\\n            Size of prediction for one step of forecasting\\n        ', 'Fit the AutoRegressivePipeline.\\n\\n        Fit and apply given transforms to the data, then fit the model on the transformed data.\\n\\n        Parameters\\n        ----------\\n        ts:\\n            Dataset with timeseries data\\n\\n        Returns\\n        -------\\n        :\\n            Fitted Pipeline instance\\n        ', 'AutoRegressivePipeline', 'Create dataframe to fill with forecasts.', 'AutoRegressivePipeline is not fitted! Fit the AutoRegressivePipeline before calling forecast method.', 'target', 'right', 'timestamp', 'Make predictions.', 'Something went wrong, ts is None!', \"TSDataset freq can't be inferred\", 'ignore', 'You probably set wrong freq.', 'ignore'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Randomly mask out one or more patches from an image.\\n    Args:\\n        n_holes (int): Number of patches to cut out of each image.\\n        size (int): The length (in pixels) of each square patch.\\n        probability (float): Probability to apply CutOut.\\n    ', '\\n        Args:\\n            img : PIL image of size (C, H, W).\\n        Returns:\\n            PIL image: Image with n_holes of dimension length x length cut out of it.\\n        '], 'from': [], 'import': []}\n",
      "{'FunctionDef': <16x16 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 16 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['timestamp', '2020-01-01', 'target', 'segment', 'segment_1', 'timestamp', '2020-01-01', 'target', 'segment', 'segment_1', 'timestamp', '2020-01-01', 'target', 'segment', 'segment_1', 'target', 'segment_1', 'target', 'class_name,out_column', 'test_max', 'test_min', 'test_median', 'test_mean', 'test_std', 'test_mad', 'test_min_max_diff', 'test_sum', 'target', 'segment_1', 'target', 'out_column', 'test_q', 'target', 'result', 'expected', 'expected', 'segment_1', 'result', 'window,seasonality,alpha,periods,fill_na,expected', 'target', 'result', 'expected', 'expected', 'segment_1', 'result', 'window,seasonality,periods,fill_na,expected', 'target', 'result', 'expected', 'expected', 'segment_1', 'result', 'window,periods,fill_na,expected', 'target', 'result', 'expected', 'expected', 'segment_1', 'result', 'window,periods,fill_na,expected', 'target', 'result', 'expected', 'expected', 'segment_1', 'result', 'window,periods,fill_na,expected', 'target', 'result', 'segment_1', 'result', 'window,periods,fill_na,expected', 'target', 'result', 'segment_1', 'result', 'window,periods,fill_na,expected', 'target', 'result', 'expected', 'expected', 'segment_1', 'result', 'window,periods,fill_na,expected', 'target', 'result', 'segment_1', 'result', 'window,periods,fill_na,expected', 'target', 'result', 'segment_1', 'result', 'window,periods,fill_na,expected', 'transform', 'target', 'target', 'target', 'target', 'target', 'target', 'target', 'target'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['\\n    Stanford Dogs dataset class.\\n    https://vision.stanford.edu/aditya86/ImageNetDogs/\\n\\n    Args:\\n        root: Dataset root.\\n        train: Whether to use train or test part of the dataset.\\n    ', 'lists/train_list.mat', 'lists/test_list.mat', 'images', 'file_list', 'labels', 'Whether dataset is classification or matching.', 'Whether dataset is for open-set or closed-set classification.', 'Get dataset labels array.\\n\\n        Labels are integers in the range [0, N-1], where N is number of classes\\n\\n        ', 'Get element of the dataset.\\n\\n        Returns tuple (image, label).\\n\\n        '], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['../..', 'CI_COMMIT_SHORT_SHA', 'WORKFLOW_NAME', 'ETNA Time Series Library', '2021, etna-tech@tinkoff.ru', 'etna-tech@tinkoff.ru', 'pyproject.toml', 'r', 'Publish', 'tool', 'poetry', 'version', 'nbsphinx', 'myst_parser', 'sphinx.ext.napoleon', 'sphinx.ext.autodoc', 'sphinx.ext.autosummary', 'sphinx.ext.doctest', 'sphinx.ext.intersphinx', 'sphinx.ext.mathjax', 'sphinx-mathjax-offline', 'sphinx.ext.viewcode', 'sphinx.ext.githubpages', 'statsmodels', 'sklearn', 'pytorch_forecasting', 'matplotlib', 'scipy', 'torch', 'pytorch_lightning', 'optuna', 'https://www.statsmodels.org/stable/', 'http://scikit-learn.org/stable', 'https://pytorch-forecasting.readthedocs.io/en/stable/', 'https://matplotlib.org/3.5.0/', 'https://docs.scipy.org/doc/scipy/', 'https://pytorch.org/docs/stable/', 'https://pytorch-lightning.readthedocs.io/en/stable/', 'https://optuna.readthedocs.io/en/stable/', 'both', 'all', '_templates', '**/.ipynb_checkpoints', 'sphinx_rtd_theme', '_static', '\\n    Document __init__ methods\\n    ', '__init__', 'api', \"\\n    Import by name and return imported module/function/class\\n\\n    Args:\\n        string (str): module/function/class to import, e.g. 'pandas.read_csv' will return read_csv function as\\n        defined by pandas\\n\\n    Returns:\\n        imported object\\n    \", '.', '.', '.', '', '__all__', '.', '_', '.', '__module__', '.', 'etna', '.', 'autodoc-skip-member', 'moduleautosummary', 'https://buttons.github.io/buttons.js', 'async', 'async', 'groupwise', 'both', 'api'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['examples', '*.ipynb', 'Skipping ', 'Running ', 'poetry run python -m jupyter nbconvert --ExecutePreprocessor.kernel_name=python3 --to notebook --execute ', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <7x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Original cars dataset. Train and test are splitted by sample.\\n\\n    See https://ai.stanford.edu/%7Ejkrause/cars/car_dataset.html\\n\\n    Args:\\n        root: Dataset root.\\n        train: Whether to use train or test part of the dataset.\\n    ', 'cars_train', 'cars_test', 'devkit', 'cars_train_annos.mat', 'devkit', 'cars_test_annos_withlabels.mat', 'annotations', 'annotations', 'class', 'fname', 'Whether dataset is classification or matching.', 'Whether dataset is for open-set or closed-set classification.', 'Get dataset labels array.\\n\\n        Labels are integers in the range [0, N-1].\\n\\n        ', 'Get element of the dataset.\\n\\n        Classification dataset returns tuple (image, label).\\n        Verification dataset returns ((image1, image2), label).\\n\\n        ', 'Cars dataset with different classes in train and test sets.', 'Whether dataset is for open-set or closed-set classification.'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Hierarchical clustering with DTW distance.\\n\\n    Examples\\n    --------\\n    >>> from etna.clustering import DTWClustering\\n    >>> from etna.datasets import TSDataset\\n    >>> from etna.datasets import generate_ar_df\\n    >>> ts = generate_ar_df(periods = 40, start_time = \"2000-01-01\", n_segments = 10)\\n    >>> ts = TSDataset(TSDataset.to_dataset(ts), freq=\"D\")\\n    >>> model = DTWClustering()\\n    >>> model.build_distance_matrix(ts)\\n    >>> model.build_clustering_algo(n_clusters=3, linkage=\"average\")\\n    >>> segment2cluster = model.fit_predict()\\n    >>> segment2cluster\\n    {\\'segment_0\\': 2,\\n     \\'segment_1\\': 1,\\n     \\'segment_2\\': 0,\\n     \\'segment_3\\': 1,\\n     \\'segment_4\\': 1,\\n     \\'segment_5\\': 0,\\n     \\'segment_6\\': 0,\\n     \\'segment_7\\': 1,\\n     \\'segment_8\\': 2,\\n     \\'segment_9\\': 2}\\n    ', 'Create instance of DTWClustering.', 'TSDataset', '\\n        Build distance matrix with DTW distance.\\n\\n        Parameters\\n        ----------\\n        ts:\\n            TSDataset with series to build distance matrix\\n        ', 'DTWClustering'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': [\"Makes expanding mean target encoding of the segment. Creates column 'segment_mean'.\", 'target', 'segment_mean', '\\n        Fit encoder.\\n\\n        Parameters\\n        ----------\\n        df:\\n            dataframe with data to fit expanding mean target encoder.\\n\\n        Returns\\n        -------\\n        :\\n            Fitted transform\\n        ', 'target', 'MeanSegmentEncoderTransform', '\\n        Get encoded values for the segment.\\n\\n        Parameters\\n        ----------\\n        df:\\n            dataframe with data to transform.\\n\\n        Returns\\n        -------\\n        :\\n            result dataframe\\n        ', 'segment', 'target', 'segment_mean'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['MovingAverageModel averages previous series values to forecast future one.\\n\\n    .. math::\\n        y_{t} = \\\\frac{\\\\sum_{i=1}^{n} y_{t-i} }{n},\\n\\n    where :math:`n` is window size.\\n    ', '\\n        Init MovingAverageModel.\\n\\n        Parameters\\n        ----------\\n        window: int\\n            number of history points to average\\n        ', 'MovingAverageModel'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <9x9 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 9 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['tensorboard', 'wandb', 'Unknown logger: {}', '-', '-', '-', ':', 'Dictionary HOPT specification is expected, got {} for {}.', 'values', 'values', 'distribution', 'uniform', 'log_uniform', 'min', 'max', 'uniform', 'Unknown distribution: {}.', 'min', 'max', 'min', 'max', 'min', 'max', 'wandb', 'seed', 'config.yaml', 'trainer_params', 'selection_dataset', 'selection_metric', 'mean', 'mean', 'No hyper parameters to optimize', 'trainer_params', 'value', 'hopt_backend', '-', 'wandb', 'name', 'method', 'early_terminate', 'metric', 'parameters', 'type', 'min_iter', 'eta', 'hyperband', 'early_stop_patience', 'early_stop_patience', 'name', 'goal', '{}_epoch/{}', 'selection_metric', 'selection_dataset', 'selection_minimize', 'minimize', 'maximize', 'num_hopt_trials', 'wandb', 'Need wandb logger for wandb-based hyperparameter search', 'Need experiment name for hyperparameter search', 'sweep-', 'Finished sweep', 'tpe', \"Can't attach to sweep ID using Optuna.\", 'No hyper parameters to optimize', 'trainer_params', 'hopt_backend', '-', 'optuna', 'selection_minimize', 'minimize', 'maximize', 'optuna', 'num_hopt_trials', 'wandb-bayes', 'wandb-random', 'optuna-tpe', 'Run hopt tuning.', 'hopt_params', 'seed', 'w', 'hopt_backend'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <29x29 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 29 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['2020-01-01', 'D', 'timestamp', 'segment', 'target', 'segment_0', 'segment_1', 'D', 'segment_0', 'target', 'segment_1', 'target', 'segment_0', 'target', 'segment_1', 'target', 'Test that get_residuals finds residuals correctly.', \"Test that get_residuals fails to find residuals correctly if ts hasn't answers.\", 'D', 'Test that get_residuals fails to find residuals correctly if segments of dataset and forecast differ.', 'segment', 'segment_0', 'segment_3', 'Segments of `ts` and `forecast_df` should be the same', 'Test that plot_residuals fails if meet unknown feature.', 'target', \"Given feature isn't present in the dataset\", 'unkown_feature', 'target', 'poly_degree, trend_transform_class', 'target', 'detrend_model', 'target', 'period', 'target', '', '', '', '', 'poly_degree, expect_values, trend_class', 'fold_numbers', '2020-01-01', 'D', '2020-01-01', '2D', '2020-01-01', 'D', '2020-01-01', '2020-01-02', '2020-01-05', '2020-01-06', 'fold_numbers', '2020-01-01', '2020-01-02', '2020-01-01', '2020-01-02', '2020-01-01', 'D', '2020-01-01', '2020-01-02', '2020-01-02', '2020-01-03', '2020-01-01', '2020-01-02', '2020-01-02', '2020-01-03', '2020-01-01', '2020-01-05', '2020-01-03', '2020-01-08', '2020-01-01', '2020-01-05', '2020-01-03', '2020-01-08', 'RU', 'THIS_COUNTRY_DOES_NOT_EXIST', 'RU', 'holiday', 'ds', 'New Year', '1900-01-01', '1901-01-01', 'holiday', 'ds', 'New Year', '2020-01-01', 'New Year', 'holiday', 'ds', 'upper_window', 'New Year', '2020-01-01', 'holiday', 'ds', 'upper_window', 'Christmas', '2019-12-25', 'holiday', 'ds', 'lower_window', 'Christmas', '2020-01-07', 'holiday', 'ds', 'lower_window', 'Moscow Anime Festival', '2020-02-22', 'holiday', 'ds', 'upper_window', 'lower_window', 'Christmas', '2020-01-07', '2020-01-07', '2020-01-10', 'Christmas', '2020-01-01', 'H', 'holiday', 'ds', 'upper_window', 'Christmas', '2020-01-01', '2020-01-01', '15T', 'holiday', 'ds', 'upper_window', 'New Year', '2020-01-01 01:00:00', '2020-01-01 01:00:00', '2020-01-01 01:45:00', 'holiday', 'ds', 'lower_window', 'Christmas', '2020-01-07', 'holiday', 'ds', 'upper_window', 'New Year', '2020-01-01', 'holiday', 'ds', 'lower_window', 'upper_window', 'Christmas', '2020-01-07', '2020-01-07', 'holiday', 'ds', 'upper_window', 'Christmas', '2020-01-07', 'holiday', 'ds', 'lower_window', 'Christmas', '2020-01-07'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['tag:yaml.org,2002:seq', 'Read yaml from file or stream.', 'Dump yaml to file or stream.', 'w'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <8x8 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 8 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['DistanceMatrix computes distance matrix from TSDataset.', 'Init DistanceMatrix.\\n\\n        Parameters\\n        ----------\\n        distance:\\n            class for distance measurement\\n        ', 'TSDataset', 'Check that dataset does not contain NaNs.', 'target', 'Timeseries contains NaN values, which will be dropped. If it is not desirable behaviour, handle them manually.', 'TSDataset', 'Parse given TSDataset and get timestamp-indexed segment series.\\n        Build mapping from segment to idx in matrix and vice versa.\\n        ', 'target', 'Compute distance from idx-th series to other ones.', 'Something went wrong during getting the series from dataset!', 'Compute distance matrix for given series.', 'Something went wrong during getting the series from dataset!', 'Calculating distance matrix...', 'Done ', ' out of ', ' ', 'TSDataset', 'Fit distance matrix: get timeseries from ts and compute pairwise distances.\\n\\n        Parameters\\n        ----------\\n        ts:\\n            TSDataset with timeseries\\n\\n        Returns\\n        -------\\n        self:\\n            fitted DistanceMatrix object\\n\\n        ', 'DistanceMatrix', 'Get distance matrix.\\n\\n        Returns\\n        -------\\n        np.ndarray:\\n            2D array with distances between series\\n        ', 'DistanceMatrix is not fitted! Fit the DistanceMatrix before calling predict method!', 'TSDataset', 'Compute distance matrix and return it.\\n\\n        Parameters\\n        ----------\\n        ts:\\n           TSDataset with timeseries to compute matrix with\\n\\n        Returns\\n        -------\\n        np.ndarray:\\n            2D array with distances between series\\n        ', 'DistanceMatrix'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': [' ', 'Shell command returns code '], 'from': [], 'import': []}\n",
      "{'FunctionDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': [\"Create pipelines with broadcasting from models, transforms and horizons.\\n\\n    After broadcasting we have:\\n\\n    - models:\\n    .. math:: M_1, \\\\dots, M_n\\n    - transforms:\\n    .. math:: (T_{1,1}, \\\\dots, T_{1,n}), ... (T_{k,1}, \\\\dots, T_{k,n})\\n    - horizons:\\n    .. math:: H_1, \\\\dots, H_n\\n\\n    We expect that in input shape of size `n` can be reduced to size 1 or even become a scalar value. During broadcasting we copy this value `n` times.\\n\\n    Parameters\\n    ----------\\n    models:\\n        Instance of Sequence of models\\n    transforms:\\n        Sequence of the transforms\\n    horizons:\\n        Sequence of horizons\\n\\n    Returns\\n    -------\\n    :\\n        list of pipelines\\n\\n    Raises\\n    ------\\n    ValueError:\\n        If the length of models sequence not equals to length of horizons sequence.\\n\\n    Examples\\n    --------\\n    >>> from etna.pipeline import assemble_pipelines\\n    >>> from etna.models import LinearPerSegmentModel, NaiveModel\\n    >>> from etna.transforms import TrendTransform, AddConstTransform, LagTransform\\n    >>> assemble_pipelines(models=LinearPerSegmentModel(), transforms=[LagTransform(in_column='target', lags=[1]), AddConstTransform(in_column='target', value=1)], horizons=[1,2,3])\\n    [Pipeline(model = LinearPerSegmentModel(fit_intercept = True, ), transforms = [LagTransform(in_column = 'target', lags = [1], out_column = None, ), AddConstTransform(in_column = 'target', value = 1, inplace = True, out_column = None, )], horizon = 1, ),\\n    Pipeline(model = LinearPerSegmentModel(fit_intercept = True, ), transforms = [LagTransform(in_column = 'target', lags = [1], out_column = None, ), AddConstTransform(in_column = 'target', value = 1, inplace = True, out_column = None, )], horizon = 2, ),\\n    Pipeline(model = LinearPerSegmentModel(fit_intercept = True, ), transforms = [LagTransform(in_column = 'target', lags = [1], out_column = None, ), AddConstTransform(in_column = 'target', value = 1, inplace = True, out_column = None, )], horizon = 3, )]\\n    >>> assemble_pipelines(models=[LinearPerSegmentModel(), NaiveModel()], transforms=[LagTransform(in_column='target', lags=[1]), [AddConstTransform(in_column='target', value=1), TrendTransform(in_column='target')]], horizons=[1,2])\\n    [Pipeline(model = LinearPerSegmentModel(fit_intercept = True, ), transforms = [LagTransform(in_column = 'target', lags = [1], out_column = None, ), AddConstTransform(in_column = 'target', value = 1, inplace = True, out_column = None, )], horizon = 1, ),\\n    Pipeline(model = NaiveModel(lag = 1, ), transforms = [LagTransform(in_column = 'target', lags = [1], out_column = None, ), TrendTransform(in_column = 'target', out_column = None, detrend_model = LinearRegression(), model = 'ar', custom_cost = None, min_size = 2, jump = 1, n_bkps = 5, pen = None, epsilon = None, )], horizon = 2, )]\\n    \", 'Transforms elements should be either one Transform, ether sequence of Transforms with same length', 'Lengths of the result models is not equals to horizons or transforms', 'Lengths of the result transforms is not equals to models or horizons', 'Lengths of the result horizons is not equals to models or transforms'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <8x8 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 8 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['2020-01-01', 'D', 'D', 'timestamp', 'target', 'segment', '2022-06-22', 'timestamp', 'target', 'segment', '2022-06-22', 'D', 'D', 'target', 'transform_original, transform_function, out_column', 'target', 'transform_target', 'transform_target', 'target', 'transform_target', 'transform_target', 'target', 'transform_target', 'transform_target_1', 'inverse_transform_func must be defined, when inplace=True', 'target', 'target', 'target_transformed', 'target', 'target', 'inplace, segment, check_column, function, inverse_function, expected_result', '1', 'target_transformed', '1', 'target', '2', 'target_transformed', '2', 'target', 'target', 'target', 'function, inverse_function'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['ImageNet dataset class.\\n\\n    Args:\\n        root: Dataset root.\\n        train: Whether to use train or val part of the dataset.\\n    ', 'train', 'meta.mat', 'synsets', '*.JPEG', 'val', '*.JPEG', 'ILSVRC2012_validation_ground_truth.txt', 'r', 'Whether dataset is classification or matching.', 'Whether dataset is for open-set or closed-set classification.', 'Get dataset labels array.\\n\\n        Labels are integers in the range [0, N-1], where N is number of classes\\n\\n        ', 'Get element of the dataset.\\n\\n        Returns tuple (image, label).\\n\\n        '], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Expected tensor with shape (b, c, h, w).', 'Combines average, power and max poolings.\\n\\n    Args:\\n        mode: Combination of \"a\", \"m\", and digits to describe poolings used.\\n            For example \"am3\" means average, maximum and power-3 poolings.\\n        aggregate: Either \"sum\" or \"cat\".\\n    ', 'am', 'sum', 'sum', 'cat', 'Unknown aggrageation: {}.', 'a', 'm', 'Unknown pooling: {}.', 'pool{}', 'cat', 'sum', 'cat'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <7x7 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7 stored elements in Compressed Sparse Row format>, 'ClassDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['cmd', 'data', 'name', 'logger', 'config', 'train_root', 'checkpoint', 'no_strict_init', 'from_stage', 'from_seed', 'dataset_params', 'model_params', 'criterion_params', 'trainer_params', 'name', 'batch_size', 'num_workers', 'num_validation_folds', 'debug-openset', 'embedder_params', 'distribution_type', 'distribution_params', 'pretrained', 'model_type', 'resnet18', 'gmm', 'dim', 'prior_kld_weight', 'num_epochs', 'dataset_params', 'model_params', 'criterion_params', 'trainer_params', 'stages', 'name', 'batch_size', 'num_workers', 'num_validation_folds', 'debug-openset', 'embedder_params', 'classifier_type', 'distribution_type', 'distribution_params', 'pretrained', 'model_type', 'resnet18', 'gmm', 'dim', 'xent_weight', 'pfe_weight', 'num_epochs', 'criterion_params', 'pfe_match_self', 'criterion_params', 'pfe_match_self', 'Test Hinge loss.', 'xent_weight', 'hinge_weight', 'hinge_margin', 'Train with KLD loss.', 'config.yaml', 'w', 'train', 'tensorboard', 'Train with pair MLS loss.', 'config.yaml', 'w', 'train', 'tensorboard', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <40x40 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 40 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['Extract columns from feature level that are present in transformed_df but not in initial_df.', 'feature', 'feature', 'Create DataFrame with nans at the beginning of one segment.', '2021-01-01', '2021-04-01', 'timestamp', 'target', 'segment', '1', 'timestamp', 'target', 'segment', '2', 'Create df_exog for df_nans.', '2021-01-01', '2021-05-01', 'timestamp', 'regressor_1', 'segment', '1', 'timestamp', 'regressor_1', 'segment', '2', 'Create noised version of df_nans.', '1', 'target', '2', 'target', 'Check that differencing transform generates non-regressor column in transform according to repr.', 'Check that differencing transform generates regressor column in transform according to repr.', 'D', 'Check that differencing transform generates correct values in transform.', 'segment', 'target', 'Check that differencing transform does nothing during inverse_transform in non-inplace mode.', 'Check that differencing transform correctly makes inverse_transform on train data in inplace mode.', 'Check that differencing transform correctly makes inverse_transform on test data in inplace mode.', 'D', '1', 'target', '2', 'target', '1', 'target', '2', 'target', 'Wrong order', 'Check that differencing transform correctly makes inverse_transform on test data with quantiles.', 'D', 'target_0.025', 'target', 'target', 'target_0.975', 'Check that differencing transform correctly works in backtest.', 'D', 'target', 'R2', \"Test that _SingleDifferencingTransform can't be created with period < 1.\", 'Period should be at least 1', 'target', 'diff', \"Test that DifferencingTransform can't be created with period < 1.\", 'Period should be at least 1', 'target', 'diff', \"Test that DifferencingTransform can't be created with order < 1.\", 'Order should be at least 1', 'target', 'diff', 'Test that differencing transform generates new column in transform according to out_column parameter.', 'diff', 'transform', 'target', 'diff', 'target', 'diff', 'Test that _SingleDifferencingTransform generates non-regressor column in transform according to repr.', 'target', 'period', 'Test that DifferencingTransform generates non-regressor column in transform according to repr.', 'target', 'period', 'order', 'Test that _SingleDifferencingTransform generates regressor column in transform according to repr.', 'regressor_1', 'period', 'Test that DifferencingTransform generates regressor column in transform according to repr.', 'regressor_1', 'period', 'order', \"Test that differencing transform doesn't generate new column in transform in inplace mode.\", 'target', 'transform', 'target', 'target', \"Test that differencing transform doesn't change in_column in transform in non-inplace mode.\", 'transform', 'target', 'diff', 'target', 'diff', 'Test that differencing transform fails to fit on segments with NaNs inside.', 'There should be no NaNs inside the segments', 'transform', 'target', 'diff', 'target', 'diff', 'Test that differencing transform fails to make transform before fitting.', 'Transform is not fitted', 'transform', 'target', 'diff', 'target', 'diff', 'Test that _SingleDifferencingTransform generates correct values in transform.', 'target', 'period', 'inplace, out_column', 'diff', 'target', 'Test that DifferencingTransform generates correct values in transform.', 'target', 'period', 'order', 'inplace, out_column', 'diff', 'target', 'Test that differencing transform fails to make inverse_transform before fitting.', 'Transform is not fitted', 'transform', 'target', 'target', 'Test that differencing transform fails to make inverse_transform only on part of train.', 'Inverse transform can be applied only to full train', 'transform', 'target', 'target', 'Test that differencing transform fails to make inverse_transform on not adjacent test data.', 'D', 'Test should go after the train without gaps', 'transform', 'target', 'target', 'Test that _SingleDifferencingTransform does nothing during inverse_transform in non-inplace mode.', 'target', 'diff', 'period', 'Test that DifferencingTransform does nothing during inverse_transform in non-inplace mode.', 'target', 'diff', 'period', 'order', 'Test that _SingleDifferencingTransform correctly makes inverse_transform on train data in inplace mode.', 'target', 'period', 'Test that DifferencingTransform correctly makes inverse_transform on train data in inplace mode.', 'target', 'period', 'order', 'Test that differencing transform fails to make inverse_transform on test data if there are NaNs.', 'D', '1', 'target', '2', 'target', 'There should be no NaNs inside the segments', 'transform', 'target', 'target', 'Test that _SingleDifferencingTransform correctly makes inverse_transform on test data in inplace mode.', 'target', 'period', 'Test that DifferencingTransform correctly makes inverse_transform on test data in inplace mode.', 'target', 'period', 'order', 'Test that _SingleDifferencingTransform correctly makes inverse_transform on test data with quantiles.', 'target', 'period', 'Test that DifferencingTransform correctly makes inverse_transform on test data with quantiles.', 'target', 'period', 'order', 'Test that _SingleDifferencingTransform correctly works in backtest.', 'target', 'period', 'Test that DifferencingTransform correctly works in backtest.', 'target', 'period', 'order'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <13x8 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 13 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['PyTorch interface to LFW dataset with classification labels or pairs.\\n\\n    Args:\\n        root: Path to the dataset root with images and annotations.\\n        train: If True, use training part of the dataset. If False, use validation or testing part\\n            depending on `cross_val_step`.\\n        classification: If False, sample positive and negative pairs. Label will contain SAME label.\\n            If True, samples images and integer class label.\\n        cross_val_step: Index of cross validation step in the range [0, 9].\\n            If not provided, standard train/dev split will be used.\\n    ', 'lfw-deepfunneled', 'peopleDevTrain.txt', 'peopleDevTest.txt', 'people.txt', 'pairsDevTrain.txt', 'pairsDevTest.txt', 'pairs.txt', 'Cross-validation', 'Whether dataset is classification or matching.', 'Whether dataset is for open-set or closed-set classification.', 'Get dataset labels array.\\n\\n        Labels are integers in the range [0, N-1].\\n\\n        ', 'Get element of the dataset.\\n\\n        Classification dataset returns tuple (image, label).\\n        Verification dataset returns ((image1, image2), label).\\n\\n        ', '.jpg', 'PyTorch interface to CALFW and CPLFW.\\n\\n    Args:\\n        root: Path to the images root.\\n    ', '.jpg', '_', 'Whether dataset is classification or verification.', 'Whether dataset is for open-set or closed-set classification.', 'Get dataset labels array.\\n\\n        Labels are integers in the range [0, N-1].\\n\\n        ', 'Get element of the dataset.\\n\\n        Classification dataset returns tuple (image, label).\\n\\n        '], 'from': [], 'import': []}\n",
      "{'FunctionDef': [], 'ClassDef': [], 'AsyncFunctionDef': [], 'String': [], 'from': [], 'import': []}\n",
      "{'FunctionDef': <6x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['D', 'target', 'time_idx', 'target', 'segment', 'add PytorchForecastingTransform', '\\n    Given: I have dataframe with 2 segments with weekly seasonality with known future\\n    When:\\n    Then: I get {horizon} periods per dataset as a forecast and they \"the same\" as past\\n    ', 'D', 'D', 'regressor_dateflags', 'time_idx', 'regressor_dateflags_day_number_in_week', 'target', 'segment', 'macro', 'horizon', '\\n    Given: I have dataframe with 2 segments with weekly seasonality with known future\\n    When: I use scale transformations\\n    Then: I get {horizon} periods per dataset as a forecast and they \"the same\" as past\\n    ', 'target', 'regressor_dateflags', 'time_idx', 'regressor_dateflags_day_number_in_week', 'target', 'segment', 'macro', 'horizon', 'D', 'time_idx', 'target', 'segment', 'The future is not generated!', '2021-01-01', 'timestamp', 'time_idx', 'target', 'segment', 'freq', '1M', '1D', 'A-DEC', '1B', '1H', 'time_idx', 'target', 'segment', 'target_0.025', 'target_0.975', 'target', 'target_0.975', 'target_0.025', 'target', 'target_0.025', 'target_0.975', 'target'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <39x29 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 39 stored elements in Compressed Sparse Row format>, 'ClassDef': <7x7 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['cuda', 'halfcheetah-medium-expert-v2', '', 'CORL', 'CQL-D4RL', 'CQL', '-', '-', 'cpu', 'Trying to load data into non-empty replay buffer', 'observations', 'Replay buffer is smaller than the dataset you are trying to load!', 'observations', 'actions', 'rewards', 'next_observations', 'terminals', 'Dataset size: ', 'PYTHONHASHSEED', 'project', 'group', 'name', 'rewards', 'terminals', 'rewards', 'halfcheetah', 'hopper', 'walker2d', 'rewards', 'rewards', 'antmaze', 'rewards', 'cpu', 'cpu', 'Subtract the log likelihood of data', ' Policy loss ', ' Q function loss ', 'actor', 'critic1', 'critic2', 'critic1_target', 'critic2_target', 'critic_1_optimizer', 'critic_2_optimizer', 'actor_optim', 'sac_log_alpha', 'sac_log_alpha_optim', 'cql_log_alpha', 'cql_log_alpha_optim', 'total_it', 'actor', 'critic1', 'critic2', 'critic1_target', 'critic2_target', 'critic_1_optimizer', 'critic_2_optimizer', 'actor_optim', 'sac_log_alpha', 'sac_log_alpha_optim', 'cql_log_alpha', 'cql_log_alpha_optim', 'total_it', 'observations', 'observations', 'observations', 'next_observations', 'next_observations', 'Checkpoints path: ', 'config.yaml', 'w', 'critic_1', 'critic_2', 'critic_1_optimizer', 'critic_2_optimizer', 'actor', 'actor_optimizer', 'discount', 'soft_target_update_rate', 'device', 'target_entropy', 'alpha_multiplier', 'use_automatic_entropy_tuning', 'backup_entropy', 'policy_lr', 'qf_lr', 'bc_steps', 'target_update_period', 'cql_n_actions', 'cql_importance_sample', 'cql_lagrange', 'cql_target_action_gap', 'cql_temp', 'cql_min_q_weight', 'cql_max_target_backup', 'cql_clip_diff_min', 'cql_clip_diff_max', '---------------------------------------', 'Training CQL, Env: ', ', Seed: ', '---------------------------------------', '', 'Time steps: ', '---------------------------------------', 'Evaluation over ', ' episodes: ', '.3f', ' , D4RL score: ', '.3f', '---------------------------------------', 'checkpoint_', '.pt', 'd4rl_normalized_score', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['w', 'etna', 'forecast', 'D', 'w', 'etna', 'forecast', 'D', 'w', 'etna', 'forecast', 'D', 'w', 'etna', 'forecast', 'D', 'target_', 'w', 'etna', 'forecast', 'D', 'target', 'target', 'model_pipeline', 'elementary_linear_model_pipeline', 'elementary_boosting_model_pipeline'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': [\"\\n    This test checks that StandardScalerTransform.fit_transform + StandardScalerTransform.inverse_transform\\n    does not affect target's quantiles.\\n    \", 'target', 'This test checks that StandardScalerTransform.inverse_transform works correctly in macro mode.', 'target', 'macro', \"\\n    This test checks that inverse_transform transforms forecast's quantiles the same way with target itself and\\n    transform does not affect quantiles.\\n    \", 'target', \"This test checks that inverse_transform transforms forecast's quantiles the same way with target itself.\", 'transform', 'target', 'target', 'target', 'target', 'target', 'target', 'target'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['exp', 'invlin', 'abs', 'scale', 'center', 'scale', 'center', 'sigmoid', 'exp', 'invlin', 'scale', 'center', 'scale', 'center', 'sigmoid', 'abs', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Add lossy transformations to input data.', 'Get lossy dataset parameters.\\n\\n        Args:\\n            center_crop_range: Minimum and maximum size of center crop.\\n        ', 'seed', 'center_crop_range', 'Only lossy classification datasets are supported.', 'center_crop_range', 'Crop min size is greater than max.', 'seed', 'Whether dataset assigns quality score to each sample or not.', 'Get element of the dataset.\\n\\n        Classification dataset returns tuple (image, label, quality).\\n        Verification dataset returns ((image1, image2), label, (quality1, quality2)).\\n\\n        ', 'Expected Numpy or torch Tensor.'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <7x7 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['H', 'target_0.025', 'target', 'target_0.975', 'target', 'H', 'H', 'target_0.025', 'target', 'target_0.975', 'target', 'segment_1', 'target_0.025', 'target_0.025', 'target_0.975', 'target_0.975', 'H', 'per-segment', 'segment_1', 'segment_2', 'per-segment', 'segment_1', 'segment_2', 'per-segment', 'Quantile .* is not presented in tsdataset.', 'metric', 'metric, greater_is_better'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Transform for models from PytorchForecasting library.\\n\\n    Notes\\n    -----\\n    This transform should be added at the very end of ``transforms`` parameter.\\n    ', 'auto', 'Init transform.\\n\\n        Parameters here is used for initialization of :py:class:`pytorch_forecasting.data.timeseries.TimeSeriesDataSet` object.\\n        ', '\\n        Fit TimeSeriesDataSet.\\n\\n        Parameters\\n        ----------\\n        df:\\n            data to be fitted.\\n\\n        Returns\\n        -------\\n            PytorchForecastingTransform\\n        ', 'time_idx', 'timestamp', '1s', 'time_idx', 'time_idx', 'time_idx', 'target', 'segment', 'PytorchForecastingTransform', '\\n        Transform raw df to TimeSeriesDataSet.\\n\\n        Parameters\\n        ----------\\n        df:\\n            data to be transformed.\\n\\n        Returns\\n        -------\\n            DataFrame\\n\\n        Notes\\n        -----\\n        We save TimeSeriesDataSet in instance to use it in the model.\\n        It`s not right pattern of using Transforms and TSDataset.\\n        ', 'target', 'target', 'time_idx', 'timestamp', '1s', 'time_idx', 'time_idx', 'make_future'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <8x8 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 8 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['Generate dataframe with simple targets for lags check.', 'timestamp', '2020-01-01', '2020-06-01', 'segment', 'segment_1', 'target', 'timestamp', 'Generate dataframe with simple targets for lags check.', 'segment', 'segment_1', 'segment', 'segment_2', 'Test that that __repr__ method works fine.', 'LagTransform', 'lag_feature', 'target', 'target', \"(in_column = 'target', lags = \", \", out_column = '\", \"', )\", \"(in_column = 'target', lags = \", ', out_column = None, )', 'Test that transform generates correct column names using out_column parameter.', 'target', 'regressor_lag_feature', 'segment', 'regressor_lag_feature', 'lags,expected_columns', 'regressor_lag_feature_1', 'regressor_lag_feature_2', 'regressor_lag_feature_3', 'regressor_lag_feature_5', 'regressor_lag_feature_8', 'Test that transform generates correct column names without setting out_column parameter.', 'segment', 'target', 'feature', 'target', 'feature', 'target', 'lags', 'Test that transform generates correct values.', 'target', 'regressor_lag_feature', 'segment', 'target', 'regressor_lag_feature_', 'lags', \"Test that LagTransform can't be created with non-positive lags.\", 'target', 'lags', 'Test that transform correctly works with NaNs at the end.', 'target'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': [' ', 'gh', 'api', '-H', '\"Accept: application/vnd.github+json\"', '\"https://api.github.com/orgs/tinkoff-ai/packages/container/etna%2F', '/versions?page=', '\"', 'utf-8', 'metadata', 'container', 'tags', 'created_at', '%Y-%m-%dT%H:%M:%SZ', 'Removing ', 'url', ' ', 'echo -n |', 'gh', 'api', '--method', 'DELETE', '-H', '\"Accept: application/vnd.github+json\"', '\"', 'url', '\"', '--input -', '__main__', 'etna-cpu', 'etna-cuda-10.2', 'etna-cuda-11.1', 'etna-cuda-11.6.2'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['SVHN dataset class.\\n\\n    Args:\\n        root: Dataset root.\\n        train: Whether to use train or val part of the dataset.\\n    ', 'train', 'Whether dataset is classification or matching.', 'Whether dataset is for open-set or closed-set classification.', 'Get dataset labels array.\\n\\n        Labels are integers in the range [0, N-1], where N is number of classes\\n\\n        ', 'Get element of the dataset.\\n\\n        Returns tuple (image, label).\\n\\n        ', 'RGB'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <46x8 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 46 stored elements in Compressed Sparse Row format>, 'ClassDef': <9x9 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 9 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Pretrained model input image size.', 'Number of output channels.', 'Pretrained model input normalization mean.', 'Pretrained model input normalization STD.', 'Pretrained model input image size.', 'Number of output channels.', 'Pretrained model input normalization mean.', 'Pretrained model input normalization STD.', 'Pretrained co-training models are not available.', 'Pretrained model input image size.', 'Number of output channels.', 'Pretrained model input normalization mean.', 'Pretrained model input normalization STD.', 'Pretrained model input image size.', 'Number of output channels.', 'Pretrained model input normalization mean.', 'Pretrained model input normalization STD.', 'No pretrained PyramidNet available.', 'Pretrained model input image size.', 'Number of output channels.', 'Pretrained model input normalization mean.', 'Pretrained model input normalization STD.', 'imagenet', 'Pretrained model input image size.', 'Input size is available only for pretrained models.', 'Number of output channels.', 'Pretrained model input normalization mean.', 'Pretrained model input normalization STD.', 'Bad input shape', 'RGB', 'BGR', 'Pretrained weights are not available for VGG model.', 'M3', 'Model name ', ' is not available for VGG models.', 'Pretrained model input image size.', 'Number of output channels.', 'Pretrained model input normalization mean.', 'Pretrained model input normalization STD.', 'bn_inception_simple', 'Unknown model {}.'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['segment_code', 'Number of columns not the same as segments', 'Row missing', 'segment', 'segment_code', 'category', 'Column type is not category', 'Values are not the same for the whole column', 'Codes are not 0 and 1'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <15x13 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 15 stored elements in Compressed Sparse Row format>, 'ClassDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['predict', 'Test predict on full train dataset.\\n\\n    Expected that target values are filled after prediction.\\n    ', 'predict', 'model, transforms', 'target', 'target', 'Input contains NaN, infinity or a value too large', 'predict', 'model, transforms', 'target', 'target', 'target', 'target', \"Given context isn't big enough\", 'predict', 'model, transforms', 'predict', \"Method predict isn't currently implemented\", 'model, transforms', 'time_idx', 'target', 'segment', 'time_idx', 'target', 'segment', 'predict', 'It is not possible to make in-sample predictions', 'model, transforms', 'Test predict on suffix of train dataset.\\n\\n    Expected that target values are filled after prediction.\\n    ', 'predict', 'model, transforms', 'target', 'target', 'target', 'target', 'target', 'target', 'predict', \"Method predict isn't currently implemented\", 'model, transforms', 'time_idx', 'target', 'segment', 'time_idx', 'target', 'segment', 'predict', 'It is not possible to make in-sample predictions', 'model, transforms', 'Test predict on future dataset.\\n\\n    Expected that target values are filled after prediction.\\n    ', 'target', 'model, transforms', 'target', 'target', 'target', 'target', 'target', 'target', \"Method predict isn't currently implemented\", 'model, transforms', 'time_idx', 'target', 'segment', 'time_idx', 'target', 'segment', 'Test predict on mixture of in-sample and out-sample.\\n\\n    Expected that predictions on in-sample and out-sample separately match predictions on full mixed dataset.\\n    ', 'model, transforms', 'target', 'target', 'target', 'target', 'target', 'target', \"Method predict isn't currently implemented\", 'model, transforms', 'time_idx', 'target', 'segment', 'time_idx', 'target', 'segment'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <9x9 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 9 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['Download best seed metrics for each group from WandB.', 'wandb_path', \"Path to the project in format 'entity/project'.\", '-f', '--filename', 'Dump output to file.', '-n', '--num-seeds', 'Number of best seeds to compute statistics for.', '--std', 'Show std for each metric.', 'store_true', '--selection-metric', 'Metric to select best seed by.', '--selection-maximize', 'It true, maximize selection metric. Minimize for false value.', 'true', 'false', '--metric-regexp', '*', 'Regexp to filter metrics.', '--percent', 'Multiply metrics by 100.', 'store_true', '--precision', 'Number of decimal places.', '--separator', 'Fields separator.', ' ', '--url', 'WandB URL.', 'https://api.wandb.ai', '{:.', 'f}', ' ', 'group', 'N/A', 'N/A', '{} $\\\\pm$ {}', 'Returns mean/std metrics for best seeds from each group.', 'true', 'false', \"Group {} doesn't have metric {}.\", '/', 'base_url', '{}/{}', 'separator', 'percent', 'precision', 'add_std', 'w', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Test MLS is equal to estimation by sampling.', 'dim', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['range', 'sum', 'wandb-sweeps', 'test', 'sweeps', 'pipeline', 'backtest', 'config.yaml', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <7x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7 stored elements in Compressed Sparse Row format>, 'ClassDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Batch specification for MLP.', 'torch.Tensor', 'torch.Tensor', 'torch.Tensor', 'MLP model.', 'torch.nn.Module', 'Init MLP model.\\n\\n        Parameters\\n        ----------\\n        input_size:\\n            size of the input feature space: target plus extra features\\n        hidden_size:\\n            list of sizes of the hidden states\\n        lr:\\n            learning rate\\n        loss:\\n            loss function\\n        optimizer_params:\\n            parameters for optimizer for Adam optimizer (api reference :py:class:`torch.optim.Adam`)\\n        ', 'Forward pass.\\n\\n        Parameters\\n        ----------\\n        batch:\\n            batch of data\\n        Returns\\n        -------\\n        :\\n            forecast\\n        ', 'decoder_real', 'Step for loss computation for training or validation.\\n\\n        Parameters\\n        ----------\\n        batch:\\n            batch of data\\n        Returns\\n        -------\\n        :\\n            loss, true_target, prediction_target\\n        ', 'decoder_real', 'decoder_target', 'Make samples from segment DataFrame.', 'decoder_real', 'decoder_target', 'segment', 'target', 'decoder_real', 'target', 'target', 'decoder_target', 'segment', 'segment', 'Optimizer configuration.', 'MLPModel.', 'torch.nn.Module', 'Init MLP model.\\n        Parameters\\n        ----------\\n        input_size:\\n            size of the input feature space: target plus extra features\\n        decoder_length:\\n            decoder length\\n        hidden_size:\\n            List of sizes of the hidden states\\n        encoder_length:\\n            encoder length\\n        lr:\\n            learning rate\\n        loss:\\n            loss function, MSELoss by default\\n        train_batch_size:\\n            batch size for training\\n        test_batch_size:\\n            batch size for testing\\n        optimizer_params:\\n            parameters for optimizer for Adam optimizer (api reference :py:class:`torch.optim.Adam`)\\n        trainer_params:\\n            Pytorch ligthning trainer parameters (api reference :py:class:`pytorch_lightning.trainer.trainer.Trainer`)\\n        train_dataloader_params:\\n            parameters for train dataloader like sampler for example (api reference :py:class:`torch.utils.data.DataLoader`)\\n        test_dataloader_params:\\n            parameters for test dataloader\\n        val_dataloader_params:\\n            parameters for validation dataloader\\n        split_params:\\n            dictionary with parameters for :py:func:`torch.utils.data.random_split` for train-test splitting\\n                * **train_size**: (*float*) value from 0 to 1 - fraction of samples to use for training\\n                * **generator**: (*Optional[torch.Generator]*) - generator for reproducibile train-test splitting\\n                * **torch_dataset_size**: (*Optional[int]*) - number of samples in dataset, in case of dataset not implementing ``__len__``\\n        '], 'from': [], 'import': []}\n",
      "{'FunctionDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Naive model predicts t-th value of series with its (t - lag) value.\\n\\n    .. math::\\n        y_{t} = y_{t-s},\\n\\n    where :math:`s` is lag.\\n    ', '\\n        Init NaiveModel.\\n\\n        Parameters\\n        ----------\\n        lag: int\\n            lag for new value prediction\\n        ', 'NaiveModel'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Class for holding time series predictability prediction.', 'Init PredictabilityAnalyzer with given parameters.\\n\\n        Parameters\\n        ----------\\n        feature_extractor:\\n            Instance of time series feature extractor.\\n        classifier:\\n            Instance of classifier with sklearn interface.\\n        threshold:\\n            Positive class probability threshold.\\n        ', 'Transform the dataset into the array with time series samples.\\n\\n        Series in the result array are sorted in the alphabetical order of the corresponding segment names.\\n\\n        Parameters\\n        ----------\\n        ts:\\n            TSDataset with the time series.\\n\\n        Returns\\n        -------\\n        :\\n            Array with time series from TSDataset.\\n        ', 'target', 'Analyse the time series in the dataset for predictability.\\n\\n        Parameters\\n        ----------\\n        ts:\\n            Dataset with time series.\\n\\n        Returns\\n        -------\\n        :\\n            The indicators of predictability for the each segment in the dataset.\\n        ', 'Return the list of available models.', 'weasel', 'tsfresh', 'tsfresh_min', 'Return the list of available models.\\n\\n        Parameters\\n        ----------\\n        model_name:\\n            Name of the pretrained model.\\n        dataset_freq:\\n            Frequency of the dataset.\\n        path:\\n            Path to save the file with model.\\n\\n        Raises\\n        ------\\n        ValueError:\\n            If the model does not exist in s3.\\n        ', 'http://etna-github-prod.cdn-tinkoff.ru/series_classification/22_11_2022/', '/', '.pickle', 'Model not found! Check the list of available models!'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <8x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 8 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Improved version of WEASEL transform to work with the series of different length.', 'back_fill', 'Init CustomWEASEL with given parameters.\\n\\n        Parameters\\n        ----------\\n        padding_value:\\n            Value to pad the series to fit the `series_len`, if equals to \"back_fill\" the first value in\\n            the series is used.\\n        word_size:\\n            Size of each word.\\n        ngram_range:\\n            The lower and upper boundary of the range of ngrams.\\n        n_bins:\\n            The number of bins to produce. It must be between 2 and 26.\\n        window_sizes:\\n            Size of the sliding windows. All the elements must be either integers\\n            or floats. In the latter case, each element represents the percentage\\n            of the size of each time series and must be between 0 and 1; the size\\n            of the sliding windows will be computed as\\n            ``np.ceil(window_sizes * n_timestamps)``.\\n        window_steps:\\n            Step of the sliding windows. If None, each ``window_step`` is equal to\\n            ``window_size`` so that the windows are non-overlapping. Otherwise, all\\n            the elements must be either integers or floats. In the latter case,\\n            each element represents the percentage of the size of each time series\\n            and must be between 0 and 1; the step of the sliding windows will be\\n            computed as ``np.ceil(window_steps * n_timestamps)``.\\n        anova:\\n            If True, the Fourier coefficient selection is done via a one-way\\n            ANOVA test. If False, the first Fourier coefficients are selected.\\n        drop_sum:\\n            If True, the first Fourier coefficient (i.e. the sum of the subseries)\\n            is dropped. Otherwise, it is kept.\\n        norm_mean:\\n            If True, center each subseries before scaling.\\n        norm_std:\\n            If True, scale each subseries to unit variance.\\n        strategy:\\n            Strategy used to define the widths of the bins:\\n            - \\'uniform\\': All bins in each sample have identical widths\\n            - \\'quantile\\': All bins in each sample have the same number of points\\n            - \\'normal\\': Bin edges are quantiles from a standard normal distribution\\n            - \\'entropy\\': Bin edges are computed using information gain\\n        chi2_threshold:\\n            The threshold used to perform feature selection. Only the words with\\n            a chi2 statistic above this threshold will be kept.\\n        sparse:\\n            Return a sparse matrix if True, else return an array.\\n        alphabet:\\n            Alphabet to use. If None, the first `n_bins` letters of the Latin\\n            alphabet are used.\\n        ', 'Create the samples of length window_size with window_step.', 'Fit the feature extractor.\\n\\n        Parameters\\n        ----------\\n        x:\\n            Array with time series.\\n        y:\\n            Array of class labels.\\n\\n        Returns\\n        -------\\n        :\\n            Fitted instance of feature extractor.\\n        ', '', ' ', ' ', 'CustomWEASEL', 'Extract weasel features from the input data.\\n\\n        Parameters\\n        ----------\\n        x:\\n            Array with time series.\\n\\n        Returns\\n        -------\\n        :\\n            Transformed input data.\\n        ', '', ' ', 'Fit the feature extractor and extract weasel features from the input data.\\n\\n        Parameters\\n        ----------\\n        x:\\n            Array with time series.\\n\\n        Returns\\n        -------\\n        :\\n            Transformed input data.\\n        ', 'Class to extract features with WEASEL algorithm.', 'back_fill', 'entropy', 'Init WEASELFeatureExtractor with given parameters.\\n\\n        Parameters\\n        ----------\\n        padding_value:\\n            Value to pad the series to fit the `series_len`, if equals to \"back_fill\" the first value in\\n            the series is used.\\n        word_size:\\n            Size of each word.\\n        ngram_range:\\n            The lower and upper boundary of the range of ngrams.\\n        n_bins:\\n            The number of bins to produce. It must be between 2 and 26.\\n        window_sizes:\\n            Size of the sliding windows. All the elements must be either integers\\n            or floats. In the latter case, each element represents the percentage\\n            of the size of each time series and must be between 0 and 1; the size\\n            of the sliding windows will be computed as\\n            ``np.ceil(window_sizes * n_timestamps)``.\\n        window_steps:\\n            Step of the sliding windows. If None, each ``window_step`` is equal to\\n            ``window_size`` so that the windows are non-overlapping. Otherwise, all\\n            the elements must be either integers or floats. In the latter case,\\n            each element represents the percentage of the size of each time series\\n            and must be between 0 and 1; the step of the sliding windows will be\\n            computed as ``np.ceil(window_steps * n_timestamps)``.\\n        anova:\\n            If True, the Fourier coefficient selection is done via a one-way\\n            ANOVA test. If False, the first Fourier coefficients are selected.\\n        drop_sum:\\n            If True, the first Fourier coefficient (i.e. the sum of the subseries)\\n            is dropped. Otherwise, it is kept.\\n        norm_mean:\\n            If True, center each subseries before scaling.\\n        norm_std:\\n            If True, scale each subseries to unit variance.\\n        strategy:\\n            Strategy used to define the widths of the bins:\\n            - \\'uniform\\': All bins in each sample have identical widths\\n            - \\'quantile\\': All bins in each sample have the same number of points\\n            - \\'normal\\': Bin edges are quantiles from a standard normal distribution\\n            - \\'entropy\\': Bin edges are computed using information gain\\n        chi2_threshold:\\n            The threshold used to perform feature selection. Only the words with\\n            a chi2 statistic above this threshold will be kept.\\n        sparse:\\n            Return a sparse matrix if True, else return an array.\\n        alphabet:\\n            Alphabet to use. If None, the first `n_bins` letters of the Latin\\n            alphabet are used.\\n        ', 'Fit the feature extractor.\\n\\n        Parameters\\n        ----------\\n        x:\\n            Array with time series.\\n        y:\\n            Array of class labels.\\n\\n        Returns\\n        -------\\n        :\\n            Fitted instance of feature extractor.\\n        ', 'WEASELFeatureExtractor', 'Extract weasel features from the input data.\\n\\n        Parameters\\n        ----------\\n        x:\\n            Array with time series.\\n\\n        Returns\\n        -------\\n        :\\n            Transformed input data.\\n        '], 'from': [], 'import': []}\n",
      "{'FunctionDef': <8x8 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 8 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['Download metrics from WandB.', 'wandb_path', \"Path to the project in format 'entity/project'.\", '-f', '--filename', 'Dump output to file.', '--group', \"Group to load metrics from (use '-' to match ungrouped runs).\", '--run-regexp', '*', 'Regexp to filter runs.', '--metric-regexp', '*', 'Regexp to filter metrics.', '--percent', 'Multiply metrics by 100.', 'store_true', '--precision', 'Number of decimal places.', '--separator', 'Fields separator.', ' ', '--url', 'WandB URL.', 'https://api.wandb.ai', '-', '{:.', 'f}', ' ', 'N/A', '/', 'base_url', '{}/{}', 'separator', 'percent', 'precision', 'w', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['\\nMIT LICENCE\\n\\nCopyright (c) 2016 Maximilian Christ, Blue Yonder GmbH\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated\\ndocumentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the\\nrights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit\\npersons to whom the Software is furnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the\\nSoftware.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE\\nWARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\\nCOPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\\nOTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\\n', '\\n    Small helper function to initialize warnings module in multiprocessing workers.\\n\\n    On Windows, Python spawns fresh processes which do not inherit from warnings\\n    state, so warnings must be enabled/disabled before running computations.\\n\\n    :param show_warnings: whether to show warnings or not.\\n    :type show_warnings: bool\\n    ', 'ignore', 'default'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['https://towardsdatascience.com/text-similarity-w-levenshtein-distance-in-python-2f7478986e75', 'r', '.', '.', 'etna', '**/*.py', 'THIRDPARTY', 'pyproject.toml', 'r', 'tool', 'poetry', 'dependencies', 'python', 'sklearn', 'tsfresh', 'Missing deps: '], 'from': [], 'import': []}\n",
      "{'FunctionDef': <6x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['\\n    Count the approximation error by 1 bin from left to right elements.\\n\\n    Parameters\\n    ----------\\n    left:\\n        left border\\n    right:\\n        right border\\n    p:\\n        array of sums of elements, ``p[i]`` - sum from first to i elements\\n    pp:\\n        array of sums of squares of elements, ``pp[i]`` - sum of squares from first to i elements\\n\\n    Returns\\n    -------\\n    result: float\\n        approximation error\\n    ', '\\n    Count sse_one_bin[i][k] using binary search.\\n\\n    Parameters\\n    ----------\\n    i:\\n        left border of series\\n    k:\\n        number of bins\\n    sse:\\n        array of approximation errors\\n    sse_one_bin:\\n        array of approximation errors with one bin\\n\\n    Returns\\n    -------\\n    result: float\\n        calculated sse_one_bin[i][k]\\n    ', '\\n    Count an approximation error of a series with [1, bins_number] bins.\\n\\n    `Reference <http://www.vldb.org/conf/1998/p275.pdf>`_.\\n\\n    Parameters\\n    ----------\\n    series:\\n        array to count an approximation error with bins_number bins\\n    bins_number:\\n        number of bins\\n    p:\\n        array of sums of elements, p[i] - sum from 0th to i elements\\n    pp:\\n        array of sums of squares of elements, p[i] - sum of squares from 0th to i elements\\n\\n    Returns\\n    -------\\n    error: np.ndarray\\n        approximation error of a series with [1, bins_number] bins\\n    ', '\\n    Compute F. F[a][b][k] - minimum approximation error on series[a:b+1] with k outliers.\\n\\n    `Reference <http://www.vldb.org/conf/1999/P9.pdf>`_.\\n\\n    Parameters\\n    ----------\\n    series:\\n        array to count F\\n    k:\\n        number of outliers\\n    p:\\n        array of sums of elements, ``p[i]`` - sum from 0th to i elements\\n    pp:\\n        array of sums of squares of elements, ``pp[i]`` - sum of squares from 0th to i elements\\n\\n    Returns\\n    -------\\n    result: np.ndarray\\n        array F, outliers_indices\\n    ', '\\n    Compute outliers indices according to hist rule.\\n\\n    `Reference <http://www.vldb.org/conf/1999/P9.pdf>`_.\\n\\n    Parameters\\n    ----------\\n    series:\\n        array to count F\\n    bins_number:\\n        number of bins\\n\\n    Returns\\n    -------\\n    indices: np.ndarray\\n        outliers indices\\n    ', 'TSDataset', 'target', '\\n    Get point outliers in time series using histogram model.\\n\\n    Outliers are all points that, when removed, result in a histogram with a lower approximation error,\\n    even with the number of bins less than the number of outliers.\\n\\n    Parameters\\n    ----------\\n    ts:\\n        TSDataset with timeseries data\\n    in_column:\\n        name of the column in which the anomaly is searching\\n    bins_number:\\n        number of bins\\n\\n    Returns\\n    -------\\n    :\\n        dict of outliers in format {segment: [outliers_timestamps]}\\n    ', 'timestamp'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <19x19 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 19 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Embedder with optional classification head.\\n\\n    Parts of the model:\\n    1. Stem (CNN model).\\n    2. Head (mapping from CNN output to embedding).\\n    3. Normalizer (batchnorm of embeddings for some models).\\n    4. Classifier (mapping from embedding to logits).\\n\\n    Embedding pipeline just predicts distributions of embeddings.\\n    Classification pipeline matches samples from predicted distribution with target distribution.\\n\\n    Stages of classification pipeline:\\n    1. Predict embeddings distribution.\\n    2. Evaluate negative log likelihood of the learnt target embedding.\\n\\n    Args:\\n        num_classes: Number of output classes.\\n        priors: Precomputed class priors. Priors can be learned on-line or loaded from checkpoint.\\n        amp_classifier: Whether to use mixed precision for classifier or not.\\n\\n    Inputs:\\n        - images: Batch of images with the shape (B, 3, S, S).\\n        - labels: Target labels used in some scorers during training.\\n\\n    Outputs:\\n        Dictionary of:\\n            - distributions: Predicted distribution parameters.\\n            - logits (optional): Unnormalized log probabilities of each class.\\n    ', 'dirac', 'gmm', 'vmf', 'cnn', 'identity', 'dot', 'cosine', 'ecs', 'l2', 'mls', 'hib', 'linear', 'arcface', 'cosface', 'loglike', 'vmf-loss', 'spe', 'scorer', 'dirac', 'cnn', 'dot', 'linear', 'Get modle parameters.\\n\\n        Args:\\n            distribution_type: Predicted emdedding distribution type (\"dirac\", \"gmm\" or \"vmf\").\\n            distribution_params: Predicted distribution hyperparameters.\\n            embedder_type: Type of the embedder network: \"cnn\" for cnn embedder or \"identity\"\\n                if embeddings are directly providided as a model\\'s input.\\n            embedder_params: Parameters of the network for embeddings distribution estimation.\\n            scorer_type: Type of verification embeddings scorer (\"l2\" or \"cosine\").\\n            classifier_type: Type of classification embeddings scorer (\"linear\", \"arcface\", \"cosface\", \"loglike\", \"vmf-loss\" or \"spe\").\\n            classifier_params: Parameters of target distributions and scoring.\\n            freeze_classifier: If true, freeze classifier parameters (target classes embeddings).\\n        ', 'distribution_type', 'distribution_params', 'embedder_type', 'embedder_params', 'scorer_type', 'classifier_type', 'classifier_params', 'freeze_classifier', 'distribution_type', 'distribution_params', 'embedder_type', 'embedder_params', 'scorer_type', 'classifier_type', 'classifier_params', 'freeze_classifier', 'Whether model is classification or just embedder.', 'classifier_type', 'Distribution used by the model.', 'Number of output classes or None for embedder network.', 'Classifier is not available.', 'Model for embeddings generation.', 'Embeddings pairwise scorer.', 'set_ubm', 'freeze_classifier', 'distributions', 'logits', 'Target embeddings are available for classification models only.', 'Target bias is available for classification models only.', 'Target bias is available for classification models only.', 'Target variance is available for classification models only.', 'Target variance is available for classification models only.', 'Get target classification embeddings for all labels.', 'Compute useful statistics for logging.\\n\\n        Args:\\n            results: Model forward pass results.\\n\\n        Returns:\\n            Dictionary with floating-point statistics values.\\n        ', 'distributions', 'logits', 'logits/mean', 'logits/std', 'output_std', 'output_scale'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <7x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['BNInception', 'bn_inception', \"\\nInception v2 was ported from Caffee to pytorch 0.2, see\\nhttps://github.com/Cadene/pretrained-models.pytorch. I've ported it to\\nPyTorch 0.4 for the Proxy-NCA implementation, see\\nhttps://github.com/dichotomies/proxy-nca.\\n\", 'http://data.lip6.fr/cadene/pretrainedmodels/bn_inception-52deb4733.pth', 'BGR', 'fan_out'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <8x8 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 8 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['Create TSDataset with outliers and same last date.', '2021-01-01', '2021-02-20', 'D', 'timestamp', 'target', 'segment', '1', 'timestamp', 'target', 'segment', '2', 'timestamp', 'regressor_1', 'segment', 'D', 'all', \"Checks outliers transforms doesn't change structure of dataframe.\", 'in_column', 'target', 'regressor_1', 'transform_constructor, constructor_kwargs', 'Checks that outliers transforms detect anomalies according to methods from etna.analysis.', 'in_column', 'target', 'exog', 'transform_constructor, constructor_kwargs, method, method_kwargs', 'Checks that inverse transform returns dataset to its original form.', 'in_column', 'target', 'regressor_1', 'transform_constructor, constructor_kwargs', 'Checks that inverse transform does not change the future.', 'in_column', 'target', 'regressor_1', 'transform_constructor, constructor_kwargs', 'Test that transform for one segment raise error when calling transform without being fit.', 'Transform is not fitted!', 'transform', 'target', 'target', 'target', 'Test that transform for one segment raise error when calling inverse_transform without being fit.', 'Transform is not fitted!', 'transform', 'target', 'target', 'target', 'transform', 'target', 'target', 'target'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <13x13 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 13 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['Add seasonality to given series.', '2020-01-01', '2021-01-01', 'D', 'timestamp', 'target', 'segment', 'segment_1', 'segment', 'segment_2', 'D', 'FourierTransform(period = 10, order = None, mods = ', ', out_column = None, )', 'order, mods, repr_mods', 'Test that transform is not created with wrong period.', 'Period should be at least 2', 'period', 'Test that transform is not created with wrong order.', 'Order should be within', 'order', 'Test that transform is not created with wrong mods.', 'Every mod should be within', 'mods', 'Test that transform is not created without order and mods.', 'There should be exactly one option set', 'Test that transform is not created with both order and mods set.', 'There should be exactly one option set', 'Test that transform creates expected number of columns and they can be recreated by its name.', 'segment', 'feature', 'target', 'feature', 'target', 'period, order, num_columns', 'Test that transform creates expected columns if `out_column` is set', 'regressor_fourier', 'feature', 'target', 'regressor_fourier_', 'Test that transform generates correct values.', 'regressor_fourier', 'segment', 'regressor_fourier_', '1H', 'period, mod', 'Test that transform works correctly in forecast.', 'macro'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <9x9 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 9 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['Generate two series with different timestamp range.', 'timestamp', '2020-01-01', 'target', 'timestamp', 'timestamp', '2020-01-02', 'target', 'timestamp', 'target', 'target', 'Get df with complex pattern with timestamp lag.', '2020-01-0', 'timestamp', 'segment', 'target', 'D', 'Test euclidean distance in case of no trim series.', 'trim_series,expected', 'Test dtw distance in case of no trim series.', 'trim_series,expected', \"Check dtw with different series' lengths.\", 'x1,x2,expected', 'Test dtw matrix computation.', 'x1,x2,expected', 'Check that DTWDistance reconstructs path correctly.', 'matrix,expected_path', 'Check that dtw centroid catches the pattern of df series.', 'target', 'target'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <6x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['target', 'target', 'Check that binseg trend works with different custom costs.', 'target', 'custom_cost_class', 'Check that binseg trend works with different models.', 'target', 'model', 'l1', 'l2', 'normal', 'rbf', 'linear', 'ar', 'mahalanobis', 'rank', 'Check that binseg works with datasets with different length series.', 'target', 'target', 'segment', 'target', 'target', 'The input column contains NaNs in the middle of the series!'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <13x10 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 13 stored elements in Compressed Sparse Row format>, 'ClassDef': <6x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['stage', 'Event handler.', \"Doesn't support closure with accumulation_steps.\", 'scaler', 'gradient/scale', 'scale', 'gradient/growth_tracker', '_growth_tracker', 'scaler', 'gradient/norm', 'Forward-backward pass used in multi-step optimizers.', 'images', 'labels', 'criterion'], 'from': [], 'import': []}\n",
      "{'FunctionDef': [], 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['_target_', 'horizon', 'model', 'etna.pipeline.Pipeline', '${__aux__.horizon}', '_target_', 'lag', 'etna.models.NaiveModel', '_target_', 'horizon', 'model', 'etna.pipeline.Pipeline', '${__aux__.horizon}', '_target_', 'lag', 'etna.models.NaiveModel', '_target_', 'horizon', 'model', 'etna.pipeline.Pipeline', '${__aux__.horizon}', '_target_', 'window', 'etna.models.MovingAverageModel', '${mult:${horizon},1}', '_target_', 'horizon', 'model', 'etna.pipeline.Pipeline', '${__aux__.horizon}', '_target_', 'window', 'etna.models.MovingAverageModel', '${mult:${horizon},2}', '_target_', 'horizon', 'model', 'etna.pipeline.Pipeline', '${__aux__.horizon}', '_target_', 'window', 'etna.models.MovingAverageModel', '${mult:${horizon},3}', '_target_', 'horizon', 'model', 'etna.pipeline.Pipeline', '${__aux__.horizon}', '_target_', 'seasonality', 'window', 'etna.models.SeasonalMovingAverageModel', '_target_', 'horizon', 'model', 'etna.pipeline.Pipeline', '${__aux__.horizon}', '_target_', 'seasonality', 'window', 'etna.models.SeasonalMovingAverageModel', '${horizon}', '_target_', 'horizon', 'model', 'etna.pipeline.Pipeline', '${__aux__.horizon}', '_target_', 'etna.models.HoltWintersModel', '_target_', 'horizon', 'model', 'etna.pipeline.Pipeline', '${__aux__.horizon}', '_target_', 'damped_trend', 'seasonal', 'trend', 'etna.models.HoltWintersModel', 'add', 'add', '_target_', 'horizon', 'model', 'etna.pipeline.Pipeline', '${__aux__.horizon}', '_target_', 'damped_trend', 'seasonal', 'trend', 'etna.models.HoltWintersModel', 'add', 'add', '_target_', 'horizon', 'model', 'etna.pipeline.Pipeline', '${__aux__.horizon}', '_target_', 'etna.models.AutoARIMAModel', '_target_', 'horizon', 'model', 'transforms', 'etna.pipeline.Pipeline', '${__aux__.horizon}', '_target_', 'etna.models.LinearPerSegmentModel', '_target_', 'in_column', 'etna.transforms.StandardScalerTransform', 'target', '_target_', 'in_column', 'lags', 'etna.transforms.LagTransform', 'target', '${shift:${horizon},[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]}', '_target_', 'horizon', 'model', 'transforms', 'etna.pipeline.Pipeline', '${__aux__.horizon}', '_target_', 'etna.models.LinearMultiSegmentModel', '_target_', 'in_column', 'mode', 'etna.transforms.StandardScalerTransform', 'target', 'macro', '_target_', 'in_column', 'lags', 'etna.transforms.LagTransform', 'target', '${shift:${horizon},[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]}', '_target_', 'horizon', 'model', 'transforms', 'etna.pipeline.Pipeline', '${__aux__.horizon}', '_target_', 'etna.models.ElasticPerSegmentModel', '_target_', 'in_column', 'etna.transforms.StandardScalerTransform', 'target', '_target_', 'in_column', 'lags', 'etna.transforms.LagTransform', 'target', '${shift:${horizon},[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]}', '_target_', 'horizon', 'model', 'transforms', 'etna.pipeline.Pipeline', '${__aux__.horizon}', '_target_', 'etna.models.ElasticMultiSegmentModel', '_target_', 'in_column', 'mode', 'etna.transforms.StandardScalerTransform', 'target', 'macro', '_target_', 'in_column', 'lags', 'etna.transforms.LagTransform', 'target', '${shift:${horizon},[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]}', '_target_', 'horizon', 'model', 'transforms', 'etna.pipeline.Pipeline', '${__aux__.horizon}', '_target_', 'etna.models.CatBoostMultiSegmentModel', '_target_', 'in_column', 'mode', 'etna.transforms.StandardScalerTransform', 'target', 'macro', '_target_', 'in_column', 'lags', 'etna.transforms.LagTransform', 'target', '${shift:${horizon},[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]}', '_target_', 'etna.transforms.SegmentEncoderTransform', '_target_', 'day_number_in_week', 'is_weekend', 'week_number_in_year', 'etna.transforms.DateFlagsTransform', '_target_', 'horizon', 'model', 'transforms', 'etna.pipeline.Pipeline', '${__aux__.horizon}', '_target_', 'etna.models.CatBoostMultiSegmentModel', '_target_', 'in_column', 'lags', 'etna.transforms.LagTransform', 'target', '${shift:${horizon},[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]}', '_target_', 'etna.transforms.SegmentEncoderTransform', '_target_', 'day_number_in_week', 'is_weekend', 'week_number_in_year', 'etna.transforms.DateFlagsTransform', '_target_', 'horizon', 'model', 'transforms', 'etna.pipeline.Pipeline', '${__aux__.horizon}', '_target_', 'etna.models.CatBoostPerSegmentModel', '_target_', 'in_column', 'lags', 'etna.transforms.LagTransform', 'target', '${shift:${horizon},[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]}', '_target_', 'day_number_in_week', 'is_weekend', 'week_number_in_year', 'etna.transforms.DateFlagsTransform', '_target_', 'horizon', 'model', 'etna.pipeline.Pipeline', '${__aux__.horizon}', '_target_', 'seasonality_mode', 'etna.models.ProphetModel', 'multiplicative', '_target_', 'horizon', 'model', 'etna.pipeline.Pipeline', '${__aux__.horizon}', '_target_', 'seasonality_mode', 'etna.models.ProphetModel', 'additive'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <6x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'ClassDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Enum for different imputation strategy.', 'zero', 'mean', 'running_mean', 'forward_fill', 'seasonal', 'constant', \"One segment version of transform to fill NaNs in series of a given dataframe.\\n\\n    - It is assumed that given series begins with first non NaN value.\\n\\n    - This transform can't fill NaNs in the future, only on train data.\\n\\n    - This transform can't fill NaNs if all values are NaNs. In this case exception is raised.\\n\\n    \", '\\n        Create instance of _OneSegmentTimeSeriesImputerTransform.\\n\\n        Parameters\\n        ----------\\n        in_column:\\n            name of processed column\\n        strategy:\\n            filling value in missing timestamps:\\n\\n            - If \"zero\", then replace missing dates with zeros\\n\\n            - If \"mean\", then replace missing dates using the mean in fit stage.\\n\\n            - If \"running_mean\" then replace missing dates using mean of subset of data\\n\\n            - If \"forward_fill\" then replace missing dates using last existing value\\n\\n            - If \"seasonal\" then replace missing dates using seasonal moving average\\n\\n            - If \"constant\" then replace missing dates using constant value.\\n\\n        window:\\n            In case of moving average and seasonality.\\n\\n            * If ``window=-1`` all previous dates are taken in account\\n\\n            * Otherwise only window previous dates\\n\\n        seasonality:\\n            the length of the seasonality\\n        default_value:\\n            value which will be used to impute the NaNs left after applying the imputer with the chosen strategy\\n        constant_value:\\n            value to fill gaps in \"constant\" strategy\\n\\n        Raises\\n        ------\\n        ValueError:\\n            if incorrect strategy given\\n        ', '\\n        Fit preprocess params.\\n\\n        Parameters\\n        ----------\\n        df: pd.DataFrame\\n            dataframe with series to fit preprocess params with\\n\\n        Returns\\n        -------\\n        self: _OneSegmentTimeSeriesImputerTransform\\n            fitted preprocess\\n        ', \"Series hasn't non NaN values which means it is empty and can't be filled.\", 'zero strategy will be removed in etna 2.0.0. Use constant strategy instead.', '_OneSegmentTimeSeriesImputerTransform', '\\n        Transform given series.\\n\\n        Parameters\\n        ----------\\n        df: pd.Dataframe\\n            transform ``in_column`` series of given dataframe\\n\\n        Returns\\n        -------\\n        result: pd.DataFrame\\n            dataframe with in_column series with filled gaps\\n        ', '\\n        Inverse transform dataframe.\\n\\n        Parameters\\n        ----------\\n        df: pd.Dataframe\\n            inverse transform ``in_column`` series of given dataframe\\n\\n        Returns\\n        -------\\n        result: pd.DataFrame\\n            dataframe with in_column series with initial values\\n        ', '\\n        Create new Series taking all previous dates and adding missing dates.\\n\\n        Fills missed values for new dates according to ``self.strategy``\\n\\n        Parameters\\n        ----------\\n        df: pd.Series\\n            series to fill\\n\\n        Returns\\n        -------\\n        result: pd.Series\\n        ', 'Trying to apply the unfitted transform! First fit the transform.', 'ffill', \"Transform to fill NaNs in series of a given dataframe.\\n\\n    - It is assumed that given series begins with first non NaN value.\\n\\n    - This transform can't fill NaNs in the future, only on train data.\\n\\n    - This transform can't fill NaNs if all values are NaNs. In this case exception is raised.\\n\\n    Warning\\n    -------\\n    This transform can suffer from look-ahead bias in 'mean' mode. For transforming data at some timestamp\\n    it uses information from the whole train part.\\n    \", 'target', '\\n        Create instance of TimeSeriesImputerTransform.\\n\\n        Parameters\\n        ----------\\n        in_column:\\n            name of processed column\\n        strategy:\\n            filling value in missing timestamps:\\n\\n            - If \"zero\", then replace missing dates with zeros\\n\\n            - If \"mean\", then replace missing dates using the mean in fit stage.\\n\\n            - If \"running_mean\" then replace missing dates using mean of subset of data\\n\\n            - If \"forward_fill\" then replace missing dates using last existing value\\n\\n            - If \"seasonal\" then replace missing dates using seasonal moving average\\n\\n            - If \"constant\" then replace missing dates using constant value.\\n\\n        window:\\n            In case of moving average and seasonality.\\n\\n            * If ``window=-1`` all previous dates are taken in account\\n\\n            * Otherwise only window previous dates\\n\\n        seasonality:\\n            the length of the seasonality\\n        default_value:\\n            value which will be used to impute the NaNs left after applying the imputer with the chosen strategy\\n        constant_value:\\n            value to fill gaps in \"constant\" strategy\\n\\n        Raises\\n        ------\\n        ValueError:\\n            if incorrect strategy given\\n        ', 'TimeSeriesImputerTransform'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <17x17 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 17 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['Add trend to given series.', 'Add seasonality to given series.', 'timestamp', '2020-01-01', '2020-03-01', 'D', 'target', 'target', 'target', 'target', 'target', 'timestamp', 'segment', 'segment_1', 'segment', 'segment_2', 'D', 'segment', 'segment_1', 'segment', 'segment_2', 'segment_1', 'target', 'D', 'segment', 'segment_1', 'segment', 'segment_2', 'segment_1', 'target', 'D', 'Test that transform for one segment removes trend and seasonality.', 'target', 'target', 'target', 'target', 'target', 'model', 'arima', 'holt', 'df_name', 'df_trend_seasonal_one_segment', 'df_trend_seasonal_starting_with_nans_one_segment', 'Test that transform for all segments removes trend and seasonality.', 'target', 'target', 'target', 'target', 'target', 'model', 'arima', 'holt', 'ts_name', 'ts_trend_seasonal', 'ts_trend_seasonal_starting_with_nans', \"Test that transform + inverse_transform don't change dataframe.\", 'target', 'target', 'target', 'model', 'arima', 'holt', 'df_name', 'df_trend_seasonal_one_segment', 'df_trend_seasonal_starting_with_nans_one_segment', \"Test that transform + inverse_transform don't change tsdataset.\", 'target', 'target', 'target', 'model', 'arima', 'holt', 'ts_name', 'ts_trend_seasonal', 'ts_trend_seasonal_starting_with_nans', 'Test that transform works correctly in forecast.', 'target', 'target', 'target', 'model_stl', 'arima', 'holt', 'Test that transform for one segment raise error when calling transform without being fit.', 'target', 'arima', 'Transform is not fitted!', 'Test that transform for one segment raise error when calling inverse_transform without being fit.', 'target', 'arima', 'Transform is not fitted!', 'target', 'target', 'model_stl', 'arima', 'holt', 'target', 'The input column contains NaNs in the middle of the series!'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Increases maximum STD during training.', 'Get scheduler parameters.', 'min_variance', 'model', \"Classifier doesn't have variance.\", 'min_variance'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <9x9 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 9 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['per-segment', 'timestamp', '2021-06-01', '2021-07-01', '1d', 'timestamp', '2021-06-01', '2021-07-01', '1d', 'segment', 'Moscow', 'target', 'exog', 'segment', 'Omsk', 'target', 'exog', 'Check that `inverse_transform(transform(df)) == df` for all columns.', 'scaler', 'mode', 'macro', 'per-segment', 'Check that `inverse_transform(transform(df)) == df` for one column.', 'scaler', 'target', 'target', 'target', 'target', 'target', 'target', 'target', 'target', 'mode', 'macro', 'per-segment', 'Check that inversed values the same for not inplace version.', 'scaler', 'mode', 'macro', 'per-segment', 'target', 'scaler', 'mode', 'macro', 'per-segment'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['Calculate distance for :py:func:`get_anomalies_density` function by taking absolute value of difference.\\n\\n    Parameters\\n    ----------\\n    x:\\n        first value\\n    y:\\n        second value\\n\\n    Returns\\n    -------\\n    result: float\\n        absolute difference between values\\n    ', \"Get indices of outliers for one series.\\n\\n    Parameters\\n    ----------\\n    series:\\n        array to find outliers in\\n    window_size:\\n        size of window\\n    distance_threshold:\\n        if distance between two items in the window is less than threshold those items are supposed to be close to each other\\n    n_neighbors:\\n        min number of close items that item should have not to be outlier\\n    distance_func:\\n        distance function\\n\\n    Returns\\n    -------\\n    :\\n        list of outliers' indices\\n    \", 'Return 1 if item1 is closer to item2 than distance_threshold according to distance_func, 0 otherwise.', 'TSDataset', 'target', 'Compute outliers according to density rule.\\n\\n    For each element in the series build all the windows of size ``window_size`` containing this point.\\n    If any of the windows contains at least ``n_neighbors`` that are closer than ``distance_coef * std(series)``\\n    to target point according to ``distance_func`` target point is not an outlier.\\n\\n    Parameters\\n    ----------\\n    ts:\\n        TSDataset with timeseries data\\n    in_column:\\n        name of the column in which the anomaly is searching\\n    window_size:\\n        size of windows to build\\n    distance_coef:\\n        factor for standard deviation that forms distance threshold to determine points are close to each other\\n    n_neighbors:\\n        min number of close neighbors of point not to be outlier\\n    distance_func:\\n        distance function\\n\\n    Returns\\n    -------\\n    :\\n        dict of outliers in format {segment: [outliers_timestamps]}\\n\\n    Notes\\n    -----\\n    It is a variation of distance-based (index) outlier detection method adopted for timeseries.\\n    ', 'timestamp', 'get_anomalies_density', 'absolute_difference_distance'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Model weights and parameters initializer.\\n\\n    Args:\\n        model: Model to initialize.\\n        train_loader: Train batches loader (for statistics computation in vMF-loss initializer).\\n    ', 'normal', 'xavier_uniform', 'xavier_normal', 'kaiming_normal', 'kaiming_normal_fanout', 'fan_out', 'Get initializer parameters.\\n\\n        Args:\\n            matrix_initializer: Type of matrix initialization (\"normal\", \"xavier_uniform\", \"xavier_normal\",\\n                \"kaiming_normal\", \"kaiming_normal_fanout\" or None). Use PyTorch default if None is provided.\\n            num_statistics_batches: Number of batches used for statitistics computation in vMF-loss initialization.\\n        ', 'matrix_initializer', 'num_statistics_batches', 'matrix_initializer', 'matrix_initializer', 'Unexpected distribution for vMF-loss: {}.', 'num_statistics_batches'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <8x8 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 8 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['1d', 'regressor_exog', 'feature', 'floor', 'feature', 'cap', 'feature', '1d', 'all', 'logistic', 'timestamp', 'segment', 'target', '2020-01-01', 'segment_0', 'timestamp', 'segment', 'cap', 'floor', '2020-01-01', 'segment_0', 'D', 'all', 'logistic', 'target', 'target_0.025', 'target_0.975', 'target', 'target_0.975', 'target_0.025', 'target_0.025', 'target_0.975', 'target', 'target_0.975', 'target_0.025', 'Check that get_model method throws an error if per-segment model is not fitted yet.', 'Can not get the dict with base models, the model is not fitted!', 'Check that get_model method returns dict of objects of Prophet class.'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Generate a pool of pipelines from given config templates in hydra format.', \"\\n        Initialize with a list of config templates in hydra format.\\n\\n        Parameters\\n        ----------\\n        configs_template:\\n            list of template configs in hydra format\\n\\n        Notes\\n        -----\\n        Hydra configs templates:\\n        ::\\n            {\\n                '_target_': 'etna.pipeline.Pipeline',\\n                'horizon': '${__aux__.horizon}',\\n                'model': {'_target_': 'etna.models.ProphetModel'}\\n            }\\n        Values to be interpolated should be in the form of ``${__aux__.key}``\\n        \", '\\n        Fill templates with args.\\n\\n        Parameters\\n        ----------\\n        horizon:\\n            horizon to forecast\\n        ', 'horizon', 'Predefined pools of pipelines.'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['--path', '--top', '--pattern-to-filter', 'line', 'line', '\\\\n', '', '__main__', 'speedscope.json', 'r', 'py_spy.csv'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <11x11 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 11 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['context_size', 'start_timestamp, end_timestamp', '2020-01-01', '2020-01-01', '2020-01-01', '2020-01-02', '2020-01-01', '2020-01-10', '2020-01-05', '2020-01-10', 'transforms', 'regressor_exog_weekend', 'regressor_exog_weekend', 'start_timestamp, end_timestamp, expected_prediction_size', '2020-01-01', '2020-01-01', '2020-01-01', '2020-01-02', '2020-01-01', '2020-01-10', '2020-01-05', '2020-01-10', 'start_timestamp, end_timestamp', '2020-01-01', '2020-01-01', '2020-01-01', '2020-01-02', '2020-01-01', '2020-01-10', '2020-01-05', '2020-01-10', 'start_timestamp, end_timestamp', '2020-01-01', '2020-01-01', '2020-01-01', '2020-01-02', '2020-01-01', '2020-01-10', '2020-01-05', '2020-01-10', 'Model ', \" doesn't support prediction intervals\", '2020-01-01', '2020-01-02', 'model_class', '2020-01-01', '2020-01-02', 'ts', 'ts', 'prediction_size', 'ts', 'prediction_interval', 'quantiles', 'quantiles', 'prediction_interval', 'ts', 'prediction_size', 'prediction_interval', 'quantiles', 'quantiles', 'prediction_interval'], 'from': [], 'import': []}\n",
      "{'FunctionDef': [], 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['0.1.0', 'probabilistic_embeddings', 'Experiments with MDN for metric learning.', 'https://github.com/tinkoff-ai/probabilistic-embeddings', 'Ivan Karpukhin and Stanislav Dereka', 'karpuhini@yandex.ru', 'src', '', 'src', 'catalyst==21.9', 'faiss-cpu==1.7.0', 'jpeg4py==0.1.4', 'mxnet==1.8.0.post0', 'numpy==1.19.5', 'optuna==2.10.0', 'pretrainedmodels==0.7.4', 'scikit-image==0.17.2', 'scikit-learn==0.24.2', 'scipy==1.5.4', 'torch==1.10.1', 'torchvision==0.11.2', 'Pillow==8.3.1', 'PyYAML==5.4.1', 'gitpython', 'wandb'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <7x7 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['Eval train/inference speed.', 'data', 'Path to dataset root', '--config', 'Path to training config', '{}: {:.2f} +- {:.2f} ms', 'on_stage_start', 'criterion', 'optimizer', 'train', 'embedder', 'embedder', 'Memory usage (MB):', 'Memory usage per request (MB):', 'embedder', 'Train CNN', 'train', 'on_stage_start', 'criterion', 'valid', 'embedder', 'Inference CNN', 'valid', 'Inference full', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <17x17 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 17 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['DateFlagsTransform is a class that implements extraction of the main date-based features from datetime column.\\n\\n    Notes\\n    -----\\n    Small example of ``week_number_in_month`` and ``week_number_in_year`` features\\n\\n    =============  ======================  ========================  ========================\\n      timestamp      day_number_in_week      week_number_in_month      week_number_in_year\\n    =============  ======================  ========================  ========================\\n    2020-01-01     4                       1                         53\\n    2020-01-02     5                       1                         53\\n    2020-01-03     6                       1                         53\\n    2020-01-04     0                       2                         1\\n    ...\\n    2020-01-10     6                       2                         1\\n    2020-01-11     0                       3                         2\\n    =============  ======================  ========================  ========================\\n    ', \"Create instance of DateFlags.\\n\\n        Parameters\\n        ----------\\n        day_number_in_week:\\n            if True, add column with weekday info to feature dataframe in transform\\n        day_number_in_month:\\n            if True, add column with day info to feature dataframe in transform\\n        day_number_in_year:\\n            if True, add column with number of day in a year with leap year numeration (values from 1 to 366)\\n        week_number_in_month:\\n            if True, add column with week number (in month context) to feature dataframe in transform\\n        week_number_in_year:\\n            if True, add column with week number (in year context) to feature dataframe in transform\\n        month_number_in_year:\\n            if True, add column with month info to feature dataframe in transform\\n        season_number:\\n            if True, add column with season info to feature dataframe in transform\\n        year_number:\\n            if True, add column with year info to feature dataframe in transform\\n        is_weekend:\\n            if True: add column with weekends flags to feature dataframe in transform\\n        special_days_in_week:\\n            list of weekdays number (from [0, 6]) that should be interpreted as special ones, if given add column\\n            with flag that shows given date is a special day\\n        special_days_in_month:\\n            list of days number (from [1, 31]) that should be interpreted as special ones, if given add column\\n            with flag that shows given date is a special day\\n        out_column:\\n            base for the name of created columns;\\n\\n            * if set the final name is '{out_column}_{feature_name}';\\n\\n            * if don't set, name will be ``transform.__repr__()``,\\n              repr will be made for transform that creates exactly this column\\n\\n        \", ' feature does nothing with given init args configuration, at least one of day_number_in_week, day_number_in_month, day_number_in_year, week_number_in_month, week_number_in_year, month_number_in_year, season_number, year_number, is_weekend should be True or any of special_days_in_week, special_days_in_month should be not empty.', '_', 'Fit model. In this case of DateFlags does nothing.', 'DateFlagsTransform', \"Get required features from df.\\n\\n        Parameters\\n        ----------\\n        df:\\n            dataframe for feature extraction, should contain 'timestamp' column\\n\\n        Returns\\n        -------\\n        :\\n            dataframe with extracted features\\n        \", 'day_number_in_week', 'day_number_in_month', 'day_number_in_year', 'week_number_in_month', 'week_number_in_year', 'month_number_in_year', 'season_number', 'year_number', 'is_weekend', 'special_days_in_week', 'special_days_in_month', 'category', 'segment', 'segment', 'segment', 'feature', 'Return array with special days marked 1.\\n\\n        Accepts a list of special days IN WEEK as input and returns array where these days are marked with 1\\n        ', 'Return array with special days marked 1.\\n\\n        Accepts a list of special days IN MONTH as input and returns array where these days are marked with 1\\n        ', 'Generate an array with the number of the day in the week.', 'Generate an array with the number of the day in the month.', 'Generate an array with the season number.', 'Generate an array with number of day in a year with leap year numeration (values from 1 to 366).', 'Return day number with leap year numeration.', 'Generate an array with the week number in the month.', 'Return week of month number.\\n\\n            How it works:\\n            Each month starts with the week number 1, no matter which weekday the 1st day is, for example\\n\\n            * 2021-01-01 is a Friday, we mark it as 1st week\\n            * 2021-01-02 is a Saturday, 1st week\\n            * 2021-01-03 is a Sunday, 1st week\\n            * 2021-01-04 is a Monday, 2nd week\\n            * ...\\n            * 2021-01-10 is a Sunday, 2nd week\\n            * 2021-01-11 is a Monday, 3rd week\\n            * ...\\n\\n            ', 'Generate an array with the week number in the year.', 'Generate an array with the week number in the year.', 'Generate an array with the week number in the year.', 'Generate an array with the weekends flags.', 'DateFlagsTransform'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Implementation of the Proxy-NAC loss with custom scorer.\\n\\n    For details see original paper:\\n    https://openaccess.thecvf.com/content_ICCV_2017/papers/Movshovitz-Attias_No_Fuss_Distance_ICCV_2017_paper.pdf\\n    ', 'Get default config.', 'mean', 'Expected embeddings with shape (B, D), got {}', 'none', 'mean', 'Unknown aggregation: {}'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['w', '\\n        n_folds: 3\\n        n_jobs: ${n_folds}\\n        metrics:\\n          - _target_: etna.metrics.MAE\\n          - _target_: etna.metrics.MSE\\n          - _target_: etna.metrics.MAPE\\n          - _target_: etna.metrics.SMAPE\\n        ', 'etna', 'backtest', 'D', 'metrics.csv', 'forecast.csv', 'info.csv', 'etna', 'backtest', 'D', 'metrics.csv', 'forecast.csv', 'info.csv', 'etna', 'backtest', 'D', 'forecast.csv', 'segment', 'timestamp', 'target'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['test', 'MAE', 'MAPE', 'MAE', 'MAPE', 'etna.loggers.wandb_logger.wandb'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <8x8 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 8 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['VotingEnsemble is a pipeline that forecast future values with weighted averaging of it\\'s pipelines forecasts.\\n\\n    Examples\\n    --------\\n    >>> from etna.datasets import generate_ar_df\\n    >>> from etna.datasets import TSDataset\\n    >>> from etna.ensembles import VotingEnsemble\\n    >>> from etna.models import NaiveModel\\n    >>> from etna.models import ProphetModel\\n    >>> from etna.pipeline import Pipeline\\n    >>> df = generate_ar_df(periods=30, start_time=\"2021-06-01\", ar_coef=[1.2], n_segments=3)\\n    >>> df_ts_format = TSDataset.to_dataset(df)\\n    >>> ts = TSDataset(df_ts_format, \"D\")\\n    >>> prophet_pipeline = Pipeline(model=ProphetModel(), transforms=[], horizon=7)\\n    >>> naive_pipeline = Pipeline(model=NaiveModel(lag=10), transforms=[], horizon=7)\\n    >>> ensemble = VotingEnsemble(\\n    ...     pipelines=[prophet_pipeline, naive_pipeline],\\n    ...     weights=[0.7, 0.3]\\n    ... )\\n    >>> _ = ensemble.fit(ts=ts)\\n    >>> forecast = ensemble.forecast()\\n    >>> forecast\\n    segment         segment_0        segment_1       segment_2\\n    feature\\t       target           target\\t        target\\n    timestamp\\n    2021-07-01\\t        -8.84\\t       -186.67\\t        130.99\\n    2021-07-02\\t        -8.96\\t       -198.16\\t        138.81\\n    2021-07-03\\t        -9.57\\t       -212.48\\t        148.48\\n    2021-07-04\\t       -10.48\\t       -229.16\\t        160.13\\n    2021-07-05\\t       -11.20          -248.93\\t        174.39\\n    2021-07-06\\t       -12.47\\t       -281.90\\t        197.82\\n    2021-07-07\\t       -13.51\\t       -307.02\\t        215.73\\n    ', 'auto', 'Init VotingEnsemble.\\n\\n        Parameters\\n        ----------\\n        pipelines:\\n            List of pipelines that should be used in ensemble\\n        weights:\\n            List of pipelines\\' weights.\\n\\n            * If None, use uniform weights\\n\\n            * If List[float], use this weights for the base estimators, weights will be normalized automatically\\n\\n            * If \"auto\", use importances of the base estimators forecasts as weights of base estimators\\n\\n        regressor:\\n            Regression model with fit/predict interface which will be used to evaluate weights of the base estimators.\\n            It should have ``feature_importances_`` property (e.g. all tree-based regressors in sklearn)\\n        n_folds:\\n            Number of folds to use in the backtest.\\n            Backtest is used to obtain the forecasts from the base estimators;\\n            forecasts will be used to evaluate the estimator\\'s weights.\\n        n_jobs:\\n            Number of jobs to run in parallel\\n        joblib_params:\\n            Additional parameters for :py:class:`joblib.Parallel`\\n\\n        Raises\\n        ------\\n        ValueError:\\n            If the number of the pipelines is less than 2 or pipelines have different horizons.\\n        ', 'multiprocessing', 'c', 'auto', 'Validate the format of weights parameter.', 'auto', 'Weights size should be equal to pipelines number.', 'Invalid format of weights is passed!', 'Get forecasts from backtest for given pipeline.', 'Get the weights of base estimators depending on the weights mode.', 'auto', 'Something went wrong, ts is None!', 'target', 'target', 'target_', 'target', 'Fit pipelines in ensemble.\\n\\n        Parameters\\n        ----------\\n        ts:\\n            TSDataset to fit ensemble\\n\\n        Returns\\n        -------\\n        self:\\n            Fitted ensemble\\n        ', 'VotingEnsemble', 'Get average forecast.', 'Ensemble is not fitted! Fit the ensemble before calling the forecast!', 'target', \"Make predictions.\\n\\n        Compute weighted average of pipelines' forecasts\\n        \", 'Something went wrong, ts is None!', 'multiprocessing', 'Ensemble ', \" doesn't support prediction intervals!\", 'multiprocessing'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <11x11 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 11 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['2020-01-01', 'D', 'segment', 'segment', 'timestamp', 'timestamp', '2020-01-01', 'D', 'segment', 'segment', 'target', 'regressor_useless_', 'segment', 'segment', 'target', 'regressor_useful_', 'segment', 'segment', 'timestamp', 'D', 'all', 'all', 'model', 'Check that transform selects exactly top_k regressors if where are this much.', 'segment_code', 'feature', 'target', 'model', 'segment_code', 'top_k', \"Check that transform doesn't change values of columns.\", 'feature', 'model', 'segment_code', 'top_k', \"Check that transform doesn't allow you to set top_k to negative values.\", 'positive integer', 'model', 'segment_code', 'Check that transform allows you to fit on dataset with no regressors but warns about it.', 'not possible to select features', 'model', 'Check that transform correctly finds meaningful regressors.', 'feature', 'regressor_', 'useful', 'model', 'segment_code', 'Check that training with this transform can utilize selected regressors.', 'target', 'target', 'model', 'segment_code', 'model', 'regressor_exog_weekend', 'Check that transform selects exactly top_k regressors.', 'feature', 'regressor', 'relevance_table', 'top_k', 'Check that transform selects right top_k regressors.', 'feature', 'regressor', 'regressor_useful_0', 'regressor_useful_1', 'regressor_useful_2', 'relevance_table'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <6x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['D', 'target', 'D', 'target'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Class to hold tsfresh features extraction from tsfresh.\\n\\n    Notes\\n    -----\\n    `tsfresh` should be installed separately using `pip install tsfresh`.\\n    ', 'Init TSFreshFeatureExtractor with given parameters.\\n\\n        Parameters\\n        ----------\\n        default_fc_parameters:\\n            Dict with names of features.\\n            .. Examples: https://github.com/blue-yonder/tsfresh/blob/main/tsfresh/feature_extraction/settings.py\\n        fill_na_value:\\n            Value to fill the NaNs in the resulting dataframe.\\n        n_jobs:\\n            The number of processes to use for parallelization.\\n        ', 'Fit the feature extractor.', 'TSFreshFeatureExtractor', 'Extract tsfresh features from the input data.\\n\\n        Parameters\\n        ----------\\n        x:\\n            Array with time series.\\n\\n        Returns\\n        -------\\n        :\\n            Transformed input data.\\n        ', 'id', 'value', 'id', 'value'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['Train single model and eval best checkpoint.', 'Need training root path', 'Run training with config:', 'wandb', 'Skip training.', 'checkpoints', 'best.pth', 'tensorboard', 'epoch', 'wandb', 'metrics.yaml', 'Compute metrics for checkpoint.', 'Need checkpoint for evaluation'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['Check that compute_metrics return correct metrics keys.', 'per-segment', 'macro', 'per-segment', 'macro', \"MAE(mode = 'per-segment', )\", \"MAE(mode = 'macro', )\", \"MSE(mode = 'per-segment', )\", \"MAPE(mode = 'macro', eps = 1e-05, )\"], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['https://julien.danjou.info/finding-definitions-from-a-source-file-and-a-line-number-in-python', 'lineno', 'r', 'main.py', 'elapsed_time_sec', 'files', 'files', 'lines', 'n_cpu_percent_all', 'n_cpu_percent_python', 'n_cpu_percent_c', 'n_cpu_percent_all', 'file', 'function', '.', 'function_n_cpu_percent_all', 'function', 'sum', 'function_n_copy_mb_s', 'function', 'sum', 'percent_cpu_time', 'files', 'percent_cpu_time', 'total_time', 'percent_cpu_time', 'function_n_cpu_percent_all', 'n_cpu_percent_all', 'file', 'total_time', 'percent_cpu_time', 'function', 'function_n_cpu_percent_all', 'function_n_copy_mb_s', 'line', 'n_cpu_percent_all', 'n_cpu_percent_c', 'n_cpu_percent_python', 'n_copy_mb_s', 'etna/etna', 'shared', 'frames', 'profiles', 'samples', 'profiles', 'samples', 'file', 'name', 'file', 'line', 'lineno', 'file', 'tuples', 'counter', 'lineno', 'file', 'r', 'function', '.', 'file', 'lineno', 'line', 'file', 'lineno', 'approx_time', 'counter', 'file_approx_time', 'file', 'sum', 'file', '/', 'approx_time', 'file_approx_time', 'approx_time', 'file', 'file_approx_time', 'function', 'approx_time', 'line'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <21x19 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 21 stored elements in Compressed Sparse Row format>, 'ClassDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': [\"Calculate cross correlation between arrays.\\n\\n    This implementation is slow: O(n^2), but can properly ignore NaNs.\\n\\n    Parameters\\n    ----------\\n    a:\\n        first array, should be equal length with b\\n    b:\\n        second array, should be equal length with a\\n    maxlags:\\n        number of lags to compare, should be >=1 and < len(a)\\n    normed:\\n        should correlations be normed or not\\n\\n    Returns\\n    -------\\n    lags, result:\\n\\n        * lags: array of size ``maxlags * 2 + 1`` represents for which lags correlations are calculated in ``result``\\n\\n        * result: array of size ``maxlags * 2 + 1`` represents found correlations\\n\\n    Raises\\n    ------\\n    ValueError:\\n        lengths of ``a`` and ``b`` are not the same\\n    ValueError:\\n        parameter ``maxlags`` doesn't satisfy constraints\\n    \", 'Lengths of arrays should be equal', 'Parameter maxlags should be >= 1 and < len(a)', 'TSDataset', \"\\n    Cross-correlation plot between multiple timeseries.\\n\\n    Parameters\\n    ----------\\n    ts:\\n        TSDataset with timeseries data\\n    n_segments:\\n        number of random segments to plot, ignored if parameter ``segments`` is set\\n    maxlags:\\n        number of timeseries shifts for cross-correlation, should be >=1 and <= len(timeseries)\\n    segments:\\n        segments to plot\\n    columns_num:\\n        number of columns in subplots\\n    figsize:\\n        size of the figure per subplot with one segment in inches\\n\\n    Raises\\n    ------\\n    ValueError:\\n        parameter ``maxlags`` doesn't satisfy constraints\\n    \", 'There are no pairs to plot! Try set n_segments > 1.', 'Cross-correlation', 'target', 'target', 'At least one target column has integer dtype, it is converted to float in order to calculate correlation.', '-o', ' vs ', 'TSDataset', '\\n    Autocorrelation and partial autocorrelation plot for multiple timeseries.\\n\\n    Notes\\n    -----\\n    `Definition of autocorrelation <https://en.wikipedia.org/wiki/Autocorrelation>`_.\\n\\n    `Definition of partial autocorrelation <https://en.wikipedia.org/wiki/Partial_autocorrelation_function>`_.\\n\\n    * If ``partial=False`` function works with NaNs at any place of the time-series.\\n\\n    * if ``partial=True`` function works only with NaNs at the edges of the time-series and fails if there are NaNs inside it.\\n\\n    Parameters\\n    ----------\\n    ts:\\n        TSDataset with timeseries data\\n    n_segments:\\n        number of random segments to plot\\n    lags:\\n        number of timeseries shifts for cross-correlation\\n    partial:\\n        plot autocorrelation or partial autocorrelation\\n    columns_num:\\n        number of columns in subplots\\n    segments:\\n        segments to plot\\n    figsize:\\n        size of the figure per subplot with one segment in inches\\n\\n    Raises\\n    ------\\n    ValueError:\\n        If partial=True and there is a NaN in the middle of the time series\\n    ', 'Partial Autocorrelation', 'Autocorrelation', 'target', 'There is a NaN in the middle of the time series!', 'conservative', 'TSDataset', '\\n    Autocorrelation plot for multiple timeseries.\\n\\n    Notes\\n    -----\\n    `Definition of autocorrelation <https://en.wikipedia.org/wiki/Autocorrelation>`_.\\n\\n    Parameters\\n    ----------\\n    ts:\\n        TSDataset with timeseries data\\n    n_segments:\\n        number of random segments to plot\\n    lags:\\n        number of timeseries shifts for cross-correlation\\n    segments:\\n        segments to plot\\n    figsize:\\n        size of the figure per subplot with one segment in inches\\n    ', 'DeprecationWarning: This function is deprecated and will be removed in etna=2.0; Please use acf_plot instead.', 'TSDataset', '\\n    Partial autocorrelation plot for multiple timeseries.\\n\\n    Notes\\n    -----\\n    `Definition of partial autocorrelation <https://en.wikipedia.org/wiki/Partial_autocorrelation_function>`_.\\n\\n    Parameters\\n    ----------\\n    ts:\\n        TSDataset with timeseries data\\n    n_segments:\\n        number of random segments to plot\\n    lags:\\n        number of timeseries shifts for cross-correlation\\n    segments:\\n        segments to plot\\n    figsize:\\n        size of the figure per subplot with one segment in inches\\n    ', 'DeprecationWarning: This function is deprecated and will be removed in etna=2.0; Please use acf_plot instead.', 'TSDataset', '1M', 'Distribution of z-values grouped by segments and time frequency.\\n\\n    Mean is calculated by the windows:\\n\\n    .. math::\\n        mean_{i} = \\\\sum_{j=i-\\\\text{shift}}^{i-\\\\text{shift}+\\\\text{window}} \\\\frac{x_{j}}{\\\\text{window}}\\n\\n    The same is applied to standard deviation.\\n\\n    Parameters\\n    ----------\\n    ts:\\n        dataset with timeseries data\\n    n_segments:\\n        number of random segments to plot\\n    segments:\\n        segments to plot\\n    shift:\\n        number of timeseries shifts for statistics calc\\n    window:\\n        number of points for statistics calc\\n    freq:\\n        group for z-values\\n    n_rows:\\n        maximum number of rows to plot\\n    figsize:\\n        size of the figure per subplot with one segment in inches\\n    ', 'mean', 'segment', 'std', 'segment', 'z', 'target', 'mean', 'std', 'Z statistic shift: ', ' window: ', 'segment', 'z', 'segment', 'TSDataset', 'Plot STL decomposition for segments.\\n\\n    Parameters\\n    ----------\\n    ts:\\n        dataset with timeseries data\\n    period:\\n        length of seasonality\\n    segments:\\n        segments to plot\\n    columns_num:\\n        number of columns in subplots\\n    figsize:\\n        size of the figure per subplot with one segment in inches\\n    plot_kwargs:\\n        dictionary with parameters for plotting, :py:meth:`matplotlib.axes.Axes.plot` is used\\n    stl_kwargs:\\n        dictionary with parameters for STL decomposition, :py:class:`statsmodels.tsa.seasonal.STL` is used\\n    ', 'target', 'Observed', 'Trend', 'Seasonal', 'Residual', 'x', 'TSDataset', 'Plot Q-Q plots for segments.\\n\\n    Parameters\\n    ----------\\n    residuals_ts:\\n        dataset with the time series, expected to be the residuals of the model\\n    qq_plot_params:\\n        dictionary with parameters for qq plot, :py:func:`statsmodels.graphics.gofplots.qqplot` is used\\n    segments:\\n        segments to plot\\n    columns_num:\\n        number of columns in subplots\\n    figsize:\\n        size of the figure per subplot with one segment in inches\\n    ', 'target', 'TSDataset', 'Plot scatter plot with forecasted/actual values for segments.\\n\\n    Parameters\\n    ----------\\n    forecast_df:\\n        forecasted dataframe with timeseries data\\n    ts:\\n        dataframe of timeseries that was used for backtest\\n    segments:\\n        segments to plot\\n    columns_num:\\n        number of columns in subplots\\n    figsize:\\n        size of the figure per subplot with one segment in inches\\n    ', 'target', 'target', 'R2: ', '.3f', 'identity', 'dotted', 'grey', 'best fit: ', '.3f', ' x + ', '.3f', 'dashed', 'black', '$\\\\widehat{y}$', '$y$', 'Enum for types of alignment in a seasonal plot.\\n\\n    Attributes\\n    ----------\\n    first:\\n        make first period full, allow last period to have NaNs in the ending\\n    last:\\n        make last period full, allow first period to have NaNs in the beginning\\n    ', 'first', 'last', ' is not a valid ', '. Only ', ', ', ' alignments are allowed', 'Enum for types of aggregation in a seasonal plot.', 'mean', 'sum', ' is not a valid ', '. Only ', ', ', ' aggregations are allowed', 'Sum values with ignoring of NaNs.\\n\\n        * If there some nan: we skip them.\\n\\n        * If all values equal to nan we return nan.\\n        ', 'Get aggregation function.', 'mean', 'sum', 'Enum for types of cycles in a seasonal plot.', 'hour', 'day', 'week', 'month', 'quarter', 'year', ' is not a valid ', '. Only ', ', ', ' cycles are allowed', 'hour', 'day', 'week', 'month', 'quarter', 'year', 'Get unique name for each cycle in a series with timestamps.', '%Y-%m-%d %H', '%Y-%m-%d', '%Y-%W', '%Y-%b', '-', '%Y', 'hour', 'day', 'week', 'month', 'quarter', 'year', 'Get number for each point within cycle in a series of timestamps.', 'T', 'H', 'D', 'D', 'D', 'D', 'Q', 'QS', 'M', 'MS', 'Q', 'timestamp', 'cycle_name', 'timestamp', 'cycle_name', 'hour', 'day', 'week', 'month', 'quarter', 'year', 'Get unique name for each point within the cycle in a series of timestamps.', 'D', '%a', 'M', 'MS', '%b', 'hour', 'day', 'week', 'month', 'quarter', 'year', 'Create a seasonal split into cycles of a given timestamp.\\n\\n    Parameters\\n    ----------\\n    timestamp:\\n        series with timestamps\\n    freq:\\n        frequency of dataframe\\n    cycle:\\n        period of seasonality to capture (see :py:class:`~etna.analysis.eda_utils.SeasonalPlotCycle`)\\n\\n    Returns\\n    -------\\n    result: pd.DataFrame\\n        dataframe with timestamps and corresponding cycle names and in cycle names\\n    ', 'timestamp', 'cycle_name', 'timestamp', 'in_cycle_num', 'timestamp', 'cycle_name', 'in_cycle_name', 'timestamp', 'in_cycle_num', 'sum', 'mean', 'timestamp', 'segment', 'TSDataset', 'hour', 'day', 'week', 'month', 'quarter', 'year', 'first', 'last', 'sum', 'mean', 'target', 'right', 'left', 'TSDataset', 'hour', 'day', 'week', 'month', 'quarter', 'year', 'first', 'last', 'sum', 'mean', 'year', 'last', 'sum', 'target', 'plasma', \"Plot each season on one canvas for each segment.\\n\\n    Parameters\\n    ----------\\n    ts:\\n        dataset with timeseries data\\n    freq:\\n        frequency to analyze seasons:\\n\\n        * if isn't set, the frequency of ``ts`` will be used;\\n\\n        * if set, resampling will be made using ``aggregation`` parameter.\\n          If given frequency is too low, then the frequency of ``ts`` will be used.\\n\\n    cycle:\\n        period of seasonality to capture (see :class:`~etna.analysis.eda_utils.SeasonalPlotCycle`)\\n    alignment:\\n        how to align dataframe in case of integer cycle (see :py:class:`~etna.analysis.eda_utils.SeasonalPlotAlignment`)\\n    aggregation:\\n        how to aggregate values during resampling (see :py:class:`~etna.analysis.eda_utils.SeasonalPlotAggregation`)\\n    in_column:\\n        column to use\\n    cmap:\\n        name of colormap for plotting different cycles\\n        (see `Choosing Colormaps in Matplotlib <https://matplotlib.org/3.5.1/tutorials/colors/colormaps.html>`_)\\n    plot_params:\\n        dictionary with parameters for plotting, :py:meth:`matplotlib.axes.Axes.plot` is used\\n    segments:\\n        segments to use\\n    columns_num:\\n        number of columns in subplots\\n    figsize:\\n        size of the figure per subplot with one segment in inches\\n    \", 'target', 'cycle_name', 'cycle_name', 'timestamp', 'in_cycle_num', 'timestamp', 'in_cycle_name', 'in_cycle_num', 'in_cycle_name', 'upper center'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <16x10 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 16 stored elements in Compressed Sparse Row format>, 'ClassDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Split classes into train and test subsets.\\n\\n    Args:\\n        test_size: Fraction of the test in the [0, 1] range.\\n\\n    Returns:\\n        Train classes and test classes.\\n    ', \"Can't split into two non-empty datasets with the given fraction.\", 'Helper class for labels subset selection.', 'More classes than dataset has', 'Whether dataset is classification or verification.', 'Whether dataset is for open-set or closed-set classification.', 'Get dataset labels array.\\n\\n        Labels are integers in the range [0, N-1].\\n\\n        ', 'Get element of the dataset.\\n\\n        Classification dataset returns tuple (image, label).\\n        Verification dataset returns ((image1, image2), label).\\n\\n        Datasets with quality assigned to each sample return tuples like\\n        (image, label, quality) or ((image1, image2), label, (quality1, quality2)).\\n\\n        ', 'Helper class for subset selection. Allows to select a subset of indices.', 'More indices than dataset has.', 'Whether dataset is classification or verification.', 'Whether dataset is for open-set or closed-set classification.', 'Get dataset labels array.\\n\\n        Labels are integers in the range [0, N-1].\\n\\n        ', 'Get element of the dataset.\\n\\n        Classification dataset returns tuple (image, label).\\n        Verification dataset returns ((image1, image2), label).\\n\\n        Datasets with quality assigned to each sample return tuples like\\n        (image, label, quality) or ((image1, image2), label, (quality1, quality2)).\\n\\n        ', 'Split dataset into two parts with different sets of labels.\\n\\n    Function is deterministic. Split is based on hash values, not random.\\n\\n    Returns:\\n        Two datasets. The size of the first dataset is proportional to fraction,\\n        the size of the second is proportional to (1 - fraction).\\n\\n    ', \"Can't split into two non-empty datasets with the given fraction.\", 'Get i-th training and validation sets using k class-based folds.', 'Get i-th training and validation sets using k element-based folds.', \"The number of classes in train and test doesn't match.\"], 'from': [], 'import': []}\n",
      "{'FunctionDef': <7x7 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['2020-01-01', 'D', 'segment', 'segment', 'timestamp', 'timestamp', '2020-01-01', 'D', 'segment', 'segment', 'target', 'regressor_useless_', 'segment', 'segment', 'target', 'regressor_useful_', 'segment', 'segment', 'timestamp', 'D', 'df', 'target', 'regressors', 'target', 'regressors', 'regressors', 'relevance_method, expected_regressors', 'regressor_useful_0', 'regressor_useful_1', 'regressor_useful_2', 'df', 'regressors', 'feature', 'regressor_1', 'regressor_2', 'regressor_3', 'segment_1', 'segment_2', '2000-01-01', 'D', 'target', 'regressor_1', 'regressor_2', '2000-01-01', 'D', 'target', 'regressor_3', '2000-01-01', 'D', 'target', 'relevance_table', 'regressors', 'expected_answer', 'regressor_1', 'regressor_3', 'regressor_1', 'regressor_2', 'regressor_3', 'segment_1', 'segment_2', '2000-01-04', 'D', 'target', 'regressor_1', 'regressor_2', '2000-01-01', 'D', 'target', 'regressor_3', '2000-01-07', 'D', 'target', 'regressor_1', 'regressor_3', 'relevance_table', 'regressors', 'expected_answer', 'regressor_1', 'regressor_3', 'Check that transform selects the less redundant regressor out of regressors with same relevance.', 'relevance_table', 'regressors', 'expected_answer', 'Check that transform selects the less redundant regressor out of regressors with same relevance.', 'relevance_table', 'regressors', 'expected_answer'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <13x13 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 13 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['segment', 'feature', 'method,method_kwargs', 'model', 'regressor_1', '1', 'regressor_1', '2', 'regressor_2', '1', 'regressor_2', '2', 'regressor_1', '1', 'regressor_2', '1', 'regressor_1', '2', 'regressor_2', '2', 'a', 'b', '2020-01-01', '2021-01-01', 'segment', 'timestamp', 'target', '1.1', '2', '56.1', '1.1', 'two', '56.1', 'timestamp', 'exog1', 'exog2', 'exog3', 'cast', 'no_cast', 'none', 'cast', 'cast', 'category', 'no_cast', 'no_cast', 'category', 'a', 'b', 'a', 'b', '2020-01-01', '2021-01-01', 'segment', 'timestamp', 'target', 'timestamp', 'exog1', 'exog2', 'exog3', 'none', 'a', 'b', 'columns,match', 'exog1', 'exog2', 'exog3', 'cast', 'Exogenous data contains columns with category type', 'exog1', 'exog2', 'exog3', 'none', 'Exogenous or target data contains None', 'column cannot be cast to float type!', 'no_cast', 'exog', 'Exogenous or target data contains None', 'exog', 'Exogenous or target data contains None', 'exog1', 'exog2', 'exog3', 'none', 'Exogenous or target data contains None', 'Exogenous or target data contains None', 'Exogenous or target data contains None'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <6x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['\\n    ImageNet-LT dataset class.\\n    https://github.com/zhmiao/OpenLongTailRecognition-OLTR\\n\\n    Args:\\n        root: Dataset root.\\n        mode: Whether to use train, val or test part of the dataset.\\n    ', 'overall', 'many-shot', 'medium-shot', 'few-shot', 'train', 'overall', 'many-shot', 'medium-shot', 'few-shot', 'Unknown test setup.', 'train', 'val', 'test', 'Unknown dataset mode.', '.txt', 'r', ' ', '/', '/', '/', 'train.txt', 'r', ' ', 'Whether dataset is classification or matching.', 'Whether dataset is for open-set or closed-set classification.', 'Get dataset labels array.\\n\\n        Labels are integers in the range [0, N-1], where N is number of classes\\n\\n        ', 'Get element of the dataset.\\n\\n        Returns tuple (image, label).\\n\\n        '], 'from': [], 'import': []}\n",
      "{'FunctionDef': <69x68 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 69 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['timestamp', '2021-02-01', '2021-07-01', '1d', 'timestamp', '2021-02-01', '2021-07-01', '1d', 'segment', 'Moscow', 'target', 'segment', 'Omsk', 'target', '2021-01-01', 'segment', 'segment', 'segment_0', 'Moscow', 'Omsk', 'target', 'exog', '1D', '2021-01-01', '2021-02-01', 'timestamp', 'target', 'segment', '1', 'timestamp', 'target', 'segment', '2', '2020-12-01', '2021-02-11', 'timestamp', 'regressor_1', 'regressor_2', 'segment', '1', 'timestamp', 'regressor_1', 'regressor_2', 'segment', '2', 'regressor_1', 'regressor_2', 'Return flat versions of df and df_exog.', '2021-01-01', '2021-02-01', 'timestamp', 'target', 'segment', '1', 'timestamp', 'target', 'segment', '2', '2020-12-01', '2021-02-11', 'timestamp', 'regressor_1', 'regressor_2', 'regressor_3', 'segment', '3', '1', 'timestamp', 'regressor_1', 'regressor_2', 'regressor_3', 'segment', '4', '2', 'regressor_2', 'regressor_2', 'category', 'regressor_3', 'regressor_3', 'category', '2021-01-01', '2021-01-05', 'timestamp', 'target', 'segment', '1', 'timestamp', 'target', 'segment', '2', '2021-01-01', '2021-01-06', '1', '2', '1', '2', '1', '2', 'timestamp', 'regressor', 'not_regressor', 'segment', '1', 'timestamp', 'regressor', 'not_regressor', 'segment', '2', 'D', 'regressor', 'DataFrame with integer segments.', '2021-01-01', '2021-02-01', 'timestamp', 'target', 'segment', 'timestamp', 'target', 'segment', 'Check that _check_endings method raises exception if some segments end with nan.', '2021-01-01', '2021-02-01', 'timestamp', 'target', 'segment', '1', 'timestamp', 'target', 'segment', '2', 'D', 'Check that _check_endings method passes if there is no nans at the end of all segments.', '2021-01-01', '2021-02-01', 'timestamp', 'target', 'segment', '1', 'timestamp', 'target', 'segment', '2', 'D', 'Check that _check_known_future raises exception if wrong literal is given.', \"The only possible literal is 'all'\", 'wrong-literal', \"Check that _check_known_future raises exception if there are no df_exog, but known_future isn't empty.\", 'Some features in known_future are not present in df_exog', 'regressor_1', \"Check that _check_known_future raises exception if df_exog doesn't contain some features in known_future.\", 'regressor_new', 'Some features in known_future are not present in df_exog', 'Check that _check_known_future passes if known_future and df_exog are empty.', 'Check that _check_known_future passes if df_exog is not empty.', 'known_future, expected_columns', 'regressor_1', 'regressor_1', 'regressor_1', 'regressor_2', 'regressor_1', 'regressor_2', 'regressor_1', 'regressor_1', 'regressor_1', 'all', 'regressor_1', 'regressor_2', '2021-06-01', 'categorical_column', 'categorical_column', 'categorical_column', 'category', 'timestamp', 'segment', 'target', 'timestamp', 'segment', 'categorical_column', 'D', 'categorical_column', 'category', 'borders, true_borders', '2021-02-01', '2021-06-20', '2021-06-21', '2021-07-01', '2021-02-01', '2021-06-20', '2021-06-21', '2021-07-01', '2021-02-03', '2021-06-20', '2021-06-22', '2021-07-01', '2021-02-03', '2021-06-20', '2021-06-22', '2021-07-01', '2021-02-01', '2021-06-20', '2021-06-21', '2021-06-28', '2021-02-01', '2021-06-20', '2021-06-21', '2021-06-28', '2021-02-01', '2021-06-20', '2021-06-23', '2021-07-01', '2021-02-01', '2021-06-20', '2021-06-23', '2021-07-01', '2021-06-20', '2021-06-23', '2021-06-28', '2021-02-01', '2021-06-20', '2021-06-23', '2021-06-28', '2021-02-03', '2021-06-20', '2021-06-23', '2021-02-03', '2021-06-20', '2021-06-23', '2021-07-01', '2021-06-20', '2021-06-23', '2021-02-01', '2021-06-20', '2021-06-23', '2021-07-01', '2021-06-20', '2021-02-01', '2021-06-20', '2021-06-21', '2021-07-01', '2021-06-21', '2021-02-01', '2021-06-20', '2021-06-21', '2021-07-01', 'test_size, true_borders', '2021-02-01', '2021-06-20', '2021-06-21', '2021-07-01', '2021-02-01', '2021-06-22', '2021-06-23', '2021-07-01', '2021-02-01', '2021-06-30', '2021-07-01', '2021-07-01', 'test_size, borders, true_borders', '2021-02-01', '2021-06-20', '2021-06-21', '2021-07-01', '2021-02-01', '2021-06-20', '2021-06-21', '2021-07-01', '2021-02-03', '2021-06-20', '2021-06-22', '2021-07-01', '2021-02-03', '2021-06-20', '2021-06-22', '2021-07-01', '2021-02-02', '2021-06-28', '2021-02-02', '2021-06-17', '2021-06-18', '2021-06-28', '2021-02-03', '2021-06-20', '2021-07-01', '2021-02-03', '2021-06-20', '2021-06-28', '2021-07-01', '2021-02-03', '2021-06-20', '2021-02-03', '2021-06-20', '2021-06-21', '2021-06-24', 'borders, match', '2021-01-01', '2021-06-20', '2021-06-21', '2021-07-01', 'Min timestamp in df is', '2021-02-01', '2021-06-20', '2021-06-21', '2021-08-01', 'Max timestamp in df is', 'test_size, borders, match', '2021-02-01', '2021-06-21', '2021-07-01', 'test_size, test_start and test_end cannot be applied at the same time. test_size will be ignored', 'test_size, borders, match', '2021-02-03', '2021-07-01', 'At least one of train_end, test_start or test_size should be defined', '2021-02-01', '2021-06-20', '2021-07-01', 'The beginning of the test goes before the end of the train', '2021-02-01', '2021-06-20', '2021-06-26', 'test_size is 17, but only 6 available with your test_start', 'D', '2021-06-01', 'timestamp', 'timestamp', 'timestamp', 'segment', 'target', 'datetime64[ns]', '2021-06-01', 'categorical_column', 'categorical_column', 'categorical_column', 'category', 'timestamp', 'segment', 'target', 'timestamp', 'segment', 'categorical_column', 'D', 'datetime64[ns]', 'Test that `TSDataset.to_dataset` makes casting of segment to string.', 'segment', '1', '2', 'Test that `TSDataset.__init__` makes casting of segment to string.', 'segment', 'segment', 'D', 'segment', '1', '2', 'All segments should end at the same timestamp', 'target', '2020-01-01', 'D', 'timestamp', 'target', 'segment', 'segment_1', 'timestamp', 'target', 'segment', 'segment_2', 'D', '1D', 'D', 'feature', 'target', '2021-01-01', '2021-02-01', 'timestamp', 'target', 'segment', '1', 'timestamp', 'target', 'segment', '2', 'D', 'D', \"TSDataset freq can't be inferred\", '2020-01-01', 'D', 'timestamp', 'target', 'segment', 'segment_1', 'timestamp', 'target', 'segment', 'segment_2', 'timestamp', 'exog', 'segment', 'D', '1D', 'D', 'feature', 'target', 'exog', 'D', '1D', 'D', 'feature', 'target', 'regressor_1', 'regressor_2', 'D', '1 day', 'tail_steps', 'D', \"Check that warning is thrown if regressors don't have enough values for the future.\", 'D', \"Some regressors don't have enough values\", \"Check that error is raised if regressors don't have enough values for the train data.\", '2021-01-01', '2021-02-01', '2021-01-10', '2021-01-20', '2021-01-01', '2021-02-01', 'timestamp', 'target', 'segment', '1', 'timestamp', 'target', 'segment', '2', 'timestamp', 'regressor_aaa', 'segment', '1', 'timestamp', 'regressor_aaa', 'segment', '2', 'exog_starts_later,exog_ends_earlier', 'Check that regressors check on creation passes with correct regressors.', 'Check that regressors check on creation passes with no regressors.', '2021-02-01', '2021-02-01', '2021-02-01', '2021-02-01', '2021-02-03', '2021-02-01', '2021-02-03', 'timestamp', '2021-02-01', '2021-02-03', '2021-02-01', '2021-02-03', '2021-02-01', '2021-02-03', 'timestamp', '2021-02-01', '2021-02-03', 'target', 'Moscow', 'target', 'Omsk', 'target', 'Check that ts.regressors property works correctly when regressors set.', 'D', 'regressor_1', 'regressor_2', 'regressor_1', 'regressor_2', \"Check that ts.regressors property works correctly when regressors don't set.\", 'D', 'Need to check if to_dataset method does not mess up with data and column names,\\n    sorting it with no respect to each other\\n    ', 'timestamp', '2020-01-01', 'segment', 'segment_1', 'reg_2', 'reg_1', 'D', 'reg_1', 'reg_1', 'reg_2', 'reg_2', 'Check that TSDataset.to_flatten works correctly in simple case.', 'Check that TSDataset.to_flatten works correctly with exogenous features.', 'regressor_boolean', 'regressor_boolean', 'regressor_boolean', 'boolean', 'regressor_Int64', 'regressor_Int64', 'regressor_Int64', 'regressor_Int64', 'Int64', 'timestamp', 'segment', 'timestamp', 'segment', 'timestamp', 'segment', 'timestamp', '2', 'segment', 'timestamp', 'category', 'segment', 'timestamp', 'Segments contains NaNs in the last timestamps.', 'Segments contains NaNs in the last timestamps.', 'Check that TSDataset._gather_common_data correctly finds common data for info/describe methods.', 'D', 'num_segments', 'num_exogs', 'num_regressors', 'num_known_future', 'freq', 'D', 'Check that TSDataset._gather_segments_data correctly finds segment data for info/describe methods.', 'D', '1', 'start_timestamp', '2021-01-01', '2', 'start_timestamp', '2021-01-06', '1', 'end_timestamp', '2021-02-01', '2', 'end_timestamp', '2021-01-29', '1', 'length', '2', 'length', '1', 'num_missing', '2', 'num_missing', 'Check that TSDataset.describe works correctly.', 'D', '1', 'start_timestamp', '2021-01-01', '2', 'start_timestamp', '2021-01-06', '1', 'end_timestamp', '2021-02-01', '2', 'end_timestamp', '2021-01-29', '1', 'length', '2', 'length', '1', 'num_missing', '2', 'num_missing', 'num_segments', 'num_exogs', 'num_regressors', 'num_known_future', 'freq', 'D', 'D', 'all', 'transforms, expected_regressors', 'regressor_1', 'regressor_2', 'segment_code', 'target', 'regressor_lag', 'regressor_1', 'regressor_2', 'regressor_lag_1', 'regressor_lag_2', 'transforms, expected_regressors', 'regressor', 'regressor_ohe', 'regressor_ohe_0', 'regressor_ohe_1', 'regressor', 'not_regressor', 'regressor', 'transforms, expected_regressors', 'regressor_1', 'scaled', 'regressor_1', 'regressor_2', 'scaled_regressor_1', 'regressor_1', 'regressor_2', 'regressor_1', 'regressor_2', 'regressor_1', 'regressor_2', 'regressor_1', 'regressor_add_constant_regressor_1', 'regressor_1', 'regressor_2', 'regressor_add_constant_regressor_1', 'transforms, expected_regressors', 'target', 'scaled_target', 'regressor_1', 'regressor_2', 'target', 'add_constant_target', 'regressor_1', 'regressor_2', 'transforms, expected_regressors', 'regressor_1', 'regressor_2', 'regressor_1', 'regressor_2', 'return_features', 'columns', 'target', 'exog_1', 'exog_2', 'target', 'exog_1', 'exog_2', '2021-01-01', '2021-02-01', 'timestamp', 'target', 'segment', 'start_idx,end_idx', 'target', 'segment', 'segment', 'target', 'Moscow', 'target', 'target', 'Omsk', 'target', 'target', 'segment', 'segment', 'Moscow', 'target', 'target', '1 day', 'Moscow', 'target', 'target', 'Omsk', 'target'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <12x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 12 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Merge multiple datasets sharing the same set of labels.', 'Empty datasets list.', \"Can't merge classification and verification datasets.\", \"Can't merge datasets with and without quality scores.\", 'Different number of classes in datasets.', 'Different openset flag in datasets.', 'Whether dataset is classification or verification.', 'Whether dataset is for open-set or closed-set classification.', 'Whether dataset assigns quality score to each sample or not.', 'Get dataset labels array.\\n\\n        Labels are integers in the range [0, N-1].\\n\\n        ', 'Get element of the dataset.\\n\\n        Classification dataset returns tuple (image, label).\\n        Verification dataset returns ((image1, image2), label).\\n\\n        Datasets with quality assigned to each sample return tuples like\\n        (image, label, quality) or ((image1, image2), label, (quality1, quality2)).\\n\\n        ', 'Merge multiple datasets sharing different sets of labels.', 'Empty datasets list.', 'Expected classification dataset.', \"Can't merge datasets with and without quality scores.\", 'Different openset flag in datasets.', 'Whether dataset is classification or verification.', 'Whether dataset is for open-set or closed-set classification.', 'Whether dataset assigns quality score to each sample or not.', 'Get dataset labels array.\\n\\n        Labels are integers in the range [0, N-1].\\n\\n        ', 'Get element of the dataset.\\n\\n        Classification dataset returns tuple (image, label).\\n        Verification dataset returns ((image1, image2), label).\\n\\n        Datasets with quality assigned to each sample return tuples like\\n        (image, label, quality) or ((image1, image2), label, (quality1, quality2)).\\n\\n        '], 'from': [], 'import': []}\n",
      "{'FunctionDef': <6x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['Check the value of transform result', 'target', 'segment_1', 'segment_2', 'target', 'target_no_change', 'value', 'Check generated name of new column', 'target', 'segment_1', 'segment_2', 'out_column', 'result', 'Check the value of transform result in case of given out column', 'result', 'target', 'segment_1', 'segment_2', 'target_no_change', 'Check that inverse_transform rolls back transform result', 'target', 'segment_1', 'segment_2', 'target', 'target_no_change', 'value', 'Check that inverse_transform rolls back transform result in case of given out_column', 'test', 'target', 'segment_1', 'segment_2', 'target'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <17x17 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 17 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['Create pandas dataframe that represents one segment and has const value column', 'timestamp', '2020-01-01', '2020-04-01', 'D', 'target', 'timestamp', 'Create pandas dataframe that represents one segment and has non-const value column.', 'timestamp', 'target', 'timestamp', 'target', 'timestamp', 'target', 'timestamp', 'target', 'timestamp', 'target', 'timestamp', 'target', 'timestamp', 'timestamp', 'timestamp', '2020-01-01', '2020-12-31', 'timestamp', 'left', 'week_true', 'timestamp', 'month_true', 'timestamp', 'timestamp', 'Create pandas dataframe that has two segments with constant columns each.', 'segment', 'segment_1', 'segment', 'segment_2', 'timestamp', 'segment', 'segment', 'feature', \"\\n    This test checks that _OneSegmentSpecialDaysTransform that should find special weekdays creates the only column with\\n    'anomaly_weekdays' name as expected.\\n    \", 'anomaly_weekdays', 'anomaly_monthdays', 'anomaly_weekdays', 'category', \"\\n    This test checks that _OneSegmentSpecialDaysTransform that should find special month days creates the only column with\\n    'anomaly_monthdays' name as expected.\\n    \", 'anomaly_weekdays', 'anomaly_monthdays', 'anomaly_monthdays', 'category', \"\\n    This test checks that _OneSegmentSpecialDaysTransform that should find special month and week days\\n    creates two columns with 'anomaly_monthdays' and 'anomaly_weekdays' name as expected.\\n    \", 'anomaly_weekdays', 'anomaly_monthdays', 'anomaly_weekdays', 'category', 'anomaly_monthdays', 'category', 'This test checks that bad-inited _OneSegmentSpecialDaysTransform raises AssertionError.', \"\\n    This test checks that SpecialDaysTransform that should find special weekdays creates the only column with\\n    'anomaly_weekdays' name as expected.\\n    \", 'segment', 'anomaly_weekdays', 'anomaly_monthdays', 'anomaly_weekdays', 'category', \"\\n    This test checks that SpecialDaysTransform that should find special month days creates the only column with\\n    'anomaly_monthdays' name as expected.\\n    \", 'segment', 'anomaly_weekdays', 'anomaly_monthdays', 'anomaly_monthdays', 'category', \"\\n    This test checks that SpecialDaysTransform that should find special month and week days\\n    creates two columns with 'anomaly_monthdays' and 'anomaly_weekdays' name as expected.\\n    \", 'segment', 'anomaly_weekdays', 'anomaly_monthdays', 'anomaly_weekdays', 'category', 'anomaly_monthdays', 'category', 'This test checks that bad-inited SpecialDaysTransform raises AssertionError during fit_transform.', 'This test checks that _OneSegmentSpecialDaysTransform computes weekday feature correctly.', 'week_true', 'anomaly_weekdays', 'This test checks that _OneSegmentSpecialDaysTransform computes monthday feature correctly.', 'month_true', 'anomaly_monthdays', 'This test checks that there is no false-positive results in week mode.', 'anomaly_weekdays', 'bool', 'This test checks that there is no false-positive results in month mode.', 'anomaly_monthdays', 'bool', 'Test that transform for one segment raise error when calling transform without being fit.', 'Transform is not fitted!'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <6x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Simple dataset for debugging.\\n\\n    Args:\\n        root: Dataset root.\\n        train: Whether to use train or test part of the dataset.\\n\\n    ', 'Whether dataset is classification or matching.', 'Whether dataset is for open-set or closed-set classification.', 'Get dataset labels array.\\n\\n        Labels are integers in the range [0, N-1].\\n\\n        ', 'Get element of the dataset.\\n\\n        Returns tuple (image, label, quality).\\n\\n        '], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Pipeline of transforms with a final estimator.', '\\n        Create instance of Pipeline with given parameters.\\n\\n        Parameters\\n        ----------\\n        model:\\n            Instance of the etna Model\\n        transforms:\\n            Sequence of the transforms\\n        horizon:\\n            Number of timestamps in the future for forecasting\\n        ', 'Fit the Pipeline.\\n\\n        Fit and apply given transforms to the data, then fit the model on the transformed data.\\n\\n        Parameters\\n        ----------\\n        ts:\\n            Dataset with timeseries data\\n\\n        Returns\\n        -------\\n        :\\n            Fitted Pipeline instance\\n        ', 'Pipeline', 'Make predictions.', 'Something went wrong, ts is None!', 'Make predictions.\\n\\n        Parameters\\n        ----------\\n        prediction_interval:\\n            If True returns prediction interval for forecast\\n        quantiles:\\n            Levels of prediction distribution. By default 2.5% and 97.5% taken to form a 95% prediction interval\\n        n_folds:\\n            Number of folds to use in the backtest for prediction interval estimation\\n\\n        Returns\\n        -------\\n        :\\n            Dataset with predictions\\n        ', ' is not fitted! Fit the ', ' before calling forecast method.'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['\\n    Given: I have dataframe with 2 segments with weekly seasonality with known future\\n    When: I use scale transformations\\n    Then: I get {horizon} periods per dataset as a forecast and they \"the same\" as past\\n    ', 'target', 'macro', 'horizon', 'segment', 'segment_1', 'encoder_real', 'decoder_real', 'encoder_target', 'decoder_target', 'target', 'encoder_real', 'target', 'encoder_real', 'encoder_length'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <14x14 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 14 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['segment', 'target_0.025', 'target_0.975', 'target', 'target_0.975', 'target_0.025', 'method_name', 'forecast', 'predict', 'target_0.025', 'target_0.975', 'target', 'target_0.975', 'target', 'target', 'target_0.025', 'target_0.975', 'target_0.025', 'Test that SARIMAX raise error when calling prediction without being fit.', 'model is not fitted!', 'method_name', 'forecast', 'predict', 'Check that get_model method throws an error if per-segment model is not fitted yet.', 'Can not get the dict with base models, the model is not fitted!', 'Check that get_model method returns dict of objects of SARIMAX class.', 'Check that SARIMAX work with 1 point forecast.'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <7x7 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Wrapper for :py:class:`pytorch_forecasting.models.temporal_fusion_transformer.TemporalFusionTransformer`.\\n\\n    Notes\\n    -----\\n    We save :py:class:`pytorch_forecasting.data.timeseries.TimeSeriesDataSet` in instance to use it in the model.\\n    It`s not right pattern of using Transforms and TSDataset.\\n    ', 'MultiHorizonMetric', '\\n        Initialize TFT wrapper.\\n\\n        Parameters\\n        ----------\\n        batch_size:\\n            Batch size.\\n        context_length:\\n            Max encoder length, if None max encoder length is equal to 2 horizons.\\n        max_epochs:\\n            Max epochs.\\n        gpus:\\n            0 - is CPU, or [n_{i}] - to choose n_{i} GPU from cluster.\\n        gradient_clip_val:\\n            Clipping by norm is using, choose 0 to not clip.\\n        learning_rate:\\n            Learning rate.\\n        hidden_size:\\n            Hidden size of network which can range from 8 to 512.\\n        lstm_layers:\\n            Number of LSTM layers.\\n        attention_head_size:\\n            Number of attention heads.\\n        dropout:\\n            Dropout rate.\\n        hidden_continuous_size:\\n            Hidden size for processing continuous variables.\\n        loss:\\n            Loss function taking prediction and targets.\\n            Defaults to :py:class:`pytorch_forecasting.metrics.QuantileLoss`.\\n        trainer_kwargs:\\n            Additional arguments for pytorch_lightning Trainer.\\n        quantiles_kwargs:\\n            Additional arguments for computing quantiles, look at ``to_quantiles()`` method for your loss.\\n        ', '\\n        Construct TemporalFusionTransformer.\\n\\n        Returns\\n        -------\\n        LightningModule class instance.\\n        ', 'Get PytorchForecastingTransform from ts.transforms or raise exception if not found.', 'Not valid usage of transforms, please add PytorchForecastingTransform at the end of transforms', '\\n        Fit model.\\n\\n        Parameters\\n        ----------\\n        ts:\\n            TSDataset to fit.\\n\\n        Returns\\n        -------\\n        TFTModel\\n        ', 'TFTModel', 'Make predictions.\\n\\n        This method will make autoregressive predictions.\\n\\n        Parameters\\n        ----------\\n        ts:\\n            Dataset with features\\n        prediction_interval:\\n            If True returns prediction interval for forecast\\n        quantiles:\\n            Levels of prediction distribution. By default 2.5% and 97.5% are taken to form a 95% prediction interval\\n\\n        Returns\\n        -------\\n        TSDataset\\n            TSDataset with predictions.\\n        ', \"It is not possible to make in-sample predictions with TFT model! In-sample predictions aren't supported by current implementation.\", 'You can only forecast from the next point after the last one in the training dataset: last train timestamp: ', ', first test timestamp is ', 'The future is not generated! Generate future using TSDataset make_future before calling forecast method!', 'target', \"Quantiles can't be computed because TFTModel supports this only if QunatileLoss is chosen\", 'quantiles', 'quantiles', 'Quantiles: ', \" can't be computed because loss wasn't fitted on them\", 'target_', '.4g', 'Make predictions.\\n\\n        This method will make predictions using true values instead of predicted on a previous step.\\n        It can be useful for making in-sample forecasts.\\n\\n        Parameters\\n        ----------\\n        ts:\\n            Dataset with features\\n        prediction_interval:\\n            If True returns prediction interval for forecast\\n        quantiles:\\n            Levels of prediction distribution. By default 2.5% and 97.5% are taken to form a 95% prediction interval\\n\\n        Returns\\n        -------\\n        TSDataset\\n            TSDataset with predictions.\\n        ', \"Method predict isn't currently implemented!\", 'Get internal model that is used inside etna class.\\n\\n        Internal model is a model that is used inside etna to forecast segments,\\n        e.g. :py:class:`catboost.CatBoostRegressor` or :py:class:`sklearn.linear_model.Ridge`.\\n\\n        Returns\\n        -------\\n        :\\n           Internal model\\n        '], 'from': [], 'import': []}\n",
      "{'FunctionDef': <33x33 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 33 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['Generate dataset with simple values without any noise', 'target', 'segment', 'A', 'timestamp', '2020-01-01', 'target', 'segment', 'B', 'timestamp', '2020-01-01', '1d', 'model', 'model', \"Given context isn't big enough\", \"Given context isn't big enough\", 'There are NaNs in a forecast context', 'There are NaNs in a target column', 'timestamp', 'freq, periods, start, prediction_size, seasonality, window, expected', 'D', '2020-01-01', '2020-01-01', 'D', '2020-01-01', '2020-01-02', 'D', '2020-01-01', '2020-01-01', 'D', '2020-01-01', '2020-01-01', 'D', '2020-01-01', '2020-01-01', 'H', '2020-01-01', '2020-01-01', 'H', '2020-01-01', '2020-01-01 01:00', 'H', '2020-01-01', '2020-01-01', 'H', '2020-01-01', '2020-01-01', 'H', '2020-01-01', '2020-01-01', 'D', '2020-01-01', '2020-01-01', 'D', '2020-01-01', '2020-01-02', 'D', '2020-01-01', '2020-01-01', 'D', '2020-01-01', '2020-01-01', 'D', '2020-01-01', '2020-01-01', 'H', '2020-01-01', '2020-01-01', 'H', '2020-01-01', '2020-01-01 01:00', 'H', '2020-01-01', '2020-01-01', 'H', '2020-01-01', '2020-01-01', 'H', '2020-01-01', '2020-01-01', 'timestamp', \"Given context isn't big enough\", 'freq, periods, start, prediction_size, seasonality, window', 'D', '2020-01-01', 'H', '2020-01-01', 'D', '2020-01-01', 'H', '2020-01-01', 'D', '2020-01-01', 'H', '2020-01-01', 'D', '2020-01-01', 'H', '2020-01-01', 'D', '2020-01-01', 'H', '2020-01-01', 'D', '2020-01-01', 'H', '2020-01-01', 'model', 'model', \"Given context isn't big enough\", \"Given context isn't big enough\", 'There are NaNs in a forecast context', 'There are NaNs in a target column', 'target', 'segment', 'timestamp', 'target', 'segment', 'A', 'timestamp', '2020-02-19', 'target', 'segment', 'B', 'timestamp', '2020-02-19', 'segment', 'timestamp', 'segment', 'timestamp', 'target', 'segment', 'timestamp', 'target', 'segment', 'A', 'timestamp', '2020-02-19', 'target', 'segment', 'B', 'timestamp', '2020-02-19', 'segment', 'timestamp', 'segment', 'timestamp', 'target', 'segment', 'timestamp', 'target', 'segment', 'A', 'timestamp', '2020-02-19', 'target', 'segment', 'B', 'timestamp', '2020-02-19', 'segment', 'timestamp', 'segment', 'timestamp', 'month', 'target', 'segment', 'timestamp', 'target', 'segment', 'A', 'timestamp', '2020-05-20', 'target', 'segment', 'B', 'timestamp', '2020-05-20', 'segment', 'timestamp', 'segment', 'timestamp', 'target', 'segment', 'timestamp', 'target', 'segment', 'A', 'timestamp', '2020-02-12', 'target', 'segment', 'B', 'timestamp', '2020-02-12', 'segment', 'timestamp', 'segment', 'timestamp', 'target', 'segment', 'timestamp', 'target', 'segment', 'A', 'timestamp', '2020-02-12', 'target', 'segment', 'B', 'timestamp', '2020-02-12', 'segment', 'timestamp', 'segment', 'timestamp', 'target', 'segment', 'timestamp', 'target', 'segment', 'A', 'timestamp', '2020-02-12', 'target', 'segment', 'B', 'timestamp', '2020-02-12', 'segment', 'timestamp', 'segment', 'timestamp', 'month', 'target', 'segment', 'timestamp', 'target', 'segment', 'A', 'timestamp', '2020-04-30', 'target', 'segment', 'B', 'timestamp', '2020-04-30', 'segment', 'timestamp', 'segment', 'timestamp', 'model', 'timestamp', 'segment', 'target', '2020-01-01', 'segment_0', 'model, freq, expected_context_size', 'month', 'D', 'month', 'D', 'year', 'D', 'year', 'D', 'month', 'H', 'month', 'H', 'year', 'H', 'year', 'H', 'Check that get_model method throws an error if per-segment model is not fitted yet.', 'Can not get the dict with base models, the model is not fitted!', 'etna_model_class', 'Check that get_model method returns dict of objects of _SeasonalMovingAverageModel class.', 'etna_model_class,expected_class', 'timestamp', '2020-01-01', 'segment', 'segment_1', 'target', 'timestamp', '2020-01-01', 'segment', 'segment_2', 'target', 'D', 'month', 'target', 'segment', 'A', 'timestamp', '2020-01-01', '1d', 'month'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <13x8 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 13 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Calculate a time series differences of order 1.\\n\\n    This transform can work with NaNs at the beginning of the segment, but fails when meets NaN inside the segment.\\n\\n    Notes\\n    -----\\n    To understand how transform works we recommend:\\n    `Stationarity and Differencing <https://otexts.com/fpp2/stationarity.html>`_\\n    ', \"Create instance of _SingleDifferencingTransform.\\n\\n        Parameters\\n        ----------\\n        in_column:\\n            name of processed column\\n        period:\\n            number of steps back to calculate the difference with, it should be >= 1\\n        inplace:\\n\\n            * if True, apply transformation inplace to in_column,\\n\\n            * if False, add transformed column to dataset\\n\\n        out_column:\\n\\n            * if set, name of added column, the final name will be '{out_column}';\\n\\n            * if isn't set, name will be based on ``self.__repr__()``\\n\\n        Raises\\n        ------\\n        ValueError:\\n            if period is not integer >= 1\\n        \", 'Period should be at least 1', 'Fit the transform.\\n\\n        Parameters\\n        ----------\\n        df:\\n            dataframe with data.\\n\\n        Returns\\n        -------\\n        result: _SingleDifferencingTransform\\n        ', 'segment', 'There should be no NaNs inside the segments', '_SingleDifferencingTransform', 'Make a differencing transformation.\\n\\n        Parameters\\n        ----------\\n        df:\\n            dataframe with data to transform.\\n\\n        Returns\\n        -------\\n        result: pd.Dataframe\\n            transformed dataframe\\n        ', 'Transform is not fitted', 'segment', 'Make inverse difference transform.', 'Reconstruct the train in ``inverse_transform``.', 'segment', 'Reconstruct the test in ``inverse_transform``.', 'segment', 'right', 'Test should go after the train without gaps', 'feature', 'There should be no NaNs inside the segments', 'Apply inverse transformation to DataFrame.\\n\\n        Parameters\\n        ----------\\n        df:\\n            DataFrame to apply inverse transform.\\n\\n        Returns\\n        -------\\n        result: pd.DataFrame\\n            transformed DataFrame.\\n        ', 'Transform is not fitted', 'target', 'feature', 'Inverse transform can be applied only to full train or test that should be in the future', 'Calculate a time series differences.\\n\\n    This transform can work with NaNs at the beginning of the segment, but fails when meets NaN inside the segment.\\n\\n    Notes\\n    -----\\n    To understand how transform works we recommend:\\n    `Stationarity and Differencing <https://otexts.com/fpp2/stationarity.html>`_\\n    ', \"Create instance of DifferencingTransform.\\n\\n        Parameters\\n        ----------\\n        in_column:\\n            name of processed column\\n        period:\\n            number of steps back to calculate the difference with, it should be >= 1\\n        order:\\n            number of differences to make, it should be >= 1\\n        inplace:\\n\\n            * if True, apply transformation inplace to in_column,\\n\\n            * if False, add transformed column to dataset\\n\\n        out_column:\\n\\n            * if set, name of added column, the final name will be '{out_column}';\\n\\n            * if isn't set, name will be based on ``self.__repr__()``\\n\\n        Raises\\n        ------\\n        ValueError:\\n            if period is not integer >= 1\\n        ValueError:\\n            if order is not integer >= 1\\n        \", 'Period should be at least 1', 'Order should be at least 1', 'Fit the transform.\\n\\n        Parameters\\n        ----------\\n        df:\\n            dataframe with data.\\n\\n        Returns\\n        -------\\n        result: DifferencingTransform\\n        ', 'DifferencingTransform', 'Make a differencing transformation.\\n\\n        Parameters\\n        ----------\\n        df:\\n            dataframe with data to transform.\\n\\n        Returns\\n        -------\\n        result: pd.Dataframe\\n            transformed dataframe\\n        ', 'Apply inverse transformation to DataFrame.\\n\\n        Parameters\\n        ----------\\n        df:\\n            DataFrame to apply inverse transform.\\n\\n        Returns\\n        -------\\n        result: pd.DataFrame\\n            transformed DataFrame.\\n        '], 'from': [], 'import': []}\n",
      "{'FunctionDef': <14x14 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 14 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['timestamp', '2020-01-01', 'segment', 'segment_1', 'target', 'timestamp', '2020-01-01', 'segment', 'segment_2', 'target', 'timestamp', '2020-01-01', 'segment', 'segment_1', 'cat_feature', 'x', 'timestamp', '2020-01-01', 'segment', 'segment_2', 'cat_feature', 'y', 'D', 'all', '2020-02-01', 'D', 'timestamp', 'timestamp', 'segment', 'segment', 'segment_', 'segment_', 'target', 'target', 'D', 'D', 'Create TSDataset that represents 3 segments with unique linear dependency on lags in each.', 'Create TSDataset that represents 3 segments with common linear dependency on lags in each.', 'Check exception when trying to forecast with unfitted model.', 'target', 'model is not fitted!', 'model', 'Check __repr__ method of LinearPerSegmentModel and LinearMultiSegmentModel.', 'copy_X', 'positive', 'copy_X = True, positive = True', '(fit_intercept = True, ', ', )', 'model_class, model_class_repr', 'LinearPerSegmentModel', 'LinearMultiSegmentModel', 'Check __repr__ method of ElasticPerSegmentModel and ElasticMultiSegmentModel.', 'copy_X', 'positive', 'copy_X = True, positive = True', '(alpha = 1.0, l1_ratio = 0.5, fit_intercept = True, ', ', )', 'model_class, model_class_repr', 'ElasticPerSegmentModel', 'ElasticMultiSegmentModel', '\\n    Given: Dataset with 3 linear segments and LinearRegression or ElasticNet model that predicts per segment\\n    When: Creating of lag features to target, applying it to dataset and making forecast for horizon periods\\n    Then: Predictions per segment is close to real values\\n    ', 'target', 'target', 'target', 'model', 'num_lags', '\\n    Given: Dataset with 3 linear segments and LinearRegression or ElasticNet model that predicts across all segments\\n    When: Creating of lag features to target, applying it to dataset and making forecast for horizon periods\\n    Then: Predictions per segment is close to real values\\n    ', 'target', 'target', 'target', 'model', 'num_lags', 'Check that SklearnModel raises no warning working with dataset with categorical features', 'target', \"Arrays of bytes/strings is being converted to decimal numbers if dtype='numeric'.\", \"Arrays of bytes/strings is being converted to decimal numbers if dtype='numeric'.\", 'model', \"Check that SklearnModel raises error working with dataset with categorical features which can't be converted to numeric\", 'target', 'Only convertible to numeric features are accepted!', 'model', 'Check that get_model method returns objects of sklearn regressor.', 'etna_class,expected_model_class', 'Check that get_model method throws an error if per-segment model is not fitted yet.', 'Can not get the dict with base models, the model is not fitted!', 'Check that get_model method returns dict of objects of sklearn regressor class.', 'target', 'etna_class,expected_model_class'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <7x7 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['cmd', 'data', 'name', 'logger', 'config', 'train_root', 'checkpoint', 'no_strict_init', 'from_stage', 'from_seed', 'sweep_id', 'clean', 'dataset_params', 'model_params', 'trainer_params', 'metrics_params', 'num_evaluation_seeds', 'num_hopt_trials', 'hopt_backend', 'hopt_params', 'name', 'batch_size', 'num_workers', 'validation_fold', 'num_validation_folds', '_hopt', 'debug-openset', 'batch_size', 'values', 'embedder_params', 'pretrained', 'model_type', 'resnet18', 'num_epochs', 'train_classification_metrics', 'nearest', 'scores', 'optuna-tpe', 'num_evaluation_seeds', 'trainer_params', 'selection_dataset', 'selection_metric', 'valid', 'recall@1', 'config.yaml', 'train', 'tensorboard', 'test', 'checkpoints', 'best.pth', 'tensorboard', 'config.yaml', 'cval', 'tensorboard', '--config', '--logger', '--train-root', 'config.yaml', 'evaluate', 'tensorboard', '--config', '--logger', '--train-root', 'config.yaml', 'hopt', 'tensorboard', '--config', '--logger', '--train-root', 'config.yaml', 'train', 'tensorboard', 'checkpoints', 'best.pth', 'traced.pth', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Class for holding Prophet model.', 'floor', 'cap', 'linear', 'auto', 'auto', 'auto', 'additive', '\\n        Fits a Prophet model.\\n\\n        Parameters\\n        ----------\\n        df:\\n            Features dataframe\\n        regressors:\\n            List of the columns with regressors\\n        ', 'y', 'target', 'ds', 'timestamp', '_ProphetAdapter', '\\n        Compute predictions from a Prophet model.\\n\\n        Parameters\\n        ----------\\n        df:\\n            Features dataframe\\n        prediction_interval:\\n            If True returns prediction interval for forecast\\n        quantiles:\\n            Levels of prediction distribution\\n\\n        Returns\\n        -------\\n        :\\n            DataFrame with predictions\\n        ', 'y', 'target', 'ds', 'timestamp', 'yhat', 'yhat_', '.4g', 'yhat', 'yhat', 'target', 'yhat', 'Get internal prophet.Prophet model that is used inside etna class.\\n\\n        Returns\\n        -------\\n        result:\\n           Internal model\\n        ', 'Class for holding Prophet model.\\n\\n    Notes\\n    -----\\n    Original Prophet can use features \\'cap\\' and \\'floor\\',\\n    they should be added to the known_future list on dataset initialization.\\n\\n    Examples\\n    --------\\n    >>> from etna.datasets import generate_periodic_df\\n    >>> from etna.datasets import TSDataset\\n    >>> from etna.models import ProphetModel\\n    >>> classic_df = generate_periodic_df(\\n    ...     periods=100,\\n    ...     start_time=\"2020-01-01\",\\n    ...     n_segments=4,\\n    ...     period=7,\\n    ...     sigma=3\\n    ... )\\n    >>> df = TSDataset.to_dataset(df=classic_df)\\n    >>> ts = TSDataset(df, freq=\"D\")\\n    >>> future = ts.make_future(7)\\n    >>> model = ProphetModel(growth=\"flat\")\\n    >>> model.fit(ts=ts)\\n    ProphetModel(growth = \\'flat\\', changepoints = None, n_changepoints = 25,\\n    changepoint_range = 0.8, yearly_seasonality = \\'auto\\', weekly_seasonality = \\'auto\\',\\n    daily_seasonality = \\'auto\\', holidays = None, seasonality_mode = \\'additive\\',\\n    seasonality_prior_scale = 10.0, holidays_prior_scale = 10.0, changepoint_prior_scale = 0.05,\\n    mcmc_samples = 0, interval_width = 0.8, uncertainty_samples = 1000, stan_backend = None,\\n    additional_seasonality_params = (), )\\n    >>> forecast = model.forecast(future)\\n    >>> forecast\\n    segment    segment_0 segment_1 segment_2 segment_3\\n    feature       target    target    target    target\\n    timestamp\\n    2020-04-10      9.00      9.00      4.00      6.00\\n    2020-04-11      5.00      2.00      7.00      9.00\\n    2020-04-12      0.00      4.00      7.00      9.00\\n    2020-04-13      0.00      5.00      9.00      7.00\\n    2020-04-14      1.00      2.00      1.00      6.00\\n    2020-04-15      5.00      7.00      4.00      7.00\\n    2020-04-16      8.00      6.00      2.00      0.00\\n    ', 'linear', 'auto', 'auto', 'auto', 'additive', \"\\n        Create instance of Prophet model.\\n\\n        Parameters\\n        ----------\\n        growth:\\n            Options are ‘linear’ and ‘logistic’. This likely will not be tuned;\\n            if there is a known saturating point and growth towards that point\\n            it will be included and the logistic trend will be used, otherwise\\n            it will be linear.\\n        changepoints:\\n            List of dates at which to include potential changepoints. If\\n            not specified, potential changepoints are selected automatically.\\n        n_changepoints:\\n            Number of potential changepoints to include. Not used\\n            if input ``changepoints`` is supplied. If ``changepoints`` is not supplied,\\n            then ``n_changepoints`` potential changepoints are selected uniformly from\\n            the first ``changepoint_range`` proportion of the history.\\n        changepoint_range:\\n            Proportion of history in which trend changepoints will\\n            be estimated. Defaults to 0.8 for the first 80%. Not used if\\n            ``changepoints`` is specified.\\n        yearly_seasonality:\\n            By default (‘auto’) this will turn yearly seasonality on if there is\\n            a year of data, and off otherwise. Options are [‘auto’, True, False].\\n            If there is more than a year of data, rather than trying to turn this\\n            off during HPO, it will likely be more effective to leave it on and\\n            turn down seasonal effects by tuning ``seasonality_prior_scale``.\\n        weekly_seasonality:\\n            Same as for ``yearly_seasonality``.\\n        daily_seasonality:\\n            Same as for ``yearly_seasonality``.\\n        holidays:\\n            ``pd.DataFrame`` with columns holiday (string) and ds (date type)\\n            and optionally columns lower_window and upper_window which specify a\\n            range of days around the date to be included as holidays.\\n            ``lower_window=-2`` will include 2 days prior to the date as holidays. Also\\n            optionally can have a column ``prior_scale`` specifying the prior scale for\\n            that holiday.\\n        seasonality_mode:\\n            'additive' (default) or 'multiplicative'.\\n        seasonality_prior_scale:\\n            Parameter modulating the strength of the\\n            seasonality model. Larger values allow the model to fit larger seasonal\\n            fluctuations, smaller values dampen the seasonality. Can be specified\\n            for individual seasonalities using ``add_seasonality``.\\n        holidays_prior_scale:\\n            Parameter modulating the strength of the holiday components model, unless overridden\\n            in the holidays input.\\n        changepoint_prior_scale:\\n            Parameter modulating the flexibility of the\\n            automatic changepoint selection. Large values will allow many\\n            changepoints, small values will allow few changepoints.\\n        mcmc_samples:\\n            Integer, if greater than 0, will do full Bayesian inference\\n            with the specified number of MCMC samples. If 0, will do MAP\\n            estimation.\\n        interval_width:\\n            Float, width of the uncertainty intervals provided\\n            for the forecast. If ``mcmc_samples=0``, this will be only the uncertainty\\n            in the trend using the MAP estimate of the extrapolated generative\\n            model. If ``mcmc.samples>0``, this will be integrated over all model\\n            parameters, which will include uncertainty in seasonality.\\n        uncertainty_samples:\\n            Number of simulated draws used to estimate\\n            uncertainty intervals. Settings this value to 0 or False will disable\\n            uncertainty estimation and speed up the calculation.\\n        stan_backend:\\n            as defined in StanBackendEnum default: None - will try to\\n            iterate over all available backends and find the working one\\n        additional_seasonality_params: Iterable[Dict[str, Union[int, float, str]]]\\n            parameters that describe additional (not 'daily', 'weekly', 'yearly') seasonality that should be\\n            added to model; dict with required keys 'name', 'period', 'fourier_order' and optional ones 'prior_scale',\\n            'mode', 'condition_name' will be used for :py:meth:`prophet.Prophet.add_seasonality` method call.\\n        \"], 'from': [], 'import': []}\n",
      "{'FunctionDef': <8x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 8 stored elements in Compressed Sparse Row format>, 'ClassDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Common class for several TorchVision datasets.\\n\\n    Args:\\n        root: Dataset root.\\n        train: Whether to use train or val part of the dataset.\\n    ', 'Whether dataset is classification or matching.', 'Whether dataset is for open-set or closed-set classification.', 'Get dataset labels array.\\n\\n        Labels are integers in the range [0, N-1], where N is number of classes\\n\\n        ', 'Get element of the dataset.\\n\\n        Returns tuple (image, label).\\n\\n        '], 'from': [], 'import': []}\n",
      "{'FunctionDef': <27x22 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 27 stored elements in Compressed Sparse Row format>, 'ClassDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['cuda', 'halfcheetah-medium-expert-v2', '', 'CORL', 'TD3_BC-D4RL', 'TD3_BC', '-', '-', 'cpu', 'Trying to load data into non-empty replay buffer', 'observations', 'Replay buffer is smaller than the dataset you are trying to load!', 'observations', 'actions', 'rewards', 'next_observations', 'terminals', 'Dataset size: ', 'PYTHONHASHSEED', 'project', 'group', 'name', 'rewards', 'terminals', 'rewards', 'halfcheetah', 'hopper', 'walker2d', 'rewards', 'rewards', 'antmaze', 'rewards', 'cpu', 'cpu', 'critic_loss', 'actor_loss', 'critic_1', 'critic_1_optimizer', 'critic_2', 'critic_2_optimizer', 'actor', 'actor_optimizer', 'total_it', 'critic_1', 'critic_1_optimizer', 'critic_2', 'critic_2_optimizer', 'actor', 'actor_optimizer', 'total_it', 'observations', 'observations', 'observations', 'next_observations', 'next_observations', 'Checkpoints path: ', 'config.yaml', 'w', 'max_action', 'actor', 'actor_optimizer', 'critic_1', 'critic_1_optimizer', 'critic_2', 'critic_2_optimizer', 'discount', 'tau', 'device', 'policy_noise', 'noise_clip', 'policy_freq', 'alpha', '---------------------------------------', 'Training TD3 + BC, Env: ', ', Seed: ', '---------------------------------------', '', 'Time steps: ', '---------------------------------------', 'Evaluation over ', ' episodes: ', '.3f', ' , D4RL score: ', '.3f', '---------------------------------------', 'checkpoint_', '.pt', 'd4rl_normalized_score', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['\\n    102 Category Flower Dataset dataset class.\\n    https://www.robots.ox.ac.uk/~vgg/data/flowers/102/\\n\\n    Args:\\n        root: Dataset root.\\n        train: Whether to use train or test part of the dataset.\\n    ', 'trnid', 'trnid', 'valid', 'tstid', 'setid.mat', 'jpg', 'jpg', 'imagelabels.mat', 'labels', 'Whether dataset is classification or matching.', 'Whether dataset is for open-set or closed-set classification.', 'Get dataset labels array.\\n\\n        Labels are integers in the range [0, N-1], where N is number of classes\\n\\n        ', 'Get element of the dataset.\\n\\n        Returns tuple (image, label).\\n\\n        '], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['Check change points on validity.', 'Test that find_change_points works fine with multitrend example.', 'D', 'target', 'n_bkps', 'Test that find_change_points works fine with nans at the beginning of the series.', 'D', 'target', 'n_bkps', 'Test that find_change_points works fine with nans at the end of the series.', 'D', 'target', 'n_bkps'], 'from': [], 'import': []}\n",
      "{'FunctionDef': [], 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['pytorch_lightning.callbacks'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['2000-01-01', 'target', 'segment', 'segment_', 'segment_', 'D'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['1D', '\\n    Create DataFrame with AR process data.\\n\\n    Parameters\\n    ----------\\n    periods:\\n        number of timestamps\\n    start_time:\\n        start timestamp\\n    ar_coef:\\n        AR coefficients\\n    sigma:\\n        scale of AR noise\\n    n_segments:\\n        number of segments\\n    freq:\\n        pandas frequency string for :py:func:`pandas.date_range` that is used to generate timestamp\\n    random_seed:\\n        random seed\\n    ', 'segment_', 'timestamp', 'timestamp', 'target', 'segment', '1D', '\\n    Create DataFrame with periodic data.\\n\\n    Parameters\\n    ----------\\n    periods:\\n        number of timestamps\\n    start_time:\\n        start timestamp\\n    scale:\\n        we sample data from Uniform[0, scale)\\n    period:\\n        data frequency -- x[i+period] = x[i]\\n    n_segments:\\n        number of segments\\n    freq:\\n        pandas frequency string for :py:func:`pandas.date_range` that is used to generate timestamp\\n    add_noise:\\n        if True we add noise to final samples\\n    sigma:\\n        scale of added noise\\n    random_seed:\\n        random seed\\n    ', '1D', '\\n    Create DataFrame with const data.\\n\\n    Parameters\\n    ----------\\n    periods:\\n        number of timestamps\\n    start_time:\\n        start timestamp\\n    scale:\\n        const value to fill\\n    period:\\n        data frequency -- x[i+period] = x[i]\\n    n_segments:\\n        number of segments\\n    freq:\\n        pandas frequency string for :py:func:`pandas.date_range` that is used to generate timestamp\\n    add_noise:\\n        if True we add noise to final samples\\n    sigma:\\n        scale of added noise\\n    random_seed:\\n        random seed\\n    ', '1D', '\\n    Create DataFrame from patterns.\\n\\n    Parameters\\n    ----------\\n    periods:\\n        number of timestamps\\n    start_time:\\n        start timestamp\\n    patterns:\\n        list of lists with patterns to be repeated\\n    freq:\\n        pandas frequency string for :py:func:`pandas.date_range` that is used to generate timestamp\\n    add_noise:\\n        if True we add noise to final samples\\n    sigma:\\n        scale of added noise\\n    random_seed:\\n        random seed\\n    ', 'segment_', 'timestamp', 'timestamp', 'target', 'segment'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Hierarchical clustering with euclidean distance.\\n\\n    Examples\\n    --------\\n    >>> from etna.clustering import EuclideanClustering\\n    >>> from etna.datasets import TSDataset\\n    >>> from etna.datasets import generate_ar_df\\n    >>> ts = generate_ar_df(periods = 40, start_time = \"2000-01-01\", n_segments = 10)\\n    >>> ts = TSDataset(TSDataset.to_dataset(ts), freq=\"D\")\\n    >>> model = EuclideanClustering()\\n    >>> model.build_distance_matrix(ts)\\n    >>> model.build_clustering_algo(n_clusters=3, linkage=\"average\")\\n    >>> segment2cluster = model.fit_predict()\\n    >>> segment2cluster\\n    {\\'segment_0\\': 2,\\n     \\'segment_1\\': 1,\\n     \\'segment_2\\': 0,\\n     \\'segment_3\\': 1,\\n     \\'segment_4\\': 1,\\n     \\'segment_5\\': 0,\\n     \\'segment_6\\': 0,\\n     \\'segment_7\\': 0,\\n     \\'segment_8\\': 2,\\n     \\'segment_9\\': 2}\\n    ', 'Create instance of EuclideanClustering.', 'TSDataset', '\\n        Build distance matrix with euclidean distance.\\n\\n        Parameters\\n        ----------\\n        ts:\\n            TSDataset with series to build distance matrix\\n        ', 'EuclideanClustering'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <32x28 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 32 stored elements in Compressed Sparse Row format>, 'ClassDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['CORL', 'AWAC-D4RL', 'AWAC', 'halfcheetah-medium-expert-v2', 'cuda', '-', '-', 'cpu', 'Trying to load data into non-empty replay buffer', 'observations', 'Replay buffer is smaller than the dataset you are trying to load!', 'observations', 'actions', 'rewards', 'next_observations', 'terminals', 'Dataset size: ', 'critic_loss', 'actor_loss', 'actor', 'critic_1', 'critic_2', 'actor', 'critic_1', 'critic_2', 'PYTHONHASHSEED', 'rewards', 'terminals', 'rewards', 'halfcheetah', 'hopper', 'walker2d', 'rewards', 'rewards', 'antmaze', 'rewards', 'project', 'group', 'name', 'observations', 'observations', 'observations', 'next_observations', 'next_observations', 'state_dim', 'action_dim', 'hidden_dim', 'Checkpoints path: ', 'config.yaml', 'w', 'eval_score', 'get_normalized_score', 'normalized_eval_score', 'checkpoint_', '.pt', '/eval_scores.npy', 'wb', '/normalized_eval_scores.npy', 'wb', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <7x7 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['model', 'model_config', 'model', 'model_config', 'some-model', '_type', 'arg1', 'arg2', 'SimpleModel', 'model', 'model_config', 'some-model', '_type', 'arg1', 'arg2', 'SimpleModel', 'config.yaml', 'model', 'model_config', 'some-model', '_type', 'arg1', 'arg2', 'SimpleModel', 'model', 'model', 'model_config', 'arg1', 'model_config', 'arg1', 'model_config', 'arg2', 'model_config', 'arg2', 'a', 'e', 'f', 'b', '_hopt', 'c', 'b', 'd', 'aoeu', 'i', '_hopt', 'g', '_hopt', 'h', 'a.b', 'a.c.d', 'e', 'f.0.i', '_hopt', 'aoeu', 'a.b', 'f.0.g', 'f.1.h', '_hopt', 'b', 'a', 'b', 'a', 'b', 'a', 'a', 'a', 'c', 'b', 'd', 'e', 'a', 'f', 'c', 'b', 'g', 'h', 'a', 'f', 'c', 'b', 'd', 'e', 'g', 'h', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <6x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['DirectEnsemble is a pipeline that forecasts future values merging the forecasts of base pipelines.\\n\\n    Ensemble expects several pipelines during init. These pipelines are expected to have different forecasting horizons.\\n    For each point in the future, forecast of the ensemble is forecast of base pipeline with the shortest horizon,\\n    which covers this point.\\n\\n    Examples\\n    --------\\n    >>> from etna.datasets import generate_ar_df\\n    >>> from etna.datasets import TSDataset\\n    >>> from etna.ensembles import DirectEnsemble\\n    >>> from etna.models import NaiveModel\\n    >>> from etna.models import ProphetModel\\n    >>> from etna.pipeline import Pipeline\\n    >>> df = generate_ar_df(periods=30, start_time=\"2021-06-01\", ar_coef=[1.2], n_segments=3)\\n    >>> df_ts_format = TSDataset.to_dataset(df)\\n    >>> ts = TSDataset(df_ts_format, \"D\")\\n    >>> prophet_pipeline = Pipeline(model=ProphetModel(), transforms=[], horizon=3)\\n    >>> naive_pipeline = Pipeline(model=NaiveModel(lag=10), transforms=[], horizon=5)\\n    >>> ensemble = DirectEnsemble(pipelines=[prophet_pipeline, naive_pipeline])\\n    >>> _ = ensemble.fit(ts=ts)\\n    >>> forecast = ensemble.forecast()\\n    >>> forecast\\n    segment    segment_0 segment_1 segment_2\\n    feature       target    target    target\\n    timestamp\\n    2021-07-01    -10.37   -232.60    163.16\\n    2021-07-02    -10.59   -242.05    169.62\\n    2021-07-03    -11.41   -253.82    177.62\\n    2021-07-04     -5.85   -139.57     96.99\\n    2021-07-05     -6.11   -167.69    116.59\\n    ', 'Init DirectEnsemble.\\n\\n        Parameters\\n        ----------\\n        pipelines:\\n            List of pipelines that should be used in ensemble\\n        n_jobs:\\n            Number of jobs to run in parallel\\n        joblib_params:\\n            Additional parameters for :py:class:`joblib.Parallel`\\n\\n        Raises\\n        ------\\n        ValueError:\\n            If two or more pipelines have the same horizons.\\n        ', 'multiprocessing', 'c', \"Get ensemble's horizon.\", 'All the pipelines should have pairwise different horizons.', 'Fit pipelines in ensemble.\\n\\n        Parameters\\n        ----------\\n        ts:\\n            TSDataset to fit ensemble\\n\\n        Returns\\n        -------\\n        self:\\n            Fitted ensemble\\n        ', 'DirectEnsemble', 'Merge the forecasts of base pipelines according to the direct strategy.', 'target', 'target', 'Make predictions.\\n\\n        In each point in the future, forecast of the ensemble is forecast of base pipeline with the shortest horizon,\\n        which covers this point.\\n        ', 'Something went wrong, ts is None!', 'multiprocessing', 'Ensemble ', \" doesn't support prediction intervals!\"], 'from': [], 'import': []}\n",
      "{'FunctionDef': <10x10 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 10 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['result', 'Generate pd.DataFrame with timestamp.', 'timestamp', '2019-12-01', '2019-12-31', 'target', 'segment', 'segment_1', '2021-05-20', 'D', 'D', 'segment_1', 'target', 'Check that fit method save intervals.', 'target', 'segment_1', 'Check that transform method generate new column.', 'target', 'segment_1', 'segment_1', 'target', 'category', 'Check that resulting column is monotonously non-decreasing.', 'target', 'segment_1', 'segment_1', 'Test that transform for one segment raise error when calling transform without being fit.', 'target', 'Transform is not fitted!', 'segment_1', 'target', 'target', '2021-06-01', '2021-08-01', 'target'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['wandb-sweeps', 'test', 'sweeps', 'D', 'Optuna objective function.', 'iterations', 'depth', 'target', 'target', 'lags', 'MAE', 'sqlite:///optuna.db', 'data', 'example_dataset.csv', 'minimize', 'D', '\\n    Run optuna optimization for CatBoostModelMultiSegment.\\n    ', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <6x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['Check that v_optimal_hist works correctly.', 'series,bins_number,expected', 'Check that v_optimal_hist works correctly.', 'series,bins_number,expected', 'Check that computeF produce the correct size output.', 'series_len,k', 'Check that computeF works correctly.', 'series,k,dim,expected', 'Check that hist works correctly.', 'series,bins_number,expected', 'feature', '1', '2', '2021-01-08', '2021-01-26'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <15x15 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 15 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['Check that StackingEnsemble._validate_cv works correctly in case of valid cv parameter.', 'input_cv,true_cv', 'Check that StackingEnsemble._validate_cv works correctly in case of wrong number for cv parameter.', 'Folds number should be a positive number, 0 given', 'input_cv', 'Check that StackingEnsemble._get_features_to_use works correctly.', 'features_to_use,expected_features', 'all', 'regressor_lag_feature_10', 'regressor_dateflag_day_number_in_month', 'regressor_dateflag_day_number_in_week', 'regressor_dateflag_is_weekend', 'regressor_lag_feature_10', 'regressor_dateflag_day_number_in_week', 'regressor_lag_feature_10', 'regressor_dateflag_day_number_in_week', 'Check that StackingEnsemble._get_features_to_use raises warning in case of wrong format.', 'Feature list is passed in the wrong format.', 'features_to_use', 'regressor_lag_feature_10', 'Check that StackingEnsemble._get_features_to_use raises warning in case of unavailable features.', 'Features ', ' are not found and will be dropped!', 'features_to_use', 'unknown_feature', 'Check that StackingEnsemble._make_features returns X,y with all the expected columns\\n    and which are compatible with the sklearn interface.\\n    ', 'feature', 'features_to_use,expected_features', 'regressor_target_0', 'regressor_target_1', 'all', 'regressor_lag_feature_10', 'regressor_dateflag_day_number_in_month', 'regressor_dateflag_day_number_in_week', 'regressor_dateflag_is_weekend', 'regressor_target_0', 'regressor_target_1', 'regressor_lag_feature_10', 'regressor_dateflag_day_number_in_week', 'unknown', 'regressor_lag_feature_10', 'regressor_dateflag_day_number_in_week', 'regressor_target_0', 'regressor_target_1', 'Check that StackingEnsemble.forecast returns TSDataset of correct length, containing all the expected columns', 'feature', 'target', 'features_to_use,expected_features', 'regressor_target_0', 'regressor_target_1', 'all', 'regressor_lag_feature_10', 'regressor_dateflag_day_number_in_month', 'regressor_dateflag_day_number_in_week', 'regressor_dateflag_is_weekend', 'regressor_target_0', 'regressor_target_1', 'regressor_lag_feature_10', 'regressor_dateflag_day_number_in_week', 'unknown', 'regressor_lag_feature_10', 'regressor_dateflag_day_number_in_week', 'regressor_target_0', 'regressor_target_1', 'Check that StackingEnsemble.predict returns TSDataset of correct length, containing all the expected columns', 'feature', 'target', 'features_to_use,expected_features', 'regressor_target_0', 'regressor_target_1', 'all', 'regressor_lag_feature_10', 'regressor_dateflag_day_number_in_month', 'regressor_dateflag_day_number_in_week', 'regressor_dateflag_is_weekend', 'regressor_target_0', 'regressor_target_1', 'regressor_lag_feature_10', 'regressor_dateflag_day_number_in_week', 'unknown', 'regressor_lag_feature_10', 'regressor_dateflag_day_number_in_week', 'regressor_target_0', 'regressor_target_1', 'Test the forecast interface with prediction intervals.', 'target_0.025', 'target_0.975', 'target', 'target_0.975', 'target_0.025', 'TSDataset', 'TSDataset', 'Check that StackingEnsemble.forecast forecast correct values', 'macro', 'Check that StackingEnsemble works the same in case of multi and single jobs modes.', 'Check that backtest works with StackingEnsemble.', 'n_jobs', 'Test that StackingEnsemble raise error when calling forecast without being fit.', 'StackingEnsemble is not fitted!'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <14x14 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 14 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Dataset selector and constructor.', 'casia-openset', 'ms1mv2-openset', 'ms1mv3-openset', 'lfw-openset', 'clfw-openset', 'lfw-joined-openset', 'cub200-openset', 'cars196-openset', 'cub200-interleave-openset', 'cars196-interleave-openset', 'sop-openset', 'inshop-openset', 'mnist-openset', 'imagenette', 'tinyimagenet', 'imagenet', 'stanforddogs', 'flower102', 'imagenetlt', 'cifar10', 'cifar100', 'mnist', 'svhn', 'serialized-openset', 'debug-openset', 'train', 'flower102', 'imagenetlt', 'valid', 'val', 'casia-openset', 'ms1mv2-openset', 'ms1mv3-openset', 'lfw-openset', 'clfw-openset', 'lfw-joined-openset', 'cub200-openset', 'cars196-openset', 'cub200-interleave-openset', 'cars196-interleave-openset', 'sop-openset', 'inshop-openset', 'mnist-openset', 'imagenette', 'tinyimagenet', 'imagenet', 'stanforddogs', 'flower102', 'imagenetlt', 'cifar10', 'cifar100', 'mnist', 'svhn', 'serialized-openset', 'debug-openset', '.bin', '.bin', '.bin', 'tstid', 'imagenetlt-overall', 'imagenetlt-many-shot', 'imagenetlt-medium-shot', 'imagenetlt-few-shot', 'test', 'overall', 'test', 'many-shot', 'test', 'medium-shot', 'test', 'few-shot', 'test', 'train', 'same_class', 'Get collection parameters.\\n\\n        Args:\\n            name: Type of the training dataset (`casia`, `ms1mv2`, `ms1mv3`, `lfw`, `cub200`, `cars196` or `sop`).\\n            validation_fold: Fold index used for validation.\\n            num_validation_folds: Number of validation splits.\\n            validation_split_interleave: If True, use interleave splitting scheme. Split using segments otherwise.\\n            transform_params: Parameters of :class:`ImageTransform`.\\n            transform_test_params: Parameters of :class:`ImageTestTransform` used during testing.\\n            augmenter_params: Parameters of :class:`ImageAugmenter` used during training.\\n            mixup_type: Type of mixup strategy for classification datasets. (None or \"same_class\").\\n            batch_size: Batch size.\\n            samples_per_class: If not None, sample classes uniformly with the given number of samples per class.\\n            uniform_sampling: If true and samples_per_class is not None, classes are sampled uniformly for each batch.\\n            num_workers: Number of loader workers.\\n            num_valid_workers: Number of workers used for validation. Set None to use the same number as in train.\\n            persistent_workers: Keep loader workers alive after iteration.\\n            shuffle_train: Whether to shuffle train or not.\\n            train_repeat: Number of training set repetition during epoch (useful for small datasets).\\n            preload: Load full dataset to the memory before training.\\n            add_lossy_valsets: Add lossy variants of validation sets.\\n            add_lossy_testsets: Add lossy variants of test sets.\\n            lossy_params: Parameters of lossy datasets.\\n            add_verification_valsets: Whether to add verification validation sets in addition to classification.\\n            add_verification_testsets: Whether to add verification testsets in addition to classification.\\n            validate_on_test: Compute test metrics between epochs.\\n        ', 'name', 'validation_fold', 'num_validation_folds', 'validation_split_interleave', 'transform_params', 'transform_test_params', 'augmenter_params', 'mixup_type', 'batch_size', 'samples_per_class', 'uniform_sampling', 'num_workers', 'persistent_workers', 'num_valid_workers', 'shuffle_train', 'train_repeat', 'preload', 'add_lossy_valsets', 'add_lossy_testsets', 'lossy_params', 'add_verification_testsets', 'add_verification_valsets', 'validate_on_test', 'name', 'Dataset type must be provided', 'transform_params', 'transform_test_params', 'augmenter_params', 'Get dataset image size.', 'Get total number of classes in train.', 'Get array of trainset class priors.', 'validation_fold', 'Get training dataset.', 'name', 'validation_fold', 'name', \"`validation_fold` is not None. Cannot perform validation split,because this dataset has author's validation split.\", 'validation_fold', 'num_validation_folds', 'validation_split_interleave', 'validation_fold', 'num_validation_folds', 'validation_split_interleave', 'preload', 'num_workers', 'train_repeat', 'Get validation datasets. Returns None if not available.', 'validation_fold', 'name', \"`validation_fold` is not None. Cannot perform validation split,because this dataset has author's validation split.\", 'name', 'validation_fold', 'num_validation_folds', 'validation_split_interleave', 'validation_fold', 'num_validation_folds', 'validation_split_interleave', 'name', 'name', 'valid', 'add_lossy_valsets', '-lossy', 'lossy_params', 'preload', 'num_workers', 'add_verification_valsets', '-pairs', 'Get dictionary of testsets.', 'name', 'name', 'name', 'infer-', 'add_lossy_testsets', '-lossy', 'lossy_params', 'preload', 'num_workers', 'add_verification_testsets', '-pairs', 'Get datasets dictionary.\\n\\n        Args:\\n            train: Whether to make training set or not.\\n            transform: Whether to apply transforms or not.\\n\\n        ', 'train', 'validate_on_test', 'Get dataset loaders.', 'train', 'num_workers', 'num_valid_workers', 'num_valid_workers', 'batch_size', 'samples_per_class', 'shuffle_train', 'Balanced sampling requires shuffling.', 'batch_sampler', 'samples_per_class', 'uniform_sampling', 'batch_size', 'drop_last', 'shuffle', 'shuffle_train', 'mixup_type', 'collate_fn', 'mixup_type', 'persistent_workers'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <20x17 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 20 stored elements in Compressed Sparse Row format>, 'ClassDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': [\"Check if a path is available in your environment.\\n    >>> _module_available('os')\\n    True\\n    >>> _module_available('bla.bla')\\n    False\\n    \", 'pytorch_forecasting', 'pytorch_lightning', 'torch', 'etna[torch] is not available, to install it, run `pip install etna[torch]`', 'wandb', 'wandb is not available, to install it, run `pip install etna[wandb]`', 'prophet', 'etna[prophet] is not available, to install it, run `pip install etna[prophet]`', 'tsfresh', '`tsfresh` is not available, to install it, run `pip install tsfresh==0.19.0 && pip install protobuf==3.20.1`', 'etna settings.', 'etna[torch] is not available, to install it, run `pip install etna[torch]`.', 'wandb is not available, to install it, run `pip install wandb`.', 'etna[prophet] is not available, to install it, run `pip install etna[prophet]`.', '`tsfresh` is not available, to install it, run `pip install tsfresh==0.19.0 && pip install protobuf==3.20.1`', 'Parse and return the settings.\\n\\n        Returns\\n        -------\\n        Settings:\\n            Dictionary of the parsed and merged Settings.\\n        ', 'etna', 'Settings', 'Return type hint for the specified ``key``.\\n\\n        Parameters\\n        ----------\\n        key:\\n            key of interest\\n\\n        Returns\\n        -------\\n            type hint for the specified key\\n        ', 'Encapsulate the logic for finding and reading config files.\\n\\n    Adapted from:\\n\\n    - https://github.com/catalyst-team/catalyst (Apache-2.0 License)\\n    ', 'Initialize object to find config files.\\n\\n        Parameters\\n        ----------\\n        program_name:\\n            Name of the current program (e.g., catalyst).\\n        ', '.', 'nt', '~', '.', 'XDG_CONFIG_HOME', '~/.config', 'There was an error decoding a config file. The file with a problem was ', '.', 'There was an error trying to parse a config file. The file with a problem was ', '.', 'Find and generate all local config files.\\n\\n        Yields\\n        ------\\n        str:\\n            Path to config file.\\n        ', '\\n        Find all local config files which actually exist.\\n\\n        Returns\\n        -------\\n        List[str]:\\n            List of files that exist that are\\n            local project config  files with extra config files\\n            appended to that list (which also exist).\\n        ', 'Parse all local config files into one config object.', 'Found local configuration files: ', 'Parse the user config file into a config object.', 'Found user configuration files: ', 'Encapsulate merging different types of configuration files.\\n\\n    This parses out the options registered that were specified in the\\n    configuration files, handles extra configuration files, and returns\\n    dictionaries with the parsed values.\\n\\n    Adapted from:\\n\\n    - https://github.com/catalyst-team/catalyst (Apache-2.0 License)\\n    ', 'store_true', 'store_false', 'Initialize the MergedConfigParser instance.\\n\\n        Parameters\\n        ----------\\n        config_finder:\\n            Initialized ConfigFileFinder.\\n        ', ' has been normalized to ', \" for option '\", \"'\", 'Parse and return the local and user config files.\\n\\n        First this copies over the parsed local configuration and then\\n        iterates over the options in the user configuration and sets them if\\n        they were not set by the local configuration file.\\n\\n        Returns\\n        -------\\n        dict:\\n            Dictionary of the parsed and merged configuration options.\\n        ', 'SETTINGS', 'Settings', 'ConfigFileFinder', 'MergedConfigParser'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <34x34 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 34 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['TSDataset is the main class to handle your time series data.\\n    It prepares the series for exploration analyzing, implements feature generation with Transforms\\n    and generation of future points.\\n\\n    Notes\\n    -----\\n    TSDataset supports custom indexing and slicing method.\\n    It maybe done through these interface: ``TSDataset[timestamp, segment, column]``\\n    If at the start of the period dataset contains NaN those timestamps will be removed.\\n\\n    During creation segment is casted to string type.\\n\\n    Examples\\n    --------\\n    >>> from etna.datasets import generate_const_df\\n    >>> df = generate_const_df(periods=30, start_time=\"2021-06-01\", n_segments=2, scale=1)\\n    >>> df_ts_format = TSDataset.to_dataset(df)\\n    >>> ts = TSDataset(df_ts_format, \"D\")\\n    >>> ts[\"2021-06-01\":\"2021-06-07\", \"segment_0\", \"target\"]\\n    timestamp\\n    2021-06-01    1.0\\n    2021-06-02    1.0\\n    2021-06-03    1.0\\n    2021-06-04    1.0\\n    2021-06-05    1.0\\n    2021-06-06    1.0\\n    2021-06-07    1.0\\n    Freq: D, Name: (segment_0, target), dtype: float64\\n\\n    >>> from etna.datasets import generate_ar_df\\n    >>> pd.options.display.float_format = \\'{:,.2f}\\'.format\\n    >>> df_to_forecast = generate_ar_df(100, start_time=\"2021-01-01\", n_segments=1)\\n    >>> df_regressors = generate_ar_df(120, start_time=\"2021-01-01\", n_segments=5)\\n    >>> df_regressors = df_regressors.pivot(index=\"timestamp\", columns=\"segment\").reset_index()\\n    >>> df_regressors.columns = [\"timestamp\"] + [f\"regressor_{i}\" for i in range(5)]\\n    >>> df_regressors[\"segment\"] = \"segment_0\"\\n    >>> df_to_forecast = TSDataset.to_dataset(df_to_forecast)\\n    >>> df_regressors = TSDataset.to_dataset(df_regressors)\\n    >>> tsdataset = TSDataset(df=df_to_forecast, freq=\"D\", df_exog=df_regressors, known_future=\"all\")\\n    >>> tsdataset.df.head(5)\\n    segment      segment_0\\n    feature    regressor_0 regressor_1 regressor_2 regressor_3 regressor_4 target\\n    timestamp\\n    2021-01-01        1.62       -0.02       -0.50       -0.56        0.52   1.62\\n    2021-01-02        1.01       -0.80       -0.81        0.38       -0.60   1.01\\n    2021-01-03        0.48        0.47       -0.81       -1.56       -1.37   0.48\\n    2021-01-04       -0.59        2.44       -2.21       -1.21       -0.69  -0.59\\n    2021-01-05        0.28        0.58       -3.07       -1.45        0.77   0.28\\n    ', 'all', 'Init TSDataset.\\n\\n        Parameters\\n        ----------\\n        df:\\n            dataframe with timeseries\\n        freq:\\n            frequency of timestamp in df\\n        df_exog:\\n            dataframe with exogenous data;\\n        known_future:\\n            columns in ``df_exog[known_future]`` that are regressors,\\n            if \"all\" value is given, all columns are meant to be regressors\\n        ', \"TSDataset freq can't be inferred\", 'You probably set wrong freq. Discovered freq in you data is ', ', you set ', 'Transform', 'Transform', 'Apply given transform to the data.', 'Transform ', ' is applied to dataset', 'feature', 'feature', 'Transform', 'Fit and apply given transforms to the data.', 'Transform ', ' is applied to dataset', 'feature', 'feature', 'segment', 'segment', 'Transform', 'in_column', 'out_columns', 'out_column', 'Transform is not FutureMixin and does not have in_column attribute!', 'Return new TSDataset with future steps.\\n\\n        Parameters\\n        ----------\\n        future_steps:\\n            number of timestamp in the future to build features for.\\n        tail_steps:\\n            number of timestamp for context to build features for.\\n\\n        Returns\\n        -------\\n        :\\n            dataset with features in the future.\\n\\n        Examples\\n        --------\\n        >>> from etna.datasets import generate_const_df\\n        >>> df = generate_const_df(\\n        ...    periods=30, start_time=\"2021-06-01\",\\n        ...    n_segments=2, scale=1\\n        ... )\\n        >>> df_regressors = pd.DataFrame({\\n        ...     \"timestamp\": list(pd.date_range(\"2021-06-01\", periods=40))*2,\\n        ...     \"regressor_1\": np.arange(80), \"regressor_2\": np.arange(80) + 5,\\n        ...     \"segment\": [\"segment_0\"]*40 + [\"segment_1\"]*40\\n        ... })\\n        >>> df_ts_format = TSDataset.to_dataset(df)\\n        >>> df_regressors_ts_format = TSDataset.to_dataset(df_regressors)\\n        >>> ts = TSDataset(\\n        ...     df_ts_format, \"D\", df_exog=df_regressors_ts_format, known_future=\"all\"\\n        ... )\\n        >>> ts.make_future(4)\\n        segment      segment_0                      segment_1\\n        feature    regressor_1 regressor_2 target regressor_1 regressor_2 target\\n        timestamp\\n        2021-07-01          30          35    NaN          70          75    NaN\\n        2021-07-02          31          36    NaN          71          76    NaN\\n        2021-07-03          32          37    NaN          72          77    NaN\\n        2021-07-04          33          38    NaN          73          78    NaN\\n        ', 'right', 'timestamp', \"Some regressors don't have enough values in segment \", ', NaN-s will be used for missing values', 'Transform ', ' is applied to dataset', 'TSDataset', 'Return new TSDataset with integer-location based indexing.\\n\\n        Parameters\\n        ----------\\n        start_idx:\\n            starting index of the slice.\\n        end_idx:\\n            last index of the slice.\\n\\n        Returns\\n        -------\\n        :\\n            TSDataset based on indexing slice.\\n        ', 'TSDataset', 'all', 'Check that ``known_future`` corresponds to ``df_exog`` and returns initial list of regressors.', 'feature', 'all', \"The only possible literal is 'all'\", 'Some features in known_future are not present in df_exog: ', 'Check that regressors begin not later than in ``df`` and end later than in ``df``.', 'segment', 'target', 'target', \"All the regressor series should start not later than corresponding 'target'.Series of segment \", ' have not enough history: ', ' < ', '.', \"All the regressor series should finish later than corresponding 'target'.Series of segment \", ' have not enough history: ', ' >= ', '.', 'Something went wrong, Trying to merge df_exog which is None!', 'Check that all targets ends at the same timestamp.', 'target', 'Segments contains NaNs in the last timestamps.Some of the transforms might work incorrectly or even fail.Make sure that you use the imputer before making the forecast.', 'All segments should end at the same timestamp', 'Apply inverse transform method of transforms to the data.\\n\\n        Applied in reversed order.\\n        ', 'Inverse transform ', ' is applied to dataset', 'Get list of all segments in dataset.\\n\\n        Examples\\n        --------\\n        >>> from etna.datasets import generate_const_df\\n        >>> df = generate_const_df(\\n        ...    periods=30, start_time=\"2021-06-01\",\\n        ...    n_segments=2, scale=1\\n        ... )\\n        >>> df_ts_format = TSDataset.to_dataset(df)\\n        >>> ts = TSDataset(df_ts_format, \"D\")\\n        >>> ts.segments\\n        [\\'segment_0\\', \\'segment_1\\']\\n        ', 'segment', 'Get list of all regressors across all segments in dataset.\\n\\n        Examples\\n        --------\\n        >>> from etna.datasets import generate_const_df\\n        >>> df = generate_const_df(\\n        ...    periods=30, start_time=\"2021-06-01\",\\n        ...    n_segments=2, scale=1\\n        ... )\\n        >>> df_ts_format = TSDataset.to_dataset(df)\\n        >>> regressors_timestamp = pd.date_range(start=\"2021-06-01\", periods=50)\\n        >>> df_regressors_1 = pd.DataFrame(\\n        ...     {\"timestamp\": regressors_timestamp, \"regressor_1\": 1, \"segment\": \"segment_0\"}\\n        ... )\\n        >>> df_regressors_2 = pd.DataFrame(\\n        ...     {\"timestamp\": regressors_timestamp, \"regressor_1\": 2, \"segment\": \"segment_1\"}\\n        ... )\\n        >>> df_exog = pd.concat([df_regressors_1, df_regressors_2], ignore_index=True)\\n        >>> df_exog_ts_format = TSDataset.to_dataset(df_exog)\\n        >>> ts = TSDataset(\\n        ...     df_ts_format, df_exog=df_exog_ts_format, freq=\"D\", known_future=\"all\"\\n        ... )\\n        >>> ts.regressors\\n        [\\'regressor_1\\']\\n        ', 'target', 'Plot of random or chosen segments.\\n\\n        Parameters\\n        ----------\\n        n_segments:\\n            number of random segments to plot\\n        column:\\n            feature to plot\\n        segments:\\n            segments to plot\\n        seed:\\n            seed for local random state\\n        start:\\n            start plot from this timestamp\\n        end:\\n            end plot at this timestamp\\n        figsize:\\n            size of the figure per subplot with one segment in inches\\n        ', 'Return pandas DataFrame with flatten index.\\n\\n        Parameters\\n        ----------\\n        df:\\n            DataFrame in ETNA format.\\n\\n        Returns\\n        -------\\n        pd.DataFrame:\\n            dataframe with TSDataset data\\n\\n        Examples\\n        --------\\n        >>> from etna.datasets import generate_const_df\\n        >>> df = generate_const_df(\\n        ...    periods=30, start_time=\"2021-06-01\",\\n        ...    n_segments=2, scale=1\\n        ... )\\n        >>> df.head(5)\\n            timestamp    segment  target\\n        0  2021-06-01  segment_0    1.00\\n        1  2021-06-02  segment_0    1.00\\n        2  2021-06-03  segment_0    1.00\\n        3  2021-06-04  segment_0    1.00\\n        4  2021-06-05  segment_0    1.00\\n        >>> df_ts_format = TSDataset.to_dataset(df)\\n        >>> TSDataset.to_flatten(df_ts_format).head(5)\\n           timestamp  target    segment\\n        0 2021-06-01     1.0  segment_0\\n        1 2021-06-02     1.0  segment_0\\n        2 2021-06-03     1.0  segment_0\\n        3 2021-06-04     1.0  segment_0\\n        4 2021-06-05     1.0  segment_0\\n        ', 'category', 'feature', 'segment', 'timestamp', 'segment', 'Return pandas DataFrame.\\n\\n        Parameters\\n        ----------\\n        flatten:\\n            * If False, return pd.DataFrame with multiindex\\n\\n            * If True, return with flatten index\\n\\n        Returns\\n        -------\\n        pd.DataFrame\\n            dataframe with TSDataset data\\n\\n        Examples\\n        --------\\n        >>> from etna.datasets import generate_const_df\\n        >>> df = generate_const_df(\\n        ...    periods=30, start_time=\"2021-06-01\",\\n        ...    n_segments=2, scale=1\\n        ... )\\n        >>> df.head(5)\\n            timestamp    segment  target\\n        0  2021-06-01  segment_0    1.00\\n        1  2021-06-02  segment_0    1.00\\n        2  2021-06-03  segment_0    1.00\\n        3  2021-06-04  segment_0    1.00\\n        4  2021-06-05  segment_0    1.00\\n        >>> df_ts_format = TSDataset.to_dataset(df)\\n        >>> ts = TSDataset(df_ts_format, \"D\")\\n        >>> ts.to_pandas(True).head(5)\\n           timestamp  target    segment\\n        0 2021-06-01     1.0  segment_0\\n        1 2021-06-02     1.0  segment_0\\n        2 2021-06-03     1.0  segment_0\\n        3 2021-06-04     1.0  segment_0\\n        4 2021-06-05     1.0  segment_0\\n        >>> ts.to_pandas(False).head(5)\\n        segment    segment_0 segment_1\\n        feature       target    target\\n        timestamp\\n        2021-06-01      1.00      1.00\\n        2021-06-02      1.00      1.00\\n        2021-06-03      1.00      1.00\\n        2021-06-04      1.00      1.00\\n        2021-06-05      1.00      1.00\\n        ', 'Convert pandas dataframe to ETNA Dataset format.\\n\\n        Columns \"timestamp\" and \"segment\" are required.\\n\\n        Parameters\\n        ----------\\n        df:\\n            DataFrame with columns [\"timestamp\", \"segment\"]. Other columns considered features.\\n\\n        Notes\\n        -----\\n        During conversion segment is casted to string type.\\n\\n        Examples\\n        --------\\n        >>> from etna.datasets import generate_const_df\\n        >>> df = generate_const_df(\\n        ...    periods=30, start_time=\"2021-06-01\",\\n        ...    n_segments=2, scale=1\\n        ... )\\n        >>> df.head(5)\\n           timestamp    segment  target\\n        0 2021-06-01  segment_0    1.00\\n        1 2021-06-02  segment_0    1.00\\n        2 2021-06-03  segment_0    1.00\\n        3 2021-06-04  segment_0    1.00\\n        4 2021-06-05  segment_0    1.00\\n        >>> df_ts_format = TSDataset.to_dataset(df)\\n        >>> df_ts_format.head(5)\\n        segment    segment_0 segment_1\\n        feature       target    target\\n        timestamp\\n        2021-06-01      1.00      1.00\\n        2021-06-02      1.00      1.00\\n        2021-06-03      1.00      1.00\\n        2021-06-04      1.00      1.00\\n        2021-06-05      1.00      1.00\\n\\n        >>> df_regressors = pd.DataFrame({\\n        ...     \"timestamp\": pd.date_range(\"2021-01-01\", periods=10),\\n        ...     \"regressor_1\": np.arange(10), \"regressor_2\": np.arange(10) + 5,\\n        ...     \"segment\": [\"segment_0\"]*10\\n        ... })\\n        >>> TSDataset.to_dataset(df_regressors).head(5)\\n        segment      segment_0\\n        feature    regressor_1 regressor_2\\n        timestamp\\n        2021-01-01           0           5\\n        2021-01-02           1           6\\n        2021-01-03           2           7\\n        2021-01-04           3           8\\n        2021-01-05           4           9\\n        ', 'timestamp', 'timestamp', 'segment', 'segment', 'timestamp', 'segment', 'timestamp', 'segment', 'segment', 'feature', \"Find borders for train_test_split if some values wasn't specified.\", 'test_size, test_start and test_end cannot be applied at the same time. test_size will be ignored', 'test_size is ', ', but only ', ' available with your test_start', 'At least one of train_end, test_start or test_size should be defined', 'The beginning of the test goes before the end of the train', 'Split given df with train-test timestamp indices or size of test set.\\n\\n        In case of inconsistencies between ``test_size`` and (``test_start``, ``test_end``), ``test_size`` is ignored\\n\\n        Parameters\\n        ----------\\n        train_start:\\n            start timestamp of new train dataset, if None first timestamp is used\\n        train_end:\\n            end timestamp of new train dataset, if None previous to ``test_start`` timestamp is used\\n        test_start:\\n            start timestamp of new test dataset, if None next to ``train_end`` timestamp is used\\n        test_end:\\n            end timestamp of new test dataset, if None last timestamp is used\\n        test_size:\\n            number of timestamps to use in test set\\n\\n        Returns\\n        -------\\n        train, test:\\n            generated datasets\\n\\n        Examples\\n        --------\\n        >>> from etna.datasets import generate_ar_df\\n        >>> pd.options.display.float_format = \\'{:,.2f}\\'.format\\n        >>> df = generate_ar_df(100, start_time=\"2021-01-01\", n_segments=3)\\n        >>> df = TSDataset.to_dataset(df)\\n        >>> ts = TSDataset(df, \"D\")\\n        >>> train_ts, test_ts = ts.train_test_split(\\n        ...     train_start=\"2021-01-01\", train_end=\"2021-02-01\",\\n        ...     test_start=\"2021-02-02\", test_end=\"2021-02-07\"\\n        ... )\\n        >>> train_ts.df.tail(5)\\n        segment    segment_0 segment_1 segment_2\\n        feature       target    target    target\\n        timestamp\\n        2021-01-28     -2.06      2.03      1.51\\n        2021-01-29     -2.33      0.83      0.81\\n        2021-01-30     -1.80      1.69      0.61\\n        2021-01-31     -2.49      1.51      0.85\\n        2021-02-01     -2.89      0.91      1.06\\n        >>> test_ts.df.head(5)\\n        segment    segment_0 segment_1 segment_2\\n        feature       target    target    target\\n        timestamp\\n        2021-02-02     -3.57     -0.32      1.72\\n        2021-02-03     -4.42      0.23      3.51\\n        2021-02-04     -5.09      1.02      3.39\\n        2021-02-05     -5.10      0.40      2.15\\n        2021-02-06     -6.22      0.92      0.97\\n        ', 'Max timestamp in df is ', '.', 'Min timestamp in df is ', '.', 'TSDataset', 'TSDataset', 'Return TSDataset timestamp index.\\n\\n        Returns\\n        -------\\n        pd.core.indexes.datetimes.DatetimeIndex\\n            timestamp index of TSDataset\\n        ', 'Return columns of ``self.df``.\\n\\n        Returns\\n        -------\\n        pd.core.indexes.multi.MultiIndex\\n            multiindex of dataframe with target and features.\\n        ', 'Return self.df.loc method.\\n\\n        Returns\\n        -------\\n        pd.core.indexing._LocIndexer\\n            dataframe with self.df.loc[...]\\n        ', 'Return dataframe with flag that means if the correspondent object in ``self.df`` is null.\\n\\n        Returns\\n        -------\\n        pd.Dataframe\\n            is_null dataframe\\n        ', 'Return the first ``n_rows`` rows.\\n\\n        Mimics pandas method.\\n\\n        This function returns the first ``n_rows`` rows for the object based\\n        on position. It is useful for quickly testing if your object\\n        has the right type of data in it.\\n\\n        For negative values of ``n_rows``, this function returns all rows except\\n        the last ``n_rows`` rows, equivalent to ``df[:-n_rows]``.\\n\\n        Parameters\\n        ----------\\n        n_rows:\\n            number of rows to select.\\n\\n        Returns\\n        -------\\n        pd.DataFrame\\n            the first ``n_rows`` rows or 5 by default.\\n        ', 'Return the last ``n_rows`` rows.\\n\\n        Mimics pandas method.\\n\\n        This function returns last ``n_rows`` rows from the object based on\\n        position. It is useful for quickly verifying data, for example,\\n        after sorting or appending rows.\\n\\n        For negative values of ``n_rows``, this function returns all rows except\\n        the first `n` rows, equivalent to ``df[n_rows:]``.\\n\\n        Parameters\\n        ----------\\n        n_rows:\\n            number of rows to select.\\n\\n        Returns\\n        -------\\n        pd.DataFrame\\n            the last ``n_rows`` rows or 5 by default.\\n\\n        ', 'Gather information about dataset in general.', 'num_segments', 'num_exogs', 'num_regressors', 'num_known_future', 'freq', 'feature', 'target', 'Gather information about each segment.', 'start_timestamp', 'end_timestamp', 'length', 'num_missing', 'target', 'start_timestamp', 'end_timestamp', 'length', 'num_missing', 'Overview of the dataset that returns a DataFrame.\\n\\n        Method describes dataset in segment-wise fashion. Description columns:\\n\\n        * start_timestamp: beginning of the segment, missing values in the beginning are ignored\\n\\n        * end_timestamp: ending of the segment, missing values in the ending are ignored\\n\\n        * length: length according to ``start_timestamp`` and ``end_timestamp``\\n\\n        * num_missing: number of missing variables between ``start_timestamp`` and ``end_timestamp``\\n\\n        * num_segments: total number of segments, common for all segments\\n\\n        * num_exogs: number of exogenous features, common for all segments\\n\\n        * num_regressors: number of exogenous factors, that are regressors, common for all segments\\n\\n        * num_known_future: number of regressors, that are known since creation, common for all segments\\n\\n        * freq: frequency of the series, common for all segments\\n\\n        Parameters\\n        ----------\\n        segments:\\n            segments to show in overview, if None all segments are shown.\\n\\n        Returns\\n        -------\\n        result_table: pd.DataFrame\\n            table with results of the overview\\n\\n        Examples\\n        --------\\n        >>> from etna.datasets import generate_const_df\\n        >>> pd.options.display.expand_frame_repr = False\\n        >>> df = generate_const_df(\\n        ...    periods=30, start_time=\"2021-06-01\",\\n        ...    n_segments=2, scale=1\\n        ... )\\n        >>> df_ts_format = TSDataset.to_dataset(df)\\n        >>> regressors_timestamp = pd.date_range(start=\"2021-06-01\", periods=50)\\n        >>> df_regressors_1 = pd.DataFrame(\\n        ...     {\"timestamp\": regressors_timestamp, \"regressor_1\": 1, \"segment\": \"segment_0\"}\\n        ... )\\n        >>> df_regressors_2 = pd.DataFrame(\\n        ...     {\"timestamp\": regressors_timestamp, \"regressor_1\": 2, \"segment\": \"segment_1\"}\\n        ... )\\n        >>> df_exog = pd.concat([df_regressors_1, df_regressors_2], ignore_index=True)\\n        >>> df_exog_ts_format = TSDataset.to_dataset(df_exog)\\n        >>> ts = TSDataset(df_ts_format, df_exog=df_exog_ts_format, freq=\"D\", known_future=\"all\")\\n        >>> ts.describe()\\n                  start_timestamp end_timestamp  length  num_missing  num_segments  num_exogs  num_regressors  num_known_future freq\\n        segments\\n        segment_0      2021-06-01    2021-06-30      30            0             2          1               1                 1    D\\n        segment_1      2021-06-01    2021-06-30      30            0             2          1               1                 1    D\\n        ', 'num_segments', 'num_segments', 'num_exogs', 'num_exogs', 'num_regressors', 'num_regressors', 'num_known_future', 'num_known_future', 'freq', 'freq', 'start_timestamp', 'end_timestamp', 'length', 'num_missing', 'num_segments', 'num_exogs', 'num_regressors', 'num_known_future', 'freq', 'segments', 'Overview of the dataset that prints the result.\\n\\n        Method describes dataset in segment-wise fashion.\\n\\n        Information about dataset in general:\\n\\n        * num_segments: total number of segments\\n\\n        * num_exogs: number of exogenous features\\n\\n        * num_regressors: number of exogenous factors, that are regressors\\n\\n        * num_known_future: number of regressors, that are known since creation\\n\\n        * freq: frequency of the dataset\\n\\n        Information about individual segments:\\n\\n        * start_timestamp: beginning of the segment, missing values in the beginning are ignored\\n\\n        * end_timestamp: ending of the segment, missing values in the ending are ignored\\n\\n        * length: length according to ``start_timestamp`` and ``end_timestamp``\\n\\n        * num_missing: number of missing variables between ``start_timestamp`` and ``end_timestamp``\\n\\n        Parameters\\n        ----------\\n        segments:\\n            segments to show in overview, if None all segments are shown.\\n\\n        Examples\\n        --------\\n        >>> from etna.datasets import generate_const_df\\n        >>> df = generate_const_df(\\n        ...    periods=30, start_time=\"2021-06-01\",\\n        ...    n_segments=2, scale=1\\n        ... )\\n        >>> df_ts_format = TSDataset.to_dataset(df)\\n        >>> regressors_timestamp = pd.date_range(start=\"2021-06-01\", periods=50)\\n        >>> df_regressors_1 = pd.DataFrame(\\n        ...     {\"timestamp\": regressors_timestamp, \"regressor_1\": 1, \"segment\": \"segment_0\"}\\n        ... )\\n        >>> df_regressors_2 = pd.DataFrame(\\n        ...     {\"timestamp\": regressors_timestamp, \"regressor_1\": 2, \"segment\": \"segment_1\"}\\n        ... )\\n        >>> df_exog = pd.concat([df_regressors_1, df_regressors_2], ignore_index=True)\\n        >>> df_exog_ts_format = TSDataset.to_dataset(df_exog)\\n        >>> ts = TSDataset(df_ts_format, df_exog=df_exog_ts_format, freq=\"D\", known_future=\"all\")\\n        >>> ts.info()\\n        <class \\'etna.datasets.TSDataset\\'>\\n        num_segments: 2\\n        num_exogs: 1\\n        num_regressors: 1\\n        num_known_future: 1\\n        freq: D\\n                  start_timestamp end_timestamp  length  num_missing\\n        segments\\n        segment_0      2021-06-01    2021-06-30      30            0\\n        segment_1      2021-06-01    2021-06-30      30            0\\n        ', \"<class 'etna.datasets.TSDataset'>\", ': ', 'segments', 'display.width', '\\n', '\\n', 'Convert the TSDataset to a :py:class:`torch.Dataset`.\\n\\n        Parameters\\n        ----------\\n        make_samples:\\n            function that takes per segment DataFrame and returns iterabale of samples\\n        dropna:\\n            if ``True``, missing rows are dropped\\n\\n        Returns\\n        -------\\n        :\\n            :py:class:`torch.Dataset` with with train or test samples to infer on\\n        ', 'segment', 'Dataset'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <6x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Predict embeddings, logits or dump helper tensors. Run without `outputs` to list valid output keys.', 'data', 'Path to dataset root', '--dataset', 'Name of the dataset. If not provided, list available datasets.', '--config', 'Path to training config', '--checkpoint', 'Path to initial checkpoint', '--outputs', 'A list of tensor_key:filename with output files. If not provided, list valid keys.', '+', '--augment-train', 'Augment training set', 'store_true', '--num-batches', 'Limit the number of batches to evaluate', 'train', 'stage_resume', 'dataset_params', 'samples_per_class', 'shuffle_train', 'on_experiment_start', 'on_stage_start', 'on_epoch_start', 'Available datasets are: {}.', 'on_loader_start', 'cpu', 'model_model_state_dict', 'model', 'train', 'model', 'train', ':', 'Multiple files for {}', 'gradnorms', 'optimizer', 'model', 'labels', '', '1', '2', 'embeddings', 'confidences', 'embeddings', 'gradnorms', 'Valid keys: {}', 'gradnorms', 'loss', 'model', 'model', 'Unknown key: {}', 'Model changed', 'Dump {} with shape {} to {}', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <8x8 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 8 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['TimeFlagsTransform is a class that implements extraction of the main time-based features from datetime column.', \"Initialise class attributes.\\n\\n        Parameters\\n        ----------\\n        minute_in_hour_number:\\n            if True: add column with minute number to feature dataframe in transform\\n        fifteen_minutes_in_hour_number:\\n            if True: add column with number of fifteen-minute interval within hour with numeration from 0\\n            to feature dataframe in transform\\n        hour_number:\\n            if True: add column with hour number to feature dataframe in transform\\n        half_hour_number:\\n            if True: add column with 0 for the first half of the hour and 1 for the second\\n            to feature dataframe in transform\\n        half_day_number:\\n            if True: add column with 0 for the first half of the day and 1 for the second\\n            to feature dataframe in transform\\n        one_third_day_number:\\n            if True: add column with number of 8-hour interval within day with numeration from 0\\n            to feature dataframe in transform\\n        out_column:\\n            base for the name of created columns;\\n\\n            * if set the final name is '{out_column}_{feature_name}';\\n\\n            * if don't set, name will be ``transform.__repr__()``,\\n              repr will be made for transform that creates exactly this column\\n\\n        Raises\\n        ------\\n        ValueError: if feature has invalid initial params\\n        \", ' feature does nothing with given init args configuration, at least one of minute_in_hour_number, fifteen_minutes_in_hour_number, hour_number, half_hour_number, half_day_number, one_third_day_number should be True.', '_', 'Fit datetime model.', 'TimeFlagsTransform', '\\n        Transform method for features based on time.\\n\\n        Parameters\\n        ----------\\n        df:\\n            Features dataframe with time\\n\\n        Returns\\n        -------\\n        result: pd.DataFrame\\n            Dataframe with extracted features\\n        ', 'minute_in_hour_number', 'fifteen_minutes_in_hour_number', 'hour_number', 'half_hour_number', 'half_day_number', 'one_third_day_number', 'category', 'segment', 'segment', 'segment', 'feature', 'Generate array with the minute number in the hour.', 'Generate an array with the period number in the hour.\\n\\n        Accepts a period length in minutes as input and returns array where timestamps marked by period number.\\n        ', 'Generate an array with the hour number in the day.', 'Generate an array with the period number in the day.\\n\\n        Accepts a period length in hours as input and returns array where timestamps marked by period number.\\n        ', 'TimeFlagsTransform'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <11x11 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 11 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Test Logarithm of modified Bessel Function of the first kind.', 'default', 'scl', 'SCL logiv mismatch {} for order {}.', 'SCL logiv derivative mismatch {} for order {}', 'Test split is inverse of join.', 'separate', 'norm', 'dim', 'k', 'Test distribution mean.', 'dim', 'Test batch norm.', 'separate', 'norm', 'dim', 'k', 'Test KL-divergence with uniform in simple cases.', 'dim', 'max_logk', 'Test PDF for small and large k values.\\n\\n        Double precision is used.\\n        ', 'dim', 'max_logk', 'dim', 'Check output for equal weights and one-hot weights.\\n\\n        Double precision is used.\\n        ', 'dim', 'max_logk', 'dim', 'dim', 'Test integral of vMF is equal to 1.', 'dim', 'dim', 'Test MLS is equal to estimation by sampling.', 'dim', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['``LambdaTransform`` applies input function for given series.', 'Init ``LambdaTransform``.\\n\\n        Parameters\\n        ----------\\n        in_column:\\n            column to apply transform\\n        out_column:\\n            name of added column. If not given, use ``self.__repr__()``\\n        transform_func:\\n            function to transform data\\n        inverse_transform_func:\\n            inverse function of ``transform_func``\\n        inplace:\\n\\n            * if `True`, apply transformation inplace to ``in_column``,\\n\\n            * if `False`, add column and apply transformation to ``out_column``\\n\\n        Warnings\\n        --------\\n        throws if `inplace=True` and ``out_column`` is initialized, transformation will be applied inplace\\n\\n        Raises\\n        ------\\n        Value error:\\n            if `inplace=True` and ``inverse_transform_func`` is not defined\\n        ', 'Transformation will be applied inplace, out_column param will be ignored', 'inverse_transform_func must be defined, when inplace=True', 'Fit preprocess method, does nothing in ``LambdaTransform`` case.\\n\\n        Parameters\\n        ----------\\n        df:\\n            dataframe with data.\\n\\n        Returns\\n        -------\\n        result: ``LambdaTransform``\\n        ', 'LambdaTransform', 'Apply lambda transformation to series from df.\\n\\n        Parameters\\n        ----------\\n        df:\\n            series to transform\\n\\n        Returns\\n        -------\\n        :\\n            transformed series\\n        ', 'segment', 'Apply inverse transformation to the series from df.\\n\\n        Parameters\\n        ----------\\n        df:\\n            series to transform\\n\\n        Returns\\n        -------\\n        :\\n            transformed series\\n        ', 'target', 'feature'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['Find trend change points using ruptures models.\\n\\n    Parameters\\n    ----------\\n    ts:\\n        dataset to work with\\n    in_column:\\n        name of column to work with\\n    change_point_model:\\n        ruptures model to get trend change points\\n    model_predict_params:\\n        params for ``change_point_model`` predict method\\n\\n    Returns\\n    -------\\n    Dict[str, List[pd.Timestamp]]\\n        dictionary with list of trend change points for each segment\\n    '], 'from': [], 'import': []}\n",
      "{'FunctionDef': <9x9 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 9 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['2020-01-01', 'D', 'target', 'target', 'exog_1', 'exog_', 'D', 'Extract columns from feature level that are present in transformed_df but not present in initial_df.', 'feature', 'feature', 'Test that transform raises error in invalid mode.', 'non_existent', 'transform_constructor', 'Test that transform raises warning if inplace is set to True, but out_column is also given.', 'Transformation will be applied inplace', 'new_exog', 'transform_constructor', \"Test that transform in inplace mode doesn't generate new columns.\", 'transform_constructor', 'in_column', 'exog_1', 'exog_1', 'exog_2', 'Test that transform creates new columns according to out_column parameter.', 'new_exog', 'new_exog_', 'new_exog_', 'transform_constructor', 'in_column', 'exog_1', 'exog_1', 'exog_2', 'Test that transform generates names for the columns correctly.', 'transform_constructor', 'in_column', 'exog_1', 'exog_1', 'exog_2', 'Test that transform can process all columns using None value for in_column.', 'feature', 'transform_constructor', \"Test that transform don't mix columns between each other.\", 'transform_constructor', 'in_column', 'exog_1', 'exog_2', 'exog_3', 'exog_2', 'exog_1', 'exog_3', 'exog_3', 'exog_2', 'exog_1', 'mode', 'macro', 'per-segment'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <15x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 15 stored elements in Compressed Sparse Row format>, 'ClassDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Configurable SGD.', 'Get optimizer parameters.', 'lr', 'momentum', 'weight_decay', 'lr', 'momentum', 'weight_decay', 'Configurable RMSprop.', 'Get optimizer parameters.', 'lr', 'momentum', 'weight_decay', 'lr', 'momentum', 'weight_decay', 'Configurable Adam.', 'Get optimizer parameters.', 'lr', 'weight_decay', 'lr', 'weight_decay', 'Configurable AdamW.', 'Get optimizer parameters.', 'lr', 'weight_decay', 'lr', 'weight_decay', 'sgd', 'rmsprop', 'adam', 'adamw', 'sgd', 'Get optimizer parameters.', 'rho', 'adaptive', 'base_type', 'base_params', 'adaptive_bias_and_bn', 'adaptive_bias_and_bn', 'adaptive', 'base_type', 'base_params', 'rho', 'adaptive', 'Split each parameter groups into two parts with tensors of rank > 1 and tensors of rank <= 1.\\n        Apply extra parameters for those tensors with rank <= 1.', 'params', 'params', 'params', 'params', 'params', 'params', 'params', 'params'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <17x10 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 17 stored elements in Compressed Sparse Row format>, 'ClassDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['%Y-%m-%dT%H-%M-%S', 'Base logger for logging files.', '\\n        Log any event.\\n\\n        This class does nothing with it, use other loggers to do it.\\n\\n        Parameters\\n        ----------\\n        msg:\\n            Message or dict to log\\n        kwargs:\\n            Additional parameters for particular implementation\\n        ', 'Save table with given name.\\n\\n        Parameters\\n        ----------\\n        table:\\n            dataframe to save\\n        name:\\n            filename without extensions\\n        ', 'Save dictionary with given name.\\n\\n        Parameters\\n        ----------\\n        dictionary:\\n            dict to save\\n        name:\\n            filename without extensions\\n        ', 'Save config during init.\\n\\n        Parameters\\n        ----------\\n        config:\\n            a dictionary-like object for saving inputs to your job,\\n            like hyperparameters for a model or settings for a data preprocessing job\\n        ', 'config', \"Start experiment within current experiment, it is used for separate different folds during backtest.\\n\\n        Parameters\\n        ----------\\n        job_type:\\n            Specify the type of run, which is useful when you're grouping runs together\\n            into larger experiments using group.\\n        group:\\n            Specify a group to organize individual runs into a larger experiment.\\n        \", '\\n        Backtest metrics from one fold to logger.\\n\\n        Parameters\\n        ----------\\n        metrics:\\n            Dataframe with metrics from backtest fold\\n        forecast:\\n            Dataframe with forecast\\n        test:\\n            Dataframe with ground truth\\n\\n        Notes\\n        -----\\n        If some exception during saving is raised, then it becomes a warning.\\n        ', 'segment', 'metrics', 'forecast', 'test', 'metrics_summary', 'TSDataset', '\\n        Write metrics to logger.\\n\\n        Parameters\\n        ----------\\n        ts:\\n            TSDataset to with backtest data\\n        metrics_df:\\n            Dataframe produced with :py:meth:`etna.pipeline.Pipeline._get_backtest_metrics`\\n        forecast_df:\\n            Forecast from backtest\\n        fold_info_df:\\n            Fold information from backtest\\n\\n        Notes\\n        -----\\n        If some exception during saving is raised, then it becomes a warning.\\n        ', 'metrics', 'forecast', 'fold_info', 'metrics_summary', 'Logger for logging files into local folder.\\n\\n    It writes its result into folder like ``experiments_folder/2021-12-12T12-12-12``, where the second part\\n    is related to datetime of starting the experiment.\\n\\n    After every ``start_experiment`` it creates a new subfolder ``job_type/group``.\\n    If some of these two values are None then behaviour is little different and described in ``start_experiment`` method.\\n    ', '\\n        Create instance of LocalFileLogger.\\n\\n        Parameters\\n        ----------\\n        experiments_folder:\\n            path to folder to create experiment in\\n        config:\\n            a dictionary-like object for saving inputs to your job,\\n            like hyperparameters for a model or settings for a data preprocessing job\\n        gzip:\\n            indicator whether to use compression during saving tables or not\\n        ', \"Start experiment within current experiment, it is used for separate different folds during backtest.\\n\\n        As a result, within ``self.experiment_folder`` subfolder ``job_type/group`` is created.\\n\\n        * If ``job_type`` or ``group`` isn't set then only one-level subfolder is created.\\n\\n        * If none of ``job_type`` and ``group`` is set then experiment logs files into ``self.experiment_folder``.\\n\\n        Parameters\\n        ----------\\n        job_type:\\n            Specify the type of run, which is useful when you're grouping runs together\\n            into larger experiments using group.\\n        group:\\n            Specify a group to organize individual runs into a larger experiment.\\n        \", 'Save table with given name.\\n\\n        Parameters\\n        ----------\\n        table:\\n            dataframe to save\\n        name:\\n            filename without extensions\\n        ', 'You should start experiment before using log_backtest_run or log_backtest_metrics', '.csv.gz', 'gzip', '.csv', 'Save dictionary with given name.\\n\\n        Parameters\\n        ----------\\n        dictionary:\\n            dict to save\\n        name:\\n            filename without extensions\\n        ', 'You should start experiment before using log_backtest_run or log_backtest_metrics', '.json', 'w', 'Logger for logging files into S3 bucket.\\n\\n    This logger is very similar to :class:`~etna.loggers.file_logger.LocalFileLogger`,\\n    but works with S3 keys instead of paths at local file system.\\n    ', \"\\n        Create instance of S3FileLogger.\\n\\n        Parameters\\n        ----------\\n        bucket:\\n            name of the S3 bucket\\n        experiments_folder:\\n            path to folder to create experiment in\\n        config:\\n            a dictionary-like object for saving inputs to your job,\\n            like hyperparameters for a model or settings for a data preprocessing job\\n        gzip:\\n            indicator whether to use compression during saving tables or not\\n\\n\\n        Raises\\n        ------\\n        ValueError:\\n            if environment variable ``endpoint_url`` isn't set\\n        ValueError:\\n            if environment variable ``aws_access_key_id`` isn't set\\n        ValueError:\\n            if environment variable ``aws_secret_access_key`` isn't set\\n        ValueError:\\n            if bucket doesn't exist\\n        \", '/', 'Error occurred during checking bucket: ', 'endpoint_url', 'Environment variable `endpoint_url` should be specified for using this class', 'aws_access_key_id', 'Environment variable `aws_access_key_id` should be specified for using this class', 'aws_secret_access_key', 'Environment variable `aws_secret_access_key` should be specified for using this class', 's3', \"Start experiment within current experiment, it is used for separate different folds during backtest.\\n\\n        As a result, ``self.experiment_folder`` key is extended with ``job_type/group``.\\n\\n        * If ``job_type`` or ``group`` isn't set then key is extended with one value.\\n\\n        * If none of ``job_type`` and ``group`` is set then ``self.experiment_folder`` is not extended.\\n\\n        Parameters\\n        ----------\\n        job_type:\\n            Specify the type of run, which is useful when you're grouping runs together\\n            into larger experiments using group.\\n        group:\\n            Specify a group to organize individual runs into a larger experiment.\\n        \", '/', '/', '/', '/', 'Save table with given name.\\n\\n        Parameters\\n        ----------\\n        table:\\n            dataframe to save\\n        name:\\n            filename without extensions\\n        ', 'You should start experiment before using log_backtest_run or log_backtest_metrics', 'gzip', '.csv.gz', '.csv', '/', 'Save dictionary with given name.\\n\\n        Parameters\\n        ----------\\n        dictionary:\\n            dict to save\\n        name:\\n            filename without extensions\\n        ', 'You should start experiment before using log_backtest_run or log_backtest_metrics', 'w+', '.json', '/'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['Print configs for all training stages.', '-c', '--config', 'Path to training config.', '--hopt', 'Print config for hyper-parameter tuning.', 'store_true', 'hopt_params', '=== STAGE {} ===', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <8x8 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 8 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['\\nMIT LICENCE\\n\\nCopyright (c) 2016 Maximilian Christ, Blue Yonder GmbH\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated\\ndocumentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the\\nrights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit\\npersons to whom the Software is furnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the\\nSoftware.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE\\nWARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\\nCOPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\\nOTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\\n', '\\n    Calculate the feature significance of a binary feature to a binary target as a p-value.\\n    Use the two-sided univariate fisher test from :func:`~scipy.stats.fisher_exact` for this.\\n\\n    :param x: the binary feature vector\\n    :type x: pandas.Series\\n\\n    :param y: the binary target vector\\n    :type y: pandas.Series\\n\\n    :return: the p-value of the feature significance test. Lower p-values indicate a higher feature significance\\n    :rtype: float\\n\\n    :raise: ``ValueError`` if the target or the feature is not binary.\\n    ', 'two-sided', \"\\n    Calculate the feature significance of a real-valued feature to a binary target as a p-value.\\n    Use either the `Mann-Whitney U` or `Kolmogorov Smirnov` from  :func:`~scipy.stats.mannwhitneyu` or\\n    :func:`~scipy.stats.ks_2samp` for this.\\n\\n    :param x: the real-valued feature vector\\n    :type x: pandas.Series\\n\\n    :param y: the binary target vector\\n    :type y: pandas.Series\\n\\n    :param test: The significance test to be used. Either ``'mann'`` for the Mann-Whitney-U test\\n                 or ``'smir'`` for the Kolmogorov-Smirnov test\\n    :type test: str\\n\\n    :return: the p-value of the feature significance test. Lower p-values indicate a higher feature significance\\n    :rtype: float\\n\\n    :raise: ``ValueError`` if the target is not binary.\\n    \", 'mann', 'two-sided', 'smir', 'Please use a valid entry for test_for_binary_target_real_feature. ', \"Valid entries are 'mann' and 'smir'.\", '\\n    Calculate the feature significance of a binary feature to a real-valued target as a p-value.\\n    Use the `Kolmogorov-Smirnov` test from from :func:`~scipy.stats.ks_2samp` for this.\\n\\n    :param x: the binary feature vector\\n    :type x: pandas.Series\\n\\n    :param y: the real-valued target vector\\n    :type y: pandas.Series\\n\\n    :return: the p-value of the feature significance test. Lower p-values indicate a higher feature significance.\\n    :rtype: float\\n\\n    :raise: ``ValueError`` if the feature is not binary.\\n    ', \"\\n    Calculate the feature significance of a real-valued feature to a real-valued target as a p-value.\\n    Use `Kendall's tau` from :func:`~scipy.stats.kendalltau` for this.\\n\\n    :param x: the real-valued feature vector\\n    :type x: pandas.Series\\n\\n    :param y: the real-valued target vector\\n    :type y: pandas.Series\\n\\n    :return: the p-value of the feature significance test. Lower p-values indicate a higher feature significance.\\n    :rtype: float\\n    \", 'asymptotic', '\\n    Helper function to check if both x and y are pandas.Series. If not, raises a ``TypeError``.\\n\\n    :param x: the first object to check.\\n    :type x: Any\\n\\n    :param y: the second object to check.\\n    :type y: Any\\n\\n    :return: None\\n    :rtype: None\\n\\n    :raise: ``TypeError`` if one of the objects is not a pandas.Series.\\n    ', 'x should be a pandas Series', 'y should be a pandas Series', 'X and y need to have the same index!', '\\n    Helper function to check if a target column is binary.\\n    Checks if only the values true and false (or 0 and 1) are present in the values.\\n\\n    :param y: the values to check for.\\n    :type y: pandas.Series or numpy.array\\n\\n    :return: None\\n    :rtype: None\\n\\n    :raises: ``ValueError`` if the values are not binary.\\n    ', 'Target is not binary!', 'The binary target should have values 1 and 0 (or True and False). Instead found', '\\n    Helper function to check if a feature column is binary.\\n    Checks if only the values true and false (or 0 and 1) are present in the values.\\n\\n    :param y: the values to check for.\\n    :type y: pandas.Series or numpy.array\\n\\n    :return: None\\n    :rtype: None\\n\\n    :raises: ``ValueError`` if the values are not binary.\\n    ', '[target_binary_feature_binary_test] Feature is not binary!', 'A binary feature should have only values 1 and 0 (incl. True and False). Instead found ', \" in feature ''\", \"''.\", '\\n    Helper function to check if target or feature contains NaNs.\\n    :param x: A feature\\n    :type x: pandas.Series\\n    :param y: The target\\n    :type y: pandas.Series\\n    :raises: `ValueError` if target or feature contains NaNs.\\n    ', 'Feature {} contains NaN values', 'Target contains NaN values'], 'from': [], 'import': []}\n",
      "{'FunctionDef': [], 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['\\nMIT LICENCE\\n\\nCopyright (c) 2016 Maximilian Christ, Blue Yonder GmbH\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated\\ndocumentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the\\nrights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit\\npersons to whom the Software is furnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the\\nSoftware.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE\\nWARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\\nCOPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\\nOTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\\n', 'cumulative', 'profile.txt', 'fisher', 'mann', 'mann', 'kendall', 'logging'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': [], 'from': [], 'import': []}\n",
      "{'FunctionDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['BinsegTrendTransform uses :py:class:`ruptures.detection.Binseg` model as a change point detection model.\\n\\n    Warning\\n    -------\\n    This transform can suffer from look-ahead bias. For transforming data at some timestamp\\n    it uses information from the whole train part.\\n    ', 'ar', 'Init BinsegTrendTransform.\\n\\n        Parameters\\n        ----------\\n        in_column:\\n            name of column to apply transform to\\n        detrend_model:\\n            model to get trend in data\\n        model:\\n            binseg segment model, [\"l1\", \"l2\", \"rbf\",...]. Not used if \\'custom_cost\\' is not None.\\n        custom_cost:\\n            binseg custom cost function\\n        min_size:\\n            minimum segment length necessary to decide it is a stable trend segment\\n        jump:\\n            jump value can speed up computations: if ``jump==k``,\\n            the algo will use every k-th value for change points search.\\n        n_bkps:\\n            number of change points to find\\n        pen:\\n            penalty value (>0)\\n        epsilon:\\n            reconstruction budget (>0)\\n        '], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Filters features in each segment of the dataframe.', 'Create instance of FilterFeaturesTransform.\\n\\n        Parameters\\n        ----------\\n        include:\\n            list of columns to pass through filter\\n        exclude:\\n            list of columns to not pass through\\n        return_features:\\n            indicates whether to return features or not.\\n        Raises\\n        ------\\n        ValueError:\\n            if both options set or non of them\\n        ', 'There should be exactly one option set: include or exclude', 'Fit method does nothing and is kept for compatibility.\\n\\n        Parameters\\n        ----------\\n        df:\\n            dataframe with data.\\n\\n        Returns\\n        -------\\n        result: FilterFeaturesTransform\\n        ', 'FilterFeaturesTransform', 'Filter features according to include/exclude parameters.\\n\\n        Parameters\\n        ----------\\n        df:\\n            dataframe with data to transform.\\n\\n        Returns\\n        -------\\n        result: pd.Dataframe\\n            transformed dataframe\\n        ', 'feature', 'Features ', ' are not present in the dataset.', 'Features ', ' are not present in the dataset.', 'feature', 'Apply inverse transform to the data.\\n\\n        Parameters\\n        ----------\\n        df:\\n            dataframe to apply inverse transformation\\n\\n        Returns\\n        -------\\n        result: pd.DataFrame\\n            dataframe before transformation\\n        '], 'from': [], 'import': []}\n",
      "{'FunctionDef': <7x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Transform that selects features according to tree-based models feature importance.\\n\\n    Notes\\n    -----\\n    Transform works with any type of features, however most of the models works only with regressors.\\n    Therefore, it is recommended to pass the regressors into the feature selection transforms.\\n    ', 'all', 'all', '\\n        Init TreeFeatureSelectionTransform.\\n\\n        Parameters\\n        ----------\\n        model:\\n            model to make selection, it should have ``feature_importances_`` property\\n            (e.g. all tree-based regressors in sklearn)\\n        top_k:\\n            num of features to select; if there are not enough features, then all will be selected\\n        features_to_use:\\n            columns of the dataset to select from; if \"all\" value is given, all columns are used\\n        return_features:\\n            indicates whether to return features or not.\\n        ', 'Parameter top_k should be positive integer', 'Get train data for model.', 'target', 'Get weights for features based on model feature importances.', '\\n        Fit the model and remember features to select.\\n\\n        Parameters\\n        ----------\\n        df:\\n            dataframe with all segments data\\n\\n        Returns\\n        -------\\n        result: TreeFeatureSelectionTransform\\n            instance after fitting\\n        ', \"It is not possible to select features if there aren't any\", 'TreeFeatureSelectionTransform', 'Transform that selects features according to MRMR variable selection method adapted to the timeseries case.\\n\\n    Notes\\n    -----\\n    Transform works with any type of features, however most of the models works only with regressors.\\n    Therefore, it is recommended to pass the regressors into the feature selection transforms.\\n    ', 'all', 'all', '\\n        Init MRMRFeatureSelectionTransform.\\n\\n        Parameters\\n        ----------\\n        relevance_table:\\n            method to calculate relevance table\\n        top_k:\\n            num of features to select; if there are not enough features, then all will be selected\\n        features_to_use:\\n            columns of the dataset to select from\\n            if \"all\" value is given, all columns are used\\n        relevance_aggregation_mode:\\n            the method for relevance values per-segment aggregation\\n        redundancy_aggregation_mode:\\n            the method for redundancy values per-segment aggregation\\n        atol:\\n            the absolute tolerance to compare the float values\\n        return_features:\\n            indicates whether to return features or not.\\n        ', 'Parameter top_k should be positive integer', '\\n        Fit the method and remember features to select.\\n\\n        Parameters\\n        ----------\\n        df:\\n            dataframe with all segments data\\n\\n        Returns\\n        -------\\n        result: MRMRFeatureSelectionTransform\\n            instance after fitting\\n        ', 'target', 'MRMRFeatureSelectionTransform'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <18x11 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 18 stored elements in Compressed Sparse Row format>, 'ClassDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Pass input embeddings to the output.', 'Get embedder parameters.', 'head_normalize', 'head_normalize', 'Pretrained model input image size.', 'Input size is unavailable for identity embedder.', 'Input channels are unavailable for identity embedder.', 'Expected embeddings with dimension {}, got {}', 'Model to map input images to embeddings.\\n\\n    Embedder computation pipeline:\\n    1. Stem (CNN model).\\n    2. Pooling (CNN output spatial aggregation method).\\n    3. Head (mapping from CNN output to embedding).\\n    3*. Extra head for uncertainty prediction.\\n    4. Normalizer (batchnorm of embeddings for some models).\\n    ', 'resnet18', 'resnet34', 'resnet50', 'resnet101', 'wide_resnet16_8', 'wide_resnet50_2', 'wide_resnet101_2', 'wide_resnet28_10', 'efficientnet_v2_s', 'efficientnet_v2_m', 'efficientnet_v2_l', 'pyramidnet272', 'bninception', 'bninception_simple', 'se_resnet50', 'cgd_se_resnet50', 'vgg_m3', 'vgg19', 'resnet18', 'resnet34', 'resnet50', 'resnet101', 'wide_resnet16_8', 'wide_resnet50_2', 'wide_resnet101_2', 'wide_resnet28_10', 'efficientnet_v2_s', 'efficientnet_v2_m', 'efficientnet_v2_l', 'cifar10', 'bninception', 'bn_inception_simple', 'se_resnet50', 'cgd_se_resnet50', 'M3', 'vgg19', 'avg', 'max', 'multi', 'resnet50', 'avg', 'Get embedder parameters.\\n\\n        Args:\\n            model_type: One of \"resnet18\", \"resnet34\", \"resnet50\", \"resnet101\", \"bninception\", \"se_resnet50\" and \"cgd_se_resnet50\".\\n            pretrained: Whether to use ImageNet-pretrained model or start from scratch.\\n            freeze_bn: Whether to freez batch normalization or not.\\n            pooling_type: Type of pooling (\"avg\", \"max\" or \"multi\").\\n            pooling_params: Parameters of the pooling.\\n            dropout: Head dropout probability during training.\\n            head_batchnorm: Whether to apply 1-D batchnorm to CNN output or not.\\n            head_normalize: Whether to apply provided normalizer or not.\\n            extra_head_dim: Use additional head (usually for distribution concentration estimation).\\n                Output embedding is concatenation of the main and extra heads.\\n            extra_head_layers: The number of FC layers in extra head.\\n            freeze_stem: Freeze stem during training.\\n            freeze_head: Freeze main head during training.\\n            freeze_extra_head: Freeze extra head during training.\\n            freeze_normalizer: Freeze normalizer during training.\\n            output_scale: Output embedding multiplier (used in vMF-loss).\\n            disable_head: Whether to disable head layers.\\n        ', 'model_type', 'pretrained', 'freeze_bn', 'pooling_type', 'pooling_params', 'dropout', 'head_batchnorm', 'head_normalize', 'extra_head_dim', 'extra_head_layers', 'freeze_stem', 'freeze_head', 'freeze_extra_head', 'freeze_normalizer', 'output_scale', 'disable_head', 'model_type', 'pretrained', 'pooling_type', 'pooling_params', 'channels_multiplier', 'disable_head', 'extra_head_dim', 'Expected number of output dimensions (', \") doesn't match the actual number (\", ') when `disable_head=True`.', 'extra_head_dim', 'extra_head_dim', 'head_normalize', 'output_scale', 'freeze_bn', 'freeze_stem', 'freeze_head', 'freeze_extra_head', 'freeze_normalizer', 'Pretrained model input image size.', 'Pretrained model input normalization mean.', 'Pretrained model input normalization STD.', '_output_scale', 'Set main head output scale.', '_output_scale', '_output_scale', 'freeze_bn', 'freeze_stem', 'freeze_head', 'freeze_extra_head', 'freeze_normalizer', 'head_batchnorm', 'dropout', 'dropout', 'disable_head', 'extra_head_layers'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['seed-{}', 'tensorboard', 'tensorboard', 'wandb', '-seed-{}', ':', 'seed', 'config.yaml', '--config', '--train-root', '--logger', 'seed', '--checkpoint', '{seed}', 'cval', 'train', '_std', 'Train and eval multiple models using cross validation and multiple seeds.', 'num_evaluation_seeds', 'metrics.yaml', 'num_seeds', 'metrics.yaml'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['ni,im->nm'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <7x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7 stored elements in Compressed Sparse Row format>, 'ClassDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['timestamp', \"Can't determine frequency of a given dataframe\", 'target', 'timestamp', 'Model is not fitted! Fit the model before calling predict method!', 'timestamp', \"It is not possible to make in-sample predictions with BATS/TBATS model! In-sample predictions aren't supported by current implementation.\", 'timestamp', 'target', 'target_', '.4g', 'lower_bound', 'target_', '.4g', 'upper_bound', 'target', \"Method predict isn't currently implemented!\", 'Get internal :py:class:`tbats.tbats.Model` model that was fitted inside etna class.\\n\\n        Returns\\n        -------\\n        :\\n           Internal model\\n        ', 'Class for holding segment interval BATS model.', 'spawn', \"Create BATSModel with given parameters.\\n\\n        Parameters\\n        ----------\\n        use_box_cox: bool or None, optional (default=None)\\n            If Box-Cox transformation of original series should be applied.\\n            When None both cases shall be considered and better is selected by AIC.\\n        box_cox_bounds: tuple, shape=(2,), optional (default=(0, 1))\\n            Minimal and maximal Box-Cox parameter values.\\n        use_trend: bool or None, optional (default=None)\\n            Indicates whether to include a trend or not.\\n            When None both cases shall be considered and better is selected by AIC.\\n        use_damped_trend: bool or None, optional (default=None)\\n            Indicates whether to include a damping parameter in the trend or not.\\n            Applies only when trend is used.\\n            When None both cases shall be considered and better is selected by AIC.\\n        seasonal_periods: iterable or array-like of int values, optional (default=None)\\n            Length of each of the periods (amount of observations in each period).\\n            BATS accepts only int values here.\\n            When None or empty array, non-seasonal model shall be fitted.\\n        use_arma_errors: bool, optional (default=True)\\n            When True BATS will try to improve the model by modelling residuals with ARMA.\\n            Best model will be selected by AIC.\\n            If False, ARMA residuals modeling will not be considered.\\n        show_warnings: bool, optional (default=True)\\n            If warnings should be shown or not.\\n            Also see Model.warnings variable that contains all model related warnings.\\n        n_jobs: int, optional (default=None)\\n            How many jobs to run in parallel when fitting BATS model.\\n            When not provided BATS shall try to utilize all available cpu cores.\\n        multiprocessing_start_method: str, optional (default='spawn')\\n            How threads should be started.\\n            See https://docs.python.org/3/library/multiprocessing.html#contexts-and-start-methods\\n        context: abstract.ContextInterface, optional (default=None)\\n            For advanced users only. Provide this to override default behaviors\\n        \", 'Class for holding segment interval TBATS model.', 'spawn', \"Create TBATSModel with given parameters.\\n\\n        Parameters\\n        ----------\\n        use_box_cox: bool or None, optional (default=None)\\n            If Box-Cox transformation of original series should be applied.\\n            When None both cases shall be considered and better is selected by AIC.\\n        box_cox_bounds: tuple, shape=(2,), optional (default=(0, 1))\\n            Minimal and maximal Box-Cox parameter values.\\n        use_trend: bool or None, optional (default=None)\\n            Indicates whether to include a trend or not.\\n            When None both cases shall be considered and better is selected by AIC.\\n        use_damped_trend: bool or None, optional (default=None)\\n            Indicates whether to include a damping parameter in the trend or not.\\n            Applies only when trend is used.\\n            When None both cases shall be considered and better is selected by AIC.\\n        seasonal_periods: iterable or array-like of floats, optional (default=None)\\n            Length of each of the periods (amount of observations in each period).\\n            TBATS accepts int and float values here.\\n            When None or empty array, non-seasonal model shall be fitted.\\n        use_arma_errors: bool, optional (default=True)\\n            When True BATS will try to improve the model by modelling residuals with ARMA.\\n            Best model will be selected by AIC.\\n            If False, ARMA residuals modeling will not be considered.\\n        show_warnings: bool, optional (default=True)\\n            If warnings should be shown or not.\\n            Also see Model.warnings variable that contains all model related warnings.\\n        n_jobs: int, optional (default=None)\\n            How many jobs to run in parallel when fitting BATS model.\\n            When not provided BATS shall try to utilize all available cpu cores.\\n        multiprocessing_start_method: str, optional (default='spawn')\\n            How threads should be started.\\n            See https://docs.python.org/3/library/multiprocessing.html#contexts-and-start-methods\\n        context: abstract.ContextInterface, optional (default=None)\\n            For advanced users only. Provide this to override default behaviors\\n        \"], 'from': [], 'import': []}\n",
      "{'FunctionDef': <23x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 23 stored elements in Compressed Sparse Row format>, 'ClassDef': <10x10 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 10 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['WindowStatisticsTransform handles computation of statistical features on windows.', \"Init WindowStatisticsTransform.\\n\\n        Parameters\\n        ----------\\n        in_column: str\\n            name of processed column\\n        out_column: str\\n            result column name\\n        window: int\\n            size of window to aggregate, if -1 is set all history is used\\n        seasonality: int\\n            seasonality of lags to compute window's aggregation with\\n        min_periods: int\\n            min number of targets in window to compute aggregation;\\n            if there is less than ``min_periods`` number of targets return None\\n        fillna: float\\n            value to fill results NaNs with\\n        \", 'Fits transform.', 'WindowStatisticsTransform', 'Aggregate targets from given series.', \"Compute feature's value.\\n\\n        Parameters\\n        ----------\\n        df: pd.DataFrame\\n            dataframe to generate features for\\n\\n        Returns\\n        -------\\n        result: pd.DataFrame\\n            dataframe with results\\n        \", 'segment', 'MeanTransform computes average value for given window.\\n\\n    .. math::\\n       MeanTransform(x_t) = \\\\sum_{i=1}^{window}{x_{t - i}\\\\cdot\\\\alpha^{i - 1}}\\n    ', \"Init MeanTransform.\\n\\n        Parameters\\n        ----------\\n        in_column: str\\n            name of processed column\\n        window: int\\n            size of window to aggregate\\n        seasonality: int\\n            seasonality of lags to compute window's aggregation with\\n        alpha: float\\n            autoregressive coefficient\\n        min_periods: int\\n            min number of targets in window to compute aggregation;\\n            if there is less than ``min_periods`` number of targets return None\\n        fillna: float\\n            value to fill results NaNs with\\n        out_column: str, optional\\n            result column name. If not given use ``self.__repr__()``\\n        \", \"Compute feature's value.\\n\\n        Parameters\\n        ----------\\n        df: pd.DataFrame\\n            dataframe to generate features for\\n\\n        Returns\\n        -------\\n        result: pd.DataFrame\\n            dataframe with results\\n        \", 'Compute weighted average for window series.', 'StdTransform computes std value for given window.\\n\\n    Notes\\n    -----\\n    Note that ``pd.Series([1]).std()`` is ``np.nan``.\\n    ', \"Init StdTransform.\\n\\n        Parameters\\n        ----------\\n        in_column: str\\n            name of processed column\\n        window: int\\n            size of window to aggregate\\n        seasonality: int\\n            seasonality of lags to compute window's aggregation with\\n        min_periods: int\\n            min number of targets in window to compute aggregation;\\n            if there is less than ``min_periods`` number of targets return None\\n        fillna: float\\n            value to fill results NaNs with\\n        out_column: str, optional\\n            result column name. If not given use ``self.__repr__()``\\n        ddof:\\n            delta degrees of freedom; the divisor used in calculations is N - ddof, where N is the number of elements\\n        \", 'Compute std over the series.', 'QuantileTransform computes quantile value for given window.', \"Init QuantileTransform.\\n\\n        Parameters\\n        ----------\\n        in_column: str\\n            name of processed column\\n        quantile: float\\n            quantile to calculate\\n        window: int\\n            size of window to aggregate\\n        seasonality: int\\n            seasonality of lags to compute window's aggregation with\\n        min_periods: int\\n            min number of targets in window to compute aggregation;\\n            if there is less than ``min_periods`` number of targets return None\\n        fillna: float\\n            value to fill results NaNs with\\n        out_column: str, optional\\n            result column name. If not given use ``self.__repr__()``\\n        \", 'Compute quantile over the series.', 'MinTransform computes min value for given window.', \"Init MinTransform.\\n\\n        Parameters\\n        ----------\\n        in_column: str\\n            name of processed column\\n        window: int\\n            size of window to aggregate\\n        seasonality: int\\n            seasonality of lags to compute window's aggregation with\\n        min_periods: int\\n            min number of targets in window to compute aggregation;\\n            if there is less than ``min_periods`` number of targets return None\\n        fillna: float\\n            value to fill results NaNs with\\n        out_column: str, optional\\n            result column name. If not given use ``self.__repr__()``\\n        \", 'Compute min over the series.', 'MaxTransform computes max value for given window.', \"Init MaxTransform.\\n\\n        Parameters\\n        ----------\\n        in_column: str\\n            name of processed column\\n        window: int\\n            size of window to aggregate\\n        seasonality: int\\n            seasonality of lags to compute window's aggregation with\\n        min_periods: int\\n            min number of targets in window to compute aggregation;\\n            if there is less than ``min_periods`` number of targets return None\\n        fillna: float\\n            value to fill results NaNs with\\n        out_column: str, optional\\n            result column name. If not given use ``self.__repr__()``\\n        \", 'Compute max over the series.', 'MedianTransform computes median value for given window.', \"Init MedianTransform.\\n\\n        Parameters\\n        ----------\\n        in_column: str\\n            name of processed column\\n        window: int\\n            size of window to aggregate\\n        seasonality: int\\n            seasonality of lags to compute window's aggregation with\\n        min_periods: int\\n            min number of targets in window to compute aggregation;\\n            if there is less than ``min_periods`` number of targets return None\\n        fillna: float\\n            value to fill results NaNs with\\n        out_column: str, optional\\n            result column name. If not given use ``self.__repr__()``\\n        \", 'Compute median over the series.', 'MADTransform computes Mean Absolute Deviation over the window.', \"Init MADTransform.\\n\\n        Parameters\\n        ----------\\n        in_column: str\\n            name of processed column\\n        window: int\\n            size of window to aggregate\\n        seasonality: int\\n            seasonality of lags to compute window's aggregation with\\n        min_periods: int\\n            min number of targets in window to compute aggregation;\\n            if there is less than ``min_periods`` number of targets return None\\n        fillna: float\\n            value to fill results NaNs with\\n        out_column: str, optional\\n            result column name. If not given use ``self.__repr__()``\\n        \", 'Compute MAD over the series.', 'MinMaxDifferenceTransform computes difference between max and min values for given window.', \"Init MaxTransform.\\n\\n        Parameters\\n        ----------\\n        in_column: str\\n            name of processed column\\n        window: int\\n            size of window to aggregate\\n        seasonality: int\\n            seasonality of lags to compute window's aggregation with\\n        min_periods: int\\n            min number of targets in window to compute aggregation;\\n            if there is less than ``min_periods`` number of targets return None\\n        fillna: float\\n            value to fill results NaNs with\\n        out_column: str, optional\\n            result column name. If not given use ``self.__repr__()``\\n        \", 'Compute max over the series.', 'SumTransform computes sum of values over given window.', \"Init SumTransform.\\n\\n        Parameters\\n        ----------\\n        in_column:\\n            name of processed column\\n        window:\\n            size of window to aggregate, if window == -1 compute rolling sum all over the given series\\n        seasonality:\\n            seasonality of lags to compute window's aggregation with\\n        min_periods:\\n            min number of targets in window to compute aggregation;\\n            if there is less than ``min_periods`` number of targets return None\\n        fillna:\\n            value to fill results NaNs with\\n        out_column:\\n            result column name. If not given use ``self.__repr__()``\\n        \", 'Compute sum over the series.', 'MedianTransform', 'MaxTransform', 'MinTransform', 'QuantileTransform', 'StdTransform', 'MeanTransform', 'WindowStatisticsTransform', 'MADTransform', 'MinMaxDifferenceTransform', 'SumTransform'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <21x16 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 21 stored elements in Compressed Sparse Row format>, 'ClassDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Base class for a member of Gale-Shapley matching.', 'Init BaseGaleShapley.\\n\\n        Parameters\\n        ----------\\n        name:\\n            name of object\\n        ranked_candidates:\\n            list of preferences for the object ranked descending by importance\\n        ', 'Create match with object name.\\n\\n        Parameters\\n        ----------\\n        name:\\n            name of candidate to match\\n        ', 'Break tmp current.', 'Class for segment member of Gale-Shapley matching.', 'Init SegmentGaleShapley.\\n\\n        Parameters\\n        ----------\\n        name:\\n            name of segment\\n        ranked_candidates:\\n            list of features sorted descending by importance\\n        ', 'Create match with given feature.\\n\\n        Parameters\\n        ----------\\n        name:\\n            name of feature to match\\n        ', 'Get name of the next feature to try.\\n\\n        Returns\\n        -------\\n        name: str\\n            name of feature\\n        ', 'Class for feature member of Gale-Shapley matching.', 'Check if given segment is better than current match according to preference list.\\n\\n        Parameters\\n        ----------\\n        segment:\\n            segment to check\\n\\n        Returns\\n        -------\\n        is_better: bool\\n            returns True if given segment is a better candidate than current match.\\n        ', 'Class for handling Gale-Shapley matching algo.', 'Init GaleShapleyMatcher.\\n\\n        Parameters\\n        ----------\\n        segments:\\n            list of segments to build matches\\n        features:\\n            list of features to build matches\\n        ', 'Build match between segment and feature.\\n\\n        Parameters\\n        ----------\\n        segment:\\n            segment to match\\n        feature:\\n            feature to match\\n        ', 'Break match between segment and feature.\\n\\n        Parameters\\n        ----------\\n        segment:\\n            segment to break match\\n        feature:\\n            feature to break match\\n        ', '\\n        Run iteration of Gale-Shapley matching for given available_segments.\\n\\n        Parameters\\n        ----------\\n        available_segments:\\n            list of segments that have no match at this iteration\\n\\n        Returns\\n        -------\\n        success: bool\\n            True if there is at least one match attempt at the iteration\\n\\n        Notes\\n        -----\\n        Success code is necessary because in ETNA usage we can not guarantee that number of features will be\\n        big enough to build matches with all the segments. In case ``n_features < n_segments`` some segments always stay\\n        available that can cause infinite while loop in ``__call__``.\\n        ', 'Get list of available segments.', 'Run matching.\\n\\n        Returns\\n        -------\\n        matching: Dict[str, str]\\n            matching dict of segment x feature\\n        ', 'GaleShapleyFeatureSelectionTransform provides feature filtering with Gale-Shapley matching algo according to relevance table.\\n\\n\\n    Notes\\n    -----\\n    Transform works with any type of features, however most of the models works only with regressors.\\n    Therefore, it is recommended to pass the regressors into the feature selection transforms.\\n    ', 'all', 'all', 'Init GaleShapleyFeatureSelectionTransform.\\n\\n        Parameters\\n        ----------\\n        relevance_table:\\n            class to build relevance table\\n        top_k:\\n            number of features that should be selected from all the given ones\\n        features_to_use:\\n            columns of the dataset to select from\\n            if \"all\" value is given, all columns are used\\n        use_rank:\\n            if True, use rank in relevance table computation\\n        return_features:\\n            indicates whether to return features or not.\\n        ', 'Compute relevance table with given data.', 'target', 'Get ranked lists of candidates from table of relevance.', 'Get number of necessary Gale-Shapley algo iterations.', 'Given top_k=', ' is bigger than n_features=', '. Transform will not filter features.', 'Given top_k=', ' is less than n_segments. Algo will filter data without Gale-Shapley run.', 'Build matching for all the segments.\\n\\n        Parameters\\n        ----------\\n        segment_features_ranking:\\n            dict of relevance segment x sorted features\\n\\n        Returns\\n        -------\\n        matching dict: Dict[str, str]\\n            dict of segment x feature\\n        ', 'Delete chosen features from candidates ranked lists.', 'Choose n features from given ones according to relevance_matrix.', 'Fit Gale-Shapley algo and find a pool of ``top_k`` features.\\n\\n        Parameters\\n        ----------\\n        df:\\n            dataframe to fit algo\\n        ', 'GaleShapleyFeatureSelectionTransform'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <8x8 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 8 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['timestamp', '2021-06-01', '2021-07-01', '1d', 'timestamp', '2021-06-01', '2021-07-01', '1d', 'segment', 'Moscow', 'target', 'exog', 'segment', 'Omsk', 'target', 'exog', 'timestamp', '2021-06-01', '2021-07-01', '1d', 'timestamp', '2021-06-01', '2021-07-01', '1d', 'segment', 'Moscow', 'target', 'exog', 'segment', 'Omsk', 'target', 'exog', 'Check BoxCoxPreprocessing behavior in case of negative-value series.', 'mode', 'macro', 'per-segment', 'Check the value of transform result for all columns.', 'feature', 'preprocessing_class,method', 'box-cox', 'yeo-johnson', 'Check the value of transform result.', 'target', 'target', 'target', 'feature', 'target', 'feature', 'target', 'preprocessing_class,method', 'box-cox', 'yeo-johnson', 'Check that inverse_transform rolls back transform result for all columns.', 'feature', 'preprocessing_class', 'mode', 'macro', 'per-segment', 'Check that inverse_transform rolls back transform result for one column.', 'target', 'preprocessing_class', 'mode', 'macro', 'per-segment', 'target', 'target', 'preprocessing_class', 'mode', 'macro', 'per-segment'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <13x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 13 stored elements in Compressed Sparse Row format>, 'ClassDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Configurable LR scheduler.', 'Get scheduler parameters.', 'step', 'gamma', 'step', 'gamma', 'Configurable LR scheduler.', 'Get scheduler parameters.', 'milestones', 'gamma', 'milestones', 'gamma', 'Configurable LR scheduler.', 'Get scheduler parameters.', 'patience', 'factor', 'min', 'max', 'patience', 'factor', 'Configurable LR scheduler.', 'Get scheduler parameters.', 'lr_at_last_epoch', 'lr', 'lr_at_last_epoch', 'Add warmup steps to LR scheduler.', 'warmup_epochs', 'warmup_epochs'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <13x13 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 13 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['segment', 'target_0.025', 'target_0.975', 'target', 'target_0.975', 'target_0.025', 'method_name', 'forecast', 'predict', 'target_0.025', 'target_0.975', 'target', 'target_0.975', 'target', 'target', 'target_0.025', 'target_0.975', 'target_0.025', 'Test that AutoARIMA raise error when calling prediction without being fit.', 'model is not fitted!', 'method_name', 'forecast', 'predict', 'Check that get_model method throws an error if per-segment model is not fitted yet.', 'Can not get the dict with base models, the model is not fitted!', 'Check that get_model method returns dict of objects of AutoARIMA class.', 'Check that AutoARIMA work with 1 point forecast.'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <6x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['minute_in_hour_number', 'fifteen_minutes_in_hour_number', 'hour_number', 'half_hour_number', 'half_day_number', 'one_third_day_number', 'Generate dataset for TimeFlags feature.\\n\\n    Returns\\n    -------\\n    dataset with timestamp column and columns true_minute_in_hour_number, true_fifteen_minutes_in_hour_number,\\n    true_half_hour_number, true_hour_number, true_half_day_number, true_one_third_day_number that contain\\n    true answers for corresponding features\\n    ', 'timestamp', '2020-06-01', '2021-06-01', '5 min', 'timeflag', '_minute_in_hour_number', 'timestamp', '_fifteen_minutes_in_hour_number', '_minute_in_hour_number', '_half_hour_number', '_minute_in_hour_number', '_hour_number', 'timestamp', '_half_day_number', '_hour_number', '_one_third_day_number', '_hour_number', 'segment', 'segment_', 'target', 'timestamp', 'segment', 'segment', 'feature', '\\n    Generate dataset without dateflags\\n    ', 'timestamp', '2020-06-01', '2021-06-01', '5 min', 'segment', 'segment_', 'target', 'timestamp', 'segment', 'segment', 'feature', \"Test that transform can't be created with no features to generate.\", 'Test that transform generates correct column names using out_column parameter.', 'segment', 'timeflag', 'feature', 'segment', 'segment', '_', 'target', 'category', 'true_params', 'minute_in_hour_number', 'fifteen_minutes_in_hour_number', 'hour_number', 'half_hour_number', 'half_day_number', 'one_third_day_number', 'minute_in_hour_number', 'fifteen_minutes_in_hour_number', 'hour_number', 'half_hour_number', 'half_day_number', 'one_third_day_number', 'Test that transform generates correct column names without setting out_column parameter.', 'segment', 'feature', 'segment', 'segment', 'feature', 'target', 'category', 'feature', 'target', 'true_params', 'minute_in_hour_number', 'fifteen_minutes_in_hour_number', 'hour_number', 'half_hour_number', 'half_day_number', 'one_third_day_number', 'minute_in_hour_number', 'fifteen_minutes_in_hour_number', 'hour_number', 'half_hour_number', 'half_day_number', 'one_third_day_number', 'Test that transform generates correct values.', 'timeflag', 'segment', 'segment', '_', 'target', 'true_params', 'minute_in_hour_number', 'fifteen_minutes_in_hour_number', 'hour_number', 'half_hour_number', 'half_day_number', 'one_third_day_number'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <10x10 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 10 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Test split is inverse of join.', 'dim', 'covariance', 'max_logivar', 'spherical', 'Test batch norm.', 'dim', 'covariance', 'max_logivar', 'spherical', 'Test KL-divergence with standard in simple cases.', 'spherical', 'diagonal', 'dim', 'covariance', 'spherical', 'Test density estimation in simple cases.', 'dim', 'covariance', 'spherical', 'Test integral of GMM is equal to 1.', 'dim', 'covariance', 'diagonal', 'Test broadcasting.', 'dim', 'Test MLS for GMM comparison with identical GMM.', 'dim', 'covariance', 'diagonal', 'Test MLS for GMM comparison with different GMMs.', 'dim', 'covariance', 'max_logivar', 'diagonal', 'dim', 'diagonal', 'spherical', 'dim', 'covariance', 'Test MLS is equal to estimation by sampling.', 'dim', 'covariance', 'diagonal', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <6x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Optimization pipeline.', 'sgd', 'rmsprop', 'adam', 'adamw', 'sam', 'step', 'multistep', 'plateau', 'exponential', 'exponential', 'sgd', 'train', 'loss', 'Get trainer parameters.\\n\\n        Args:\\n            num_epochs: Number of training epochs.\\n            optimizer_type: One of `sgd` and `adam`.\\n            optimizer_params: Parameters of optimizer class.\\n            classifier_optimizer_params: Parameters of classifier optimizer. If not provided, same as optimizer_params.\\n            gradient_clipping: Size of gradient clipping.\\n            use_gradient_normalizer: Normalize gradient using moving norm.\\n            gradient_normalizer_params: Parameters of gradient normalizer.\\n            scheduler_type: One of `None` and `multistep`.\\n            scheduler_params: Parameters of :class:`LRScheduler`.\\n            variance_scheduler_type: One of `None` and `linear`.\\n            variance_scheduler_params: Parameters of the classifier variance scheduler.\\n            selection_dataset: Dataset used for checkpoint selection and early stopping.\\n            selection_metric: Metric used for checkpoint selection and early stopping.\\n            selection_minimize: Whether to minimize metric or maximize.\\n            early_stop_patience: Number of epochs without improvement for early stopping.\\n              Use None to disable early stopping.\\n            early_stop_epsilon: Improvement threshold for early stopping.\\n\\n        ', 'num_epochs', 'optimizer_type', 'optimizer_params', 'classifier_optimizer_params', 'gradient_clipping', 'use_gradient_normalizer', 'gradient_normalizer_params', 'scheduler_type', 'scheduler_params', 'variance_scheduler_type', 'variance_scheduler_params', 'warmup_epochs', 'selection_dataset', 'selection_metric', 'selection_minimize', 'early_stop_patience', 'early_stop_epsilon', 'use_gradient_normalizer', 'gradient_clipping', 'Gradient clipping and gradient normalization are mutually exclusive.', 'gradient_normalizer_params', 'num_epochs', 'optimizer_type', 'params', 'params', 'classifier_optimizer_params', 'params', 'classifier_optimizer_params', 'params', 'optimizer_params', 'scheduler_type', 'scheduler_type', 'selection_minimize', 'scheduler_params', 'warmup_epochs', 'warmup_epochs', 'gradient_clipping', 'grad_clip_fn', 'grad_clip_params', 'max_norm', 'error_if_nonfinite', 'gradient_clipping', 'use_gradient_normalizer', 'grad_clip_fn', 'grad_clip_params', 'optimizer', 'checkpoint', 'model', 'selection_dataset', 'selection_metric', 'selection_minimize', 'scheduler_type', 'scheduler', 'selection_dataset', 'selection_metric', 'variance_scheduler_type', 'variance_scheduler', 'variance_scheduler_type', 'num_epochs', 'variance_scheduler_params', 'early_stop_patience', 'early_stop', 'early_stop_patience', 'selection_dataset', 'selection_metric', 'early_stop_epsilon', 'selection_minimize'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <32x26 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 32 stored elements in Compressed Sparse Row format>, 'ClassDef': <6x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['CORL', 'EDAC-D4RL', 'EDAC', 'halfcheetah-medium-v2', 'cpu', '-', '-', 'project', 'group', 'name', 'PYTHONHASHSEED', 'cpu', 'Trying to load data into non-empty replay buffer', 'observations', 'Replay buffer is smaller than the dataset you are trying to load!', 'observations', 'actions', 'rewards', 'next_observations', 'terminals', 'Dataset size: ', 'cpu', 'alpha_loss', 'critic_loss', 'actor_loss', 'batch_entropy', 'alpha', 'q_policy_std', 'q_random_std', 'actor', 'critic', 'target_critic', 'log_alpha', 'actor_optim', 'critic_optim', 'alpha_optim', 'actor', 'critic', 'target_critic', 'actor_optim', 'critic_optim', 'alpha_optim', 'log_alpha', 'rewards', 'terminals', 'rewards', 'halfcheetah', 'hopper', 'walker2d', 'rewards', 'rewards', 'antmaze', 'rewards', 'Checkpoints path: ', 'config.yaml', 'w', 'Training', 'Epoch', 'epoch', 'eval/reward_mean', 'eval/reward_std', 'epoch', 'get_normalized_score', 'eval/normalized_score_mean', 'eval/normalized_score_std', '.pt', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <18x18 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 18 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Mapping from real numbers to non-negative ones and vise-versa.\\n\\n    Args:\\n        type: Type of parametrization (`exp`, `invlin`, `abs` or `sigmoid`).\\n        min: Minimum positive value.\\n        max: Maximum value for sigmoid parametrization.\\n        center: Shift values prior to positive transform.\\n        scale: Scale tangent slop at the center.\\n    ', 'exp', 'invlin', 'abs', 'sigmoid', 'Unknown parametrization: {}.', 'sigmoid', 'Maximum is supported for sigmoid parametrization only.', 'sigmoid', 'Maximum value must be provided for sigmoid parametrization.', 'Smooth mapping from real to positive numbers.', 'exp', 'invlin', 'sigmoid', 'abs', 'Logarithm of positive function.', 'exp', 'invlin', 'sigmoid', 'abs', 'Inverse of positive function.', 'exp', 'invlin', 'sigmoid', 'abs', 'Smooth mapping from real to positive numbers.', 'Only non-negative minimum is supported.', 'Logarithm of exponential function with min.', 'Inverse of exp function with min.', 'Only non-negative minimum is supported.', 'Smooth mapping from real to positive numbers.\\n\\n        Inverse function for x < 0 and linear for x > 0.\\n        ', 'Only non-negative minimum is supported.', 'Logarithm of invlin function.', 'Only non-negative minimum is supported.', 'Inverse of invlin.', 'Only non-negative minimum is supported.', 'Mapping from real to positive numbers.', 'Only non-negative minimum is supported.', 'Logarithm of abs function.', 'Inverse of abs (true inverse for positives only).', 'Only non-negative minimum is supported.', 'Smooth mapping from real to positive numbers.', 'Only non-negative minimum is supported.', 'Minimum must be less than maximum.', 'Logarithm of sigmoid function.', 'Only non-negative minimum is supported.', 'Minimum must be less than maximum.', 'Inverse sigmoid.', 'Only non-negative minimum is supported.', 'Minimum must be less than maximum.'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <7x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['x', 'x', '.db', 'sqlite:///', 'x', 'pipeline', 'x', 'pipeline', 'x', 'pipeline', 'The number of trials is non-deterministic'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <8x8 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 8 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['sqlite:///test.db', 'test.db', 'COMPLETE', 'RUNNING', 'PENDING', 'COMPLETE', 'pipeline', 'SMAPE_median', 'mean', 'mean', '_target_', 'horizon', 'model', 'etna.pipeline.Pipeline', '_target_', 'lag', 'etna.models.NaiveModel', 'maximize', 'etna.auto.auto.ConfigSampler', 'etna.auto.auto.Optuna', 'median', 'SMAPE_median', 'SMAPE_median', 'SMAPE', 'median', 'k'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <9x9 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 9 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['target', 'target', 'target', 'target', 'target_object', 'target', 'target', 'target', 'partial function after initialization instead of original function, dumps return different results', 'target', 'lambdas in class attributes', 'target_object, expected', 'target', 'in_column', 'window_size', 'distance_coef', 'n_neighbors', 'distance_func', '_target_', 'target', '_target_', 'etna.analysis.outliers.density_outliers.absolute_difference_distance', 'etna.transforms.outliers.point_outliers.DensityOutliersTransform', 'max_epochs', 'callbacks', 'val_loss', 'input_size', 'decoder_length', 'hidden_size', 'encoder_length', 'lr', 'train_batch_size', 'test_batch_size', 'trainer_params', 'train_dataloader_params', 'test_dataloader_params', 'val_dataloader_params', 'split_params', '_target_', 'max_epochs', 'callbacks', 'monitor', 'patience', '_target_', 'val_loss', 'etna.libs.pytorch_lightning.callbacks.EarlyStopping', 'train_size', 'etna.models.nn.mlp.MLPModel', 'target_model', 'some bug', 'target_object', 'target', 'target', 'target_object', 'macro', 'target_ensemble', 'Some of external objects in input parameters could be not written in dict'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Adds fourier features to the dataset.\\n\\n    Notes\\n    -----\\n    To understand how transform works we recommend:\\n    `Fourier series <https://otexts.com/fpp2/useful-predictors.html#fourier-series>`_.\\n\\n    * Parameter ``period`` is responsible for the seasonality we want to capture.\\n    * Parameters ``order`` and ``mods`` define which harmonics will be used.\\n\\n    Parameter ``order`` is a more user-friendly version of ``mods``.\\n    For example, ``order=2`` can be represented as ``mods=[1, 2, 3, 4]`` if ``period`` > 4 and\\n    as ``mods=[1, 2, 3]`` if 3 <= ``period`` <= 4.\\n    ', \"Create instance of FourierTransform.\\n\\n        Parameters\\n        ----------\\n        period:\\n            the period of the seasonality to capture in frequency units of time series;\\n\\n            ``period`` should be >= 2\\n        order:\\n            upper order of Fourier components to include;\\n\\n            ``order`` should be >= 1 and <= ceil(period/2))\\n        mods:\\n            alternative and precise way of defining which harmonics will be used,\\n            for example ``mods=[1, 3, 4]`` means that sin of the first order\\n            and sin and cos of the second order will be used;\\n\\n            ``mods`` should be >= 1 and < period\\n        out_column:\\n\\n            * if set, name of added column, the final name will be '{out_columnt}_{mod}';\\n\\n            * if don't set, name will be ``transform.__repr__()``,\\n              repr will be made for transform that creates exactly this column\\n\\n        Raises\\n        ------\\n        ValueError:\\n            if period < 2\\n        ValueError:\\n            if both or none of order, mods is set\\n        ValueError:\\n            if order is < 1 or > ceil(period/2)\\n        ValueError:\\n            if at least one mod is < 1 or >= period\\n        \", 'Period should be at least 2', 'Order should be within [1, ceil(period/2)] range', 'Every mod should be within [1, int(period)) range', 'There should be exactly one option set: order or mods', 'Fit method does nothing and is kept for compatibility.\\n\\n        Parameters\\n        ----------\\n        df:\\n            dataframe with data.\\n\\n        Returns\\n        -------\\n        result: FourierTransform\\n        ', 'FourierTransform', '_', 'segment', 'segment', 'segment', 'feature', 'Add harmonics to the dataset.\\n\\n        Parameters\\n        ----------\\n        df:\\n            dataframe with data to transform.\\n\\n        Returns\\n        -------\\n        result: pd.Dataframe\\n            transformed dataframe\\n        '], 'from': [], 'import': []}\n",
      "{'FunctionDef': <13x12 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 13 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Combination of crossentropy and KL-divergence regularization.\\n\\n    PFE loss is described in Probabilistic Face Embeddings:\\n      https://openaccess.thecvf.com/content_ICCV_2019/papers/Shi_Probabilistic_Face_Embeddings_ICCV_2019_paper.pdf\\n\\n    HIB loss is described in Modeling Uncertainty with Hedged Instance Embedding:\\n      https://arxiv.org/pdf/1810.00319.pdf\\n    ', 'Get optimizer parameters.', 'use_softmax', 'xent_weight', 'xent_smoothing', 'hinge_weight', 'hinge_margin', 'proxy_anchor_weight', 'proxy_nca_weight', 'multi_similarity_weight', 'multi_similarity_params', 'prior_kld_weight', 'pfe_weight', 'pfe_match_self', 'hib_weight', 'multi_similarity_weight', 'multi_similarity_params', 'proxy_nca_weight', 'xent_weight', 'Need logits for Xent loss.', 'xent_weight', 'hinge_weight', 'Need logits for Hinge loss.', 'hinge_weight', 'proxy_anchor_weight', 'Need logits for Proxy-Anchor loss.', 'proxy_anchor_weight', 'proxy_nca_weight', 'Need scorer for Proxy-NCA loss.', 'Need final weights for Proxy-NCA loss.', 'Final bias is redundant for Proxy-NCA loss.', 'proxy_nca_weight', 'multi_similarity_weight', 'Need scorer for Multi-similarity loss.', 'multi_similarity_weight', 'prior_kld_weight', 'prior_kld_weight', 'pfe_weight', 'pfe_weight', 'hib_weight', 'hib_weight', 'use_softmax', 'xent_smoothing', 'label_smoothing', 'xent_smoothing', 'Compute Hinge loss.\\n\\n        Args:\\n            logits: Logits tensor with shape (*, N).\\n            labels: Integer labels with shape (*).\\n\\n        Returns:\\n            Loss value.\\n        ', 'hinge_margin', 'See Proxy Anchor Loss for Deep Metric Learning (2020):\\n        https://arxiv.org/pdf/2003.13911.pdf\\n        ', 'pfe_match_self', 'Compute criterion in FP32 and pass distribution and scorer to criterion.', 'amp', 'IRunner', 'model', 'model', 'model', 'scorer', 'IRunner'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <7x7 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['special_days_in_week', 'special_days_in_month', 'day_number_in_week', 'day_number_in_month', 'day_number_in_year', 'week_number_in_year', 'week_number_in_month', 'month_number_in_year', 'season_number', 'year_number', 'is_weekend', 'special_days_in_week', 'special_days_in_month', 'Generate dataset for TimeFlags feature.\\n\\n    Returns\\n    -------\\n    dataset with timestamp column and columns true_minute_in_hour_number, true_fifteen_minutes_in_hour_number,\\n    true_half_hour_number, true_hour_number, true_half_day_number, true_one_third_day_number that contain\\n    true answers for corresponding features\\n    ', 'timestamp', '2010-06-01', '2021-06-01', '3h', 'dateflag', '_day_number_in_week', 'timestamp', '_day_number_in_month', 'timestamp', '_day_number_in_year', 'timestamp', '_week_number_in_year', 'timestamp', '_month_number_in_year', 'timestamp', '_season_number', 'timestamp', '_year_number', 'timestamp', '_week_number_in_month', 'timestamp', '_is_weekend', 'timestamp', '_special_days_in_week', '_day_number_in_week', '_special_days_in_month', '_day_number_in_month', 'segment', 'segment_', 'target', 'timestamp', 'segment', 'segment', 'feature', 'Generate dataset without dateflags', 'timestamp', '2010-06-01', '2021-06-01', '3h', 'segment', 'segment_', 'target', 'timestamp', 'segment', 'segment', 'feature', \"Test that transform can't be created with no features to generate.\", 'Test that __repr__ method works fine.', 'DateFlagsTransform', '(day_number_in_week = True, day_number_in_month = True, day_number_in_year = False, week_number_in_month = False, week_number_in_year = False, month_number_in_year = True, season_number = True, year_number = True, is_weekend = True, special_days_in_week = (1, 2), special_days_in_month = (12,), out_column = None, )', 'Test that transform generates correct column names using out_column parameter.', 'segment', 'dateflags', 'feature', 'segment', 'segment', '_', 'target', 'category', 'true_params', 'day_number_in_week', 'day_number_in_month', 'day_number_in_year', 'week_number_in_year', 'week_number_in_month', 'month_number_in_year', 'season_number', 'year_number', 'is_weekend', 'day_number_in_week', 'day_number_in_month', 'day_number_in_year', 'week_number_in_year', 'week_number_in_month', 'month_number_in_year', 'season_number', 'year_number', 'is_weekend', 'Test that transform generates correct column names without setting out_column parameter.', 'segment', 'feature', 'segment', 'segment', 'feature', 'target', 'category', 'feature', 'target', 'true_params', 'day_number_in_week', 'day_number_in_month', 'day_number_in_year', 'week_number_in_year', 'week_number_in_month', 'month_number_in_year', 'season_number', 'year_number', 'is_weekend', 'day_number_in_week', 'day_number_in_month', 'day_number_in_year', 'week_number_in_year', 'week_number_in_month', 'month_number_in_year', 'season_number', 'year_number', 'is_weekend', 'special_days_in_week', 'special_days_in_month', 'special_days_in_week', 'special_days_in_month', 'Test that transform generates correct values.', 'dateflag', 'segment', 'segment', '_', 'target', 'true_params', 'day_number_in_week', 'day_number_in_month', 'day_number_in_year', 'week_number_in_year', 'week_number_in_month', 'month_number_in_year', 'season_number', 'year_number', 'is_weekend', 'special_days_in_week', 'special_days_in_month'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <7x7 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Enum for different metric aggregation modes.', 'macro', 'per-segment', 'Base class for different sklearn transforms.', 'per-segment', '\\n        Init SklearnTransform.\\n\\n        Parameters\\n        ----------\\n        in_column:\\n            columns to be transformed, if None - all columns will be transformed.\\n        transformer:\\n            :py:class:`sklearn.base.TransformerMixin` instance.\\n        inplace:\\n            features are changed by transformed.\\n        out_column:\\n            base for the names of generated columns, uses ``self.__repr__()`` if not given.\\n        mode:\\n            \"macro\" or \"per-segment\", way to transform features over segments.\\n\\n            * If \"macro\", transforms features globally, gluing the corresponding ones for all segments.\\n\\n            * If \"per-segment\", transforms features for each segment separately.\\n\\n        Raises\\n        ------\\n        ValueError:\\n            if incorrect mode given\\n        ', 'Transformation will be applied inplace, out_column param will be ignored', '_', '\\n        Fit transformer with data from df.\\n\\n        Parameters\\n        ----------\\n        df:\\n            DataFrame to fit transformer.\\n\\n        Returns\\n        -------\\n        :\\n        ', 'feature', \"'\", \"' is not a valid TransformMode.\", 'SklearnTransform', '\\n        Transform given data with fitted transformer.\\n\\n        Parameters\\n        ----------\\n        df:\\n            DataFrame to transform with transformer.\\n\\n        Returns\\n        -------\\n        :\\n            transformed DataFrame.\\n        ', 'segment', \"'\", \"' is not a valid TransformMode.\", '\\n        Apply inverse transformation to DataFrame.\\n\\n        Parameters\\n        ----------\\n        df:\\n            DataFrame to apply inverse transform.\\n\\n        Returns\\n        -------\\n        :\\n            transformed DataFrame.\\n        ', 'Transform is not fitted yet.', 'target', 'feature', 'target', 'target', 'target', 'target', 'target', 'target', \"'\", \"' is not a valid TransformMode.\", 'segment', 'segment'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Enum for different aggregation modes.', 'mean', 'max', 'min', 'median', '\\n    Maximum Relevance and Minimum Redundancy feature selection method.\\n\\n    Here relevance for each regressor is calculated as the per-segment aggregation of the relevance\\n    values in relevance_table. The redundancy term for the regressor is calculated as a mean absolute correlation\\n    between this regressor and other ones. The correlation between the two regressors is an aggregated pairwise\\n    correlation for the regressors values in each segment.\\n\\n    Parameters\\n    ----------\\n    relevance_table:\\n        dataframe of shape n_segment x n_exog_series with relevance table, where ``relevance_table[i][j]``\\n        contains relevance of j-th ``df_exog`` series to i-th df series\\n    regressors:\\n        dataframe with regressors in etna format\\n    top_k:\\n        num of regressors to select; if there are not enough regressors, then all will be selected\\n    relevance_aggregation_mode:\\n        the method for relevance values per-segment aggregation\\n    redundancy_aggregation_mode:\\n        the method for redundancy values per-segment aggregation\\n    atol:\\n        the absolute tolerance to compare the float values\\n\\n    Returns\\n    -------\\n    selected_features: List[str]\\n        list of ``top_k`` selected regressors, sorted by their importance\\n    ', 'feature', 'feature'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['utf-8', '', 'py-spy', 'record', '-o', 'speedscope.json', '-f', 'speedscope', 'python', 'scripts', 'run.py', 'speedscope.json', 'r', 'line', 'line', '\\\\n', '', 'py_spy.csv', 'configs/', 'config', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['\\n    Imagenette datasets class. These datasets are subsets of ImageNet dataset.\\n    Imagenette official page: https://github.com/fastai/imagenette.\\n    This dataset class is applicable for Imagenette, Imagewoof, Image网, and TinyImagenet datasets.\\n\\n    Args:\\n        root: Dataset root.\\n        train: Whether to use train or test part of the dataset.\\n    ', 'train', 'val', 'train', '*.JPEG', 'Whether dataset is classification or matching.', 'Whether dataset is for open-set or closed-set classification.', 'Get dataset labels array.\\n\\n        Labels are integers in the range [0, N-1], where N is number of classes\\n\\n        ', 'Get element of the dataset.\\n\\n        Returns tuple (image, label).\\n\\n        '], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Get euclidean distance between two arrays.\\n\\n    Parameters\\n    ----------\\n    x1:\\n        first array\\n    x2:\\n        second array\\n\\n    Returns\\n    -------\\n    float:\\n        distance between x1 and x2\\n    ', 'Euclidean distance handler.', 'Init EuclideanDistance.\\n\\n        Parameters\\n        ----------\\n        trim_series:\\n            if True, compare parts of series with common timestamp\\n        ', 'Compute distance between x1 and x2.', 'TSDataset', 'Get series that minimizes squared distance to given ones according to the euclidean distance.\\n\\n        Parameters\\n        ----------\\n        ts:\\n            TSDataset with series to be averaged\\n\\n        Returns\\n        -------\\n        pd.DataFrame:\\n            dataframe with columns \"timestamp\" and \"target\" that contains the series\\n        ', 'timestamp', 'target', 'EuclideanDistance', 'euclidean_distance'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <10x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 10 stored elements in Compressed Sparse Row format>, 'ClassDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Sample labels with equal probabilities.', \"Can't sample equal number of labels. Batch is too large.\", 'Sample labels with probabilities equal to labels frequency.', 'Sampler which extracts balanced number of samples for each class.\\n\\n    Args:\\n        data_source: Source dataset. Labels field must be implemented.\\n        batch_size: Required batch size.\\n        samples_per_class: Number of samples for each class in the batch.\\n            Batch size must be a multiple of samples_per_class.\\n        uniform: If true, sample labels uniformly. If false, sample labels according to frequency.\\n    ', 'Dataset size {} is too small for batch size {}.', 'Batch size must be a multiple of samples_per_class, but {} != K * {}.', \"Can't sample {} classes from dataset with {} classes.\", 'Applies same-class mixup to a batch from base sampler.', 'Expected classification dataset for mixup.'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['2021-05-20', 'D', 'D', 'target', 'segment,params,expected', 'segment_0', 'pen', 'segment_0', 'epsilon', 'segment_1', 'pen', 'segment_1', 'epsilon', 'segment_2', 'pen', 'segment_2', 'epsilon', 'target', 'n_bkps,mode', 'segment_0', 'segment_1', 'segment_2', 'pen', 'segment_0', 'segment_1', 'segment_2', 'epsilon', 'segment_0', 'segment_1', 'segment_2', 'pen', 'segment_0', 'segment_1', 'segment_2', 'epsilon', 'target', 'Impossible number of changepoints. Please, decrease n_bkps value.', 'n_bkps,mode', 'segment_0', 'segment_1', 'segment_2', 'pen', 'segment_0', 'segment_1', 'segment_2', 'epsilon', 'target', 'Impossible number of changepoints. Please, increase max_value or increase n_bkps value.', 'n_bkps,mode', 'segment_0', 'segment_1', 'segment_2', 'pen', 'segment_0', 'segment_1', 'segment_2', 'epsilon'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <9x9 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 9 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['Context to disable AMP.', 'Context to disable AMP.', 'Centext manager for temporary random seed (random and Numpy modules).', 'Returns base torch module from wappers like DP and DDP.', 'Freeze or unfreeze all parameters of the model.', 'Freeze or unfreeze batchnorm parameters.', 'Change evaluation mode for model batchnorms.'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['dim', 'none', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <10x7 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 10 stored elements in Compressed Sparse Row format>, 'ClassDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['faiss', 'numpy', 'torch', 'dim', 'spherical', 'backend', 'dim', 'spherical', 'dim', 'spherical', 'metrics', 'prefetch_factor', 'mapr-ms', 'mapr-ms', 'metrics', 'prefetch_factor', 'mapr', 'mapr', 'Eval MAP@R on toy examples from original paper.', 'dim', 'spherical', 'metrics', 'prefetch_factor', 'mapr-ms', 'mapr-ms', 'Apply pattern to uniform distribution.', 'dim', 'spherical', 'metrics', 'recall_k_values', 'prefetch_factor', 'recall', 'recall@1', 'recall@2', 'recall@3', 'recall@4', 'recall@5', 'recall@10', 'dim', 'metrics', 'recall_k_values', 'prefetch_factor', 'erc-recall@1', 'erc-recall@1', 'dim', 'metrics', 'prefetch_factor', 'erc-mapr', 'erc-mapr', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['\\n    Random rotation transform from https://github.com/ansh941/MnistSimpleCNN/blob/master/code/transforms.py\\n    '], 'from': [], 'import': []}\n",
      "{'FunctionDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['Check that PytorchForecastingTransform works with different frequencies correctly.', 'time_idx', 'target', 'segment', 'time', 'days_offset'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <9x9 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 9 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['ts_name, expected_start_timestamp, expected_end_timestamp', 'example_tsds', '2020-01-01', '2020-04-09', 'ts_with_different_series_length', '2020-01-01 4:00', '2020-02-01', 'Value of start_timestamp is less than beginning of some segments', 'Value of end_timestamp is more than ending of dataset', 'Value of end_timestamp is less than start_timestamp', 'start_timestamp, end_timestamp', '2020-01-02', '2020-02-01', '2020-01-02', '2020-02-01', '2020-01-05', '2020-02-03', 'quantiles', 'prediction_interval', 'quantiles'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <8x8 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 8 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['D', 'target', 'time_idx', 'target', 'segment', 'add PytorchForecastingTransform', '\\n    Given: I have dataframe with 2 segments with weekly seasonality with known future\\n    When:\\n    Then: I get {horizon} periods per dataset as a forecast and they \"the same\" as past\\n    ', 'regressor_dateflag', 'time_idx', 'regressor_dateflag_day_number_in_week', 'target', 'segment', 'macro', 'horizon', '\\n    Given: I have dataframe with 2 segments with weekly seasonality with known future\\n    When: I use scale transformations\\n    Then: I get {horizon} periods per dataset as a forecast and they \"the same\" as past\\n    ', 'target', 'regressor_dateflag', 'time_idx', 'regressor_dateflag_day_number_in_week', 'target', 'segment', 'macro', 'horizon', 'D', 'time_idx', 'target', 'segment', 'The future is not generated!', 'time_idx', 'target', 'segment', 'target_0.02', 'target_0.98', 'target', 'target_0.98', 'target_0.02', 'target', 'target_0.02', 'target_0.98', 'target', \"Quantiles: \\\\[0.4\\\\] can't be computed\", 'target_0.02', 'target_0.98', 'target', 'target_0.4', \"Quantiles can't be computed\", 'target', 'target_0.02', 'target_0.98'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <15x15 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 15 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['Generate pd.DataFrame with timestamp after multitrend_df.', 'timestamp', '2021-07-01', '2021-07-31', 'target', 'segment', 'segment_1', 'Generate pd.DataFrame with timestamp before multitrend_df.', 'timestamp', '2019-12-01', '2019-12-31', 'target', 'segment', 'segment_1', 'segment_1', 'target', \"Check that fit method generates correct number of detrend model's copies.\", 'target', 'segment_1', 'Check that transform method detrends given series.', 'target', 'segment_1', 'segment_1', 'target', 'target', 'Check that detrend models get series trends.', 'target', 'segment_1', 'segment_1', 'target', 'target', 'Check that inverse_transform turns transformed series back to the origin one.', 'target', 'segment_1', 'segment_1', 'segment', 'segment_1', 'segment_1', 'target', 'segment_1', 'target', 'Check the logic of out-of-sample inverse transformation: for past and future dates unseen by transform.', 'target', 'segment_1', '2020-02-01', '2021-05-01', 'segment_1', 'segment', 'segment_1', 'segment_1', 'target', 'segment_1', 'target', 'Check that transform works correctly in case of fully unseen pre history data.', 'target', 'segment_1', 'segment_1', 'target', 'Check that inverse_transform works correctly in case of fully unseen pre history data.', 'target', 'segment_1', 'segment_1', 'target', 'Check that transform works correctly in case of fully unseen post history data with offset.', 'target', 'segment_1', 'segment_1', 'target', 'Check that inverse_transform works correctly in case of fully unseen post history data with offset.', 'target', 'segment_1', 'segment_1', 'target', 'Test that transform for one segment raise error when calling transform without being fit.', 'target', 'Transform is not fitted!', 'segment_1', 'target', 'segment', 'target', 'target', 'The input column contains NaNs in the middle of the series!'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['Script for updating contributors in README.md.\\n\\nBefore running this script you should install `github CLI <https://github.com/cli/cli>`_.\\n\\nThis scripts depends on the fact that contributors section goes after the team section\\nand license section goes after the contributors section.\\n', '/repos/tinkoff-ai/etna/contributors', '[Artem Levashov](https://github.com/soft1q)', '[Aleksey Podkidyshev](https://github.com/alekseyen)', 'application/vnd.github+json', 'gh', 'api', '-H', 'Accept: ', 'contributions', 'README.md', 'r', '### ETNA.Team\\n', '### ETNA.Contributors\\n', 'https://github.com/(.*)\\\\)', 'README.md', 'r', '### ETNA.Contributors\\n', '## License\\n', '[', 'login', '](', 'html_url', '),\\n', ',\\n', '\\n', '\\n', '\\n', 'w', 'login', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <8x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 8 stored elements in Compressed Sparse Row format>, 'ClassDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Check if quantiles presented in y_pred.', 'feature', 'target_', '.4g', 'Quantile ', ' is not presented in tsdataset.', 'Coverage metric for prediction intervals - precenteage of samples in the interval ``[lower quantile, upper quantile]``.\\n\\n    .. math::\\n        Coverage(y\\\\_true, y\\\\_pred) = \\\\frac{\\\\sum_{i=0}^{n-1}{[ y\\\\_true_i \\\\ge y\\\\_pred_i^{lower\\\\_quantile}] * [y\\\\_true_i \\\\le y\\\\_pred_i^{upper\\\\_quantile}] }}{n}\\n\\n    Notes\\n    -----\\n    Works just if quantiles presented in y_pred\\n    ', \"Init metric.\\n\\n        Parameters\\n        ----------\\n        mode: 'macro' or 'per-segment'\\n            metrics aggregation mode\\n        kwargs:\\n            metric's computation arguments\\n        \", \"\\n        Compute metric's value with y_true and y_pred.\\n\\n        Notes\\n        -----\\n        Note that if y_true and y_pred are not sorted Metric will sort it anyway\\n\\n        Parameters\\n        ----------\\n        y_true:\\n            dataset with true time series values\\n        y_pred:\\n            dataset with predicted time series values\\n\\n        Returns\\n        -------\\n            metric's value aggregated over segments or not (depends on mode)\\n        \", 'segment', 'target', 'target', 'target', 'target_', '.4g', 'target', 'target_', '.4g', 'Whether higher metric value is better.', 'Mean width of prediction intervals.\\n\\n    .. math::\\n        Width(y\\\\_true, y\\\\_pred) = \\\\frac{\\\\sum_{i=0}^{n-1}\\\\mid y\\\\_pred_i^{upper\\\\_quantile} - y\\\\_pred_i^{lower\\\\_quantile} \\\\mid}{n}\\n\\n    Notes\\n    -----\\n    Works just if quantiles presented in y_pred\\n    ', \"Init metric.\\n\\n        Parameters\\n        ----------\\n        mode: 'macro' or 'per-segment'\\n            metrics aggregation mode\\n        kwargs:\\n            metric's computation arguments\\n        \", \"\\n        Compute metric's value with y_true and y_pred.\\n\\n        Notes\\n        -----\\n        Note that if y_true and y_pred are not sorted Metric will sort it anyway\\n\\n        Parameters\\n        ----------\\n        y_true:\\n            dataset with true time series values\\n        y_pred:\\n            dataset with predicted time series values\\n\\n        Returns\\n        -------\\n            metric's value aggregated over segments or not (depends on mode)\\n        \", 'segment', 'target', 'target', 'target_', '.4g', 'target_', '.4g', 'Whether higher metric value is better.', 'Coverage', 'Width'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <9x8 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 9 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['_OneSegmentChangePointsTransform subtracts multiple linear trend from series.', 'Init _OneSegmentChangePointsTrendTransform.\\n\\n        Parameters\\n        ----------\\n        in_column:\\n            name of column to apply transform to\\n        change_point_model:\\n            model to get trend change points\\n            TODO: replace this parameters with the instance of BaseChangePointsModelAdapter in ETNA 2.0\\n        detrend_model:\\n            model to get trend in data\\n        change_point_model_predict_params:\\n            params for ``change_point_model.predict`` method\\n        ', 'Create copy of detrend model for each timestamp interval.', 'Convert ETNA timestamp-index to a list of timestamps to fit regression models.', 'Fit per-interval models with corresponding data from series.', 'Something went wrong on fit! Check the parameters of the transform.', 'Apply per-interval detrending to series.', 'Transform is not fitted! Fit the Transform before calling transform method.', 'Fit OneSegmentChangePointsTransform: find trend change points in ``df``, fit detrend models with data from intervals of stable trend.\\n\\n        Parameters\\n        ----------\\n        df:\\n            one segment dataframe indexed with timestamp\\n\\n        Returns\\n        -------\\n        :\\n        ', '_OneSegmentChangePointsTrendTransform', 'Split df to intervals of stable trend and subtract trend from each one.\\n\\n        Parameters\\n        ----------\\n        df:\\n            one segment dataframe to subtract trend\\n\\n        Returns\\n        -------\\n        detrended df: pd.DataFrame\\n            df with detrended in_column series\\n        ', 'Split df to intervals of stable trend according to previous change point detection and add trend to each one.\\n\\n        Parameters\\n        ----------\\n        df:\\n            one segment dataframe to turn trend back\\n\\n        Returns\\n        -------\\n        df: pd.DataFrame\\n            df with restored trend in in_column\\n        ', 'target', 'ChangePointsTrendTransform subtracts multiple linear trend from series.\\n\\n    Warning\\n    -------\\n    This transform can suffer from look-ahead bias. For transforming data at some timestamp\\n    it uses information from the whole train part.\\n    ', 'Init ChangePointsTrendTransform.\\n\\n        Parameters\\n        ----------\\n        in_column:\\n            name of column to apply transform to\\n        change_point_model:\\n            model to get trend change points\\n            TODO: replace this parameters with the instance of BaseChangePointsModelAdapter in ETNA 2.0\\n        detrend_model:\\n            model to get trend in data\\n        change_point_model_predict_params:\\n            params for ``change_point_model.predict`` method\\n        '], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Whether dataset is classification or matching.', 'Whether dataset is for open-set or closed-set classification.', 'No items in the dataset.'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <24x21 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 24 stored elements in Compressed Sparse Row format>, 'ClassDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['cuda', 'halfcheetah-medium-expert-v2', '', 'CORL', 'BC-D4RL', 'BC', '-', '-', 'cpu', 'Trying to load data into non-empty replay buffer', 'observations', 'Replay buffer is smaller than the dataset you are trying to load!', 'observations', 'actions', 'rewards', 'next_observations', 'terminals', 'Dataset size: ', 'PYTHONHASHSEED', 'project', 'group', 'name', 'rewards', 'terminals', 'observations', 'observations', 'actions', 'actions', 'next_observations', 'next_observations', 'rewards', 'rewards', 'terminals', 'terminals', 'cpu', 'cpu', 'actor_loss', 'actor', 'actor_optimizer', 'total_it', 'actor', 'actor_optimizer', 'total_it', 'observations', 'observations', 'observations', 'next_observations', 'next_observations', 'Checkpoints path: ', 'config.yaml', 'w', 'max_action', 'actor', 'actor_optimizer', 'discount', 'device', '---------------------------------------', 'Training BC, Env: ', ', Seed: ', '---------------------------------------', '', 'Time steps: ', '---------------------------------------', 'Evaluation over ', ' episodes: ', '.3f', ' , D4RL score: ', '.3f', '---------------------------------------', 'checkpoint_', '.pt', 'd4rl_normalized_score', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <7x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Original Caltech-UCSD Birds 200 dataset. Train and test are splitted by sample.\\n\\n    See http://www.vision.caltech.edu/visipedia/CUB-200.html\\n\\n    Args:\\n        root: Dataset root.\\n        train: Whether to use train or test part of the dataset.\\n        classification: If true, use original classification dataset.\\n            If false, sample pairs and provide verification dataset.\\n    ', 'images', 'images.txt', 'image_class_labels.txt', 'train_test_split.txt', 'Whether dataset is classification or matching.', 'Whether dataset is for open-set or closed-set classification.', 'Get dataset labels array.\\n\\n        Labels are integers in the range [0, N-1].\\n\\n        ', 'Get element of the dataset.\\n\\n        Returns tuple (image, label).\\n\\n        ', 'CUB200 dataset with different classes in train and test sets.', 'Whether dataset is for open-set or closed-set classification.'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <3x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['No frequency information was provided, so inferred frequency .* will be used', 'ignore', 'statsmodels.tsa.base.tsa_model', '\\n    Class for holding auto arima model.\\n\\n    Notes\\n    -----\\n    We use auto ARIMA [1] model from pmdarima package.\\n\\n    .. `auto ARIMA: <https://alkaline-ml.com/pmdarima/>_`\\n\\n    ', '\\n        Init auto ARIMA model with given params.\\n\\n        Parameters\\n        ----------\\n        **kwargs:\\n            Training parameters for auto_arima from pmdarima package.\\n        ', '\\n    Class for holding auto arima model.\\n\\n    Method ``predict`` can use true target values only on train data on future data autoregression\\n    forecasting will be made even if targets are known.\\n\\n    Notes\\n    -----\\n    We use :py:class:`pmdarima.arima.arima.ARIMA`.\\n    ', '\\n        Init auto ARIMA model with given params.\\n\\n        Parameters\\n        ----------\\n        **kwargs:\\n            Training parameters for auto_arima from pmdarima package.\\n        '], 'from': [], 'import': []}\n",
      "{'FunctionDef': <7x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7 stored elements in Compressed Sparse Row format>, 'ClassDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Batch specification for RNN.', 'torch.Tensor', 'torch.Tensor', 'torch.Tensor', 'torch.Tensor', 'torch.Tensor', 'RNN based Lightning module with LSTM cell.', 'torch.nn.Module', 'Init RNN based on LSTM cell.\\n\\n        Parameters\\n        ----------\\n        input_size:\\n            size of the input feature space: target plus extra features\\n        num_layers:\\n            number of layers\\n        hidden_size:\\n            size of the hidden state\\n        lr:\\n            learning rate\\n        loss:\\n            loss function\\n        optimizer_params:\\n            parameters for optimizer for Adam optimizer (api reference :py:class:`torch.optim.Adam`)\\n        ', 'Forward pass.\\n\\n        Parameters\\n        ----------\\n        x:\\n            batch of data\\n\\n        Returns\\n        -------\\n        :\\n            forecast with shape (batch_size, decoder_length, 1)\\n        ', 'encoder_real', 'decoder_real', 'decoder_target', 'Step for loss computation for training or validation.\\n\\n        Parameters\\n        ----------\\n        batch:\\n            batch of data\\n\\n        Returns\\n        -------\\n        :\\n            loss, true_target, prediction_target\\n        ', 'encoder_real', 'decoder_real', 'encoder_target', 'decoder_target', 'Make samples from segment DataFrame.', 'encoder_real', 'decoder_real', 'encoder_target', 'decoder_target', 'segment', 'target', 'decoder_real', 'target', 'target', 'decoder_real', 'target', 'encoder_real', 'target', 'target', 'encoder_real', 'target', 'encoder_real', 'encoder_real', 'target', 'encoder_target', 'decoder_target', 'segment', 'segment', 'Optimizer configuration.', 'torch.optim.Optimizer', 'RNN based model on LSTM cell.', 'torch.nn.Module', 'Init RNN model based on LSTM cell.\\n\\n        Parameters\\n        ----------\\n        input_size:\\n            size of the input feature space: target plus extra features\\n        encoder_length:\\n            encoder length\\n        decoder_length:\\n            decoder length\\n        num_layers:\\n            number of layers\\n        hidden_size:\\n            size of the hidden state\\n        lr:\\n            learning rate\\n        loss:\\n            loss function, MSELoss by default\\n        train_batch_size:\\n            batch size for training\\n        test_batch_size:\\n            batch size for testing\\n        optimizer_params:\\n            parameters for optimizer for Adam optimizer (api reference :py:class:`torch.optim.Adam`)\\n        trainer_params:\\n            Pytorch ligthning  trainer parameters (api reference :py:class:`pytorch_lightning.trainer.trainer.Trainer`)\\n        train_dataloader_params:\\n            parameters for train dataloader like sampler for example (api reference :py:class:`torch.utils.data.DataLoader`)\\n        test_dataloader_params:\\n            parameters for test dataloader\\n        val_dataloader_params:\\n            parameters for validation dataloader\\n        split_params:\\n            dictionary with parameters for :py:func:`torch.utils.data.random_split` for train-test splitting\\n                * **train_size**: (*float*) value from 0 to 1 - fraction of samples to use for training\\n\\n                * **generator**: (*Optional[torch.Generator]*) - generator for reproducibile train-test splitting\\n\\n                * **torch_dataset_size**: (*Optional[int]*) - number of samples in dataset, in case of dataset not implementing ``__len__``\\n        '], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Log any events and metrics to stderr output. Uses loguru.', 'Create instance of ConsoleLogger.\\n\\n        Parameters\\n        ----------\\n        table:\\n            Indicator for writing tables to the console\\n        ', '\\n        Log any event.\\n\\n        e.g. \"Fitted segment segment_name\" to stderr output.\\n\\n        Parameters\\n        ----------\\n        msg:\\n            Message or dict to log\\n        kwargs:\\n            Parameters for changing additional info in log message\\n        ', 'TSDataset', '\\n        Write metrics to logger.\\n\\n        Parameters\\n        ----------\\n        ts:\\n            TSDataset to with backtest data\\n        metrics_df:\\n            Dataframe produced with :py:meth:`etna.pipeline.Pipeline._get_backtest_metrics`\\n        forecast_df:\\n            Forecast from backtest\\n        fold_info_df:\\n            Fold information from backtest\\n\\n        Notes\\n        -----\\n        The result of logging will be different for ``aggregate_metrics=True`` and ``aggregate_metrics=False``\\n        options in :py:meth:`~etna.pipeline.Pipeline.backtest`.\\n        ', 'fold_number', 'Fold ', 'fold_number', ':', 'segment', ':', ' = ', 'Segment ', 'segment', ':', ' = ', 'Pytorch lightning loggers.'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': [], 'from': [], 'import': []}\n",
      "{'FunctionDef': <7x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7 stored elements in Compressed Sparse Row format>, 'ClassDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Image transform for the model.', 'Get transform config.\\n\\n        Args:\\n            image_size: Resize and center crop image to that size.\\n            center_crop: Whether to make center crop or resize full image.\\n            mean: Mean channel stats for normalization.\\n            std: Std channel stats for normalization.\\n        ', 'image_size', 'center_crop', 'mean', 'std', 'center_crop', 'image_size', 'image_size', 'image_size', 'image_size', 'mean', 'std', 'image_size', 'Image transform used for testing.', 'Get transform config.\\n\\n        Args:\\n            prescale_size: If specified, resize to the given size and crop to image_size.\\n            preserve_aspect: Whether to preserve aspect during prescaling or not.\\n        ', 'prescale_size', 'preserve_aspect', 'prescale_size', 'preserve_aspect', 'prescale_size', 'prescale_size', 'prescale_size', 'Image augmenter for face recognition.\\n\\n    Center crop and random flip by default.\\n\\n    Args:\\n        image_size: Output image size.\\n    ', 'Get augmenter config.\\n\\n        Args:\\n            cutout_n_holes: Number of cutout patches.\\n            cutout_size: Cutout patch size from 0 to 1 (proportion of image size).\\n            cutout_probability: Probability to apply cutout augmentation.\\n            translate_ratios: Relative left-right and up-down shift max values.\\n            rotation_max_angle: Maximum absolute value (in degrees) of rotation angle.\\n        ', 'random_crop_scale', 'random_crop_ratio', 'random_flip_probability', 'brightness_range', 'contrast_range', 'saturation_range', 'autoaug', 'randaug_num', 'randaug_magnitude', 'cutout_n_holes', 'cutout_size', 'cutout_probability', 'translate_ratios', 'rotation_max_angle', 'random_crop_scale', 'random_crop_ratio', 'autoaug', 'imagenet', 'cifar10', 'svhn', 'autoaug', 'randaug_magnitude', 'randaug_num', 'randaug_magnitude', 'random_flip_probability', 'random_flip_probability', 'brightness_range', 'contrast_range', 'saturation_range', 'brightness_range', 'contrast_range', 'saturation_range', 'cutout_size', 'Cutout length cannot be greater then image size.', 'cutout_size', 'cutout_n_holes', 'cutout_probability', 'cutout_n_holes', 'cutout_size', 'cutout_probability', 'rotation_max_angle', 'rotation_max_angle', 'translate_ratios', 'translate_ratios', 'translate_ratios'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <33x33 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 33 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['segment_1', 'segment', 'timestamp', 'target', 'Make dataframe with quadratic trends. Segments 1, 2 has linear trend, segments -- 3, 4 quadratic.', '2020-01-01', '2020-02-01', 'H', 'timestamp', 'segment', 'target', 'segment', 'target', 'target', 'segment', 'segment_1', 'target', 'target', 'segment', 'segment_2', 'target', 'target', 'segment', 'segment_3', 'target', 'target', 'target', 'segment', 'segment_4', 'segment', 'segment_1', 'timestamp', 'segment', 'segment_1', 'segment_2', 'segment', 'segment_3', 'timestamp', '\\n    Test if mean of residue after trend subtraction is close to zero in one segment.\\n\\n    Parameters\\n    ----------\\n    trend_transform:\\n        instance of OneSegmentLinearTrendBaseTransform to predict trend with\\n    df:\\n        dataframe to predict\\n    comparison_kwargs:\\n        arguments for numpy.testing.assert_almost_equal function in key-value format\\n    ', 'target', '\\n    Test if mean of residue after trend subtraction is close to zero in all segments.\\n\\n    Parameters\\n    ----------\\n    trend_transform:\\n         instance of LinearTrendTransform or TheilSenTrendTransform to predict trend with\\n    df:\\n        dataframe to predict\\n    comparison_kwargs:\\n        arguments for numpy.testing.assert_almost_equal function in key-value format\\n    ', 'segment', 'target', '\\n    Test if residue after trend subtraction is close to zero in one segment.\\n\\n    Parameters\\n    ----------\\n    trend_transform:\\n        instance of OneSegmentLinearTrendBaseTransform to predict trend with\\n    df:\\n        dataframe to predict\\n    comparison_kwargs:\\n        arguments for numpy.testing.assert_allclose function in key-value format\\n    ', 'target', '\\n    Test if residue after trend subtraction is close to zero in all segments.\\n\\n    Parameters\\n    ----------\\n    trend_transform:\\n         instance of LinearTrendTransform or TheilSenTrendTransform to predict trend with\\n    df:\\n        dataframe to predict\\n    comparison_kwargs:\\n        arguments for numpy.testing.assert_allclose function in key-value format\\n    ', 'segment', 'target', '\\n    This test checks that LinearRegression predicts unbiased trend on one segment of slightly noised data.\\n    ', 'target', '\\n    This test checks that TheilSenRegressor predicts unbiased trend on one segment of slightly noised data.\\n    ', 'target', '\\n    This test checks that TheilSenRegressor predicts unbiased trend on one segment of slightly noised data\\n    using all the data to train model.\\n    ', 'target', '\\n    This test checks that LinearRegression predicts unbiased trend on two segments of slightly noised data.\\n    ', 'target', '\\n    This test checks that TheilSenRegressor predicts unbiased trend on two segments of slightly noised data.\\n    ', 'target', '\\n    This test checks that TheilSenRegressor predicts unbiased trend on two segments of slightly noised data\\n    using all the data to train model.\\n    ', 'target', '\\n    Test that LinearRegression predicts correct trend on one segment of slightly noised data.\\n    ', 'target', 'df_fixture, poly_degree', 'df_one_segment_linear', 'df_one_segment_quadratic', '\\n    Test that TheilSenRegressor predicts correct trend on one segment of slightly noised data.\\n\\n    Not all data is used to train the model.\\n    ', 'target', 'df_fixture, poly_degree', 'df_one_segment_linear', 'df_one_segment_quadratic', '\\n    Test that TheilSenRegressor predicts correct trend on one segment of slightly noised data.\\n\\n    All data is used to train the model.\\n    ', 'target', 'df_fixture, poly_degree', 'df_one_segment_linear', 'df_one_segment_quadratic', '\\n    Test that LinearRegression predicts correct trend on two segments of slightly noised data.\\n    ', 'target', 'df_fixture, poly_degree', 'df_two_segments_linear', 'df_two_segments_quadratic', '\\n    Test that TheilSenRegressor predicts correct trend on two segments of slightly noised data.\\n\\n    Not all data is used to train the model.\\n    ', 'target', 'df_fixture, poly_degree', 'df_two_segments_linear', 'df_two_segments_quadratic', '\\n    Test that TheilSenRegressor predicts correct trend on two segments of slightly noised data.\\n\\n    All data is used to train the model.\\n    ', 'target', 'df_fixture, poly_degree', 'df_two_segments_linear', 'df_two_segments_quadratic', '\\n    Test that trend_transform can correctly make inverse_transform in one segment.\\n\\n    Parameters\\n    ----------\\n    trend_transform:\\n        instance of LinearTrendBaseTransform to predict trend with\\n    df:\\n        dataframe to predict\\n    comparison_kwargs:\\n        arguments for numpy.testing.assert_allclose function in key-value format\\n    ', 'target', 'target', '\\n    Test that trend_transform can correctly make inverse_transform in all segments.\\n\\n    Parameters\\n    ----------\\n    trend_transform:\\n        instance of LinearTrendTransform or TheilSenTrendTransform to predict trend with\\n    df:\\n        dataframe to predict\\n    comparison_kwargs:\\n        arguments for numpy.testing.assert_allclose function in key-value format\\n    ', 'segment', 'target', 'target', '\\n    Test that LinearTrend can correctly make inverse_transform for one segment.\\n    ', 'target', 'poly_degree', '\\n    Test that TheilSenRegressor can correctly make inverse_transform for one segment.\\n    ', 'target', 'poly_degree', '\\n    Test that LinearTrend can correctly make inverse_transform for two segments.\\n    ', 'target', 'poly_degree', '\\n    Test that TheilSenRegressor can correctly make inverse_transform for two segments.\\n    ', 'target', 'poly_degree', '\\n    Test that TrendTransform can correctly make fit_transform for two segments of different size.\\n    ', 'transformer,decimal', 'target', 'target', '\\n    Test that TrendTransform can correctly make inverse_transform for two segments of different size.\\n    ', 'transformer', 'target', 'target', 'transformer,decimal', 'target', 'target'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <9x9 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 9 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['2020-01-01', 'D', 'target', 'target', 'exog_1', 'exog_', 'D', 'Extract columns from feature level that are present in transformed_df but not present in initial_df.', 'feature', 'feature', 'Test that transform raises error in invalid mode.', 'non_existent', 'transform_constructor', 'Test that transform raises warning if inplace is set to True, but out_column is also given.', 'Transformation will be applied inplace', 'new_exog', 'transform_constructor', \"Test that transform in inplace mode doesn't generate new columns.\", 'transform_constructor', 'in_column', 'exog_1', 'exog_1', 'exog_2', 'Test that transform creates new columns according to out_column parameter.', 'new_exog', 'new_exog_', 'new_exog_', 'transform_constructor', 'in_column', 'exog_1', 'exog_1', 'exog_2', 'Test that transform generates names for the columns correctly.', 'transform_constructor', 'in_column', 'exog_1', 'exog_1', 'exog_2', 'Test that transform can process all columns using None value for in_column.', 'feature', 'transform_constructor', \"Test that transform don't mix columns between each other.\", 'transform_constructor', 'in_column', 'exog_1', 'exog_2', 'exog_3', 'exog_2', 'exog_1', 'exog_3', 'exog_3', 'exog_2', 'exog_1', 'mode', 'macro', 'per-segment'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <6x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['fold-{}', 'CUDA_VISIBLE_DEVICES', 'CUDA_VISIBLE_DEVICES required', ',', 'tensorboard', 'tensorboard', 'wandb', '-fold-{}', ':', 'CUDA_VISIBLE_DEVICES', 'dataset_params', 'dataset_params', 'dataset_params', 'validation_fold', 'seed', 'seed', 'config.yaml', '--config', '--train-root', '--logger', '--checkpoint', '{fold}', 'WANDB_SWEEP_ID', 'WANDB_RUN_ID', 'WANDB_SWEEP_PARAM_PATH', 'train', 'Subprocess failed with code {}.', 'Train and eval multiple models using cross validation.\\n\\n    For wandb logging, multiple runs are grouped together.\\n\\n    ', 'dataset_params', 'num_validation_folds', 'metrics.yaml', 'num_folds', 'metrics.yaml'], 'from': [], 'import': []}\n",
      "{'FunctionDef': [], 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <2x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['YeoJohnsonTransform applies Yeo-Johns transformation to a DataFrame.\\n\\n    Warning\\n    -------\\n    This transform can suffer from look-ahead bias. For transforming data at some timestamp\\n    it uses information from the whole train part.\\n    ', 'per-segment', '\\n        Create instance of YeoJohnsonTransform.\\n\\n        Parameters\\n        ----------\\n        in_column:\\n            columns to be transformed, if None - all columns will be transformed.\\n        inplace:\\n\\n            * if True, apply transformation inplace to in_column,\\n\\n            * if False, add column to dataset.\\n\\n        out_column:\\n            base for the names of generated columns, uses ``self.__repr__()`` if not given.\\n        standardize:\\n            Set to True to apply zero-mean, unit-variance normalization to the\\n            transformed output.\\n\\n        Raises\\n        ------\\n        ValueError:\\n            if incorrect mode given\\n        ', 'yeo-johnson', 'BoxCoxTransform applies Box-Cox transformation to DataFrame.\\n\\n    Warning\\n    -------\\n    This transform can suffer from look-ahead bias. For transforming data at some timestamp\\n    it uses information from the whole train part.\\n    ', 'per-segment', '\\n        Create instance of BoxCoxTransform.\\n\\n        Parameters\\n        ----------\\n        in_column:\\n            columns to be transformed, if None - all columns will be transformed.\\n        inplace:\\n\\n            * if True, apply transformation inplace to in_column,\\n\\n            * if False, add column to dataset.\\n\\n        out_column:\\n            base for the names of generated columns, uses ``self.__repr__()`` if not given.\\n        standardize:\\n            Set to True to apply zero-mean, unit-variance normalization to the\\n            transformed output.\\n\\n        Raises\\n        ------\\n        ValueError:\\n            if incorrect mode given\\n        ', 'box-cox', 'BoxCoxTransform', 'YeoJohnsonTransform'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['cmd', 'data', 'name', 'logger', 'config', 'train_root', 'checkpoint', 'no_strict_init', 'from_stage', 'from_seed', 'fp16', 'dataset_params', 'model_params', 'trainer_params', 'num_evaluation_seeds', 'name', 'batch_size', 'num_workers', 'num_valid_workers', 'num_validation_folds', 'debug-openset', 'embedder_params', 'pretrained', 'model_type', 'resnet18', 'optimizer_params', 'num_epochs', 'lr', 'seed', 'config.yaml', 'w', 'train', 'tensorboard', 'test', 'checkpoints', 'best.pth', 'tensorboard', 'checkpoint_hash', 'model_model_state_dict', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['Mean absolute percentage error.\\n\\n    `Wikipedia entry on the Mean absolute percentage error\\n    <https://en.wikipedia.org/wiki/Mean_absolute_percentage_error>`_\\n\\n    Parameters\\n    ----------\\n    y_true:\\n        array-like of shape (n_samples,) or (n_samples, n_outputs)\\n\\n        Ground truth (correct) target values.\\n\\n    y_pred:\\n        array-like of shape (n_samples,) or (n_samples, n_outputs)\\n\\n        Estimated target values.\\n\\n    eps: float=1e-15\\n        MAPE is undefined for ``y_true[i]==0`` for any ``i``, so all zeros ``y_true[i]`` are\\n        clipped to ``max(eps, abs(y_true))``.\\n\\n    Returns\\n    -------\\n    float\\n        A non-negative floating point value (the best value is 0.0).\\n    ', 'Shapes of the labels must be the same', 'Symmetric mean absolute percentage error.\\n\\n    `Wikipedia entry on the Symmetric mean absolute percentage error\\n    <https://en.wikipedia.org/wiki/Symmetric_mean_absolute_percentage_error>`_\\n\\n    .. math::\\n        SMAPE = \\\\dfrac{100}{n}\\\\sum_{t=1}^{n}\\\\dfrac{|ytrue_{t}-ypred_{t}|}{(|ypred_{t}|+|ytrue_{t}|) / 2}\\n\\n    Parameters\\n    ----------\\n    y_true:\\n        array-like of shape (n_samples,) or (n_samples, n_outputs)\\n\\n        Ground truth (correct) target values.\\n\\n    y_pred:\\n        array-like of shape (n_samples,) or (n_samples, n_outputs)\\n\\n        Estimated target values.\\n\\n    eps: float=1e-15\\n        SMAPE is undefined for ``y_true[i] + y_pred[i] == 0`` for any ``i``, so all zeros ``y_true[i] + y_pred[i]`` are\\n        clipped to ``max(eps, abs(y_true) + abs(y_pred))``.\\n\\n    Returns\\n    -------\\n    float\\n        A non-negative floating point value (the best value is 0.0).\\n    ', 'Shapes of the labels must be the same', 'Sign error metric.\\n\\n    .. math::\\n        Sign(y\\\\_true, y\\\\_pred) = \\\\frac{1}{n}\\\\cdot\\\\sum_{i=0}^{n - 1}{sign(y\\\\_true_i - y\\\\_pred_i)}\\n\\n    Parameters\\n    ----------\\n    y_true:\\n        array-like of shape (n_samples,) or (n_samples, n_outputs)\\n\\n        Ground truth (correct) target values.\\n\\n    y_pred:\\n        array-like of shape (n_samples,) or (n_samples, n_outputs)\\n\\n        Estimated target values.\\n\\n    Returns\\n    -------\\n    float\\n        A floating point value (the best value is 0.0).\\n    ', 'Shapes of the labels must be the same'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <8x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 8 stored elements in Compressed Sparse Row format>, 'ClassDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Mixin for transforms that can convert non-regressor column to a regressor one.', 'Base class to create any transforms to apply to data.', 'Fit feature model.\\n\\n        Should be implemented by user.\\n\\n        Parameters\\n        ----------\\n        df\\n\\n        Returns\\n        -------\\n        :\\n        ', 'Transform', 'Transform dataframe.\\n\\n        Should be implemented by user\\n\\n        Parameters\\n        ----------\\n        df\\n\\n        Returns\\n        -------\\n        :\\n        ', '\\n        May be reimplemented. But it is not recommended.\\n\\n        Parameters\\n        ----------\\n        df\\n\\n        Returns\\n        -------\\n        :\\n        ', 'Inverse transforms dataframe.\\n\\n        Parameters\\n        ----------\\n        df\\n\\n        Returns\\n        -------\\n        :\\n        ', 'Class to apply transform in per segment manner.', 'Fit transform on each segment.', 'PerSegmentWrapper', 'Apply transform to each segment separately.', 'segment', 'segment', 'feature', 'Apply inverse_transform to each segment.', 'segment', 'segment', 'feature'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <7x7 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Wrapper for :py:class:`pytorch_forecasting.models.deepar.DeepAR`.\\n\\n    Notes\\n    -----\\n    We save :py:class:`pytorch_forecasting.data.timeseries.TimeSeriesDataSet` in instance to use it in the model.\\n    It`s not right pattern of using Transforms and TSDataset.\\n    ', 'DistributionLoss', 'LSTM', \"\\n        Initialize DeepAR wrapper.\\n\\n        Parameters\\n        ----------\\n        batch_size:\\n            Batch size.\\n        context_length:\\n            Max encoder length, if None max encoder length is equal to 2 horizons.\\n        max_epochs:\\n            Max epochs.\\n        gpus:\\n            0 - is CPU, or [n_{i}] - to choose n_{i} GPU from cluster.\\n        gradient_clip_val:\\n            Clipping by norm is using, choose 0 to not clip.\\n        learning_rate:\\n            Learning rate.\\n        cell_type:\\n            One of 'LSTM', 'GRU'.\\n        hidden_size:\\n            Hidden size of network which can range from 8 to 512.\\n        rnn_layers:\\n            Number of LSTM layers.\\n        dropout:\\n            Dropout rate.\\n        loss:\\n            Distribution loss function. Keep in mind that each distribution\\n            loss function might have specific requirements for target normalization.\\n            Defaults to :py:class:`pytorch_forecasting.metrics.NormalDistributionLoss`.\\n        trainer_kwargs:\\n            Additional arguments for pytorch_lightning Trainer.\\n        quantiles_kwargs:\\n            Additional arguments for computing quantiles, look at ``to_quantiles()`` method for your loss.\\n        \", '\\n        Construct DeepAR.\\n\\n        Returns\\n        -------\\n        DeepAR\\n            Class instance.\\n        ', 'Get PytorchForecastingTransform from ts.transforms or raise exception if not found.', 'Not valid usage of transforms, please add PytorchForecastingTransform at the end of transforms', '\\n        Fit model.\\n\\n        Parameters\\n        ----------\\n        ts:\\n            TSDataset to fit.\\n\\n        Returns\\n        -------\\n        DeepARModel\\n        ', 'DeepARModel', 'Make predictions.\\n\\n        This method will make autoregressive predictions.\\n\\n        Parameters\\n        ----------\\n        ts:\\n            Dataset with features\\n        prediction_interval:\\n            If True returns prediction interval for forecast\\n        quantiles:\\n            Levels of prediction distribution. By default 2.5% and 97.5% are taken to form a 95% prediction interval\\n\\n        Returns\\n        -------\\n        TSDataset\\n            TSDataset with predictions.\\n        ', \"It is not possible to make in-sample predictions with DeepAR model! In-sample predictions aren't supported by current implementation.\", 'You can only forecast from the next point after the last one in the training dataset: last train timestamp: ', ', first test timestamp is ', 'The future is not generated! Generate future using TSDataset make_future before calling forecast method!', 'target', 'quantiles', 'quantiles', 'target_', '.4g', 'Make predictions.\\n\\n        This method will make predictions using true values instead of predicted on a previous step.\\n        It can be useful for making in-sample forecasts.\\n\\n        Parameters\\n        ----------\\n        ts:\\n            Dataset with features\\n        prediction_interval:\\n            If True returns prediction interval for forecast\\n        quantiles:\\n            Levels of prediction distribution. By default 2.5% and 97.5% are taken to form a 95% prediction interval\\n\\n        Returns\\n        -------\\n        TSDataset\\n            TSDataset with predictions.\\n        ', \"Method predict isn't currently implemented!\", 'Get internal model that is used inside etna class.\\n\\n        Internal model is a model that is used inside etna to forecast segments,\\n        e.g. :py:class:`catboost.CatBoostRegressor` or :py:class:`sklearn.linear_model.Ridge`.\\n\\n        Returns\\n        -------\\n        :\\n           Internal model\\n        '], 'from': [], 'import': []}\n",
      "{'FunctionDef': <46x46 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 46 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['2019-01-01', 'D', '2019-01-01', 'D', 'feature_1', 'target', 'D', 'Check that Pipeline initialization works correctly in case of valid parameters.', 'horizon', 'Check that Pipeline initialization works correctly in case of invalid parameters.', 'At least one point in the future is expected', 'horizon', 'Test that Pipeline correctly transforms dataset on fit stage.', 'target', 'target', 'etna.pipeline.pipeline.Pipeline._forecast', 'model_class', 'model_class', 'etna.pipeline.base.BasePipeline.forecast', 'model_class', 'Test that the forecast from the Pipeline is correct.', 'target', 'quantiles,prediction_interval_cv,error_msg', 'Quantile should be a number from', 'Folds number should be a positive number, 0 given', 'Test that forecast method uses built-in prediction intervals for the listed models.', 'model', 'Test the forecast interface for the models without built-in prediction intervals.', 'target_0.025', 'target_0.975', 'target', 'target_0.975', 'target_0.025', 'model', 'Test that the prediction interval for piecewise-constant dataset is correct.', 'Test that narrow quantile levels gives more narrow interval than wide quantile levels.', 'target_', 'target_', 'target_', 'target_', 'quantiles_narrow,quantiles_wide', 'Test that prediction interval for noisy dataset is wider then for the dataset without noise.', 'target_0.975', 'target_0.025', 'target_0.975', 'target_0.025', 'Test Pipeline.backtest behavior in case of invalid n_folds.', 'n_folds', \"Test Pipeline.backtest behavior in case of small dataframe that\\n    can't be divided to required number of splits.\\n    \", 'Test Pipeline.backtest behavior in case of invalid metrics.', 'metrics', 'Test train-test timeranges generation in expand mode with daily freq', 'timestamp', '2021-01-01', '2021-04-01', 'segment', 'seg', 'target', 'timestamp', 'segment', 'segment', 'feature', 'D', '2021-01-01', '2021-02-24', '2021-02-25', '2021-03-08', '2021-01-01', '2021-03-08', '2021-03-09', '2021-03-20', '2021-01-01', '2021-03-20', '2021-03-21', '2021-04-01', 'expand', '%Y-%m-%d', '%Y-%m-%d', 'Test train-test timeranges generation in expand mode with hour freq', 'timestamp', '2020-01-01', '2020-02-01', 'H', 'segment', 'seg', 'target', 'timestamp', 'segment', 'segment', 'feature', 'H', '2020-01-01 00:00:00', '2020-01-30 12:00:00', '2020-01-30 13:00:00', '2020-01-31 00:00:00', '2020-01-01 00:00:00', '2020-01-31 00:00:00', '2020-01-31 01:00:00', '2020-01-31 12:00:00', '2020-01-01 00:00:00', '2020-01-31 12:00:00', '2020-01-31 13:00:00', '2020-02-01 00:00:00', 'expand', '%Y-%m-%d %H:%M:%S', '%Y-%m-%d %H:%M:%S', 'Test train-test timeranges generation with constant mode with daily freq', 'timestamp', '2021-01-01', '2021-04-01', 'segment', 'seg', 'target', 'timestamp', 'segment', 'segment', 'feature', 'D', '2021-01-01', '2021-02-24', '2021-02-25', '2021-03-08', '2021-01-13', '2021-03-08', '2021-03-09', '2021-03-20', '2021-01-25', '2021-03-20', '2021-03-21', '2021-04-01', 'constant', '%Y-%m-%d', '%Y-%m-%d', 'Test train-test timeranges generation with constant mode with hours freq', 'timestamp', '2020-01-01', '2020-02-01', 'H', 'segment', 'seg', 'target', 'timestamp', 'segment', 'segment', 'feature', 'H', '2020-01-01 00:00:00', '2020-01-30 12:00:00', '2020-01-30 13:00:00', '2020-01-31 00:00:00', '2020-01-01 12:00:00', '2020-01-31 00:00:00', '2020-01-31 01:00:00', '2020-01-31 12:00:00', '2020-01-02 00:00:00', '2020-01-31 12:00:00', '2020-01-31 13:00:00', '2020-02-01 00:00:00', 'constant', '%Y-%m-%d %H:%M:%S', '%Y-%m-%d %H:%M:%S', 'Check that Pipeline.backtest returns metrics in correct format.', 'per-segment', 'per-segment', 'per-segment', 'per-segment', 'aggregate_metrics,expected_columns', 'fold_number', 'MAE', 'MSE', 'segment', 'SMAPE', 'per-segment', 'MAE', 'MSE', 'segment', 'SMAPE', 'per-segment', 'Check that Pipeline.backtest returns forecasts in correct format.', 'regressor_lag_feature_10', 'regressor_lag_feature_11', 'regressor_lag_feature_12', 'fold_number', 'target', 'feature', 'Check that Pipeline.backtest returns forecasts in correct format with non-daily seasonality.', 'regressor_lag_feature_10', 'regressor_lag_feature_11', 'regressor_lag_feature_12', 'fold_number', 'target', 'feature', 'Check that Pipeline.backtest returns info dataframe in correct format.', 'fold_number', 'test_end_time', 'test_start_time', 'train_end_time', 'train_start_time', 'Check that Pipeline.backtest returns info dataframe in correct format with non-daily seasonality.', 'fold_number', 'test_end_time', 'test_start_time', 'train_end_time', 'train_start_time', 'Check that Pipeline.backtest gives the same results in case of single and multiple jobs modes.', 'Check that Pipeline.backtest gives correct forecasts according to the simple case.', 'Test that Pipeline raise error when calling forecast without being fit.', 'Pipeline is not fitted!', 'Test that Pipeline can forecast with datasets with nans at the end.', 'forward_fill', '1H', 'n_folds, mode, expected_masks', 'expand', '2020-01-01', '2020-04-03', '2020-04-04', '2020-04-05', '2020-04-06', '2020-01-01', '2020-04-06', '2020-04-07', '2020-04-08', '2020-04-09', 'constant', '2020-01-01', '2020-04-03', '2020-04-04', '2020-04-05', '2020-04-06', '2020-01-04', '2020-04-06', '2020-04-07', '2020-04-08', '2020-04-09', 'Check _generate_folds_datasets for correct work.', 'constant', 'D', 'D', 'mask', '2020-01-01', '2020-01-02', '2020-01-03', '2020-01-03', '2020-01-05', '2020-01-06', 'ts_name', 'simple_ts', 'simple_ts_starting_with_nans_one_segment', 'simple_ts_starting_with_nans_all_segments', 'Check _generate_folds_datasets for correct work without first date.', 'constant', 'D', 'D', 'mask', '2020-01-02', '2020-01-03', '2020-01-05', '2020-01-06', 'ts_name', 'simple_ts', 'simple_ts_starting_with_nans_one_segment', 'simple_ts_starting_with_nans_all_segments', 'metrics', 'MAE', 'metrics', 'MAE', 'mask,expected', '2020-01-01', '2020-01-07', '2020-01-10', 'segment_0', 'segment_1', '2020-01-01', '2020-01-07', '2020-01-08', '2020-01-11', 'segment_0', 'segment_1', 'D', 'D', 'lag,expected', 'segment_0', 'segment_1', 'segment_0', 'segment_1', 'D', 'D', 'D', 'lag,expected', 'segment_0', 'segment_1', 'segment_0', 'segment_1', 'quantiles', 'prediction_interval', 'target_', 'target_', 'feature_1', 'feature_1', 'ts_name', 'simple_ts_starting_with_nans_one_segment', 'simple_ts_starting_with_nans_all_segments', 'D', 'D', 'D', 'ts_name', 'simple_ts_starting_with_nans_one_segment', 'simple_ts_starting_with_nans_all_segments', 'target', 'model, transforms', 'target', 'target'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <12x10 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 12 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['\\n    Search for anomalies in values, marked this days as 1 (and return new column with 1 in corresponding places).\\n\\n    Notes\\n    -----\\n    You can read more about other anomalies detection methods in:\\n    `Time Series of Price Anomaly Detection <https://towardsdatascience.com/time-series-of-price-anomaly-detection-13586cd5ff46>`_\\n    ', '\\n        Create instance of _OneSegmentSpecialDaysTransform.\\n\\n        Parameters\\n        ----------\\n        find_special_weekday:\\n            flag, if True, find special weekdays in transform\\n        find_special_month_day:\\n            flag, if True, find special monthdays in transform\\n\\n        Raises\\n        ------\\n        ValueError:\\n            if all the modes are False\\n        ', ' feature does nothing with given init args configuration, at least one of find_special_weekday, find_special_month_day should be True.', 'df_sample', 'columns', 'anomaly_weekdays', 'anomaly_monthdays', 'df_sample', 'columns', 'anomaly_weekdays', 'df_sample', 'columns', 'anomaly_monthdays', 'nothing to do', '\\n        Fit _OneSegmentSpecialDaysTransform with data from df.\\n\\n        Parameters\\n        ----------\\n        df: pd.DataFrame\\n            value series with index column in timestamp format\\n        ', 'target', 'datetime', 'value', '_OneSegmentSpecialDaysTransform', \"\\n        Transform data from df with _OneSegmentSpecialDaysTransform and generate a column of special day flags.\\n\\n        Parameters\\n        ----------\\n        df: pd.DataFrame\\n            value series with index column in timestamp format\\n\\n        Returns\\n        -------\\n        :\\n            pd.DataFrame with 'anomaly_weekday', 'anomaly_monthday' or both of them columns no-timestamp indexed that\\n            contains 1 at i-th position if i-th day is a special day\\n        \", 'target', 'datetime', 'value', 'df_sample', 'columns', 'Transform is not fitted! Fit the Transform before calling transform method.', 'anomaly_weekdays', 'anomaly_weekdays', 'anomaly_weekdays', 'category', 'Transform is not fitted! Fit the Transform before calling transform method.', 'anomaly_monthdays', 'anomaly_monthdays', 'anomaly_monthdays', 'category', 'datetime', 'weekday', 'weekday', 'value', 'value', 'weekday', 'datetime', 'monthday', 'monthday', 'value', 'value', 'monthday', 'Mark desired week day in dataframe, return column with original length.', 'datetime', 'datetime', 'anomaly_weekdays', 'Mark desired month day in dataframe, return column with original length.', 'datetime', 'datetime', 'anomaly_monthdays', \"SpecialDaysTransform generates series that indicates is weekday/monthday is special in given dataframe.\\n\\n    Creates columns 'anomaly_weekdays' and 'anomaly_monthdays'.\\n\\n    Warning\\n    -------\\n    This transform can suffer from look-ahead bias. For transforming data at some timestamp\\n    it uses information from the whole train part.\\n    \", '\\n        Create instance of SpecialDaysTransform.\\n\\n        Parameters\\n        ----------\\n        find_special_weekday:\\n            flag, if True, find special weekdays in transform\\n        find_special_month_day:\\n            flag, if True, find special monthdays in transform\\n\\n        Raises\\n        ------\\n        ValueError:\\n            if all the modes are False\\n        ', 'SpecialDaysTransform'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <6x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['Generate pd.DataFrame with timestamp.', 'timestamp', '2019-12-01', '2019-12-31', 'target', 'segment', 'segment_1', 'segment_1', '2021-05-20', 'D', 'segment_0', 'The input column contains NaNs in the middle of the series!', 'target', 'Check correctness of intervals generation with list of change points.', '2020-01-01', '2020-01-18', '2020-02-24', '2020-01-01', '2020-01-01', '2020-01-18', '2020-01-18', '2020-02-24', '2020-02-24', 'target', 'target'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['y', 'Test for masked_crossval_score method.', 'tmp.pkl'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['segment_0', 'segment_1', 'window_size, alpha, right_anomal', '1', '2', '2021-01-11', '2021-01-09', '2021-01-27', '1', '2', '2021-01-11', '2021-01-09', '2021-01-16', '2021-01-27', '1', '2', '2021-01-11', '2021-01-09', '2021-01-27', 'true_params', '1', '2', 'feature', '1', '2', '2021-01-08', '2021-01-26'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['AddConstTransform add constant for given series.', '\\n        Init AddConstTransform.\\n\\n        Parameters\\n        ----------\\n        in_column:\\n            column to apply transform\\n        value:\\n            value that should be added to the series\\n        inplace:\\n\\n            * if True, apply add constant transformation inplace to in_column,\\n\\n            * if False, add transformed column to dataset\\n\\n        out_column:\\n            name of added column. If not given, use ``self.__repr__()``\\n        ', 'Transformation will be applied inplace, out_column param will be ignored', 'Fit method does nothing and is kept for compatibility.\\n\\n        Parameters\\n        ----------\\n        df:\\n            dataframe with data.\\n\\n        Returns\\n        -------\\n        result: AddConstTransform\\n        ', 'AddConstTransform', 'Apply adding constant to the dataset.\\n\\n        Parameters\\n        ----------\\n        df:\\n            dataframe with data to transform.\\n\\n        Returns\\n        -------\\n        result: pd.Dataframe\\n            transformed dataframe\\n        ', 'segment', 'Apply inverse transformation to the dataset.\\n\\n        Parameters\\n        ----------\\n        df:\\n            dataframe with data to transform.\\n\\n        Returns\\n        -------\\n        result: pd.DataFrame\\n            transformed series\\n        ', 'target', 'feature', 'AddConstTransform'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Implementation of CGD network with multiple global pooling branches.\\n\\n    See original paper:\\n        Combination of Multiple Global Descriptors for Image Retrieval (2019).\\n    ', 'num_classes', 'num_classes should be {}, but is {}', 'num_classes', 'url', 'last_linear.weight', 'last_linear.weight', 'last_linear.bias', 'last_linear.bias', 'imagenet', 'se_resnet50', 'input_space', 'input_size', 'input_range', 'mean', 'std'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <18x18 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 18 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Single-point distribution with infinity density in one point and zero in others.', 'Get distribution parameters.\\n\\n        Args:\\n            dim: Point dimension.\\n            spherical: Whether distribution is on sphere or R^n.\\n        ', 'dim', 'spherical', 'Point dimension.', 'dim', 'Whether distribution is on sphere or R^n.', 'spherical', 'Whether distribution has builtin confidence estimation or not.', 'Number of distribution parameters.', 'dim', 'Returns dict with distribution parameters.', 'mean', 'Returns vector from parameters dict.', 'mean', 'Expected dict with keys {}.', 'mean', 'Parameters dim mismatch.', 'mean', 'Create and return normalization layer.', 'Sample from distributions.\\n\\n        Args:\\n            parameters: Distribution parameters with shape (..., K).\\n            size: Sample size (output shape without dimension). Parameters must be broadcastable to the given size.\\n              If not provided, output shape will be consistent with parameters.\\n\\n        Returns:\\n            Tuple of:\\n                - Samples with shape (..., D).\\n                - Choosen components with shape (...).\\n        ', 'Extract mean for each distribution.\\n\\n        Args:\\n            parameters: Distribution parameters with shape (..., K).\\n\\n        Returns:\\n            Distribution means with shape (..., D).\\n        ', 'Unexpected number of parameters: {} != {}.', 'spherical', 'Get modes of distributions.\\n\\n        Args:\\n            parameters: Distribution parameters with shape (..., K).\\n\\n        Returns:\\n            Tuple of mode log probabilities with shape (..., C) and modes with shape (..., C, D).\\n        ', 'Get confidence score for each element of the batch.\\n\\n        Args:\\n            parameters: Distribution parameters with shape (..., K).\\n\\n        Returns:\\n            Confidences with shape (...).\\n        ', \"Dirac distribution doesn't have confidence.\", 'Get KL-divergence between distributions and prior.\\n\\n        Is not defined for dirac.\\n        ', 'KLD is meaningless for dirac distribution.', 'Compute log density for all points.\\n\\n        Args:\\n            parameters: Distribution parameters with shape (..., K).\\n            points: Points for density evaluation with shape (..., D).\\n\\n        Returns:\\n            Log probabilities with shape (...).\\n        ', \"Logpdf can't be estimated for Dirac density since it can be infinity.\", 'Compute Log Mutual Likelihood Score (MLS) for pairs of distributions.\\n\\n        Args:\\n            parameters1: Distribution parameters with shape (..., K).\\n            parameters2: Distribution parameters with shape (..., K).\\n\\n        Returns:\\n            MLS scores with shape (...).\\n        ', \"MLS can't be estimated for Dirac density since it can be infinity.\", \"Compute product of two densities.\\n\\n        Returns:\\n            Tuple of new distribution class and it's parameters.\\n        \", \"PDF product can't be estimated for Dirac density since it is unstable.\", 'Compute useful statistics for logging.\\n\\n        Args:\\n            parameters: Distribution parameters with shape (..., K).\\n\\n        Returns:\\n            Dictionary with floating-point statistics values.\\n        '], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['exog', 'target', 'Can not infer in_column frequency!', 'ts', 'distribution', 'regressor_exog', 'target', 'segment', 'ts', 'daily_exog_ts', 'weekly_exog_same_start_ts', 'weekly_exog_diff_start_ts', 'ts', 'regressor_exog', 'target', 'inplace,out_column,expected_resampled_ts', 'inplace_resampled_daily_exog_ts', 'resampled_exog', 'noninplace_resampled_daily_exog_ts', 'ts', 'regressor_exog', 'target', 'inplace,out_column,expected_resampled_ts', 'inplace_resampled_daily_exog_ts', 'resampled_exog', 'noninplace_resampled_daily_exog_ts', 'regressor_exog', 'target'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <24x24 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 24 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['2020-01-01', '2020-01-01', 'target', 'regressor_1', '2020-01-01', 'target', 'target', 'regressor_', 'timestamp', 'segment', '2020-01-01', 'target', 'regressor_', 'timestamp', 'segment', 'D', 'all', 'regressor_1', 'regressor_2', 'regressor_3', 'segment_1', 'segment_2', 'segment_3', 'segment_4', 'regressor_1', 'segment_1', 'segment_3', 'segment_2', 'segment_4', 'regressor_1', 'segment_1', 'segment_3', 'segment_2', 'segment_4', 'segment_1', 'regressor_1', 'regressor_2', 'regressor_3', 'regressor_4', 'segment_1', 'regressor_1', 'regressor_2', 'regressor_3', 'segment_2', 'regressor_1', 'regressor_3', 'regressor_2', 'segment_3', 'regressor_2', 'regressor_3', 'regressor_1', 'regressor_1', 'segment_3', 'segment_1', 'segment_2', 'regressor_2', 'segment_2', 'segment_3', 'segment_1', 'regressor_3', 'segment_1', 'segment_2', 'segment_3', 'segment_1', 'segment_2', 'segment_3', 'regressor_1', 'regressor_2', 'regressor_3', 'regressor_4', 'regressor_5', 'regressor_6', 'regressor_7', 'ascending,expected', 'segment_1', 'segment_2', 'segment_3', 'segment_4', 'regressor_1', 'regressor_3', 'regressor_2', 'regressor_2', 'regressor_1', 'regressor_3', 'regressor_3', 'regressor_1', 'regressor_2', 'regressor_2', 'regressor_3', 'regressor_1', 'segment_1', 'segment_2', 'segment_3', 'segment_4', 'regressor_2', 'regressor_3', 'regressor_1', 'regressor_3', 'regressor_1', 'regressor_2', 'regressor_2', 'regressor_1', 'regressor_3', 'regressor_1', 'regressor_3', 'regressor_2', 'ascending,expected', 'regressor_1', 'regressor_2', 'regressor_3', 'segment_1', 'segment_2', 'segment_3', 'segment_4', 'segment_2', 'segment_4', 'segment_1', 'segment_3', 'segment_3', 'segment_1', 'segment_4', 'segment_2', 'regressor_1', 'regressor_2', 'regressor_3', 'segment_4', 'segment_3', 'segment_2', 'segment_1', 'segment_3', 'segment_1', 'segment_4', 'segment_2', 'segment_2', 'segment_4', 'segment_1', 'segment_3', 'top_k,n_segments,n_features,expected', 'ranked_features,features_to_drop,expected', 'segment_1', 'segment_2', 'segment_3', 'regressor_1', 'regressor_2', 'regressor_3', 'regressor_4', 'regressor_3', 'regressor_2', 'regressor_1', 'regressor_4', 'regressor_4', 'regressor_3', 'regressor_1', 'regressor_2', 'regressor_2', 'regressor_3', 'segment_1', 'segment_2', 'segment_3', 'regressor_1', 'regressor_4', 'regressor_1', 'regressor_4', 'regressor_4', 'regressor_1', 'segment_1', 'segment_2', 'segment_3', 'regressor_1', 'regressor_2', 'regressor_3', 'regressor_4', 'regressor_3', 'regressor_2', 'regressor_1', 'regressor_4', 'regressor_4', 'regressor_3', 'regressor_1', 'regressor_2', 'regressor_2', 'regressor_3', 'regressor_1', 'regressor_4', 'segment_1', 'segment_2', 'segment_3', 'segment_2', 'segment_2', 'segment_4', 'segment_2', 'segment_4', 'segment_1', 'regressor_1', 'regressor_1', 'regressor_2', 'segments,features,expected', 'segment_1', 'regressor_1', 'regressor_2', 'regressor_3', 'regressor_4', 'segment_2', 'regressor_1', 'regressor_3', 'regressor_2', 'regressor_4', 'segment_3', 'regressor_2', 'regressor_4', 'regressor_1', 'regressor_3', 'segment_4', 'regressor_3', 'regressor_1', 'regressor_4', 'regressor_2', 'regressor_1', 'segment_2', 'segment_1', 'segment_3', 'segment_4', 'regressor_2', 'segment_1', 'segment_2', 'segment_3', 'segment_4', 'regressor_3', 'segment_3', 'segment_2', 'segment_4', 'segment_1', 'regressor_4', 'segment_3', 'segment_1', 'segment_4', 'segment_2', 'segment_1', 'segment_2', 'segment_3', 'segment_4', 'regressor_2', 'regressor_1', 'regressor_4', 'regressor_3', 'segment_1', 'regressor_1', 'regressor_2', 'regressor_3', 'regressor_4', 'segment_2', 'regressor_1', 'regressor_2', 'regressor_3', 'regressor_4', 'segment_3', 'regressor_1', 'regressor_2', 'regressor_3', 'regressor_4', 'segment_4', 'regressor_1', 'regressor_2', 'regressor_3', 'regressor_4', 'regressor_1', 'segment_2', 'segment_1', 'segment_3', 'segment_4', 'regressor_2', 'segment_1', 'segment_2', 'segment_3', 'segment_4', 'regressor_3', 'segment_3', 'segment_2', 'segment_4', 'segment_1', 'regressor_4', 'segment_3', 'segment_1', 'segment_4', 'segment_2', 'segment_1', 'segment_2', 'segment_3', 'segment_4', 'regressor_2', 'regressor_1', 'regressor_3', 'regressor_4', 'segment_1', 'regressor_1', 'regressor_5', 'regressor_2', 'regressor_4', 'regressor_3', 'segment_2', 'regressor_5', 'regressor_2', 'regressor_3', 'regressor_4', 'regressor_1', 'segment_3', 'regressor_1', 'regressor_2', 'regressor_3', 'regressor_4', 'regressor_5', 'regressor_1', 'segment_3', 'segment_1', 'segment_2', 'regressor_2', 'segment_3', 'segment_2', 'segment_1', 'regressor_3', 'segment_3', 'segment_1', 'segment_2', 'regressor_4', 'segment_1', 'segment_2', 'segment_3', 'regressor_5', 'segment_1', 'segment_3', 'segment_2', 'segment_1', 'segment_2', 'segment_3', 'regressor_5', 'regressor_2', 'regressor_1', 'segment_feature_ranking,feature_segments_ranking,expected', 'segment_1', 'segment_2', 'segment_3', 'segment_4', 'regressor_1', 'regressor_2', 'regressor_3', 'regressor_4', 'regressor_1', 'regressor_3', 'regressor_2', 'regressor_4', 'regressor_2', 'regressor_4', 'regressor_1', 'regressor_3', 'regressor_3', 'regressor_1', 'regressor_4', 'regressor_2', 'regressor_1', 'regressor_2', 'regressor_3', 'regressor_4', 'segment_2', 'segment_1', 'segment_3', 'segment_4', 'segment_1', 'segment_2', 'segment_3', 'segment_4', 'segment_3', 'segment_2', 'segment_4', 'segment_1', 'segment_3', 'segment_1', 'segment_4', 'segment_2', 'segment_1', 'segment_2', 'segment_3', 'segment_4', 'regressor_2', 'regressor_1', 'regressor_4', 'regressor_3', 'segment_1', 'segment_2', 'segment_3', 'segment_4', 'regressor_1', 'regressor_2', 'regressor_3', 'regressor_4', 'regressor_1', 'regressor_2', 'regressor_3', 'regressor_4', 'regressor_1', 'regressor_2', 'regressor_3', 'regressor_4', 'regressor_1', 'regressor_2', 'regressor_3', 'regressor_4', 'regressor_1', 'regressor_2', 'regressor_3', 'regressor_4', 'segment_2', 'segment_1', 'segment_3', 'segment_4', 'segment_1', 'segment_2', 'segment_3', 'segment_4', 'segment_3', 'segment_2', 'segment_4', 'segment_1', 'segment_3', 'segment_1', 'segment_4', 'segment_2', 'segment_1', 'segment_2', 'segment_3', 'segment_4', 'regressor_2', 'regressor_1', 'regressor_3', 'regressor_4', 'segment_1', 'segment_2', 'segment_3', 'regressor_1', 'regressor_5', 'regressor_2', 'regressor_4', 'regressor_3', 'regressor_5', 'regressor_2', 'regressor_3', 'regressor_4', 'regressor_1', 'regressor_1', 'regressor_2', 'regressor_3', 'regressor_4', 'regressor_5', 'regressor_1', 'regressor_2', 'regressor_3', 'regressor_4', 'regressor_5', 'segment_3', 'segment_1', 'segment_2', 'segment_3', 'segment_2', 'segment_1', 'segment_3', 'segment_1', 'segment_2', 'segment_1', 'segment_2', 'segment_3', 'segment_1', 'segment_3', 'segment_2', 'segment_1', 'segment_2', 'segment_3', 'regressor_5', 'regressor_2', 'regressor_1', 'matches,n,greater_is_better,expected', 'segment_1', 'segment_2', 'segment_3', 'regressor_4', 'regressor_7', 'regressor_5', 'regressor_5', 'regressor_7', 'segment_1', 'segment_2', 'segment_3', 'regressor_4', 'regressor_7', 'regressor_5', 'regressor_4', 'segment_1', 'segment_2', 'segment_3', 'regressor_3', 'regressor_2', 'regressor_1', 'regressor_1', 'regressor_2', 'segment_1', 'segment_2', 'segment_3', 'regressor_3', 'regressor_2', 'regressor_1', 'regressor_1', 'regressor_2', 'regressor_3', 'use_rank', 'top_k', 'feature', 'target', 'regressor_1', 'regressor_2', 'regressor_3', 'regressor_4', 'regressor_5', 'use_rank', 'top_k', 'all'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['target', 'add_const_target', 'target', 'lag', 'H', 'Test that SklearnPerSegmentModel saves the list of regressors from dataset on fit.', 'model', 'Test that the number of features used by SklearnPerSegmentModel is the same as the number of regressors.', 'model', 'Test that SklearnMultiSegmentModel saves the list of regressors from dataset on fit.', 'model', 'Test that the number of features used by SklearnMultiSegmentModel is the same as the number of regressors.', 'model'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <6x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['Check that generated_value is equal to expected_value.', 'Check that generated_value is not equal to expected_value, but within 3 sigma range.', '2020-01-01', '2020-01-01', 'add_noise, checker', '2020-01-01', 'add_noise, checker', '2020-01-01', 'segment_0', 'segment_0', 'segment_0', 'segment_1', 'segment_1', 'segment_1', 'add_noise, checker'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['arima', '\\n        Init _OneSegmentSTLTransform.\\n\\n        Parameters\\n        ----------\\n        in_column:\\n            name of processed column\\n        period:\\n            size of seasonality\\n        model:\\n            model to predict trend, default options are:\\n\\n            1. \"arima\": ``ARIMA(data, 1, 1, 0)`` (default)\\n\\n            2. \"holt\": ``ETSModel(data, trend=\\'add\\')``\\n\\n            Custom model should be a subclass of :py:class:`statsmodels.tsa.base.tsa_model.TimeSeriesModel`\\n            and have method ``get_prediction`` (not just ``predict``)\\n        robust:\\n            flag indicating whether to use robust version of STL\\n        model_kwargs:\\n            parameters for the model like in :py:class:`statsmodels.tsa.seasonal.STLForecast`\\n        stl_kwargs:\\n            additional parameters for :py:class:`statsmodels.tsa.seasonal.STLForecast`\\n        ', 'arima', 'order', 'holt', 'trend', 'add', 'Not a valid option for model: ', 'Model should be a string or TimeSeriesModel', '\\n        Perform STL decomposition and fit trend model.\\n\\n        Parameters\\n        ----------\\n        df:\\n            Features dataframe with time\\n\\n        Returns\\n        -------\\n        result: _OneSegmentSTLTransform\\n            instance after processing\\n        ', 'The input column contains NaNs in the middle of the series! Try to use the imputer.', '_OneSegmentSTLTransform', '\\n        Subtract trend and seasonal component.\\n\\n        Parameters\\n        ----------\\n        df:\\n            Features dataframe with time\\n\\n        Returns\\n        -------\\n        result: pd.DataFrame\\n            Dataframe with extracted features\\n        ', 'Transform is not fitted! Fit the Transform before calling transform method.', '\\n        Add trend and seasonal component.\\n\\n        Parameters\\n        ----------\\n        df:\\n            Features dataframe with time\\n\\n        Returns\\n        -------\\n        result: pd.DataFrame\\n            Dataframe with extracted features\\n        ', 'Transform is not fitted! Fit the Transform before calling inverse_transform method.', 'target', 'Transform that uses :py:class:`statsmodels.tsa.seasonal.STL` to subtract season and trend from the data.\\n\\n    Warning\\n    -------\\n    This transform can suffer from look-ahead bias. For transforming data at some timestamp\\n    it uses information from the whole train part.\\n    ', 'arima', '\\n        Init STLTransform.\\n\\n        Parameters\\n        ----------\\n        in_column:\\n            name of processed column\\n        period:\\n            size of seasonality\\n        model:\\n            model to predict trend, default options are:\\n\\n            1. \"arima\": ``ARIMA(data, 1, 1, 0)`` (default)\\n\\n            2. \"holt\": ``ETSModel(data, trend=\\'add\\')``\\n\\n            Custom model should be a subclass of :py:class:`statsmodels.tsa.base.tsa_model.TimeSeriesModel`\\n            and have method ``get_prediction`` (not just ``predict``)\\n        robust:\\n            flag indicating whether to use robust version of STL\\n        model_kwargs:\\n            parameters for the model like in :py:class:`statsmodels.tsa.seasonal.STLForecast`\\n        stl_kwargs:\\n            additional parameters for :py:class:`statsmodels.tsa.seasonal.STLForecast`\\n        '], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['models, transforms, horizons, message', 'target', 'Lengths of the result models is not equals to horizons or transforms', 'target', 'target', 'target', 'Lengths of the result transforms is not equals to models or horizons', 'target', 'Lengths of the result horizons is not equals to models or transforms', 'models, transforms, horizons, expected_len', 'target', 'target', 'target', 'target', 'target', 'target', 'target', 'target', 'target', 'target', 'target', 'target', 'target', 'target', 'target', 'target', 'models, transforms, horizons, expected_transforms_lens', 'target', 'target', 'target', 'target', 'target', 'target', 'target', 'models, transforms, horizons, expected_len', 'target', 'target', 'target', 'target', 'target', 'target', 'target', 'target', 'target', 'target', 'target', 'target'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Check margin in simple case.', 'margin', 'Compare computation with formula-based.', 'dim', 'sample_size', 'approximate_logc', 'Test probability estimation with high concentration.', 'dim', 'max_logk', 'sample_size', 'dim', 'max_logivar', 'parametrization', 'exp', 'train_epsilon', 'sample_size', 'dim', 'max_logivar', 'parametrization', 'exp', 'train_epsilon', 'sample_size', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['quality_scc', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <6x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['\\nMIT LICENCE\\n\\nCopyright (c) 2016 Maximilian Christ, Blue Yonder GmbH\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated\\ndocumentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the\\nrights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit\\npersons to whom the Software is furnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the\\nSoftware.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE\\nWARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\\nCOPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\\nOTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\\n', 'auto', '\\n    Calculate the relevance table for the features contained in feature matrix `X` with respect to target vector `y`.\\n    The relevance table is calculated for the intended machine learning task `ml_task`.\\n\\n    To accomplish this for each feature from the input pandas.DataFrame an univariate feature significance test\\n    is conducted. Those tests generate p values that are then evaluated by the Benjamini Hochberg procedure to\\n    decide which features to keep and which to delete.\\n\\n    We are testing\\n\\n        :math:`H_0` = the Feature is not relevant and should not be added\\n\\n    against\\n\\n        :math:`H_1` = the Feature is relevant and should be kept\\n\\n    or in other words\\n\\n        :math:`H_0` = Target and Feature are independent / the Feature has no influence on the target\\n\\n        :math:`H_1` = Target and Feature are associated / dependent\\n\\n    When the target is binary this becomes\\n\\n        :math:`H_0 = \\\\left( F_{\\\\text{target}=1} = F_{\\\\text{target}=0} \\\\right)`\\n\\n        :math:`H_1 = \\\\left( F_{\\\\text{target}=1} \\\\neq F_{\\\\text{target}=0} \\\\right)`\\n\\n    Where :math:`F` is the distribution of the target.\\n\\n    In the same way we can state the hypothesis when the feature is binary\\n\\n        :math:`H_0 =  \\\\left( T_{\\\\text{feature}=1} = T_{\\\\text{feature}=0} \\\\right)`\\n\\n        :math:`H_1 = \\\\left( T_{\\\\text{feature}=1} \\\\neq T_{\\\\text{feature}=0} \\\\right)`\\n\\n    Here :math:`T` is the distribution of the target.\\n\\n    TODO: And for real valued?\\n\\n    :param X: Feature matrix in the format mentioned before which will be reduced to only the relevant features.\\n              It can contain both binary or real-valued features at the same time.\\n    :type X: pandas.DataFrame\\n\\n    :param y: Target vector which is needed to test which features are relevant. Can be binary or real-valued.\\n    :type y: pandas.Series or numpy.ndarray\\n\\n    :param ml_task: The intended machine learning task. Either `\\'classification\\'`, `\\'regression\\'` or `\\'auto\\'`.\\n                    Defaults to `\\'auto\\'`, meaning the intended task is inferred from `y`.\\n                    If `y` has a boolean, integer or object dtype, the task is assumed to be classification,\\n                    else regression.\\n    :type ml_task: str\\n\\n    :param multiclass: Whether the problem is multiclass classification. This modifies the way in which features\\n                       are selected. Multiclass requires the features to be statistically significant for\\n                       predicting n_significant classes.\\n    :type multiclass: bool\\n\\n    :param n_significant: The number of classes for which features should be statistically significant predictors\\n                          to be regarded as \\'relevant\\'\\n    :type n_significant: int\\n\\n    :param test_for_binary_target_binary_feature: Which test to be used for binary target, binary feature\\n                                                  (currently unused)\\n    :type test_for_binary_target_binary_feature: str\\n\\n    :param test_for_binary_target_real_feature: Which test to be used for binary target, real feature\\n    :type test_for_binary_target_real_feature: str\\n\\n    :param test_for_real_target_binary_feature: Which test to be used for real target, binary feature (currently unused)\\n    :type test_for_real_target_binary_feature: str\\n\\n    :param test_for_real_target_real_feature: Which test to be used for real target, real feature (currently unused)\\n    :type test_for_real_target_real_feature: str\\n\\n    :param fdr_level: The FDR level that should be respected, this is the theoretical expected percentage of irrelevant\\n                      features among all created features.\\n    :type fdr_level: float\\n\\n    :param hypotheses_independent: Can the significance of the features be assumed to be independent?\\n                                   Normally, this should be set to False as the features are never\\n                                   independent (e.g. mean and median)\\n    :type hypotheses_independent: bool\\n\\n    :param n_jobs: Number of processes to use during the p-value calculation\\n    :type n_jobs: int\\n\\n    :param show_warnings: Show warnings during the p-value calculation (needed for debugging of calculators).\\n    :type show_warnings: bool\\n\\n    :param chunksize: The size of one chunk that is submitted to the worker\\n        process for the parallelisation.  Where one chunk is defined as\\n        the data for one feature. If you set the chunksize\\n        to 10, then it means that one task is to filter 10 features.\\n        If it is set it to None, depending on distributor,\\n        heuristics are used to find the optimal chunksize. If you get out of\\n        memory exceptions, you can try it with the dask distributor and a\\n        smaller chunksize.\\n    :type chunksize: None or int\\n\\n    :return: A pandas.DataFrame with each column of the input DataFrame X as index with information on the significance\\n             of this particular feature. The DataFrame has the columns\\n             \"feature\",\\n             \"type\" (binary, real or const),\\n             \"p_value\" (the significance of this feature as a p-value, lower means more significant)\\n             \"relevant\" (True if the Benjamini Hochberg procedure rejected the null hypothesis [the feature is\\n             not relevant] for this feature).\\n             If the problem is `multiclass` with n classes, the DataFrame will contain n\\n             columns named \"p_value_CLASSID\" instead of the \"p_value\" column.\\n             `CLASSID` refers here to the different values set in `y`.\\n             There will also be n columns named `relevant_CLASSID`, indicating whether\\n             the feature is relevant for that class.\\n    :rtype: pandas.DataFrame\\n    ', 'The index of X and y need to be the same', 'auto', 'classification', 'regression', \"ml_task must be one of: 'auto', 'classification', 'regression'\", 'auto', 'classification', 'ml_task must be classification for multiclass problem', 'n_significant must not exceed the total number of classes', 'Two or fewer classes, binary feature selection will be used (multiclass = False)', 'ignore', 'default', 'feature', 'feature', 'type', 'real', 'binary', 'constant', 'p_value', 'relevant', '[test_feature_significance] Constant features: {}', ', ', 'classification', 'feature', 'type', '_', 'feature', 'type', 'outer', 'n_significant', '^relevant_', 'relevant', 'n_significant', 'feature', 'regression', '^relevant_', 'n_significant', 'p_value', 'relevant', 'No feature was found relevant for {} for fdr level = {} (which corresponds to the maximal percentage of irrelevant features, consider using an higher fdr level or add other features.', 'p_value', 'p_value', 'fdr_bh', 'fdr_by', 'relevant', 'p_value', \"\\n    Infer the machine learning task to select for.\\n    The result will be either `'regression'` or `'classification'`.\\n    If the target vector only consists of integer typed values or objects, we assume the task is `'classification'`.\\n    Else `'regression'`.\\n\\n    :param y: The target vector y.\\n    :type y: pandas.Series\\n    :return: 'classification' or 'regression'\\n    :rtype: str\\n    \", 'AllInteger', 'classification', 'regression', '\\n    Create a combined relevance table out of a list of relevance tables,\\n    aggregating the p-values and the relevances.\\n\\n    :param relevance_tables: A list of relevance tables\\n    :type relevance_tables: List[pd.DataFrame]\\n    :return: The combined relevance table\\n    :rtype: pandas.DataFrame\\n    ', \"\\n    For a given feature, determine if it is real, binary or constant.\\n    Here binary means that only two unique values occur in the feature.\\n\\n    :param feature_column: The feature column\\n    :type feature_column: pandas.Series\\n    :return: 'constant', 'binary' or 'real'\\n    \", 'constant', 'binary', 'real'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <7x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['MNIST dataset class.\\n\\n    Args:\\n        root: Dataset root.\\n        train: Whether to use train or val part of the dataset.\\n    ', 'Whether dataset is classification or matching.', 'Whether dataset is for open-set or closed-set classification.', 'Get dataset labels array.\\n\\n        Labels are integers in the range [0, N-1], where N is number of classes\\n\\n        ', 'Get element of the dataset.\\n\\n        Returns tuple (image, label).\\n\\n        ', 'RGB', 'MNIST dataset with different classes in train and test sets.', 'Whether dataset is for open-set or closed-set classification.'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['path to yaml config with desired pipeline', 'path to backtest config file', 'path to csv with data to forecast', 'frequency of timestamp in files in pandas format', 'where to save forecast', 'path to csv with exog data', 'list of all known_future columns (regressor columns). If not specified then all exog_columns considered known_future.', 'Command to run backtest with etna without coding.\\n\\n    Expected format of csv with target timeseries:\\n\\n    \\x08\\n    =============  ===========  ==========\\n      timestamp      segment      target\\n    =============  ===========  ==========\\n    2020-01-01     segment_1         1\\n    2020-01-02     segment_1         2\\n    2020-01-03     segment_1         3\\n    2020-01-04     segment_1         4\\n    ...\\n    2020-01-10     segment_2        10\\n    2020-01-11     segment_2        20\\n    =============  ===========  ==========\\n\\n    Expected format of csv with exogenous timeseries:\\n\\n    \\x08\\n    =============  ===========  ===============  ===============\\n      timestamp      segment      regressor_1      regressor_2\\n    =============  ===========  ===============  ===============\\n    2020-01-01     segment_1          11               12\\n    2020-01-02     segment_1          22               13\\n    2020-01-03     segment_1          31               14\\n    2020-01-04     segment_1          42               15\\n    ...\\n    2020-02-10     segment_2         101               61\\n    2020-02-11     segment_2         205               54\\n    =============  ===========  ===============  ===============\\n    ', 'timestamp', 'all', 'timestamp', 'all', 'metrics.csv', 'forecast.csv', 'info.csv', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': [\"Encode segment label to categorical. Creates column 'segment_code'.\", '\\n        Fit encoder on existing segment labels.\\n\\n        Parameters\\n        ----------\\n        df:\\n            dataframe with data to fit label encoder.\\n\\n        Returns\\n        -------\\n        :\\n            Fitted transform\\n        ', 'segment', 'SegmentEncoderTransform', '\\n        Get encoded (categorical) for each segment.\\n\\n        Parameters\\n        ----------\\n        df:\\n            dataframe with data to transform.\\n\\n        Returns\\n        -------\\n        :\\n            result dataframe\\n        ', 'segment_code', 'segment', 'feature', 'category'], 'from': [], 'import': []}\n",
      "{'FunctionDef': [], 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['__main__', 'data', 'example_dataset.csv', 'D', 'auto-example'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['HolidayTransform generates series that indicates holidays in given dataframe.', 'RUS', '\\n        Create instance of HolidayTransform.\\n\\n        Parameters\\n        ----------\\n        iso_code:\\n            internationally recognised codes, designated to country for which we want to find the holidays\\n        out_column:\\n            name of added column. Use ``self.__repr__()`` if not given.\\n        ', '\\n        Fit HolidayTransform with data from df. Does nothing in this case.\\n\\n        Parameters\\n        ----------\\n        df: pd.DataFrame\\n            value series with index column in timestamp format\\n        ', 'HolidayTransform', '\\n        Transform data from df with HolidayTransform and generate a column of holidays flags.\\n\\n        Parameters\\n        ----------\\n        df: pd.DataFrame\\n            value series with index column in timestamp format\\n\\n        Returns\\n        -------\\n        :\\n            pd.DataFrame with added holidays\\n        ', 'Frequency of data should be no more than daily.', 'segment', 'segment', 'feature', 'category'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <12x7 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 12 stored elements in Compressed Sparse Row format>, 'ClassDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Expected k > 0, got {}.', 'Empty index', 'Expected k > 0, got {}.', 'Empty index', 'faiss', 'numpy', 'torch', 'torch', \"Can't create context multiple times.\"], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['window_size, window_step, expected', 'many_time_series_windowed_3_1', 'many_time_series_windowed_3_2'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <45x16 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 45 stored elements in Compressed Sparse Row format>, 'ClassDef': <8x8 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 8 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Base class for all nearest neighbour metrics.', 'Whether to compare each sample with self or not.', 'Whether metric requires positive scores or not.', 'Whether metric requires confidences or not.', 'Get the number of required neighbours.\\n\\n        Args:\\n            labels: Dataset labels.\\n        ', 'Compute metric value.\\n\\n        Args:\\n            nearset_same: Binary labels of nearest neighbours equal to 1 iff class is equal to the query.\\n            nearest_scores: Similarity scores of nearest neighbours.\\n            class_sizes: Class size for each element.\\n            positive_scores (optional): Similarity scores of elements with the same class (depends on match_self).\\n            confidences (optional): Confidence for each element of the batch with shape (B).\\n\\n        Returns:\\n            Metric value.\\n        ', 'Recall@K metric.', 'Whether to compare each sample with self or not.', 'Whether metric requires positive scores or not.', 'Whether metric requires confidences or not.', 'Get the number of required neighbours.\\n\\n        Args:\\n            labels: Dataset labels.\\n        ', 'Compute metric value.\\n\\n        Args:\\n            nearset_same: Binary labels of nearest neighbours equal to 1 iff class is equal to the query.\\n            nearest_scores: Similarity scores of nearest neighbours.\\n            class_sizes: Class size for each element.\\n            positive_scores: Similarity scores of elements with the same class.\\n            confidences (optional): Confidence for each element of the batch with shape (B).\\n\\n        Returns:\\n            Metric value.\\n        ', 'Error-versus-Reject-Curve based on Recall@K metric.', 'Whether to compare each sample with self or not.', 'Whether metric requires positive scores or not.', 'Whether metric requires confidences or not.', 'Get the number of required neighbours.\\n\\n        Args:\\n            labels: Dataset labels.\\n        ', 'Compute metric value.\\n\\n        Args:\\n            nearset_same: Binary labels of nearest neighbours equal to 1 iff class is equal to the query.\\n            nearest_scores: Similarity scores of nearest neighbours.\\n            class_sizes: Class size for each element.\\n            positive_scores: Similarity scores of elements with the same class.\\n            confidences (optional): Confidence for each element of the batch with shape (B).\\n\\n        Returns:\\n            Metric value.\\n        ', \"Can't compute ERC without confidences.\", 'Compute maximum accuracy for R@1 prediction from confidence.\\n\\n    NOTE: Decision threshold is adjusted using testset.\\n    ', 'Whether to compare each sample with self or not.', 'Whether metric requires positive scores or not.', 'Whether metric requires confidences or not.', 'Get the number of required neighbours.\\n\\n        Args:\\n            labels: Dataset labels.\\n        ', 'Compute metric value.\\n\\n        Args:\\n            nearset_same: Binary labels of nearest neighbours equal to 1 iff class is equal to the query.\\n            nearest_scores: Similarity scores of nearest neighbours.\\n            class_sizes: Class size for each element.\\n            positive_scores: Similarity scores of elements with the same class.\\n            confidences: Confidence for each element of the batch with shape (B).\\n\\n        Returns:\\n            Metric value.\\n        ', 'Base class for @R metrics.\\n\\n    All @R metrics search for the number of neighbours equal to class size.\\n\\n    Args:\\n        match_self: Whether to compare each sample with self or not.\\n\\n    Inputs:\\n        - parameters: Embeddings distributions tensor with shape (B, P).\\n        - labels: Label for each embedding with shape (B).\\n\\n    Outputs:\\n        - Metric value.\\n    ', 'Sample times more nearest neighbours.', 'Compute metric value.\\n\\n        Args:\\n            nearest_same: Matching labels for nearest neighbours with shape (B, R).\\n                Matches are coded with 1 and mismatches with 0.\\n            nearest_scores: Score for each neighbour with shape (B, R).\\n            num_nearest: Number of nearest neighbours for each element of the batch with shape (B).\\n            class_sizes: Number of elements in the class for each element of the batch.\\n            positive_scores: Similarity scores of elements with the same class.\\n            confidences (optional): Confidence for each element of the batch with shape (B).\\n        ', 'Whether to compare each sample with self or not.', 'Whether metric requires positive scores or not.', 'Whether metric requires confidences or not.', 'Get maximum number of required neighbours.\\n\\n        Args:\\n            labels: Dataset labels.\\n        ', 'Compute metric value.\\n\\n        Args:\\n            nearset_same: Binary labels of nearest neighbours equal to 1 iff class is equal to the query.\\n            nearest_scores: Similarity scores of nearest neighbours.\\n            class_sizes: Number of elements in the class for each element of the batch.\\n            positive_scores: Similarity scores of elements with the same class.\\n            confidences (optional): Confidence for each element of the batch with shape (B).\\n\\n        Returns:\\n            Metric value.\\n        ', 'MAP@R metric.\\n\\n    See \"A Metric Learning Reality Check\" (2020) for details.\\n    ', 'Sample times more nearest neighbours.', 'Compute MAP@R.\\n\\n        Args:\\n            nearest_same: Matching labels for nearest neighbours with shape (B, R).\\n                Matches are coded with 1 and mismatches with 0.\\n            nearest_scores: (unused) Score for each neighbour with shape (B, R).\\n            num_nearest: Number of nearest neighbours for each element of the batch with shape (B).\\n            class_sizes: (unused) Number of elements in the class for each element of the batch.\\n            positive_scores: Similarity scores of elements with the same class.\\n            confidences (optional): Confidence for each element of the batch with shape (B).\\n        ', 'ERC curve for MAP@R metric.', 'Whether metric requires confidences or not.', 'Sample times more nearest neighbours.', 'Compute MAP@R ERC.\\n\\n        Args:\\n            nearest_same: Matching labels for nearest neighbours with shape (B, R).\\n                Matches are coded with 1 and mismatches with 0.\\n            nearest_scores: (unused) Score for each neighbour with shape (B, R).\\n            num_nearest: Number of nearest neighbours for each element of the batch with shape (B).\\n            class_sizes: (unused) Number of elements in the class for each element of the batch.\\n            positive_scores: Similarity scores of elements with the same class.\\n            confidences (optional): Confidence for each element of the batch with shape (B).\\n        ', \"Can't compute ERC without confidences.\", 'Metrics based on nearest neighbours search.\\n\\n    Args:\\n        distribution: Distribution object.\\n        scorer: Scorer object.\\n\\n    Inputs:\\n        - parameters: Embeddings distributions tensor with shape (B, P).\\n        - labels: Label for each embedding with shape (B).\\n\\n    Outputs:\\n        - Metrics values.\\n    ', 'recall', 'erc-recall@1', 'confidence-accuracy', 'mapr', 'erc-mapr', 'mapr-ms', 'torch', 'torch', 'Get metrics parameters.\\n\\n        Args:\\n            backend: KNN search engine (\"faiss\", \"torch\" or \"numpy\").\\n            broadcast_backend: Torch doesn\\'t support broadcast for gather method.\\n              We can emulate this behaviour with Numpy (\"numpy\") or tiling (\"torch\").\\n            metrics: List of metric names to compute (\"recall\", \"mapr\", \"mapr-nms\").\\n                By default compute all available metrics.\\n            prefetch_factor: Nearest neighbours number scaler for presampling.\\n            recall_k_values: List of K values to compute recall at.\\n        ', 'backend', 'broadcast_backend', 'metrics', 'prefetch_factor', 'recall_k_values', 'metrics', 'metrics', 'recall', 'recall_k_values', '{}@{}', 'Expected parameters matrix.', 'Batch size mismatch between labels and parameters.', 'broadcast_backend', 'Find nearest neighbours for each element of the batch.\\n\\n        Stage 1. Find elements close to query by L2. Nearest neighbours are searched\\n        for each distribution mode independently (in multi-modal setup).\\n        Stage 2. Remove duplicates caused by cross-modal mining in stage 1.\\n        Stage 3. Rescore nearest neighbours using scorer.\\n        ', 'prefetch_factor', 'broadcast_backend', 'broadcast_backend', 'Find nearest neighbours for multimodal queries.\\n\\n        Args:\\n            x: Embeddings with shape (B, C, D) where C is the number of modalities.\\n            k: Number of nearest neighbours.\\n\\n        Returns:\\n            Nearest neighbours indices with shape (B, C, K). Indices are in the range [0, B - 1].\\n        ', 'Number of nearest neighbours is too large: {} for batch size {}.', 'backend', 'Take first n unique values from each row.\\n\\n        Args:\\n            indices: Input indices with shape (B, K).\\n            num_unique: Number of unique indices in each row.\\n\\n        Returns:\\n            Unique indices with shape (B, num_unique) and new scores if scores are provided.\\n        ', 'torch', 'torch', 'numpy', 'Unknown broadcast backend: {}.'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <6x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'ClassDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Transform that uses :py:func:`~etna.analysis.outliers.median_outliers.get_anomalies_median` to find anomalies in data.\\n\\n    Warning\\n    -------\\n    This transform can suffer from look-ahead bias. For transforming data at some timestamp\\n    it uses information from the whole train part.\\n    ', 'Create instance of MedianOutliersTransform.\\n\\n        Parameters\\n        ----------\\n        in_column:\\n            name of processed column\\n        window_size:\\n            number of points in the window\\n        alpha:\\n            coefficient for determining the threshold\\n        ', 'Call :py:func:`~etna.analysis.outliers.median_outliers.get_anomalies_median` function with self parameters.\\n\\n        Parameters\\n        ----------\\n        ts:\\n            dataset to process\\n\\n        Returns\\n        -------\\n        :\\n            dict of outliers in format {segment: [outliers_timestamps]}\\n        ', 'Transform that uses :py:func:`~etna.analysis.outliers.density_outliers.get_anomalies_density` to find anomalies in data.\\n\\n    Warning\\n    -------\\n    This transform can suffer from look-ahead bias. For transforming data at some timestamp\\n    it uses information from the whole train part.\\n    ', 'Create instance of DensityOutliersTransform.\\n\\n        Parameters\\n        ----------\\n        in_column:\\n            name of processed column\\n        window_size:\\n            size of windows to build\\n        distance_coef:\\n            factor for standard deviation that forms distance threshold to determine points are close to each other\\n        n_neighbors:\\n            min number of close neighbors of point not to be outlier\\n        distance_func:\\n            distance function\\n        ', 'Call :py:func:`~etna.analysis.outliers.density_outliers.get_anomalies_density` function with self parameters.\\n\\n        Parameters\\n        ----------\\n        ts:\\n            dataset to process\\n\\n        Returns\\n        -------\\n        :\\n            dict of outliers in format {segment: [outliers_timestamps]}\\n        ', 'Transform that uses :py:func:`~etna.analysis.outliers.prediction_interval_outliers.get_anomalies_prediction_interval` to find anomalies in data.', 'ProphetModel', 'SARIMAXModel', 'Create instance of PredictionIntervalOutliersTransform.\\n\\n        Parameters\\n        ----------\\n        in_column:\\n            name of processed column\\n        model:\\n            model for prediction interval estimation\\n        interval_width:\\n            width of the prediction interval\\n\\n        Notes\\n        -----\\n        For not \"target\" column only column data will be used for learning.\\n        ', 'Call :py:func:`~etna.analysis.outliers.prediction_interval_outliers.get_anomalies_prediction_interval` function with self parameters.\\n\\n        Parameters\\n        ----------\\n        ts:\\n            dataset to process\\n\\n        Returns\\n        -------\\n        :\\n            dict of outliers in format {segment: [outliers_timestamps]}\\n        ', 'MedianOutliersTransform', 'DensityOutliersTransform', 'PredictionIntervalOutliersTransform'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Test metrics in simple cases.', 'fpr', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <18x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 18 stored elements in Compressed Sparse Row format>, 'ClassDef': <6x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Compare two embeddings using dot product.\\n\\n    Args:\\n        distribution: Distribution used in the model.\\n\\n    Inputs:\\n        - parameters1: First group of distributions with shape (..., K).\\n        - parameters2: Second group of distributions with shape (..., K).\\n\\n    Outputs:\\n        - scores: Similarities with shape (...).\\n    ', 'Compute useful statistics for logging.\\n\\n        Returns:\\n            Dictionary with floating-point statistics values.\\n        ', 'Compare two embeddings using cosine similarity.\\n\\n    Args:\\n        distribution: Distribution used in the model.\\n\\n    Inputs:\\n        - parameters1: First group of distributions with shape (..., K).\\n        - parameters2: Second group of distributions with shape (..., K).\\n\\n    Outputs:\\n        - scores: Similarities with shape (...).\\n    ', 'Compute useful statistics for logging.\\n\\n        Returns:\\n            Dictionary with floating-point statistics values.\\n        ', 'Compare two embeddings using expected cosine similarity.\\n\\n    Args:\\n        distribution: Distribution used in the model.\\n\\n    Inputs:\\n        - parameters1: First group of distributions with shape (..., K).\\n        - parameters2: Second group of distributions with shape (..., K).\\n\\n    Outputs:\\n        - scores: Similarities with shape (...).\\n    ', 'Compute useful statistics for logging.\\n\\n        Returns:\\n            Dictionary with floating-point statistics values.\\n        ', 'Compare two embeddings using similarity based on euclidean distance.\\n\\n    Args:\\n        distribution: Distribution used in the model.\\n\\n    Inputs:\\n        - parameters1: First group of distributions with shape (..., K).\\n        - parameters2: Second group of distributions with shape (..., K).\\n\\n    Outputs:\\n        - scores: Similarities with shape (...).\\n    ', 'Compute useful statistics for logging.\\n\\n        Returns:\\n            Dictionary with floating-point statistics values.\\n        ', 'Compare two embeddings using MLS.\\n\\n    Args:\\n        distribution: Distribution used in the model.\\n\\n    Inputs:\\n        - parameters1: First group of distributions with shape (..., K).\\n        - parameters2: Second group of distributions with shape (..., K).\\n\\n    Outputs:\\n        - scores: Similarities with shape (...).\\n    ', 'Compute useful statistics for logging.\\n\\n        Returns:\\n            Dictionary with floating-point statistics values.\\n        ', 'Compare two embeddings using expectation of L2 sigmoid with trainable scale and bias.\\n\\n    Scorer is used by HIB: https://arxiv.org/pdf/1810.00319.pdf\\n\\n    Args:\\n        distribution: Distribution used in the model.\\n\\n    Inputs:\\n        - parameters1: First group of distributions with shape (..., K).\\n        - parameters2: Second group of distributions with shape (..., K).\\n\\n    Outputs:\\n        - scores: Similarities with shape (...).\\n    ', 'Compute useful statistics for logging.\\n\\n        Returns:\\n            Dictionary with floating-point statistics values.\\n        ', 'scorer_scale', 'scorer_bias'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <8x8 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 8 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['2020-01-01', '2020-05-01', 'timestamp', 'segment', 'target', 'D', 'Check that all the series are divided to the clusters according to mu\\n    (in case of number of clusters is equal to number of different mus).', 'cluster', 'expected_mean', 'cluster', 'expected_mean', 'min', 'max', 'mean', 'min', 'max', 'mean', 'max', 'Check that dtw clustering works.', 'clustering,n_clusters', 'Check that centroids work in euclidean clustering pipeline.', 'cluster', 'cluster', 'target', 'clustering,n_clusters', 'Test that HierarchicalClustering raise error when calling fit_predict without building distance matrix.', 'Distance matrix is not built!', 'clustering', 'Test that HierarchicalClustering raise error when calling fit_predict without building clustering algorithm.', 'Clustering algorithm is not built!', 'clustering', 'Test that HierarchicalClustering raise error when calling get_centroids without being fit.', 'HierarchicalClustering is not fitted!', 'clustering'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <29x27 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 29 stored elements in Compressed Sparse Row format>, 'ClassDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['separate', 'norm', 'Order must be number, got {}', 'Negative order: {}.', 'Compute log IV using SCL implementation.', 'Differentiable logarithm of modified Bessel function of the first kind.\\n\\n    Internal computations are done in double precision.\\n\\n    Inputs:\\n        - v: Scalar order. Only non-negative values (>= 0) are supported.\\n        - z: Arguments tensor. Only positive values (> 0) are supported.\\n\\n    Outputs:\\n        - Logarithm of modified Bessel function result the same shape as `z`.\\n    ', 'Order must be number, got {}', 'Negative order.', 'Von Mises-Fisher Mixture Model.\\n\\n    For MLS implemenation details see \"Spherical Confidence Learning\\n    for Face Recognition\":\\n    https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Spherical_Confidence_Learning_for_Face_Recognition_CVPR_2021_paper.pdf\\n\\n    Layer supports diffent types of k parametrization. Use \"separate\"\\n    to encode k as separate encoder output. Use \"norm\" to extract k\\n    from embedding L2 norm. You can also provide fixed k value, which\\n    will not be changed during training.\\n\\n    ', 'default', 'scl', 'separate', 'invlin', 'default', 'Get vMF parameters.\\n\\n        Args:\\n            dim: Point dimension.\\n            k: Type of k parametrization (`separate`, `norm` or number). See class documentation for details.\\n            parameterization: Type of parametrization (`exp` or `invlin`).\\n            max_logk: Maximum value of log concentration for \"separate\" parametrization.\\n            logiv_type: Algorithm used for log IV computation (`default` or `scl`).\\n        ', 'dim', 'k', 'parametrization', 'max_logk', 'logiv_type', 'dim', 'Feature space must have dimension >= 2, got {}.', 'dim', 'k', 'k', 'Unknow type of k parametrization: {}.', 'k', 'k', 'max_logk', 'max_logk', 'parametrization', 'logiv_type', 'Point dimension.', 'dim', 'Whether distribution is on sphere or R^n.', 'Whether distribution has builtin confidence estimation or not.', 'Number of distribution parameters.', 'dim', 'k', 'Returns dict with distribution parameters.', 'log_probs', 'mean', 'k', 'Returns vector from parameters dict.', 'log_probs', 'mean', 'k', 'Expected dict with keys {}.', 'k', 'log_probs', 'mean', 'Create and return normalization layer.', 'dim', 'k', 'Extract log probs, means and inverse k from parameters.', 'Wrong number of parameters: {} != {}.', 'dim', 'k', 'k', 'k', 'k', 'Join different vMF parameters into vectors.', 'k', 'k', 'All k must be equal to {} for fixed k parametrization', 'k', 'k', 'k', 'Sample from distributions.\\n\\n        Args:\\n            parameters: Distribution parameters with shape (..., K).\\n            size: Sample size (output shape without dimension). Parameters must be broadcastable to the given size.\\n              If not provided, output shape will be consistent with parameters.\\n\\n        Returns:\\n            Tuple of:\\n                - Samples with shape (..., D).\\n                - Means with shape (...).\\n        ', 'Extract mean for each distribution.\\n\\n        Args:\\n            parameters: Distribution parameters with shape (..., K).\\n\\n        Returns:\\n            Distribution means with shape (..., D).\\n        ', 'dim', 'Get modes of distributions.\\n\\n        Args:\\n            parameters: Distribution parameters with shape (..., K).\\n\\n        Returns:\\n            Tuple of mode log probabilities with shape (..., C) and modes with shape (..., C, D).\\n        ', 'Get confidence score for each element of the batch.\\n\\n        Args:\\n            parameters: Distribution parameters with shape (..., K).\\n\\n        Returns:\\n            Confidences with shape (...).\\n        ', 'Get KL-divergence between distributions and prior.\\n\\n        Warning: This is not true KLD, but just simple regularizer\\n        on concentration parameter of vMF distribution.\\n        ', 'Compute log density for all points after normalization.\\n\\n        Args:\\n            parameters: Distribution parameters with shape (..., K).\\n            points: Points for density evaluation with shape (..., D).\\n\\n        Returns:\\n            Log probabilities with shape (...).\\n        ', 'Compute Log Mutual Likelihood Score (MLS) for pairs of distributions.\\n\\n\\n        Args:\\n            parameters1: Distribution parameters with shape (..., K).\\n            parameters2: Distribution parameters with shape (..., K).\\n\\n        Returns:\\n            MLS scores with shape (...).\\n        ', \"Compute product of two densities.\\n\\n        Returns:\\n            Tuple of new distribution class and it's parameters.\\n        \", 'Compute useful statistics for logging.\\n\\n        Args:\\n            parameters: Distribution parameters with shape (..., K).\\n\\n        Returns:\\n            Dictionary with floating-point statistics values.\\n        ', 'vmf_sqrt_inv_k/mean', 'vmf_sqrt_inv_k/std', 'Project points to sphere.', 'dim', 'Compute Log MLS for unimodal distributions.', 'Logarithm of the unit sphere area.', 'dim'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <18x18 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 18 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['%Y-%m-%dT%H-%M-%S', 'Test that LocalFileLogger creates subfolder during init.', 'Test that LocalFileLogger creates folder with config during init.', 'key', 'value', 'config.json', 'Test that LocalFileLogger creates new subfolder according to the parameters.', 'test', '1', 'test', '1', \"Test that LocalFileLogger can't save table before starting the experiment.\", 'keys', 'values', '1', '2', '3', 'You should start experiment before', 'example', 'Test that LocalFileLogger saves table after starting the experiment.', 'example', 'example', 'keys', 'values', 'first', 'second', 'third', 'example', 'example', 'example', 'example.csv', 'example.csv', \"Test that LocalFileLogger can't save dict before starting the experiment.\", 'keys', 'values', 'first', 'second', 'third', 'You should start experiment before', 'example', 'Test that LocalFileLogger saves dict after starting the experiment.', 'example', 'example', 'keys', 'values', 'first', 'second', 'third', 'example', 'example', 'example', 'example.json', 'example.json', 'Test that BaseLogger correctly works in log_backtest_run on LocalFileLogger example.', 'crossval', 'metrics.csv', 'forecast.csv', 'test.csv', 'metrics_summary.json', 'r', 'median', 'mean', 'std', 'percentile_5', 'percentile_25', 'percentile_75', 'percentile_95', 'Test that BaseFileLogger correctly works in log_backtest_metrics on LocaFileLogger example.', 'crossval_results', 'all', 'metrics.csv', 'segment', 'segment', 'segment', 'segment', 'forecast.csv', 'timestamp', 'timestamp', 'fold_number', 'segment', 'timestamp', 'fold_number', 'segment', 'target', 'target', 'fold_info.csv', 'train_start_time', 'train_end_time', 'test_start_time', 'test_end_time', 'metrics_summary.json', 'r', 'median', 'mean', 'std', 'percentile_5', 'percentile_25', 'percentile_75', 'percentile_95', 'aggregate_metrics', 'Test that LocalFileLogger correctly works in with stacking.', '1H', \"we've run one experiment\", 'crossval and crossval_results folders', 'crossval', 'crossval should have `n_folds` runs', 'Test that LocalFileLogger correctly works in with empirical predicition intervals via backtest.', '1H', 'prediction_interval', \"we've run one experiment\", 'crossval and crossval_results folders', 'crossval', 'crossval should have `n_folds` runs', \"Test that S3FileLogger can't be created without setting 'endpoint_url' environment variable.\", 'endpoint_url', 'aws_access_key_id', 'example', 'aws_secret_access_key', 'example', 'Environment variable `endpoint_url` should be specified', 'example', 'experiments_folder', \"Test that S3FileLogger can't be created without setting 'aws_access_key_id' environment variable.\", 'endpoint_url', 'https://s3.example.com', 'aws_access_key_id', 'aws_secret_access_key', 'example', 'Environment variable `aws_access_key_id` should be specified', 'example', 'experiments_folder', \"Test that S3FileLogger can't be created without setting 'aws_secret_access_key' environment variable.\", 'endpoint_url', 'https://s3.example.com', 'aws_access_key_id', 'example', 'aws_secret_access_key', 'Environment variable `aws_secret_access_key` should be specified', 'example', 'experiments_folder', \"Test that S3FileLogger can't save table before starting the experiment.\", 'example', 'experiments_folder', 'keys', 'values', 'first', 'second', 'third', 'You should start experiment before', 'example', 'etna.loggers.S3FileLogger._check_bucket', 'etna.loggers.S3FileLogger._get_s3_client', \"Test that S3FileLogger can't save dict before starting the experiment.\", 'example', 'experiments_folder', 'keys', 'values', 'first', 'second', 'third', 'You should start experiment before', 'example', 'etna.loggers.S3FileLogger._check_bucket', 'etna.loggers.S3FileLogger._get_s3_client', \"Test that S3FileLogger saves table after starting the experiment.\\n\\n    This test is optional and requires environment variable 'etna_test_s3_bucket' to be set.\\n    \", 'etna_test_s3_bucket', \"To perform this test you should set 'etna_test_s3_bucket' environment variable first\", 's3_logger_test', 'test_simple', '1', 'keys', 'values', 'first', 'second', 'third', 'example', 'Contents', 'Key', 'Key', '/', \"Test that S3FileLogger saves dict after starting the experiment.\\n\\n    This test is optional and requires environment variable 'etna_test_s3_bucket' to be set.\\n    \", 'etna_test_s3_bucket', 's3_logger_test', 'test_simple', '1', 'keys', 'values', 'first', 'second', 'third', 'example', 'Contents', 'Key', 'Key', '/', 'r'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['Add logging for method of the model.', 'function', 'line', 'name', 'Calling method ', ' of '], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['Generate simple dataframe with multiple segments.', '2020-01-01', 'timestamp', 'segment', 'A', 'target', 'timestamp', 'segment', 'B', 'target', 'timestamp', 'segment', 'C', 'target', 'timestamp', 'segment', 'D', 'target', 'target', 'target', 'D', 'Check that mapping is correct.', 'A', 'B', 'C', 'D', 'A', 'B', 'C', 'D', 'Check distance matrix in case of euclidean distance.', 'Check distance matrix in case of dtw distance.', 'Check that distance matrix fails on predict if it is not fitted.', 'DistanceMatrix is not fitted!'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['mean', 'threshold', 'margin', 'positive_scale', 'negative_scale', 'Embeddings and labels shape mismatch', 'margin', 'margin', 'positive_scale', 'positive_scale', 'threshold', 'negative_scale', 'negative_scale', 'threshold', 'none', 'mean', 'Unknown aggregation: {}'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['     óǎ    ͦŭ   ', 'cmd', 'data', 'name', 'logger', 'config', 'train_root', 'checkpoint', 'no_strict_init', 'from_stage', 'from_seed', 'dataset_params', 'model_params', 'trainer_params', 'num_evaluation_seeds', 'stages', 'name', 'batch_size', 'num_workers', 'num_validation_folds', 'debug-openset', 'distribution_type', 'distribution_params', 'embedder_params', 'classifier_type', 'vmf', 'k', 'separate', 'pretrained', 'model_type', 'extra_head_dim', 'resnet18', 'loglike', 'num_epochs', 'model_params', 'embedder_params', 'freeze_extra_head', 'resume_prefixes', 'model_params', '_embedder.,_classifier.', 'freeze_classifier', 'embedder_params', 'freeze_stem', 'freeze_head', 'freeze_normalizer', '      ', 'Keys mismatch', 'trainer_params', 'num_epochs', '.pth', 'cpu', 'No checkpoint for prefix {}.', '                 Ɂ ', 'config.yaml', 'w', 'train', 'tensorboard', 'model', 'checkpoints', 'train-0.', 'model_model_state_dict', 'checkpoints', 'train-1.', 'model_model_state_dict', '_embedder._extra_head.', '_embedder._stem.', '_embedder._head.', '_embedder._normalizer.', '_classifier.', '_embedder._extra_head.', '_embedder._stem.', '_embedder._head.', '_classifier.', '_embedder._normalizer.', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <9x9 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 9 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['ŖGene/Ŭàratéǅȱ ȥʙdatǃa\\xadsȑet withͿĕĤ ġnžon-pȒokuāǚsit¬ive \\x89tar˙ŸgeĤʹ·̠ʟtΕȉ.', 'timestamp', '2020-01-01', 'segment', 'segment_1', 'target', 'timestamp', '2020-01-01', 'segment', 'segment_2', 'target', 'timestamp', 'segment', 'segment', 'feature', 'Generκaįtϝe ƃnōŬdȕaǠ\\x83ɸtęa«ʠùǛƠʌset ̾ŢåΡƫwitF͚ˡϞě˼ʘh pξosσiÕtiȓĊve tȁrîgetˀ.', 'timestamp', '2020-01-01', 'segment', 'segment_1', 'target', 'expected', 'target', 'timestamp', '2020-01-01', 'segment', 'segment_2', 'target', 'expected', 'target', 'timestamp', 'segment', 'segment', 'feature', 'target', 'ϫ̎Check t\\x90heʌ vaÕlue oñf Ntranαs˵\\x8ef»Ųoͳrm resultƿ.ʑȦΧ', 'target', 'segment_1', 'segment_2', 'target', 'expected', 'C͉heckĦͪ đthe coĕ~\\x93ʦŗluâmn @naȅʥHǋme΄ ɺaǰfĦ͌ʦět¬er Ŀno,ɹn øiÀnpΣ»ʡͦl͉ace traĜn;sͦfǡo\\x82rîm.', 'target', 'segment_1', 'segment_2', 'out_column', 'log_transform', 'target_log_10', 'target', 'segment_1', 'segment_2', 'expected', 'Ư!ȬChecăk Ɏ\"štha\\x8bt i͒nve˭rseɗĲ_tran\\xads\\x90foƤrmʝ ɽro\\x8eǹllsϺ back transform reδsult.Ξ', 'target', 'segment_1', 'segment_2', 'target', 'target', 'base', '̖CϳǚȘheΎck tha/͎tœ inverse_tʛrĖɝanχsform roΌɣ\\x87llsͿ b΄aˡZck tra˥nÏsforȷȩm¸ rϥeΝ˦ƌsϚul̜ʉtώȑ Ⱥinˈ÷Ôɝǡ ̲ˤ̔caȺseͬ #of gΪi˨veň ouH×ƌωtȔ_cǫÞlu͐ɯmn.', 'target_log_10', 'target', 'segment_1', 'segment_2', 'target', 'target'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <8x8 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 8 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['1d', 'target', 'catboostmodel', '    ƔϠ̒Ɗ͋  ͨ   ͛  ϧ ͻƞΊʁ', 'regressor_exog', 'feature', '1d', 'all', 'target', 'regressor_exog', 'catboostmodel', '2020-01-03', 'D', 'timestamp', 'target', 'segment', 'segment_', 'D', 'Ƶ        θ  Ȓyʯ    ȁ  ȿ  ', 'target', 'target', 'target', ' Ş Ʀ ', 'ŃǇkȑ    ɹ ĵ  Ȃ   ª Ϋ   ', 'Can not get the dict with base models, the model is not fitted!', '˼ +  ƨϏ   Ι  \\x9e  ˒ ĊR υι˻ ', 'target', '2021-01-01', 'D', 'date_flag', 'encoder', 'date_flag_day_number_in_month', 'date_flag_day_number_in_month'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['features_to_use, expected_features', 'all', 'regressor_1', 'regressor_2', 'exog', 'regressor_1', 'regressor_1', 'regressor_1', 'unknown_column', 'regressor_1', 'regressor_1', 'unknown_column', 'Columns from feature_to_use which are out of dataframe columns will be dropped!', ' Ʀ      ', 'feature', 'features_to_use, selected_features, expected_columns', 'all', 'regressor_1', 'regressor_1', 'target', 'regressor_1', 'regressor_2', 'regressor_1', 'regressor_1', 'exog', 'target', 'feature', 'return_features', 'features_to_use, selected_features, expected_columns', 'all', 'regressor_1', 'exog', 'regressor_2', 'regressor_1', 'regressor_2', 'regressor_1', 'regressor_2', '\\x89Τ        ͊æʹǻ    Ǫ  Ƣ ', 'feature', 'features_to_use, expected_columns, return_features', 'all', 'exog', 'regressor_1', 'regressor_2', 'target', 'regressor_1', 'regressor_2', 'regressor_2', 'regressor_1', 'exog', 'target', 'all', 'regressor_2', 'exog', 'target', 'regressor_1', 'regressor_2', 'regressor_2', 'regressor_1', 'exog', 'target'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['pen', 'epsilon', ' is not a valid ', '. Only ', ', ', ' modes allowed', 'GʔȅivƃeπˣŊϡʾ̭΄ɝ;ǟá nƅexέǈPtě˓ vζalue ǡaЀc°Fco¯ˏſ̕rd͘i͟nĂ˙g͒ ʙιŹ_toϺς bHȊ̝ɩinϕ̭\\x82aũry Ǡùɵseaɂ˿rƣch.ζ\\n     \\n\\nPaʸrϴaĿmȺet˭eLĜrsí\\n-ä̍--ĵ----Ͱ---\\n*nʗowāǡ_ʵvaâΤlýue:\\nĊ    cpur!ɘπr̋eǖnt \\x98valĽuƙe\\x9c\\nl1˺ƓoweZşrȯ_b΄ëou˘ȷnd©:\\n  \\x9bΰ \\x90ĩ l͞ower ΛboϏundʒ foĵɪr8ʢ ̴\\x98sea\\x80Ȓr˓ȷcɪhĞ\\nĳʫupper_boͳϨundŬΰ:βɈœ\\n  ü t uǊp̆̓per boΒu̮ɳͱnd˭ ǚϒforƈľ> seŗŬarϥcǢ̍hǳ\\u0381\\n\\x87n̯7heeȲd[_gȋr̺eaɪˤÄtÜer˰ʏ:\\n ͺ\\x86 ɓ˔  ΰTrΡue ÿiǟfǍ weʵ nφeed˰~ gʘre͇ater̵ ǀv˧ΌȊalueͿ fɳor n_ĔUbʪkΌps Ƕgthan ʕ´\\u038bpϫŊrŕɦĎevious¬ timƢe\\n\\nȪΣšRe̡t͘ʵuǍ˃r[n`̦\\u0383̫s\\n-ϥ-Ǉ---ġ--͓ȴϣ\\nΟǐ:\\nł  Ϟ υ̋̒ʵ ħn\\x83eśxtϜ±ȿὨ value ƺaǑnd itβsό b̾ɱo³eund\\x89s', 'Run ơbinary search fɳor optimal r½egularizatǽions.\\n\\nParameters\\n-Ώ--------A-\\nserieŰs:Ϛ\\n   \\n\\n     \\n    series forʘ search\\nchange_point_model:\\n    model Ʋto get trend change points\\nn_bkMps:\\n #vsgEy\\n    targeti nu¢mbeƤrs of chaϙnge_pointsͿ\\n!opt_param:\\n    parŴameter for optɶimization\\nmax_valuƘe:\\n    maximum possible value, the uȸpper bo˱und for ʘĨPseɶarch\\nmax_iters:\\n    NmaŶximum iterations; in case if ɨthe required nu·mber of poinȗts is unattainable, values ͓wǀill be selɮected after maxʹ_iters iterations\\x8d\\n\\nReșturns\\n     \\n-------\\n     \\nɘ:\\n    regularization paramƌet϶eÊrsy value\\n     \\n\\nRaiͯsesɿ\\n______\\nValueError:ǧι\\n ó  ƫ IĎf max_value is tɧo\\x9eo low for neededǤ n_bkps\\nValueErrɂor:\\n   ľ If n_bkps ́is tɐooǮ high fo̚Ĳr tƪhisƊ series', 'Impossible number of changepoints. Please, decrease n_bkps value.', 'Impossible number of changepoints. Please, increase max_value or increase n_bkps value.'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <6x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Convert dataset to mxnet format', 'src', 'Source dataset root', 'dst', 'Target dataset root', '--dataset', 'Type of the dataset (like in training config)', '--batch-size', 'Batch size', '--num-workers', 'Number of loader workers', 'jpeg', 'w', '    đ   Ǟ     ˯ ɥq   Ƈ ', 'classification', 'num_classes', 'num_samples', '  ˰ ǆΡ', 'name', 'validation_fold', 'add_verification_testsets', 'add_lossy_testsets', 'train_repeat', 'Datasets:', 'Skip verification dataset', 'Serialize', '.yaml', '.labels', '.idx', '.rec', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Run forĢwșGard for default model.', 'logits', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <9x8 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 8 stored elements in Compressed Sparse Row format>, 'ClassDef': ['D'], 'AsyncFunctionDef': [], 'String': ['DTW difstance handler.ͧ', \"BuȿͯÚiēl͗Õdǅ a ̟w'a9ƽQ÷˪rping ̕ɢp͘atǐγȞ̂ǏBýh wiĵȴ̀t͋h ~͞gi0CʷĢͣɓΖʴǥ@vLeύ3n matrix ͩofǟ̢ɧ dtɥw-dɉisǪtƶance.Ŧ\\x7f\", 'TSDataset', 'Gő̲̔Õϐ˼etǼƭ sЀerieưs ϻfrÒom the øTSDa˔ta\\x95͢Ţsetž̤˴Ǜ.', 'target', 'TSDataset', 'GetʽǮ\\u03a2 seriʸes tʧhatŊƜζςͦϑ mǳci˦nÌǚͷǆi$miρzːƦ̲ɚ̭ͫešȀs sqǦu̯Ⱥaϯr˃Ǻϋe͡ʅd˸͚ ĭdiȖst̩̂£aǈȟnūø̈́c;ϔǦe ¢°to giv˽en ĻoůŞĭne;s aă×͉cˣ7ȊcoŌrdϯing to ϢthHe ơdtw dǣȚ\\x81\\x8ciř͔sǓϑtıƨanËƝcĴe.\\n\\nĨƞPya¯ɨrưamet̗äeϠrsͳʱĢΨ\\nE--̲³-ȩ-˱---q-+--Ȁ\\nts:EϬϥȜÊ\\nÐƜ öǬ ͺ  T&SXDaĲŲt{ˬaǿưˁðs̗̥et#̅ ŷȟw̦ith serieǨs to ϘϬTbϼe avȢeraͧŘŭ\\x86ged\\nƇ6n_iʨtńe̽)̭rs͒:\\n ůϸˊ  Ď nϠumber ǁoΫ˟ȈɎǏ͌γfϚ\\\\\\x8eA ΦD̼BFȬ\\x7fƦļÍA Şnit˾er˔ďΛùǣa\\x83Ά_ti÷ĘonsA ątoę˃ ˳aÿGŒΗ\\x80̓dj5usƹλtϊ ceα˼ƒntʇroäƵid÷ΰτ wiρ8̈ƞtƱhˋ se[riesŵ\\n\\u0383\\nƆRď×etpurns\\nͶ-ǘɄͲ--˞-ϫʄgς-Ū[ǋ--\\n͂ɇp̮\\x96Ł̈\\x90d¡.Dɢatƿƕ̯aframȓeϾ\\x94̔ƈ̊Ϲ:Ĳ\\x9a\\n\\x9eĶ    dț͘atɅƑafrȇǍϳɴame˽ ϘǻÀwitĴhŘ ÑcolƖ\\x9a̫uΊāÇmňsͳǢ nƨ\"̘̤tſi¯meĥstaěͻmɜpŐ\" anΫbϣdǯǁ \"Ɣ˫tʵaƼĉȸǣrǖgˮɊet\" ŨÇtȠhatÝ̠ conʇtaʋins ϐƹ˽tʗhυe seͳr̴i@es˯', 'timestamp', 'target', \"IǫΛnf͏ĪiĶ\\u038bt DTWʋòDi̢staɰϧnv̠ƣcʤe.\\nΞʀ\\nPar\\u0383ύameterɉs\\n0\\u0379έǛ--ǝ--À̛Ϋ-˽σ\\x9dι-ūɒ-ˆ--\\u0378Ë-\\npo\\x92inɔ=͊ts_ΐ˔dǑiŏΩsʛtance͠[ĉȚī:ć\\n  ȷ \\x9f ňè\\u0382Ʋf˕pŊuǊnctˤĩ÷ǐ͛Ƒġiɰˠon ɻǱt̋oõ bϴɅe u\\x99©ºŽsɃǣ̙edǖΣ ¶Ŧǌīfor c̒oȫmpΪuƏġtatŇäiʱşũoξǎnŏĎĖ of di>ǛŹsƄtȨance \\x90ǭbetwƴeȍ˅en t͓wơ·ȌoɗŎ s˼̦eriȥŗes'ø poiȘnśƣɤƨVtǟsΖ!\\ntrxim_Ƞseʯries:\\nƿ͛Ěλ¾    TϹ¢ru\\x8bȍŒe iȏ/fˋ͚ Ιʚit Ρϡiɰs δɌn˰ecesΞ˔sýϪaȰr\\x9ay ɲato Ót̓rimƌ̂ǆò\\x81ÁŹ ͜seɺries, Ũdď©e˝˯fŝauωʟlt̸ǋƏ Fals̯e.Ɏ̴\\x99Ĭw\\n÷\\nǏNotʗe͝˥sˮˈ\\n-----\\n̦ǆS\\x85peǔ7ϹcifŃƂyǌˇȟiŷng͏ mΑaņǹȭŵɬnu\\x83al `j`ģŤϯpoɈ̳Ͷ͛ʡiĵǾnÄÎtđsĵaǞƐÄ_ƸʆdÁisȬʢϭtςaü͓nƸcδeŻξ``ύ mA̢i͜ΨgĂht˫ Mǽƪƫ͵ŝsɹl̓9ow ˛τdoȏwɣn tΜOh˙e c%lusteȣŘring ̲alƈʵ͋gorÆiŎthmϧ.\", 'ComĀputΑeĻ͓ disȀtaϳnce īļbe\\x96ŷtwėen̰ ˍx1 and x2.', 'TSDataset', 'GJet ϺthÑe ¬âlˢongeΕst ŉņϊɔseΊrīiʖes fϾ˚rȘom the list.', 'target', 'DTWDistance', 'simple_dist'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['          ', 'adaptive', 'params', 'params', 'params', 'adaptive', 'params', 'adaptive_bias_and_bn', 'params', 'params', 'params', 'params', 'adaptive_bias_and_bn', 'params', 'params', 'params', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <16x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 16 stored elements in Compressed Sparse Row format>, 'ClassDef': <8x7 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['WɆîø͖̓hȰeǔàJther hiɳg0heǈr Ϡmet\\x83Ńri̍ϡcЀĚ valƹπŁu˼e Ϲis bƓetterŧƻ.\\x84', \"̿˚ŇInXitǽùï m͖˫etric.\\n   \\nˠȜ\\nParaʙɎȅmeϸters\\n--έƪʩͩ-------˫Ȇ-ȗ\\nmĒoϔde:\\x9b³ 'macro̲' ƅŕor 'pe\\x9aΌĢrŚ-segment'ǪΣ\\n   ´ mǞĎeǌŨ̈Ɣtrics aĠgg̕ʥregatioΈnǼ ȚȂmode\\n   \\ṇ¥kwϴͿargƬs:̙\\nɝ   Ϫ mΨetÂrȊic˘'sǖ˜ ʱcompuǙtationœɊ arguǢmȹeͻnǌtĕǁsŰƧ\", 'Coefficient of determination metric with multi-segment computation support.\\n\\n.. math::\\n  R^2(y\\\\_true, y˛\\\\_pred) = 1 - ̻\\\\frac{\\\\sum_{i=0}^{n-1}{(y\\\\_true_i - y\\\\_pred_i)^2}}{\\\\sum_{i=0}^Ě{n-1}{(y\\\\_truˍe_i - \\\\overline{y\\\\_true})^2}}\\nNotes\\n-----\\nYou can read more about logicϏ of multi-]segment metrics in Metric docs.', \"InČi˃¬pt¤ϯ mǜetric.ÞȤ˴\\n\\n   \\nPǅƛj«įara\\x85mře͚ters\\nϡƶȻ̕-Δσ--R-Ŏ--S-±ė}--˹-̕š\\nemoΛ³wdeǾ: 'ma̖cro'\\x7f orƫɃ 'Ĭper-seɵgmenƽet'\\n\\nː \\u0383̗ʇ   ǽûmetr\\x97ic\\u0379˞ˁs΄ α͋aʎȉg\\u03809gr\\x84ƒɆeȝgδϒɊßaƍtioŠn Ʒmo»dée\\nЀkùώwargs:̓\\nű ŝ  ¤© metrƀic's coǟmʔput̺aħŋntioȡ¤n Βη4ÔͶ˟ȧr˳g\\x98u}meħnƈtsɟ\", 'WẖϙŏŎethΰerό ɝhϣighǚer metric valuÑeϝʅ is bettʌeϠr.', 'W¿ƞhe΄$ɢϖİtheʁr ¯Ȃh˪igȑhϺer\" mʩewɅtric va̦Ʒlueĝ ʺȟȗi\\x93s¶ bϋetteφr.', 'ˍM\"̢eˊƈʁ̫ȂdpiaƏn aʁb̗sǰȆolƔĥutȋɑe ƲerrϾoƮƻr͓ metrSic with m;ȣullti-Ɣsϫegmeânt cͳƐoḿȈc̋ΣpjϺƢuʽǳtaɃtion ƍsȘ̷ŵuppŵorϠt.\\u0381͡#TtDazkJSCbvfUrwHBsi\\n\\n.\\x95\\x88. ʑ̓maĴth::Ȥċ\\n   MeÎdA\\'ÂE(y\\\\Ŋ_ɝtr̓uŌeƥ,7 yƪ\\\\_ǜp˪ʳ{ßrɩeťƓd) = mɛÊơɽͩedЀianϻL˙ɏǽ(Ė\\\\šɻmiψǫd QȻ,y\\\\ǹ_tťrǁǪɐue_1ĔnϚ ςĦ- y\\\\̬_Ńˆp̢reʽƣƻdό_1 \\\\mid, \\\\XcÆdoƙȡB̼t̼sǣ˗, \\\\ʭmʶid 8y\\\\_ðS_tūrue̤_n -į y\\\\ʒ_predȲºαε6_n ǻ\\\\˵͎Ηmj\\x88iǫ\\x9ad)ȉ;\\n\\n   \\nNotKes˟\\n-ů----ɂͮÕ\\nşYou øcanɻϒ reaǜĹͯd ĲmorŬeăɅ faboutǽǛ ϚlʭŌǭoŹg.iDc oOf mulʯ\\x88tǲ\\xa0i-őseɑȸtgmén\\u038d̏t \\x8fm̌Ĭetriǃcs Ήin˽ Me©triǓc docsȞϯƩɆ.', \"Iͪni͇tő mʗ΄\\x88etșriƇcʬ.\\n\\n\\nőPġa̝̘ramleters\\n--đ\\x9a˙--------\\nmoϧǘdɢe: 'mϡacro«' orá 'per-ϟseg¶ment'\\x9e\\n\\x9f ί   mĆ͘etrics aggrΰeg˻ati»on mod̶e\\nΔkĨwƑƣargs:\\n   #IRGALdUSpboxzrXlqB\\nͮ ̿ ı  Ͷmet̋ric's cʡoɐŲmpuȔtatio%n aʢrguments\", \"Init metric.\\nŋ\\nParameters\\n----------\\nmode: 'mac·ro' or 'per-segment'\\n  metrics aggregation mode\\nkwargs:\\n  \\n  metric's computation arguments\", 'ʶSơigĘŮn eˀrror\\u038d σmeǜtric åwŦi\\x8eĹth mϒultǣΔάƑi-ĮsegmoenɈǋt cφomǍputǻatδioȽʭn ɘǅsΓu̡ppŦɨäort͜.\\niΞȡ\\n   \\n.ˬH.ūŢ mȳat̕N˃h::ˮɥįƸ\\nͨϼʘ  Sign(y\\\\_true»Èϻ, y\\u0383\\\\_ʃ̲ēɀhpredʨ) =ʻ ȗŶϝ̘̋ȶ\\\\f\"\\x8aŒrƇac{Ƿ1}C{n}\\\\ǝ\\x8aΥȯcȒ̓τdɧo͓Ut̷\\\\ȸϭsumˋ_{i=ʗϠƖ0}^{n -ʟ Ƴ1ǆ\\x9dȹ̳͢}{signřș(y\\\\_tr!uDe˼Ǒ_i ǋ-ɡ y^\\\\̜ʼň_ȺpςrĶȈed_i;å)ˏ}Ű\\nϚʱ\\nNoteʚ>Ǻ\\x9eƺČϙșs\\n---ʖťϵ(Κ-̴ǭͻ-\\nYȜιou cŬá˓n rϑΒ̉ÿeadˁé more¥ aɬbĴ̃out ͻlogic Ȏoχŗf ˶̵mʍÉulɈti-segm\\x94ent mÞetr\\x81ʑics ino MeɈtrˎic dȏocs.', 'MAE', 'MSE', 'R2', 'MSLE', 'MAPE', 'SMAPE', 'MedAE', 'Sign'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <9x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 9 stored elements in Compressed Sparse Row format>, 'ClassDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['new_value', 'mean', 'none', '  ', \"The strategy '\", \"' doesn't exist\", 'LabelEncoderTransform', 'Inilt ϹŦÔLɇǁŶabelEncoderTraǡnsfoɮrňĲm.˳\\n\\nPīarameͬters\\n---ϡ--˙-ϲʉ-ǆ---ɑ\\ninÄ_cʊolumnɔ:\\n    Namǲˎe ǻoGf column to ʥbe ϖtºransformed\\nout_>coϠlumʱƚn:\\n    NaɋͲme ofʖ a¼dded c͕o̡lu̩mn. Ifh not giveĄnͬ, use `v`ÀseÇlf.__rep̿ȸr__()`Ɇ`¦̣\\ns¼trΦategͣy:Y\\n    Fi͊lling ːenɯcodɻing in nɳΔoƇt fiƴÒȮtted vͤaluƩĉes:\\n\\n Ť  è - If \"new_vȐaluȫDee\"F, ƮthĴɉen reδplǲacȅe \\x80missing valuesƠ wi#th \\'-1\\'̙\\n\\n    ǫ-Û If \"mͶěʔaϹn\"ȭ, ƆtheƝn replacϲe mis\\x91sing valuʕe²\\u038bs ˣusing thϱe meʱa¹n in ɨencodedĬβ,ƌ colʱumn\\n\\n͑ʮ    - ơIf \"none\", ǽthen r˺eplɅaĄce\\x83 missingȄ values ƦEwđ̩ith̤ Ñone', 'ǼEncodǀe theΪ ``˨̰i?n_ͭcoluǮΞɰĀmĉ:n`͉`ÍΚ ζK|bØ̊ǻy fiÛtƑteņǘ˾Ãd L\\x85abeýʞǳl ʔ˷enɈ\\x84codeʄr.Ĳ\\n\\nȒPȐϋĖaƑrɋam̥eǷƝtϞĤqϿ&ļðʁe<rsʐϯ\\n--ŷ\\x88---u˿-----\\n,dŤʍf\\nˍʟ ϗ \\x9e  ͞ȇDat͠͝afϛrƳaàme wɵiĦɜɛtĊh͘ ̻dȻa˹tœaȮΊ ŀtoǳų̜ ͨtrȅʛansfoήrḿ\\nǿ\\nĮReΙtuΦ̑šȠʖɃˉrƂķṇόs\\n̩--ʀ----ɬĻƻ@-ţ\\nĽ:\\n ±ŵ ΪƖ0ʎ \\u0380 ďDatĜµˍa9frɨ/ǳa\\xadmåeȀ wi\\u0379tȒȚɳEhͬʡ żc¸olum͓n wİithƭĉȷ eXně\\x90ā˕ξcoħdedģ ʭΓʂ˳ϼvȪɩaluẻs', 'category', \"ʈGeǩüt ʭthe `ƥ`Ǐķout_coͬlumniƙ``Ί dɎependiÞng Ʀon theàϝ tŷƊĹr̾ĴansfĊorm's paraɾm-£etersƇ.ž\", 'Encode ˷caΙtegoriϡcǄa\\x9bĺl făe̖ature\\x97Ŀ0 as a ǽoneɶ-hot ͉n˥umƣeőr˟ic f̂eaɗtuȫres.\\nü\\nIf unknown cφateʜgoryͳ˽ i˿ɟs \\x8dencouψ²ŋȝʸʏnƞtered duri\\u038dnˠg trŁansπform, tϻǷhe re]sultiňgˋ !ìone-ͦhot\\nencodeǯZdāi col\\x87̱ίu;mns f͚or th˒isͯ fÝe̟a\\x86tuɷre˧ Ȋw˚ill be ałll zeros.', 'Enνcodeů the `Ȇin_cɸolumn` żɟby ͌fi2tted One ͫHªot encoɪder.̓\\n\\nParǺameters\\n--------ϛʗ--\\ndf\\n    D˞atafrÒame wiɎt\\x9eh dϪɬata to ţrľan\\x87sfŻoʆƆrƐm\\n\\nRƌetuːr͇\"»σn3s\\n---˜----\\n:\\n  ƭ  ƦDataframeΊ ϱώwithɽ column witȯɛh encodJed valȻues', '_', 'category', 'Iǁ̔nͰitʌ Ɨ϶łOnϛeHotEncoderˀTrƒňanřsÃform.\\n\\nǶParameters\\n--Δ-ú-ɉȤ----ƫ-ž̖-\\nin_colŤumn,:\\n   \\x80¹ Nam˚e (oȫfɄ ʾcolumn to be δenco˾ded[Ȼ\\ṉout̸_column:˽\\nˊ Ȯé   Pre͏fix oȬf names Ɠof aÖƵddeȣd co̜lȆumns.̀ ŠIf not given, use ɸ``self̱Øİ.__rǲepr__()``ιƔǟσ', 'ignore', 'OneHotEncoderTransform'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['expected_global_means', '    ', '  ˳    Ž   Ē', 'timestamp', '2021-06-01', '2021-07-01', 'D', 'timestamp', '2021-06-01', '2021-07-01', 'D', 'segment', 'Moscow', 'target', 'segment', 'Omsk', 'target', 'D', 'k͒Test that MeąnSegment̂EncoderT̰rɨansform works correctlͦy in forec\\x9baj˧st pipeline\\nand helps to Şcorrectly forecast ǖalmost constant series.', 'macro'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <6x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['2000-01-01', 'D', '        ͭ          ʼ', '2000-01-04', 'D', '  Ϭ ƚ ƊZ   ', 'All the pipelines should have pairwise different horizons.', '        ǡ  Ē'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['Input checkpoint path must be provided', 'Output checkpoint path must be provided', 'tensorboard', 'embedder'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <11x11 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 11 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': [' ů  0    ͦʑ ', '2020-01-01', 'D', 'timestamp', 'exog_1', 'exog_2', 'exog_3', \"Parameter segments shouldn't be empty\", \"'wrong_format' is not a valid DataFrameFormat\", 'segment_1', 'segment_2', 'wrong_format', 'Tesˈt that `duplicate_data` fails on wrong df.', \"There should be 'timestamp' column\", 'timestamp', 'segment_1', 'segment_2', 'segment_1', 'segment_2', 'long', 'segment', 'segment', 'segment_1', 'segment_2', 'wide', 'timestamp', 'segment', 'timestamp', 'timestamp', 'ˊUˬnit Ͼtest Űf»Ȱořr `_TorchDaʛǬɢʌt͗asͅeǆ͟t` ϡclasͩʌs.', 'decoder_target', 'encoder_target', '  Ɛ  ʢ³Ž  ůǐ  \\x99  č ǿ ̙  ', '2020-01-01', 'target', 'exog_0', 'exog_0', 'exog_0', 'exog_1', 'exog_0', 'exog_2', 'exog_1', 'D', 'segment_2', 'segment_0', 'segment_1', 'target', 'exog_2', 'exog_1', 'exog_0', 'Ά Ź ɤ ', '  W̹ ͱ ', ' ', 'segment', 'segment', 'feature', 'feature', 'features_left, features_right', 'exog_0', 'exog_0', 'exog_0', 'exog_1', 'exog_0', 'exog_1', 'exog_0', 'exog_1', 'exog_1', 'exog_2', 'segments_left, segment_right', 'segment_0', 'segment_0', 'segment_0', 'segment_1', 'segment_0', 'segment_1', 'segment_0', 'segment_1', 'segment_1', 'segment_2', 'timestamps_idx_left, timestamps_idx_right'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['.hydra', 'config.yaml', '2021-06-01', '2021-06-01', 'target', 'regressor_0', 'regressor_', 'pipeline', 'backtest'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <26x26 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 26 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['segment_1', 'target', 'segment_1', 'target', 'segment_2', 'target', 'segment_2', 'target', 'target', 'wrong_strategy', 'wrong_strategy', 'target', 'target', 'target', 'fill_strategy', 'mean', 'constant', 'running_mean', 'forward_fill', 'seasonal', '\\\\Checÿϡk th˻\\x80̴ƕ\\x93aXitȉ ̿imp͎Ăɓɳutʞer ϔdoges noΎthinĈϹg wi®th sűeΗrκΤieǬɰs withˤo͍uΟƕt gaps.', 'segment', 'target', 'target', 'fill_strategy', 'mean', 'constant', 'running_mean', 'forward_fill', 'seasonal', \"ϥ͒C*h˅ecήkɰ ©Țthat imÇpâuʪt0ȌƝerϲ cϠan't f̘iɕlʌĆǽ\\x97l Ϊ¦vɄnanesėΤ Ųǝif˧ȑ ϑall val<\\u03a2ues° VɹarϮɵe ΎnϧǤ^\\xa0;̬aÒnğs.ŨĮ\", 'target', \"Series hasn't non NaN values which means it is empty and can't be filled\", 'fill_strategy', 'constant', 'mean', 'running_mean', 'forward_fill', 'seasonal', \"Series hasn't non NaN values which means it is empty and can't be filled\", 'fill_strategy', 'mean', 'running_mean', 'forward_fill', 'seasonal', 'target', 'constant', 'target', 'constant_value', 'target', 'constant', 'target', 'target', 'constant_value', 'target', 'constant', 'target', 'target', ' ¤Ί ˦ŝ  ο     ', 'target', 'seasonal', 'target', 'window, seasonality, expected', 'ίCheckτʄ öthaɳt ŚiȱmputeĥȒr ǿwitɃh® ×mŠean-³strͳ̌aÞtegyȷ woĶȩr¦ks Ơcorrectlˇy in case oΤƪÂf rangĞeȃ ȵ̏ofȬ \\xa0ǥmissing Ĩvʎaluʗes iʧnǚ data.', 'target', 'mean', 'target', 'target', 'target', 'CϬheųΆĤΠcƓÔkÈ tḫˬũat impϖ\\x83̥uteϺrɩ witǏh fˌorwaˢł¢rͨd-fil\\u038bl-ǒstȕra͒ŮʡÆtegɋy woȥ˺ΦɄrksǗ vλ̫ΔcʡȰǅoƮǫr_reɭ¬\\u0383èΜ̭âctˆ̈ǰly ʤöin̩ ϯσǔc˶aseĲǊˀčʢ ȶƐoʇϻͅf òʣnȰe ̮misPϜsʯing ˽vaĦlueJ in͋ˀ dʳbǈě˳agt\\x89a.', 'target', 'forward_fill', 'target', 'target', 'Chʚechkƪ that imputȅer\\u0382 wĖˮϼťɞitɂ¯h ͖fo̩rward-fill-stratβegɵ¢y works Wco¦ȏ̢rʓrectϽly in |c˓ase of r˪aĉƝnmgϗe Ɋɢǲof̚ mȜʦψisʋͤsiǶ˻ng vǀalues ȵiåˤn\\x80ͦ ̡dμatυaɼ¿.ϐɪ', 'target', 'forward_fill', 'target', 'target', 'target', 'ªϸ̉CƖíheSck Ͼ̂İthat ^iˏmǧ2puteǘr η̺witϘhΣϙ˔Ù ιíÂrun̋ýͽDnin<gȀͿ-mØĥƧιeanɯř-sͧt×rateg˜yS works ʮcoĥȧrɻˢrɫeͅct̓l¬̴Ƶʮ͇˓°yʼ in ȽcasǏe oÕf onˈeϤƛ misΞsāʸinɠg va˚ƑΚßlueʱϮ ̃in dʓ/ƸǠȿata.γ', 'target', 'running_mean', 'target', 'target', 'target', 'window', 'Chǹeck̯͋´ tɇʹhat ˒imp̤ut͝erī wΙithˣ rɑunn\\\\ing-ƴmean-tstrƉat¨egy ƈʹworksĞ˘ co͕rrϓectly Őinɯ caÂse of ranȠge of͔\\x9c^ missiζ˦nƌ+Ȱg valʥue¢s Ȥ\\u0383in Ύdata.Ϝ', 'target', 'running_mean', 'target', 'window', '   Ǹ>ƖΙʟ            Ϭ ', '2020-01-01', '2020-01-11', 'D', 'timestamp', 'segment', 'segment_1', 'target', 'timestamp', 'segment', 'segment_2', 'target', 'D', '2020-01-01', '2020-01-03', '2020-01-08', '2020-01-09', 'target', 'Check ͤthɽatΠ imp+óut\\x9aer wi\\\\th mean-ȿĎstrαategƓyͥ works cƆ̚orrȄecƙŨtly˦ iπn caųse hof one϶ missing value ¢in data.', 'target', 'mean', 'target', 'target', 'target', 'seasonal', 'target', 'window, seasonality, default_value, expected', 'target', 'fill_strategy', 'mean', 'constant', 'running_mean', 'forward_fill', 'seasonal', 'ȟCheck thaϥt˚ ƒtraǹαsɴform + i^ƻŌǸnvɻʲe¿rĲɖ\\\\Ƶ1se_̑ͣtǟrǻansfoɸͶȺ͠1rÇm͉ ˷̹Κʩdon͂ť\\'t chϙǭĻangȖβe oΡrϢǧigćinZɟ\\x85\\x90YaǊl df foƭrĜð t\\xa0ʙwϋo ļsͩegm\"ḙnǏtɋs.»', 'fill_strategy', 'mean', 'constant', 'running_mean', 'forward_fill', 'seasonal', \"C͝he\\x8dʒǪck˚ tΨžh¶aǞptǝ íΧnv\\x9aeǩrǨͫse_ʜtransform ɼdoȁ\\x99eǬs¹\\x8cn't changeʮ aÝny]thing iɳnώĥˊ fˡŲoʪreΛcast.\", 'target', 'target', 'target', 'fill_strategy', 'mean', 'constant', 'running_mean', 'forward_fill', 'seasonal', \"aC5Εh˯eckȧ that ΛtransformͽΨš ɦdoesϑn'tχ\\x82 fi͍lǂVl ĹÈNǰ˔¿aNïs aɀƠêt tch͙ż©e beɆgiɜn¥ni͉,n\\x9eg.\", 'target', 'target', 'target', 'fill_strategy', 'mean', 'constant', 'running_mean', 'forward_fill', 'seasonal', 'target', 'target', 'fill_strategy', 'mean', 'constant', 'running_mean', 'forward_fill', 'seasonal', '         á         j Ð ', 'target', 'constant', 'segment_1', 'segment_2', 'target', 'constant_value'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <24x10 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 24 stored elements in Compressed Sparse Row format>, 'ClassDef': <7x7 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Ø    Ĺ  ȧ', 'Make ȫpredi¸ctTiȉoɄns.\\n\\n͛ϺPaɝra*m̖ϪeƆtΡe͆ľrs\\n-------Ɩ--2-\\ntƍsˀĽ:\\n   Ą\\x85 DͶataseHt Ć£Ʃwitňǌǚhτ@ fe϶atϚurƷeƄ´ɘsˠ\\npr\\x9bedictʯionλ_ųƘÐsiǶze:\\n ξʿƗ æΏ  ͠Nɝumberȡɒ Ρof lasȌt timesȄt\\u038bamps̻Ͱ t͗o leave afteƺr̺ƭ ma͖kiʢͪng pr=ȅȾdicɔtio\\x8dͦŮn.ϘH\\n   ą ·ȧPrevious `time¹stʙa͵ϠmʥpΊϠs ƦwiχllĤ bƟe uͯsƸedȥ ͉as\\x85 a cƐontextţ for ΉɮmȄĤod̶eΕő˶Ōls ήt\\x92hatωɈý reqĿuiǮre͛ it.\\n\\nĦˎReturns\\n----͐ʑ---ĹĂ\\nȻ:\\n  +  DaƇtaset wi̔th p˿ʺɊredʰicǰtΈions', \"Mixin for models that support prediction intervals and don't need context for predictio+n.\", 'Make predictionΦsˇ.\\n\\nPûaraǴmeter\"s\\n--------ȷ--ɐ˄\\nts:Ǖ\\n    Dataset w˰ith ɉf̩ţȂeaʸture̹ßĚͷs\\npreșdǮ~i̲ͥc̅t˜iǝon_{\\u03a2interval:b\\n  ƞ ü IŋHf ŝTrue rύΝetýur͙ns͜ Οp͖Ϧredictiȗom̠n inǂteƗrval forā foṙecMιast\\nquanσtiles:Ǧ\\n    LeveȃΘ\\x97ls̥ of° preḑƽiɡctionƓ ƇdisȹtribuɛLÉtio¥An.π By defauǘl͞Νt 2͏.5%©͂ anǢdΔ \\x849Ȁ7.5%. areɦ ˝takeǼn to fo̤ƾʗrFm a ʉJ9̉5% ṕredictiǐ%on interval\\n\\nɁR͎eturnsň̺Ĵȭ\\nǇ----Ō-\\x95ŝ--\\n:\\n    DaătSaset with prƁedρic˕tióĕˡnώɣs', 'Mˠʳake prǇedictǮiÑons wiŏthȪʥ˩ usinʮgC̈ ǁtrƖċue value̒s as a\\x80utoɨrϜegʕresəɇsIionÀϛ ÃcƐoǷ΄ntexʧt ifΦ ƥp̡ϒossibleʠ (teaϡɘƈƿcgɖheʦr f˯͜ƣoƨrcing).\\n\\nPƚarÒaėƎʸmeʢ̩te˓rsʄ\\nʸ------Ƌ--ɖ--͍\\nts:\\n    șDatasάet Þ\\x9ewith fe\\x7fature5s\\npredicþt\\x95ion̚Ʒ_hiȈntervôalɓ\\u038b:j\\n   Ǧ IfˉÀϮ YT̼ruĚeƐα rɬeǷtf˹urn̰Ķs˖ pre̤ódi͍ctǉionɅ, ŹŪinºt\\x92erv˘al f̿oärŰk ǯfΩoreca̰sχ̯5͡t\\nqǕuanƲti̓l˱esʑ:\\nǱ ŷ͘   Level̔sľ ŀΓof predƎiÌction ƙƛʈdǆisͱtʇriØbuǔtio̕ǫʻn. By \\u0380dłefault Ɔ2.5% anͨdʫ Ϋ9̐ͩ7.5ͭ%Õ are tɖakeṅ˗ to Σfoͯ\\x94rˀm 4a 95\\x8cȵ%\\x8fƭ predictTionl Κintčeârva?lǊφ\\n͵Ȧ\\nReċÅtuǰrnsƨ\\n-Ύʺ---ǿſ---͋\\n:͗\\n ɢ   Dataseɟt wƧithΖ p̦̥ɀreȕȓ³dicΡϼtion§s', 'Môake pωÍͥreĉddʉ9iêcti1onsʬ¿Uņ.ĥŶȖ\\x9b\\nζf\\nΕ˳˸P̌aramŲķΑ`ƾet#er˭ɠs\\nƳͪ--δʣị-------Iø´Ȧ̘-\\nēȭts̪\\u038d:\\nÈ  ρĭʑ  Dat̐ȰȖaʹsˀeϟtʖ wǆithͫ͒ðư fe˝atΊurģe˖s\\n˘prediŗctƅĩiÝon_sˎizΒˆʇe˷¬Ț:˓\\n    NuømΨber ɇof lιFasù4Ύt t\"i͐ΟȍmesǙ;zt˞ǲampō̞ƽs ̎to leŢ5ʎaéŨvɟˠʘ9Ee IaftȬeʐr mÏak\\x81in>g Ȝpredǎǽ˱iIction.ʆ˙ŔÝɄʃ\\n Ɓă  ʎͦχ Preʹ˪viʭÒou͵sŖ t̬iâ̟ϣmestaJ̤Ǽmps wilˆÂňɧl be\\x85 ¡useȕȎÂd as Ƈa context foţr moądels tha\\x9ft r-eŜͯq˵ƯOøuirˌe iȱt.\\npredπictiŜÂoͳn_interval:\\n    İfɂ True Ǩˢrˈeturȩnsˊ preXdiμ>c`tiʺÁoɈn interval̥̆ f̔ĴoήrŻ̖ ʟfˤȍö¯orec\\x99asǑt\\nqʽu˚aʴ]˳nʃ́tiìle+ͪĉsΰö:\\n α¹͑ ɫ  ĵLeʫϼvel˼ȭs o˾f ďpredictiɪoǙɤƹn d\"̌is\\xa0tr\\u0378«ȸibutioΊn.ƿ żByh ̯ͳdefault ýȺ2H.5% Ķħƚŉa̠ndͿ̽h 9\\x8c7«Ď.5% ŏare³ć tał̦keɄn ϲȷςātoǨΌ Όf̠orɥmΊ ˜͢a đ95Ú% TpΦŪrƓediction iqȍnt͘ȗ͢ervΦǺˢal\\n\\nReͦtużƓrnÂ̶μs\\n͒-ʱ-̈́ÁȽ¤aŹ\\x81-----\\n:ɱ\\n ϋ   D\\x84atʼɜaset wi̅ƃthŧ pårediÏctiǚons', \"ωƒM̷ixin foǐr ḥolʏding͚ mĽe\\x8cΕthʈʋodƱ¯s éêΰforĽǲ ŢϟƖpeςr-sęgmeàntώğ ɾÆp̫ɟĪ͠rƒed`ʧȡiȁcti!'Ί\\x86oʜ̓n͙.\", 'forecast', 'Fit ȗmɛˑ̸ιod̜el.\\n\\nPaġr̈ameρǫtśeŎɦ̴ˠrs̛˟\\x98\\n---ω-- Ƃ---ơ\\x9d--\\nts:\\n] βĿʦÌ  ȇ Da˗ĺtäƟˤ̆ŀsetą ǰŁwith fCeʇaCtΣuresΚŶ\\n\\nΰRЀe\\x90t˗uȳrðns̮\\n--Ƈ-Ńļ-ƙ---e\\n:D\\n R   Model. ̗aft̖Ĭ͐eźrϓ fŞȧǮit', 'segment', 'PerSegmentModelMixin', 'timestamp', 'target', 'segment', 'prediction_size', 'timestamp', 'timestamp', 'Can not get the dict with base models, the model is not fitted!', \"Maĭke prʇĎBedictioȌ)onŕs.|ɢ\\n͡Ɣ\\nParameterŶȏs\\n7ʉϾƽ--·ʦ-ęϙ-ǽŌ-Y---ö-έĂ-\\nδtΚ˷s˫:\\n    Datafram¾e wθithƫͭ featʟurΣ͞es\\nprediΏȢȹcti¥on_meľth˽odσ:\\n ̵̜ͩ   ·ͭMetáh]o'd f6oϞr hδm˘aking predͳǥγicɩͩtioǵns\\n\\nRetǻ̩\\x93uȤ\\x8drns\\n--̊-ͮ-^--ľŴ-\\nǿ:\\nȕϱ ï˅   ̔ʝDśaâtaset}̷ χɄwith˙ ɐpŨredicȯȑ ɃǙtions\", 'timestamp', 'segment', 'timestamp', 'segment', 'prediction_size', 'get_model', 'get_model method is not implemented for ', \"'Initü˖ą ƿΒPʗerESƫeȡgùmenˤtMoŊd͖́eʤ\\u0382lMùi°ʁxͱiɫȷɯnƱȳ.\\n\\nParͥÁĕaΫ̼metːers\\n-5ͬ-Ǩ-ĳ--1----ǯ-\\nbaǓsTũȿe_emŉ̫ǬΤ̛ə˃ı̲ς˱oα´WìЀ½deǖ̔l͓:ϒͅĿ\\n©͉̔  Ͳ  y˗\\x91InternaŷɈΔl Ǟ˵mˈ˂\\u0383Ŀfod^eQlά w\\x99hicÇhΔ Ͻ̛ɺw̔ʲi˼ll ΪǥbeǈΛ uùsed tˠϪo f§or1˪eca\\x86sϺȀt segmentƽsʦ͛,Ζ eƼxpǗecŊ̇ted to have fit/ȃpreǔd͑iǔcΙt &̍ïnͼǫʎΫtȅerʾfĞąaĕcņɿeé\", \"ƄȒMixinˆ͏ fͬ·Ʋƹí̮oȕr hoʋ˺l̥ʠdiϯ̸nͥgµ ˚me\\x9cthˊϵȤodsì ©for muȭlŚ\\x9dti-ś˴eƠ\\x7fgmʭenϺƤ\\u0378tȾ pɿrư\\x92ͺηediİÿōctioEn.\\n\\nI¹ǥt cϥ\\x8ëǨ¸uťΟrrʀʹqenġƹɲͅȂήŖtΎ˦ŶƠlyɝñ ¥ɝʚ\\x99ĬȄisn'ɍtˉ worσkɁinʳg ʰwɥith~ p̑reʂÇƅdictǙiǚoE;nΈΥ} ĞinʨtervjaálɀsƁtɩxĤ an\\u0378d cĄoɢ©ʿQϢnɑƆtƷext.\", 'Make predictions.\\n\\nParameters\\n----------\\nts:\\n    Dataset with features\\nprediction_method:\\n    Method for making predictions\\n\\nReturns\\n-------\\n:\\n    Dataset with predictions', 'segment', 'target', 'segment', 'MultiSegmentModelMixin', 'Init MuȺlɌtiSegmentModel̤.\\n\\x97\\nPara˛me¥ƺter˱ȇs\\n--S--\\u0380-é--˛---\\n˯bĄase_model:\\n    Int̀e˲ʶr͗nal model which ǥw̴iĊll be used to forecasņt segm̼entϣs, expected to hʜ̕aveͱ ʭʲfit/preɐdictĻ interfaťce', ' ͕ʑ  ̓  ̢ʸ ', 'forecast', 'get_model', 'get_model method is not implemented for '], 'from': [], 'import': []}\n",
      "{'FunctionDef': <35x31 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 34 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['TSDataset', 'Quantiles ', ' do not exist in each forecast dataset. They will be dropped.', 'TSDataset', 'feature', 'target_0.', 'target_', 'TSDataset', 'per-segment', 'PloϥϙǊt the \\u0381peKr̪iȺǧ\\x8aodɽbograĐ̞m ˅$using :pyğ̨:fɅunˎǦ̩c\\x9eȁ:ϊ`scipyͼĩYφó.ǟsiϭ˗ɱgnaǣl͝.peÛ̠riodo¦˪gƋram`έUȟ.\\n\\nɳIt iƚ̛ös ̨Ʀċ\\x9cЀ˹ɲ\\x85ͳƈusƂefˋul to dʨeVterƯmƅɯȅine theϵ͎zȑɎ optimal ȏ``ʃoirder`` p$aram&ϛeϳt͵er\\nΨȖfǕorξ πʛό:p¥ay:claǙss:(`~etȞna.ņtransf̬Ãorms.@éƼoˆŦ!timŉeFstġaǫmΟpʶ.έfo>uɄϮriŒer͋.ǦFourierTʃrσansformʌ`.\\n\\n\\xadǣόParameters\\n--Ï--oκ-----0-\\nǱts:\\nɻ    ˭TͨͿS̭DaɲZtaǁ@s÷et witŽh tiɘmeƘˣseries data̸ő̂\\x85\\nperiͅonĭdϗş:̵\\nŖ    t˨?he ͗pÚeΎriod ofŀƤ tƵ̧he seasȤ̹ço\\x89nξalσÓʬity to c̜ƺaptϹîćure ǓMin fr;Șequ^en˵cŶy ̕unĂits ofǅ ˍ3timeX΄ seƎrƷies, it̚ shθm̩oυΧɋZu÷ld ˣ¹be >=í 2;͙Ĺ˱\\n\\x8a˟ ̶ \\'  iūώ͈Łt isΜ \\x9dɔtĐ̞rans͊ƶlÑatƔÊÎed˓ toΪͱ tʠ϶he `Ğ`fŸs``ɦĺɑ ̀pɻíarameȄɪt6er of <:Ƕȃpyà:fʧunc¥ą:`sącơŌȄipɍƞy.siơg˴nalϐ˯.pıeτǪKƗrǞiodog\\x97όramŎ`Cɹ\\nͻƐ#amɒplƘǌ¶ŌȫłiËt͖udƕe_agg̾reĻgɍ́ation_mŦɃʄŕϡʭodeŁ˛:ʤ\\nɝ  v  àagΕ͟grȍegat·Ņionʠ sŷtr˪ařtĎǰϙ̟eϺʆgĂϕy˔ for obtaiȻÀnϫed pƞϫeÓr sǇ&eϣgment ̪pʝƕerȽiŅƂodowgΈra?ɕmΎs;\\n    alʞlɟʏ tΡhe strategiɎes caɗnǳε bïĥΕe Ǘ̙examined\\n͎̓\\xad ǎ ϋ  at :pĺy:classn:`~̽e̸ȿmtnaƪ.ĩ͕analMĎysiͨs.ιÛfͤeaP¸xΈtuˍʷǥͶω̭re_seleΖction/.̯mȽrmr_oƻʧsǥele\\u0378ctiʗϏźʥƐonȧ.AʌɻgƚgƝȵregationModeϠ`\\nƨ͉pΦeriįR͔ϲĠϊodoɫgraƠğm_pŞa\\x9er͐¯ǁaʁms:\\n    aIΫc̘͂ddiǅtiuoϟn\\x84al ke·ɈŸyȏw˼ord aʪúrgumeǘųnˡtɕsź˩Ȅ βŸfor ˀpeñpriodϬŀȾȜoȅgramÞ̿ɻY, :Ő!pycū:˔fīunĥcɾ:ʐȆ`s̄ʪcip˓y.ϙsiɫg̯nŶalɪ.pǀeriodɸogra˗m`ƞ\\u038b śi_s uɻsed\\nsegments:;\\n  Ė ȐͶz ûseʇgm)entʟsȌ ·ĢtoR usφɜĮe\\nxticǂOµkǗϳÕÔs:£\\n  ŕ  ɲlʁͿist o¸ĸĳ˖f ͫtž\\x7fΐ˝șǩ\\x7fick loca%octiΚons\\x99 ȷof the x˚-aÜxÁiɃϙōsÇ,ʿ usefƔul̆ to higGhlight͈˔ ͙spʔe͋ǧcˋifi˩cȔ rɸeƑfeéɁͲreżʡnceɬȗ pe§Ȫri¡Țosdˍ˴iɊ;ciɷt̮\\u038dies\\ncoƠ\\x95ƥlumns_n\\x8eṷm:Í\\n    ưif ̖ňƆϹ``aɝŦɕmplÜiΣtu͖de_\\x8eɎȃagˈgregat̂\\x8aioűn_moĽdōe=\"pTeĵʳr-VƝse1ȇǨgmȠenʫt\"`ϡ` ČnʠumberưȁÙ ofʎȰ c˂̀olʛuɀÇͭϬmnώs ǬinƟ sϕub}ploţs, othĸe¥ɴrwˋƐiţse the valϤue ʟ\\x96is ig\\x82nƦŪχoredĳΩιϊȲ\\nΣfŊiǙgsˎizeϮ:&̭\\n    sǉʠɜize Ͽ\\x91oƖf ̬thƲʺe f\\x82ΚĎƥʪČ@igure peɄ\\x98r subǛplo2ɢt ͼwith. one; ǲsegment in ĚƓinches\\n\\nåRaises\\nŞ---Ă--/-ÑɌ\\nVʪia͈lɔueˎErroˎrÁɏ:\\n  \\x94ʔǈ ʫ˺ ȑiάf peǼrˇʓÍioǟd <Η\\x99 2\\nȶVaūluϩeErʞror:\\n    uif pʂeri˻oRdogrͲĜOɉ\\x7famǥ can\\'t2 ̒bfe Ķc\\u0379ʪaƳ˲l\\x9acǢOȸulatĲedʀÀȽ̡˾ˬþ ¸+lo2n ƿs̒egmentɿ \\x8aεbeƼcause of dn6ƢtChe NɆaNs iTnsɜid˓Ȓe i¨÷\\x95\\x81Ňtͼ\\n\\n͆ϡNotÒesĳƣ˟\\ný--̿ʤ--ʺ-\\nÍn PnaoȎƤn Ήper-sʏeλgmȉen3̵˲Tt moƁd̩e ïϟall sdefȊgmeʩ(ntŬósƨ¶Ǳ areū cəut͞Ė toĝ b˒e thxe ͩsʢÐ]amǏe lÊeengʉ̀ÓÈth, ̸the last ˙vʏaȵl͛uθesÏ ɰaεrìeğ7 taɎΒϘϣők\\x8eenɭ.', 'Period should be at least 2', 'per-segment', 'target', \"Periodogram can't be calculated on segment with NaNs inside: \", 'log', 'Frequency', 'Power spectral density', 'Periodogram: ', 'target', \"Periodogram can't be calculated on segment with NaNs inside: \", 'target', 'log', 'Frequency', 'Power spectral density', 'Periodogram', 'TSDataset', 'TSDataset', 'TSDataset', 'Prep˥aΕìrƅ»ĒƸe dɇi\\xa0ʪ˚ctiɹüoϿɷna͌νry ʹǤwiϕtȐh fo̭rec͡ǰasts resulʄts.Ʉ', '1', 'Unknown type of `forecast_ts`', 'TSDataset', 'TSDataset', 'TSDataset', 'TSDataset', 'TSDataset', 'TSDataset', 'timestamp', 'timestamp', 'timestamp', 'target', 'segment', 'timestamp', 'target', 'segment', 'timestamp', 'target', 'segment', 'train', 'purple', 'test', 'target_', ': ', '', 'timestamp', 'forecast', '-', '-', '--', 'x', 'upper left', 'TSDataset', \"Parameter 'end' must be greater than 'start'!\", 'TSDataset', 'all', 'all', \"Parameter history_len should be non-negative or 'all'\", 'fold_number', 'axes.prop_cycle', 'color', 'history', 'test', 'forecast', 'all', 'history', 'test', 'forecast', 'test', 'forecast', 'skyblue', 'o', 'x', 'TSDataset', 'target', 'description_width', 'initial', '_', 'r', 'TSDataset', 'target', 'r', 'x', 'TSDataset', 'pearson', 'Cˁ˗ʽʙĎo\\x83͈mpu˼t͓·bνe ΰpairw˗Ɠise correȩlation ofź tiϻmeÏseΉϼrʍi¿esƱ foɫrΦ ÚselecƛHtƈed sϮÇĚ\\x80āΈe˵Ŵ̾\\u0379ǢɓϨgmeµnts0.\\n\\n͈PaˁŻraκųmeteϱʒ1rzsƈ̦¬)\\n---ō-¿--ɏ--γ̯-æ-\\nȼtǀɕs:\\n̞ˌȔĵ\\u0382    T±̜SData̋seπʤtȊ witÖh ti˂ƾmeʓ̒ϙˌsòeries dʙĉatak\\ncα˜oȥlu͑ˋmnsϢ:\\n   ň ɗCĞǔolτumnsR toŅ u͐>seo,=˽ΰ ̋ɩ͵ifÏ NŇoɷ\\\\neΨ useɂ ŷal̼l ¼columns\\nsÊϼegmenfȢtsƇ:\\nǦ͈͑ ǯBƨ ¦  ˪S˰egmen͈tsÓ tȝo ǰŨΦusƹƀǳeʑ\\nmϣȟethoƿd:϶ŘƘóʤ\\nm y ɂȩ  Met͵hãoöȪˊdĳ uœƴof ˜^cƤorreElaΣti̔V÷\\x97on:\\n\\n  ˫ʝ  * pÂ²o[e̓ars̋oƢʧn: űsĴtƢandar,rϽd ̀σcorr̲eɬlaƱtȁ˳ioȆn ̫coéfficiʟent\\n\\n ƾ   *\\x93 kendĝaͨll:Ǉ ̌ɱΚKendall Tau coȱhñļr̾rel\\x9eχaŭǧ\\x80ʓtiϪ͝Ŭon coǐeffiucÌΫɛiτent\\n\\nǵ  Ƿώ  * Ϭsέňpearm\\x8aaʢŕʢ̘ƀRnā: °Spªearma+\\x8eUn¡ rƤʇankǧǁ mc̼oVrrelĮȷǙatiʤͿon\\nͨ\\nRe\\x93turͳnƠΌs\\nś------̝-\\x86\\nŶó]ϥnp.ɰndarrʩǖŘaεyǺ\\n ́  ɠ CorreƄlaάÛtĽϕioEnĂ mʻ1aƛtrϪixe', 'pearson', 'kendall', 'spearman', \"'\", \"' is not a valid method of correlation.\", 'feature', 'TSDataset', 'pearson', 'macro', 'PloƎt pairwise c˟˂oĒ\\x87rrelatĜion heatmap for selͼected segments.\\n\\nParamet͘ersŦ\\n--R------e--\\nʖts:\\n    \\u0379TSData˖sϦ˦eϽtɾ wƐ\"ith ͱtimϼeseries datǐa\\ncolìumŨns:\\n    Columns Ĳ́to use, if NΩŰoʓne(Ŗ ʎuse a̎ll ȴcolumΖns\\nsegϿmentsΊ:\\n  Ʋ  Segments to ˗use\\nmϘeƶthŉo¸d:\\n Χ\\x9e  Ȝ MƎe\\x8ethoW̘d of coȣrrelationƇ:\\n\\n   ̶9À * pƢeaɅrs̕on:o stå$ƍn̜dard Ǻǝcņ́orrel͉õÈȚationϳ coeffˊicient\\n\\n    Ŏ* kendal˿ïl: ΆKeÛndall Tʬau cǘorrelǞation co͟efficiˮƾent\\n\\n   ̆ ŭȺ* spearmǢan: SΪp˩ear\\x8aman rank coǎrrel̜ation\\n\\nmode: \\'macro\\'< ψor \\'per-segΕmeònt\\'\\n ˊ   Agg;̿re7gatióon \\x86modƶe\\ncolϛumns_num:\\n  N  ŁNumber of ̀sǪąub1plots ͜`cȄoʼluϫ¾mns\\nfigsize:\\n  ȑ  ɘsKize of tʴhe ʑfæiŠguȎrǄe Ʒin Ʀfinches', 'feature', 'vmin', 'vmin', 'vmax', 'vmax', 'macro', 'per-segment', \"'\", \"' is not a valid method of mode.\", 'macro', '.1g', 'right', 'anchor', 'right', 'anchor', 'Correlation Heatmap', 'per-segment', '.1g', 'right', 'anchor', 'right', 'anchor', 'Correlation Heatmap', ' ', 'fold_start', 'fold_end', 'fold_start', 'fold_start', 'fold_end', 'Folds are intersecting', 'TSDataset', 'bPlo¾t ʠ2ʋǡclus˼tʢeğrsǦǴ Ìι[wřithÏ ceƷntr~oids].\\x94\\n\\nPʸvaʷrɥŜa̝mĆeteĦrsf\\n----ω--\\x98-e---ʔ̙ʨ\\ntΝșsʯ˭Ō:Ƿ\\n Þ   pTSD@óaǳtasǰet ̙wiȥt\\u0383ǟh tςiʣmeseɳries\\nĀseĬgm̀e×nt2cl̙uȜster:\\n    ĩma¶pιp˸iɺȢǻng frŦoméϗ ûsegment to ȹclustĮer× iɀôn fϷoærŵm4at {\\u0381ķsüeg2meϵǩntͪƑ: cluϗster}\\ncȁĭͧentroɔiědsʡ_Ydf:\\n    dʛ½atʶȰʏafȤraŴȆme ˌwith ceÍntroΌids\\x9cɦm˛Õ\\ncoυlȬumns_Z̒\\x8fǊn/um:Ω\\n    numb̻er Ǿof col\\x8eǆumɤns in ǅsubplotsǃ\\x93\\nfig\\x9csirzɗeǉ:ǵ\\nƵĈǏ \\u038d Ɂ  ʏsizĲe of ½ʸthe>»\\x9b figure pʖerĚ subpƚślɞʋot ɧwith oneɕ s͝˿Ňegmen\\x8ft πinf̹ \\x94fincheŤėǴs', 'axes.prop_cycle', 'color', 'target', 'cluster=', '\\n', ' segments in cluster', 'target', 'red', 'centroid', 'TSDataset', '\\x8aļϢČPlot Ās@egme)Ǹnɧts dđwi˝th ̊their Ƌtȯɦrɫcfend έch+(ƵangÄe pŲƞoɉûȒĐƞi\\x93nt͚ϵsǡ.\\nͩ\\n˞ʐP˧ĔäϪarC͝ametſͼe\\x85ȱǛrs\\nƇ\\x98ˤƂ--Ϯ5ɭ-˄--\"?ƴ--5-ƈ-3ǗĉÞŝǬʤ-ȗo\\ntϝɦȡ̟ɾέsǮƹ:ƠɃ\\nȿ   ˖ ùT\\\\SDaŋÏ\\x89taseʢ<tα͖ ϒw?ƀi½ʅth Ʒ§ϝtōYåimeǮseɶrϷiIƕeò\\x86Ƙs̀\\ncϗhağnɁge̩_˰pʄoĔÎáŴiō̋nts:\\nϷ G à  dʢơŹ÷ύĜ\\x8dƾľŕi\\x84Ιctʹ¶ioϺnƔaryrńǋ( wiǜΛȲÓt́h tarŁƩen-d chaǧÌn¢gÞțe p˓oinÊɃg&ơ˗͓tȍ̼s foǁr ea\\x9cLʐcÜȃǨϼh segmeənƉî̷¾tʳ\\x98,ͤ\\n͎ Ͳ Ɣϗ χ caΪn\\u03a2ʉx ĜŪbeɐΖ U˿\\x9cίɃoƣbût˒ΗainešdĀϐ̈ βɎ͝ɩfrom Ɲ:$ɋ̹ɮĀpy:ɊfuDʺnc:`\\u038b~eĥtnʢa̓ͿÕ.a͐n˞al\\xa0ÁϮysisŽɯǚ.cΈhϹϹ˩@aϴn$ϋgeÕΆƭƩȫ_pȋoin̼ts7_ĭtreēndȟ.sτeǤģíɆ˦̛arǩch.fiİƍǘ̴ndſ_ãōcΐhange_Ƕpóʩo±in̖ΉtƊϧ̆ţ¤͆sǋ`\\nseʑgm͊B\\x90enώtoȀΨΜs:ȔFı\\n˝ʨ˄ġ ŏǎ  /^ sͨͼeg\\x98îmŕeƖnts˕ϒ͊ tˋo ŀusɉȆŒe\\ncolJ͊ƶumns\\u0379_nEumƬ:\\n̒ \\u0382   Ȍnάǌuųõmber͈ oŲ̃f˖\\x9băǺò ŗsņ̿ubplɚots colƵuŒ4̦mns\\nfϾ˂igsi\\x8aŢ̑zeů:\\nŁ ̇   sƁize ̯of7ʒ thɜeȯ ΐΥfigſ ρure ŭperŽ subɳϒÅɖp˵ͦʛǆ|ŁùāψȫlϿoȟt˓£ɋ ɺwđ˽iɮƀΒKth Ĭ̝o¿ne Ŀsegmźent in iśnʶchňesʨ˷Ǚ`\\n̒stŹ̺õartʟ:·\\n  ʖ  Ûʱs\\x9dtart ƻt˕imèʪǩψes˗ͧ̕t̏Δų³ȵƍʒamÈpΰƳǲ\\x9b Ƙf˾NorKl ȋ£pflϯüoƸṯƀǀ\\nŸ͚enˍd:ÞͿ\\n\\x90˿ Ȣ ų  Ťend ˬtȺʷimǚestƅͬƋaȨmÓ[p fĢͬoͻr pˆlɏˆot', 'target', 'dashed', 'grey', 'x', 'TSDataset', 'segment', 'Segments of `ts` and `forecast_df` should be the same', 'target', 'target', 'TSDataset', 'TSDataset', 'timestamp', 'timestamp', 'Plo°t ɾrˢeʼsiɁduaɋl̥sȶ for pʾȹredictiƦons fʯrom backtest against some featu\\x93re.\\n\\nPárameters\\n--------ŷɋ--\\nfoǵrοec,ast_̽dyf:\\nʃ  ň  for˕ecastͥed ϨdaəƯtafraͨmeē ϻwith ˩̡timeseries data\\x8a\\nts:ʍ\\n    da~taframe of tiǣmeserieosƯ that w\\xa0ɯas ȅused for bạcktzestȺ\\nfeature:\\n    feȣʷaturƲe name to ͽdraw agμaiưƟnst residuǚœals, if \"timestamp\" plot r{esƒidŬu·͈als agaiƂnđst thʐeȷ tζimeǠstaÜmp\\ntranüsforms:\\n  \\x99Ő  s+equenc¿e of tra¬nsforms tož g̐eɇt feature̦ colum\\x83n\\nUγƣȈƴsegment̚s:\\n   ɒ̚ segmentůs to| usƆe͓\\nco\\x9alumĸns_num:\\n    ˰Änumber ofɌ columns in subpϛlot\\x80s͊\\nfigsize:\\n ΕΉ   ôsizɧe of thķe figure per subplot with ˵o«ne segment in inches\\n\\nRai͜ses\\n---Ɛ-ś--ϵϷ\\nVĮŇalueŘErroor:ĭ\\n   · ÈifȲ featuĽre isnǯ\\'t pʶreseˮϞnt iʳÎn the dataset ǳaftμeʪr appƢlying trans\\x85foǋrmations͠\\n\\nNote̓s\\n-----\\nPʏarameter˖ ÷``traƴnsforɂόŲmūs`` Žis Eʋnecessarƶy beϱcausγe someƈ piƜpelͷi͏neƸ;s¢ does\\x85n\\'\\x96t sȖave features in theiĞr forecastsŹ,\\neƈ.g. Í:Έpy:mod:`etnħƬŢa.ensemblejˮs` pipelines.', 'timestamp', 'feature', \"Given feature isn't present in the dataset after applying transformations\", 'target', 'timestamp', 'fold_number', 'fold_number', 'timestamp', 'timestamp', 'fold_number', 'skyblue', 'b', 'x', 'ChangePointsTrendTransform', 'LinearTrendTransform', 'TheilSenTrendTransform', 'STLTransform', '(', '', ', k=', 'g', 'TSDataset', 'TrendTransformType', 'TrendTransformType', 'target', 'Initial series', 'target', 'target', 'x', 'ΠCɖo{nvÑɶeÈnrύt p-̸ͫvȴalČu̶̎eƟsǭɺ ǜiϖnto fϘiƽcŵtëitƨ(C©ious vò̦aϽriȣɧables, ΚČ˕wʩithĐ Ŕ˹fuɋϕnƕ:cſȭĜtiḼ́éon őf¶(Ơx) = ϸ1 ϡ˵ʋɐ-ˡ Õ¬̈́x.\\n\\nʶAǚl6soɽ Ϸc8oʬĐn̾Ļŋƅv͒erctsλ͝mɍŏƐϹ alωpʥhƧaĩ in©Ȣtǵ<ͤŮȄoƝ fiɁcǹtńitiouƷÃƓs ĨvaǻrȥiǮable.\\nϒ\\nPĨar\\x80ameters\\n-ƘɖȤ-͚Ȝ-͋--ϥñ¹---â-̏ˣ-\\npvaˆluɢ<ɏļes:\\nƏȑͥ˟ Ƕ ͒˩̷  dataFraǇme Ͻ̹wɺith ̝pϡʾΛ̑ĸvʌalʾŎƐuʹe&dϽʯµs\\nˑĕa˖lphľa:\\n Ȋĺ  ǿ͋ Ͼ\\'sɯigʛłþnifȰŷic$ʁΥaĉϚncMŖȂ\\x9f͏Ϗe leȆvˌel,Ʈ ςȽǍdefauʶνlηt ϵalpǈha =ƣ ɬǰ0̡ϰͬ.05Ǐ\\nɐȷ\\n˨ReàtuQēˤŋɻ̫rnƅsɅ̤\\n-Σ-ŞɌ-----ϩ\\nͬpvaοΜƦ˔lƃȻϗu˪ɤesε:)ʑ\\n ƌ   ̸ͥarraΰy1ȡ ̾wȮitČƝh fict\\u0378itǤiͥ͘oi͚Ȱɦuɰ˾ƕs ȫķřĕelϙЀeΟŤɀĳϹvƪaſnňcʐes\\nnǅeȗˢȩĂʼw_aƜlpha:\\nŨ  e\\x8a  ȑϛadŎjǓus}t\\u0381e˲ɕʪd s̺ȬŖiήıgniX̗fėħ÷ica}nczex5ɏ leve\"͐lõ', 'TSDataset', 'per-segment', 'ßPěǚƔlͬGɜot̵̀\" relev̳anȶΩcε͌Ⱦˑe oŤäf Ȩtˮhe f\\x8beatuδrƷes.ǻ\\n\\nTŴheØ mostŨŇ͵ȴ ǂIiƂmpo͔ˌrtƌaʑφƄnt fƱǼeaύturƚδƚḛsś aόŒre# Ǌκńat theɤȁ toϳpϒ, thŕƫ͏e hlea˦stŤ ʯim²portüażnˉ͐Ȇt +aȝrÝeń aźt thːe bo̭tƄɅt}õoHm.ƽǺ\\n\\nFˡǤjƔðorϦͦ ƬW:Z\\x8apĿy:ɱclpā˽űTa˧sǁʍsϠ:`ǹ~eΩĀôtȿnΤaɡ.a\\x9bnal˒ʽyđsiȅϛθsĐƗ.fηȔeatƙˇ\\u0382uÇrÅʯe˹_ǍŏͰr4eĒϒlŞ\\x84eßƹvance.ΖrɈeʅleιvaϊnc¾e.StCatis͕Ϝt̠i͟ÞcsRe͔levˁ̘a¨ɇncȲeTͶaŇbʷ_le`̩ a\\x84lsɤoĴĽǱ ʬÄp³Υlot vͻe͵+rtƛǧɬ\\x82iǠzcaʲlìϋ line: tňɼBȥ˄r\\xa0ϧansfϧo\\x88\\u0383rmeēdħ ̳sȻi͎ǵμɧ˕gnϒifiɦcanc̨ΏeΉŒ leϻũvelª.Ěͥ͑\\nϰˁ\\n* ͢ȦʬVa͍lɽuesĉ˱̋ σ̢ŏÅthaȟtà l\\x90iʼǕǲe ɉďto tȢhe Ʉ˚\\x8fright o˗Śfσ̷̘ Τthi˥Θs lξrǙiņnčΩˠeϱ ſha\\x93vȥe Αp̳éŹϐ-\\x95val\\x88\\x8cue\"ùè < Čìal¹ǿɿph˰ạɣ.\\n\\nƺ\\x96Żč* ͠ϲAnƚ̀d thͱe d1va/lu˻δeʥņs͛ thΖat l\\x83ƍiċĳe to Ƥ\\u0381the le̍̕fċt Ȏŗh¸ʿŎave p-va̕lue ȟèĐ> alɫphòa.Ĩˑ\\x90\\n˿\\nP\\u0379arªëamƐe\\u038dterɊÎźsĺ\\nʫ-ɣoϩ(--̄--Β----͠-/?\\ntêϲsǐ:\\nȠ ̳  <ŵ ɽTSĹD]ŲʑʰƁơɽĥŴEawǆta\\x9cs¨ɀɎȼe\\x99̅t wiΊtƯh tåi̯mʑesŒľzʒeriưes dàatǋ̉a\\nĶrǞeʰɖ?ˇƉl\\xadev\\x8eŅanc˿e΅ʋ_̬tableˈ:\\nŎ˒   ÷ ΜƁmŪeϢtĊýhod tǑoo eva0Íluate Ǖt˶he fÜƉe̙aturƠ͐e ʆr¶Ăel̳evgǷa̓nɂcˬfe;\\n\\n  h Ѐ Ƶȏǐ*ʧ if :ǤǆpyϜ:όcɐɖlaĜ̫ssȑɦ͆:`ͅ~etƷnńϚa.aƒnaɩ9lŘŌysʠɇis.fƅʠeʦ;atuŋre_re̼ϱāŽlevΖa\\x9eΗnc6e.ΞreªlȅvͷaƜLnυce.SͻtatiͼstÙĝicsR̫áǑeleȥvaϠϚnɪűceɬTaǻbɐlÊ\\x92ȼʠhɃ̓ͶeƝ` tǢͱable ȓiǚs ɒØϲused tɈĲĪ˾hϴeŝn ͎r̰Ͻȅelʊe͋vanceͷs ɖșarŵξϨeB͚ ͽnυƕǧoȎźrϛmΩͥaȩlizüőϺed`Ƒ pŻ-ϤvaǪlu˄es˻\\n\\n   ϐ *͒ ˾̯if :ūpæɒÐyCÉΑ:class:`~keɾR\\x97tna.Ͼanǵalysis.feɊĥδÓˍʛatĺĖure_rƙeǺĜ\\u0380leȚvʶaɌ\\x8aåǧŶnƼCɻcȭeκ.re¿leɍvanǰc5\\x90ŧɀëe.ṀɹþéodǞΛ0eʾlơPRelȇevanòpcΣBeTºaɬˆbοϳleɀ˗` \\u0382ȋǯtaǛble iôƅs ̉used thˮe̶nʍ rʎú\\x80elȗζevǈanc˜\\x95eƊſʔs ar͂e͇ imŢpoνǗrʵŇta͕nĮceÞÐ̃s~Ź fˊǃĴğēɻ\\u0380rʏomϋ ̼so͒kƲmeȦ[ĵ mo]ǚϭdχelɵ\\n\\nŮnoĸʱΑrma\\x9fliȗzΦ̷ed:T\\n  ̶Ȋù͌ϩ C wɾhęth̞er ìo͞btOaiɘnčϠedN ɶƐrƦaRƹʎe̞͝ÜȽlevϱanϺƂǃces ʯshoΆ̥uldɆ ɐbẹÖ normƶȅaʛlŲ˭iȀȶzˆϢeŐǞˆd tȍ\\x84¡ \\x89ƨͮsŖuɛÉľm̢ up ĵto 1\\nɓrƗelϚeЀ͢v)ưa3nceͫ_ă˸ÀgϵgregatȠ͌ΡȻǸ\\x9cio͏ϙşn_̢mode:\\n;    ŞagȮFgrȬ½\\x91̽Ȝeĥga,tion ŗįŔ͟þs˃tȅraŋ͖te˿gΪy for žobtainͤey(dΙ˨ϣžʣ\\u0379ρãĸʾ fųǋeat\\x8dʱurȝßȫuͲe relʢevaɦnce tϐÅablϖŋe;˭̰\\n ăŋǶϦĿ ȴ ςő łaƽ̟ll t\" Aheƞˤ stɴrŎ>aūʡ˧2ât_«etgies cȪaĊʲn Ý\\x82\\u0380\\x92be̺ ¯eǊxða͑ʫmine˸d\\n    aǾtʵ :py˔:cǑlas΅͐əĨs3:`ʒà~eΟ̖˓tnaͲ.aǾġϰʹnϕÑͤǀ\\u0382aĦlysis.feŵaʆt̾urʠ\\u03a2eůʁ_ ƌs̾ʡe6lϙ\\x83ec͠tiȠo˴~̆n.ġ\\x90ϟmΤrmr_Țseʄȼleʢȣcsϧutioœǔ̊nŧ.A\\x96gįǐgrʫ͔̆Ύťēgaͼʔʺ˺ʳtˌiĿȘ̄Ő\\'o¦n̜þM\\x80o>ïȺŕdýey`Ί\\nrLʹΝ\\x83ÅΜuežƘlevǬaɫȒnceʷǒ_Ȉßͯ͢pŇÈarʎÒa´msȱȵ:ɍ\\n    add˫it̟͊ŅioŴ͔ʺnal k¯\\x99e@ywʳĻordˠ arguÜ˂mɨ`ʾΗăeθnʊ:˓̦tť¥ǂs for͊ ¡the± ``__˫cƁZ̃˝allƼ__ǟɦ`ý`Ļ\\u038d͔αȵ~ȩ ¾̰methȂod ̃ofȻæ\\n    Ŋ:py:OcˈlWaɽsǯɶs:¹`űϙţ~μƷɤeȔtnʕa.ȓanΉƤal4̃͆ày˴sis.fǩea˩tȦ̺ureǓ_reě̷Ūǖîle-čvʷancİeĶɸ.Ďrelevanc͢eȣ̯ʿςȏȷ.ȝůRo\\u0380ʜelevanέŐcπʸǼeʸ̪Tɫable`˞\\nt̔oʕˬpƒ_ÿͷk˨:ʹ\\n˜ʠĀ¨Ɗ  ̿\\u03a2 ʵ num¨ɏbeƙr Ϩʰof besô]ͥt\\\\ǻPţ fȡĩeat͒œuresȅʢ to ʺpƯlOotʓ, if \\u0381No˵Ƕ̯áЀȵnǯ!e:F M^pͩlʞ̺o\\x96Ȯtʸ all̚ ̩t¦hňe ϸ\\x91fō̦]˼þĞeaturϾe˙sĒ\\nalpɾȱha:\\n Ɇ̹ ˸  ĩsÀāiTgniſfΎicaDƽnc̟ǟeȲ RȻleΓˀv˘eel, d:ϦĀãͻƒͭefaɔƇultł ͒a̙ȶl˖ʳphͪa = 0.0Π5, only ̰for ˳ʣŚ:pÆĳy:cϞĝlĄa±˹ŔήsΌβs:`έ~etna.ɮanͬalysΝʼis.feǨaȋͩturƢe˫_rĜƷeͥleˮvance˽.ȳrelevance.ƔSʈtatistiƚpcsReǿŽleηPvaÝ\\x96ncɠɞeTaʣblŗe`̿\\nƋsČegmǐθńİeƁεnΦtȅs·:\\nɔ    seŃ¯®gϕ̳ǭmɼeǳʰntsɸʶ Ņ̣ět́̽?o ıus1̲ϥeɅ̏ɭç\\nc\\x83ώϘŭɼȈwoηlǄuŧmǴÀnǠs_nľuĹm˽:Ƙ\\n ˝χ Ϭ  ɘi˚fĩk `ŸËļ`reōʙleΛva˼ɓnce_aȯggregaCͳη¼t͠ʘèion·_modϖe͍Ąŀ=ΰ\"pŘe\\\\ǙĭǸɺǯϕr˨-segmenttɱ\"ϸ`åɠ` ø¯nuɋΦmber Ĳɟ\\x97of ϿcoɍlǗΈÖuúmns in ̤sđ̙ɰƥuÞ̔bpUlăots, ³ʪoΝπ=čt¤ǫheǫϊrΪwise \\u03a2th\\x83Ϊɺɰe έʷv{aƃ̐luͼe ϘƆiǫsà ignȨʪored\\nʘ\\x86Ȅ̃˩figsŘůizze:\\nɛ Ĩ ǳ  ǻsiɃś̃ġze of2 th\\x83͘ʅe ˟-figł̏˫ure̟͵˪˚ pƄerɓ ̉suοbεpfloȽt wiŸ¾ϘtƯh oɥneɪϨ se\\x8bgmTenĆ˥tɀơ iͱɠnʎ ƛiΞ¾ṇchÕιḺ́eΔs', 'feature', 'target', 'target', 'per-segment', 'Relevances on segment: ', ' of features: ', \" can't be calculated.\", 'h', 'Feature relevance: ', 'Relevances of features: ', \" can't be calculated.\", 'h', 'Feature relevance', 'TSDataset', 'TimeSeriesImputerTransform', 'Pȇloɻt thÆeu re˹sultȄɠ oƪfɾ imȮpu\\\\tat\\u0382ion by ˔a g4ivenƤ¼ ˆΈim̧pudter.\\n\\nǦƕ¿Paǫrametpers\\n--Ϯώ---ºœ-ɔ--C--\\nts:\\x9dȔ\\n    TSDatasetʏ Ǥwith¼ timesεeries αdatȡa\\niȳ͆mpuŇteˊr:\\n ŗ   ũtr\\u0382ansĹform toƻ mak͂e imputƸation ofɉ NaNs\\nɡĽsegm͛ents:΅\\n Ȇ   ä̜ςsegŢments Ʊ\\u0378toʉ uļse\\ncoǬlȸuͩ\\x94\\u03a2mnːs_num:̗\\n   - numɨber of columns in ̾sƀubplots\\nfigsize:\\n ƶ ɏ  ̈́sizͣe ̡ofÓ͎ t˒heĈΟ figure p5er subplo͛t witϮhΐ one sĳegment in inches\\nstart:\\n    start timʏe]stĻamp for ?plot\\nƲºend:\\n   ·͉ɂ end timest\\xadaΧmp for plȴσot', 'red', 'x', 'TSDataset', 'all', 'Pºőloñt targetsÕ ˙Ίøandνʏ Ɔfo͛ͅrˢecasCʌt̖ ͂fȵ\\u0382oȡr\\x8f bÍ̜äacQktʙȦesȲt ƿpɹip΄eli̒˿¸ne usài\\x92nʙg ʅpl̀ƻo\\xadtóly.\\n\\n̚Paramû̴etersũ)\\n--ʁͣ͑ʮ-Κ--Š-ʣ;----\\n[ǚf͘oεŃϨrecasϛt_dǐf:T\\n ɓ˷   ɍfo-ǺrɽeϏcaƯ\\u0378ęsted ÞοdataťfraƮme wiæth Ɣt̼iÌƪm˧αeserƀies daΩta\\nts:\\nΚˬ    ͟da͋Φtƣēaͨfr̫æame\\x84 oçǉƞͨǖϱf timeseri3es śthatʘ˦ʴ waʰƋ\\x9csυĤ uʬsed ʸfoΛr bðackĚͱĆtɕɭ4esğǝtT\\nsegÍǇmeΥǯntsɖ:\\nǿ̨    sήeϥgment÷sɌ tjȣĖ>o̽ plΩot\\nhiƈstfoͫry_Ɏø̎οlŉ³en:Ɵ\\nϳˊI   ˳ϒă leĞngʾth ɽof pre-̟backʌƳwξȖtßÇwest hƐisϚªtǭo(rɄy t˵t͍ɶo Hpφǡloϓʸt,Ƈ ͅyÑif v̊al4užeɳ i͏s ʬ\"aυl\\xadl\" theȧΛ͜%nΤ Ǻploņt ˫*řaφllƋC¨ëȞ ÷the̴˥ ŝhiϋsʭtπƛoryȤʡ\\ncfiΩgsizϩe:ū\\n̊  ¦ ʱ˽ Ŋvnìsize ήoȀͪεaɳf thęΞ˳ Ĩ̈́fȀigure[ in pixelˎ\\x89Ι0s\\n\\nĞ\\x8fRetuɐrȄn̊s\\n-̡--ı--͒Ϳ--ƫ\\nOƎˈ̊goţ.ǫFiŀguΗ4įre:\\n4¼ȭɰÕ\\x95   á˪ŏčϽĝ ɘresuÀɎlt ɲofŻ̇ͨ Ȱp˼lottȌχ̷ßi̼ÀϢngɧ\\n\\n̤RaƓǎŃ̇iʓses\\n-Ǆz-----\\n°ςValuʨeEɦʈrroƲr:Λ\\nΪ   ĵ ifŉ \\x99``histʯoΤrɣy_ǃle(n`` \\x9bŹiȲsȃ 9̷nκƷegatiəˇͨΐveɪ\\n˗ʫ̾ValuĴeƚErθ\\x88r\\x97o\\x82r:\\n ɭKøyƄ x  if fϩΨolͭΉƗĥͮds\\x8b aʳ͢re̱ intǧerseȗ͠/̸c͈ȃíϹt\\x99ɬingȎ', 'all', \"Parameter history_len should be non-negative or 'all'\", 'fold_number', 'all', 'lines', 'dash', 'Test: ', 'lines', 'solid', 'Forecast: ', 'lines', 'dot', 'Test: ', 'markers', 'Forecast: ', 'markers', 'blue', 'Backtest for all segments', 'timestamp', 'target', 'trace', 'Segments', 'buttons', 'left', 'left', 'top', 'restyle', 'visible', 'all', 'show all', 'restyle', 'visible', 'legendonly', 'hide all', 'Show segments:', 'paper', 'paper', 'left', 'ɼ ʾĩ ɠ ő-    ĺǟ    ¡    Ύ', 'Parameter holidays is expected as str or pd.DataFrame', 'Parameter `as_is` should be used with `holiday`: pd.DataFrame, not string.', '', 'Got empty `holiday` pd.DataFrame.', 'holiday', 'holiday', 'holiday', 'ds', 'upper_window', 'holiday', 'upper_window', 'Upper windows should be non-negative.', 'lower_window', 'holiday', 'lower_window', 'Lower windows should be non-positive.', 'TSDataset', \"Ṕϛlot hoÖʼlidaʖ̫y0sÆɟ for seg̳mentĮs.\\n\\nS¥ˤeɳħquŌenÍc̤;e o ͍f tϩimƑestaHη1mps͏̨ ϜwϊƇiĥthɯš^˻E oɘne ͮϽholiǳdaÁy is̄ dĲϊrawƀnb ǳŵͭ\\x82ˬas Ø̭ÐĶa ƍʾ¡colo˚ƙǦr̎ƈeǎd rǉĿ˺eƵgɾiĚoνn.\\nIn'dǺiɻviͼĵīduaȘl hͼolΕiǑday iƻs͐Ŷ ɀdraw\\x81n like a coʮlʬĹoredĥȓϒʝͧ pʸoͷiʭΌżͣnɁt.ÿɪ\\n\\u038d\\nIƦtʦΧ iÑìs nɾot possibǏɐƌle tɁo dǌisɔtiËͻnguish ϔ\\x8f\\x85Ϳɢpč̜o¾ʌiƇnǵtͧsΈ pƻlθotted̖ șat on˖ŬǄe͠ ƁtóimÆΠesɡta£mˮp,ώ ͚ěbut ǯtΓ˩ɫĢhis cas̻Ǵ̝e ɭis cͮʉonı˘;sϊ͒ʨidered raKrǌe.ŶŶ\\nT\\u0378hisł tʬƬĦhe ˽prɌoȇbǼ\\u0383w÷l|͆Ǎem isŰǪn'td rȥeͭlevñantƥ ĢfoŅȮr ƮŤƥregOion ďdrawing bΔƷǜecauʝse όtƧćheyͩ are paªûršϲt«ʑiaɎllypŭ\\x8cĸßƞ tr˞aɘaò£ʏ8nsō˂ȧpaƎrLeσnt.ːϜ\\n\\nPŠaͳ́r͵̛amˑeteǮǇrsǷ\\n--˅̬#---͍ɨ--Ø-¹̓-̯-Nȵŏ\\nts :\\n Ųʑ   TSDat§ͫƍasϙe&t ͚witϖóh \\x89ʶǽtimǥe÷se˱ries ídfaŖǞta\\nhoĦliŹdaœʶys:\\n  ͈̓\\u0379ķ  ϋtheóΩ\\x85ˬǾre areϺ seǽv˶ɿ\\u038d̃eraϑl oűϚptioĬnsçɳƘʯ:T\\n̢\\nʕ ƛ¥   * Ϲif͈ str, ͊tÔƔλheȩn ǃtɃÑhǑiǏsŏ ͫiʷÐsǍ rc˃ode ofƤÃ thȞeϓ countĆryÚ in `hºolidēaϟys- <̪Ͷhtt\\x87pΘs³:ŘĲ//pypi.oĵrg̕/pͬroje˔ǆct/holΉidays/Ɖ̏>`ϒ_ libƸrary;ˁ\\n\\n Ņ   ˮ* ȜiǜĠf DataFrame, theͣn daͱňtƢ̸HźaƋf!Örame ˥Ωʘiːʫsȸ̵ ǡŌɛƖexpectʡΊeĄdŝ \\x80ͱǷϝt̗\\x9co<ώ beƒ in pB:rϧÔophet`s Ã˂Ǯhǅ˦Ťo\\x9elϞʬȀi͵Ơday forϓěmʓ\\u0382at;h\\nȗ\\nĕ\\x95segϫmeƏntsǢŬ:\\nŎϹ  ±˸  ̆seǫgment̎s Λtoʁ use\\ncoήŖl7̄uʒmns_nϽ\\u03a2u̬͉mǅ:\\n ͇ Ϟ  ËknumWb>er oƞŒf columns in ĲsubploΜts\\nfʬigΏƴsize:\\n  ε ʳ size ǳƯī÷oϩf̝ėϲͪ tɔh̹eϘǓ ɓf˳ǟʈ´cigγure pǃer \\x98sȧQφubpȱlɦo\\x92ͥ˯t wηit³˦h one sɚeÜgmegn;Ⱥt inƭ ɗiʽ3ɕɏnche˾s\\nϭas\\x7fǰA_ɛis:\\nȾ rG  ńʚ * | ̣ΛUɕsʟĭ˲Ͷe tɐÕhţisƏ oÿ̈́ŅĨʊptʐǁόłŔi&on ͼif Daȉ̟tƯaFramϝΊeΔ ǷȍrʟisŞ ϓʠ\\x99rȋe΄preǽĉɀsǸenśtHɦeȚd a͍ΩsΒΔ ōǷǠͨa dat͒afrÒ\\x92ame wi˸ʢth̚ aĬƷƚ tͧiȠmeÊʟsƨɠtœampǙ inXÎϿϚdĀŚe͂x and hǣώoɷli~Ϭͪda¢£ğ5Ϭşìy ϡ̈́nameǬɃ*s\\x98r columns̝͕ζ.\\x8c\\n  ˋ  i  | In öͮ\\x8dʧa holi͂day żc̊oîȒlumn vǙalues Ȼ0 Ͻreǝpre̐sĜPenǛt abs̉Ȗence o\\x96fɺ holiÐdßɖaʤy ƹi\\x9an˪ thảĶt Ξtime˳åLstυamp, 1 ƩrȮe\\x9bƘpreSse/Υnˀt #the presencͧŖe.\\nǵǹĎstart:\\n    sϲtqa\\x95ɳrƊtηǎ tBë\\x8eiɓmestampÃ f͒ǉʈorƘ pňlotſÍ\\nəendˠ:\\n ǋ˪   endK tɽ͋im̒ȑesǮtaĻm\\u0383ɲptȏ ϫªfoϙr ̒Ėplˠǅot\\n\\nRaŤisĭʕeǄ\\x86s\\n-ó-----\\nVa̢Ɔ¡Äl΄Ǩue̸ǣError:\\x8a\\nĢ˩Å ǝ   ͇*Ϣ Holi÷day norʤ ΖɬpČÙd.DͻataFramǂe oËr ̥Stŵƨrinǲg.\\n ΫO Ƥ ̖þ * HoɄlɈʵiǏday iëUƿlsϞ aϻn emśpƓty Πɪòpd.DaǆtaFƮƚraŜmƫ˦ºǉeğ.\\n    *ȕ `ÍaʣsĠϸ_Ƨ]\\x96is=ϱTruβe` wΨhile hollʊ̅i˳day is SͳƎtriˏng.\\ǹÚ    *ɣϿɇ ͝IŔf]ĸ yʹu˚ʼ˃Ɗpͷp̬̉Ǉeȴr_winƼḍow iYs nbegɀäƓḁ:t˫ǨivĚe.\\n ͌ϋ  ǎ * Ìfǜ ǮOlʨoŉw¹er;̗_ɕɞ͟ĭwϷièn̎ͭ˛doƄɅ\\x9awɓ ƞ\\x95iŉs Ʃp˻oǶsɗĩϘtiȩÁve.\", 'target', 'axes.prop_cycle', 'color', 'dashed', 'dashed', 'x', 'o', 'mean', 'median', 'Get aggregËatÄioιnOδ functioɑn.', 'mean', 'median', 'ƶ      Ć˙   ¢', ' is not a valid ', '. Only ', ', ', ' aggregations are allowed', \"Given metric_name isn't present in metrics_df\", 'fold_number', 'segment', 'segment', 'h', 'Metric per-segment plot', 'Segment', 'ȱEnum ȩfor̋ ǧtyɹpesé óf \\x9cplkot͇Ï Õin :Ppy:funȔãc:`~źetna.anɻaȰlysϊiϗs.ŧplʞottersπ.metric̍_p¨er_ˉOʉsegmʜeʃʥnt_d̺istrɛibuti˞on_plͅot`.̉\\n\\n\\x83AtȬtribͰuBľǥtesʗ\\n------ą---Ċ-\\nąψhͻist:tδ\\n    Hisǉtȭograĕmο plͪ3ot, :py:̌func:`ɒseabƍorn.ĦhḭstploǺt` isú used\\n`bȚox:\\n˪    BʰoxpĿǞlot,Ǳ :ϢÆzƼčpɸ̢y:±func:`seaƲborΠn\\x9a.˩bƍoxplotϛ` is̳̣ɼʡÝ uĜsed\\nvȼiolin:\\n    VGϬioWlįin plot, :pȐy:fuÒncǖ:`seͣabœoÜ͊rn.violinplɹoˤt` is usÿedΙ', 'hist', 'box', 'violin', ' is not a valid ', '. Only ', ', ', ' plots are allowed', 'Get aggϗ$ƋrȥegaαȔȲtion funcȄίtŁioɪn.', 'hist', 'box', 'violin', 'hist', 'box', 'violin', 'hist', \"Given metric_name isn't present in metrics_df\", 'fold_number', 'fold_number', 'fold_number', 'Fold', 'fold_number', 'segment', 'Metric per-segment distribution plot', 'target', 'ÏPǬlot a ̖tim϶e seErie˗4s4 with indicatȿedϗ chang͜ˣeÏ points.\\nèȿ\\ñCϸh̶\\x86a«nqgtϻe poɫˤiƷʰnts ΅aŘrʌĖe obtσ\\x87aineͩd u\\x90sing ʶtŝDhe specifΤied metϻhod. TheΊÐù meÁthod pάarameterΦs vaḽɓueʶs\\n͜ƈcϯaˣn b˧e chȱanEged ǤġuɇϡsɳiͲng tȣhħe cor\\x86respϲĶƐoΠnĂdiǴnͧgu F˒sli˳dͻśers.\\n\\x8c\\nPa\\u0381rɛaƃmeteɸrsϜ\\n--±ĝ--------ƐHʔ\\nts:\\nȞ  ȓ ē īǘTSʺΩDataset with ˔tȐi×mese͋rieːsÙ Ŵǘda0ta\\nchangeǛ_poͳint_moʏdeŤ˹ʏl:\\n ̼\\x97 Ʊ¬ Ɗ̟ moďdɇelο tũϔ͡ʚo geʩt tƜΥÝrend cühȥanƨge pointsĸ\\nm̋ΑodelƩ9:\\n ɜ ͐  !b̂͠iɒΤnseg® segme̬ntţ moƄdelŃ, ɠű[\"ͨl1\",U \"l2\", \"rbfθ\"ɋ,.ºʡ..Ϧ].̔ ǇNċot\\u03a2 used if ˘\\'cu\\x9dƯst\\u0383͒Ƥȏ˝mδ̆_c̈ňost\\' i̇s notĸ NoǫÞne\\nˢpΜ\\x94arams̶_boușϺnds:\\n9 ͌Δɔ   Paramete˅Ȟrs ɗXrȌƳanges \\x83of theȑ ǐϓcȉhēange ɛpoinǧtͲs͡ detſecti\\x93oɯɁnÎ. Boundsƀ for \\x89tΦhe̶εɠ paϿűʻʮϴraίºΈmetyer Ϻaßrȿe (ƃmin,maˬΤx,ÑsÄtepǵ)\\nm˺˺oȝdeɥlƯ_Òpar¢aϟms:\\n  ɒźŲ  Lɐist oŤJĚ̮ßf iterableɡ para̜me͂terȁs fʛorĨ \"iènitial÷ize ʕthe modȞel\\nƳprediͧctž_pȢarams:ϤȨ\\n   ĘƟ Liʛst ofſ ξiterůaNǟble ͢parame˄terÕs for͈ [Ɨpr̝eƔdict m˸e̱thod\\niǻn˼_coŮl͏umn:\\nÑǙͨÌ  »  cq\\u0381ɢ͓̍olɇumn ´t°oĸ ďplot\\nɴsegm!ent¶̓s:\\n̽  ˚  ċs\\x93ǶegmentðŊ˟sOŇ to\\x9a use\\ncolumnÿͿŜs_ϮnuΕƐm:\\n    nɾumb͗erϜʘ of sub-plots coʽĵl͊umns\\nfiɀgƴ\\x8aȆsize:̋\\nOş    size of Ʈtheȑ fiΦgPure inɭë iƪƧncˢh˭ẽs\\nstarϬɰtɡ:Ʃ\\nĠ    stϣȃrt ȣtimestamǊp ŗfɈorǧ ploĲîtϼŭ\\nϮʻendȓ:\\n Ϩ  Ή end ʌgtimeŞstampʄ ƶˀfo¤r ʐploγƩtè\\nƻ\\nNoteǡ̯s\\n---̐--Ϥ\\nJu\\x94pyǛtǎe͵r ţΰnoetebookɢ miʝϞg˛ht dis̛plaˍy tϛhe resïults Əinɯƭco\\u0382rrecɡ̒1tʂȨly,\\niɱn\\x92 thiʳs ϗcaseɒ̫ ˝(try ǓJto us̋e ``!ǤĎjupyteÀr\\' ΐnȠbexĕëteŬnsiƕonȖ e˶nʀable --ľpy widgets\\x84nbϜeø˗xtensiϡon``.£\\n\\nE͵xamples\\n----Ï----\\n>>> froƵʹ¨mĪȜ ǳeƂ\\x89ϕtna.daî̧tʰaseİts iςmpo͵rt TSDavȘtaĦset\\n>>> fˌrom ĸ̄etna.da˭ˎtasetȚsʤ̳Ƿ) ĄimpoÎrtώ dgeƄ˫nerĂateʀȅ%ŋ_ma\\x88r_df\\n>ͭϤ>ɚͰǽȀFß> froƀʢımˈ etnµa.analysiɒǡs υʖȟimpQort plɰȄæƨot@_chaàŊnʇg˪e_ʣ\\xadpoints_interǡƧǀactive\\n>>> fromȺϩ ͫrupɨtu¤re:s.det}ecƕĥtioƀn iɃmporĮt Bi\\x87n\\x9fseg\\n>>d> «äclaɈssic˥ȿ_dfβ˞ ·\\x9c˦ˡ= gʧḙner̟ateƬ_aϚr_Cdf(period[s=ʫɖ1c\\x9c̞000, s͇]tarЀt_tũiOme=\"j20ĺɐ21-08̒-0ϙ±1\", n_sˋeȵcgmȽeƠntsΒ=2)\\n>>>ʅ ΰd̒f = ΌTSDΜat0a¹set.t¯o_daɚtaset(claêssic_ädf\\u0380)\\n˕>>> ʖ˾ts ̘Ć=  TSD©͆aȹtaset(dÆƩǽfʘ, ̣\"\\x93ƣD\")\\n>\\xad>>Ñ ăpʟara¦Ȣms˹_bounds˞\\x87 ū\"ƫ= ϑ{\"n_bkpsʃ^\"ɶ\\x93:Ũ [0,£ʤ 5Ñ, 1], \"mi\\u0380nɯ_sizeϬ\":[Ĩ̫1,10˓,3]}ŝ͟\\n>ɏ>>̔ pϪlϕ͞ot_change_puoints_interactiżvϒe(ts=tsΨ, changeűʷ_̏̾point_modɲ̉eßl=Biʩŧnsegȗŧ×, modȆel=\"lŃ2\"Ͽ,ĥ păraȐȑms_>bouɷŌ˹nds=paͩramsΑ\\x85_boʲunŐdes͖,0 ̐model_params=[Õ\"min\\x80W_ˎɾY͞si\\x82Ȱze\"Õˬ], pȞreɥţdwƻic3$ɉtΧ_paĤrļams=ʞ[\"nɽ_b̞͆kʾps\\x90ðr\"ƃ]ȱ, fǐʏi˅ȖgŅsizMeū=(2\\x9eΪM0,Ɇ½ 10)) ̀#Ķ doctēesıtϦ: ƻ+SKIP', 'description_width', 'initial', '_', 'dashed', 'grey', 'facecolor', 'edgecolor', 'boxstyle', 'grey', 'red', 'round', 'Parameters\\nError', 'center', 'white', 'x'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['2020-01-01', '2020-01-01', 'target', 'exog', '2019-12-01', 'target', 'regressor_1', '2019-12-01', 'target', 'regressor_2', 'timestamp', 'segment', 'right', 'timestamp', 'segment', 'D', 'regressor_1', 'regressor_2'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Ebay_train.txt', 'Ebay_test.txt', 'ɴGeĘt˝ǎ d`aºtasetɰ Œl abɛȶeWls φarē\\x95˿raɯyƍ˞˼.\\n΅\\nϗ˗ÃLĒabel/s [aręfçeη intege̡ϦŁέrsɎϦι ƅin thƊe ĮΦǜranƮg̨Ŷeŭ öȨʓ[0Ȟ,ͯ ʠ̞Nɷ-1]\\u0379.˂ľɝ͂', '   ', 'image_id class_id super_class_id path'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <28x28 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 28 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['tensorboard', ':', 'tensorboard', 'Bad tensorboard spec: {}.', 'wandb', 'Bad wandb spec: {}', 'Bad logger spec: {}.', 'ϾCƍotnfiɿguĒrablͭe runʺPnʋer̸ Ȭcla|sƎ̜s˞ ͆fΆǫr̙ 2tłraȽʲƺiǏºɢniǇǟnĝƥg ȸaΕȕndφ ŭe\\x8cvɛΏ¬ͽ\\x87aluaÜtiɳon.ʡ\\n˕ƛƨ\\nʈArgͭļsɠ:ɞͧ\\n\\u0378è    ʼjʊɍroqŹot: TrȦ͋ʿai̶nƑingȳ ̕ƃfεoĩld΅ǜe\\x95Ȭ͞r (Βche˫ckpoƞinĐtsŻ, ǯǆȜl̞ogs, ŤÐe\"Ϩtc.)ƙ.̔\\n    daʋʈta_ro¿͖ϩoǫ̦Ƚt\\x86:ξˇǻ \\u0380DaŽtasíϣe4ǹŃt root fÕoldwerͦ.ʆ\\n ľ ʝ  config:ĺΐ ÓϻRήuȣnȇƘnlπer \\x89ΛĖɗÓcoÕn̂Ɩˋfαig dǝƘiáctioŞnaƲrǉ̣yúKƅ Ġȳorȣʨ No¹ʝMÎȇrț̹ne ǚȱto ̢use defš\\x81aǘuͬŅltβ.Åƒ\\n    ±ȜloǈgʝgeƱr: I˶LoggeƟžɑrʧ tɢͯo ̩ʵȔʹuǩϴs˾ɸϤRe (\"ɇtLΩɶensorb¤oŦŵ\\u038baǩrd·\" ž\\u0382or \"wa\\x81nd̚φb:˚<˸ãĂȥpǆIrÿͯoject-unam1e>ϙȃ\")S.\\n  ʲā ƷΌ Ɏiníti,alːǆ_Ɋ˃kcÑhef΄c̽ãkpoiQunϙt˝:ϵ PēǸđatȃh toʢƃ ϋίcŲ.hecƺƳš̿ÔkȃȬ˸pƍoi˽ͼ̮nt1 to rβeŉsǉϴumϞǔe +tϲʸraʢAȐinȠiģngΆʢϨ.r\\nʉ ˠ   nÑoϜ_ʨǔɀωsǔtrɒ̫ic\\u0380tͼ_iɞͰnitϴ:ə ˲%Skipň che̾ȥcŸkpo^,int ϐmi͖sΆmatchϯƄÖʲ ģƻȿe:rrords.5ǕȘ\\n ΰ  ʘʊ f\\xa0\\x92ʅϫ\\u0379{̭ļ\\x97Ç̨rΕ°ϢȎomϵ_sΨtćage: ϬS̿tart¾ɑǆ ƲtraŞinǙˠiǆng fǌ̛ɓʒrom̷ ̭spǀ˅;eƎc9ified\\x8eȪ ėʔTstage indĬ˖ļΗex̀.', 'train', 'test', '-', 'stages', \"Can't start from stage {}. Total number of stages is {}.\", ' ȼ  § ', 'amp_head', 'model_params', 'Total model parameters:', 'initializer_params', 'train', 'stage_resume', 'stage_resume', 'best', 'last', 'Unexpected resume type: {}.', 'stage_resume', 'checkpoints', 'stage_resume', '.pth', \"Can't find checkpoint {}.\", 'Load', 'cpu', 'model_model_state_dict', 'resume_prefixes', 'resume_prefixes', ',', 'Empty resume prefix.', 'Unknown prefix {}.', 'Unexpected state dict keys: {}.', 'model', 'embedder', 'scorer', '   ƥɴ ʛ  ȹ9   ', 'train', '', '_', '    ', 'tensorboard', 'wandb', 'group', 'git_commit', 'Unknown logger: {}.', '_console', '_csv', 'main', 'IniĈtialƂizʎƩe coǌnƚǇòfigǵ ΚͫŞand bas͝ɱÌϹeǺ\\x8dǎ ąϱ;sʷÐtɧruθϷ̮ɛȨct̹u̱Mȃre\\x7f\\x82όs ƚˬƩforƹ tķheŃ ɭǂɷstͤaĽ2ͱ̯ge.', 'dataset_params', 'metrics_params', 'Φ    ō \\x8d ǻ   å  Ȧ ï   ǥ ř® ¾ ', 'fp16', 'init_scale', 'growth_interval', 'initial_grad_scale', 'grad_scale_growth_interval', ' ̨X   ', ' Ȩ   ', 'labels', 'quality', 'images', 'images1', 'images2', 'đ¸  Ϫ Ř   }  ®   ', 'trainer_params', '͜    -    ςǓ   sÁ ˇ ƽ ̠ŦΌ Ĉðʙr', '_epoch_', 'model_hash', 'model', '   \"  ĥɏ Ǵ     9ʙ ', '_epoch_', 'stage', '-', 'tensorboard', 'stages', 'stages', 'fp16', 'initial_grad_scale', 'num_hopt_trials', 'hopt_backend', \"Can't overwrite {} in a stage\", 'ʀ Ŋͥôþ ʫ}     Ō̱  õ  ΛɃ àȗ    Δ  ', 'stages', '-', 'stages', '                   ', 'criterion_params', '         Ƞ \\x94         ', 'embeddings1', 'embedder', 'images1', 'embeddings2', 'embedder', 'images2', 'scores', 'scorer', 'embeddings1', 'embeddings2', 'model', 'embeddings1', 'embeddings2', 'confidences', 'train', 'model', 'images', 'labels', 'embeddings', 'distributions', 'model', 'logits', 'logits', 'final_weights', 'target_embeddings', 'labels', 'final_bias', 'final_variance', 'confidences', 'embeddings', 'infnans', 'embeddings', '   ƀ ̘˚Ĳ ȑ  µ ', ' Á̄ Ù  ļĐʓ  ʁư͂     \"', 'Ι̾    έƇΚ ', 'model', 'best', 'wandb-bayes', 'dataset_params', 'model_params', 'initializer_params', 'criterion_params', 'trainer_params', 'metrics_params', 'stages', 'stage_resume', 'resume_prefixes', 'fp16', 'amp_head', 'initial_grad_scale', 'grad_scale_growth_interval', 'seed', 'num_evaluation_seeds', 'num_hopt_trials', 'hopt_backend', 'hopt_params', 'seed', 'verbose', 'model', 'embeddings', 'embeddings', 'labels', 'labels', 'logits', 'logits', 'final_weights', 'final_weights', 'target_embeddings', 'target_embeddings', 'final_bias', 'final_bias', 'final_variance', 'final_variance', 'criterion', 'amp_head', 'loss', 'train', 'checkpoints', 'loss', 'train', '_', '', 'train', 'labels', 'embeddings', 'target_embeddings', 'logits', 'confidences', 'quality', 'confidences_key', 'confidences', 'train', 'labels', 'scores', '_'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['minimize', 'maximize', 'C?lasǿs \\xa0\\x8cfˌorŐ encåapΘsÅu®late Ƅw˴orkĎ wi\\x99th OptuɅ̢ǿn˃˹\\x87a.ȵ', 'Call optunD?a8Ϳ˨ `ŀ̜ǌ`̧optΚ͌imɎōize``Ļ for chosόˑe2n Runϲnĳerͫ.\\n\\nParaā́mϨeɊtś6ers\\n--ɳ--------9Ϝå\\nobjeƾctive:\\n    objϝϕe̹Ϛctiɥv̥ͥe function to+ Ĵopt\\x95imize in½ǌ o˚ptunξaǟ śtyle\\nn_triưaŭls:\\n  ό  nϘʒumberͽ of( ʹΆtriaȸls toÍ rĆun. N.\\x92B.Ƃ˂Ϥ in ͭƁcaȕsƣe ʰof ʈparal̊½lelƇ runnȖer,* tȡhis ǯisǶ numbd̻er ɬof trsʋƉiaʜls ˱peǔrŀ work\\x84er\\ntimeȲ\\xa0out:\\n r  \\x9c ϸ{§timeoutŪ ΪfńƗorļ optimÔ(ization. ÕN.̡B̹.ƭ inʧ ɷŴcasĖeş˭ of pĄaralle˻ƀlĒĎŔ? runneϪr,˕ ͲthòÞiΟȈIs is tiϡmeǊo˼ut ΛɁper worɼker\\nkw¶args:\\n ɛ   Ĝaȶ¦dditioënaǠlė ȸaȶrϭ\\u0380guments͚ t́o pāass Âto ɵ:py:meth:`oűpȪtunaϔ.stuΙdyŘú.ƼStʳudy.òptimize`̂', 'IniÊt wr˓Ɲŉapperύƾ foĤȌr Optuna.ʿÖ\\n\\nParameters\\n--------͒ɰ--\\nd̰Ţirection:\\n    optKuna\\x96 Ë\\x81directio\\xadnϡ\\nstudyǬ_name:\\n   \" naɕˎme ʜofƚʧʰ study\\nsĊȜamplerȘ:\\n² yζƕ   zoptuna˖ Ƣs\\x80am̞pƾǛler to Óuse\\nÊsξňtoraʇgeʕ:\\n  Ʒ  sʏtýɆȽorage to͆ uŭs̐e\\npfrunÐżer:\\n Ĉ Ǩ  ɝoptuɝna pruner\\ndirections:\\n  Ț  directions toǼ \\'ƒoptimʯʏize Äin case oάf mƾΩu̮ŁlôtǸi-ʘobjectƉiķvˍɭΰe opύti.mi\\xadzatioɋn\\nloaÉd_if_exisVts:\\n˼    loadňɼ studɊŴy fΛrom Ǌstor̭ɮage if κ;ϭitɤ ex̄Šists or ͘r˙aΒͬisḙʨ exceptioná if iƐt Īdoŉȸʈesn\\'t'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['path to yaml config with desired pipeline', 'path to csv with data to forecast', 'frequency of timestamp in files in pandas format', 'where to save forecast', 'path to csv with exog data', 'path to yaml config with forecast params', 'by default we return only forecast without features', 'list of all known_future columns (regressor columns). If not specified then all exog_columns considered known_future.', \"C˚θom$PΣmaϒnXd to Ŷmakɐe Ǻfor̆eca˔ǫst wiƽtΒh\\x95 et̋na ƺw¥qi˻tɟh˲o͎ut cơoωȄid̢inǤg˒.Ę\\n#gENJwqYB\\n˰ÉEŀ̟xpɕḙìcted f;¢o;ŕmatì ̣of Ɓcsv ̗withƕ targe3͵tɢɰ tǐi\\x83ǤmĖ±϶̕eǥ½serieɉƥs:ßɐ\\n\\n\\x08\\n        \\n====Ť====ǿ=̮Ĝ˗=Ĥ=\\x7f==ǈ    ΰ==Ǌ===\\x8f======    \\x8c===α===¨====ú\\n\\u0378 ɀ̒ timJes̩tϰɵ]aŐĎmǯp˄            \\u03a2se!Ągmen̒tł    ǝ̶    á    t͟argǅǫe̺ΐt\\nšȏ====ͅ====ŭ=Ȫ==Ǭ==    Ķ=ϡǨ==δ̪̖=======Ʒ= Ž ==ʃl=ǚʧʗ===Ȉ\\x97==ΐìŚȊ==\\n202ˋĩ0Ά-01-018Ͼîίṋ̃         segmeĄϸʪnȵt\\x95ͫǟS_ɦ1     ɢ    Ϳ \\x8a    Ķ 1\\nς2\\x8dȪǶ0ĸ20͵ŵÊ-0ÿΆ1́ɯ-Ĵ,0ʓp̩2Ƨ     Ȣ ̨ ̈́s˾eƁƵς̒ǝgmenɸt̓_1            \\x94ʂ    ʹ 2\\n202÷0-01-NƢ03ʈ        , Ũ͚@ɉs\\x9d\\x9fʰegmen\\x87tġ_ˀˠ1~        Ǚ \\x91͌        3Λ\\n2020-ΌəʙIƍ01-\\x83ɵɉ04    ˮ̤     ίseΌgˤǶͶment_1 Ƭ     ȡή    ˥ɸ Ɣ \\x80Ȣ ŭħ4\\nɼϖ˥..ʞ.\\nĦ202Ə0-01-10ˈǖ    ʯΖ ³ɻ    ËsΧ\\x87egémǇǤeǾ˂ͱnt_ɨǃ˸͞2         M     10\\n \\n2ʎ020-0άǢ1-ϼ1¹1 þE͕     ē seg͖mϳʊent_ʦ2 Êʟϐ     ǻ ˾ϖʆ ĩϫ (Ŭ 20ĥ˔\\n=ɶΑ=ǜß=˾=====Ȍ===Ƌ==ɟ Ô ǜ====ó==¥====Ɏ= ˠ ĠǒŹͶʝ=ɎÕŐ=Ɔ=ƢɁ̥Ɲ=ʛ-=Ż=====̘\\n\\nˇExpeϠcte¾sd foʔˑrmat ϻΉof ͵c̅ʭ˱sďwϹv Ɍw͵ỉµȥthê e˄xogenouǗsδ ǙȏQ\\x82_tͪi˭mÜeȥΎsěrziˊΨesɁʤ:\\n\\nɡ̟\\n\\n\\x83\\x08Ş͘\\n==Ȏȱƞ̍===ͥ˥==<'====== Ί ̐=̈ȳɻ===\\x83ɴ\\x91===ǅ==ͫ=ɉ=Ǧ Ėu ==̀į==¶====ɇú=ɠōȼ=˓==șĊ===    č˞========͖ͪ====ʼ\\x83=˘===\\n ̬ bĵtiζˊmesƅtίaƳmpͧ            ϣsegmenžt Γ ÉɬƠϻƫ    ˕Ĉǻ    rĔǞegɦǶreʡ_ssƖor_1        Ι    ̃\\x93rηˮ°egǩʳtƖǈÔrƓȻessͻor_\\u0381ˣˇ2ă\\n======ϘĆYǟ=˓======\\x9b Ų͝β ==ʀ===ʆ=Ήʮ==ϵ==ī=ÜŽˑ    Xϭ|=Ȣ=====¡Ô͘ƴ²==´==ʹ=ƍ==ģ=˸= Ũ˿Ǯ ===̇==ķ̭̬===u=̩\\x8d=====Ƽ=\\n´2020ș-ħþ0\\x8f1Ñ-01ψ     Β    ˬseÞgmenưt_1 ǧ    ͒ Ǌ ȫ         1̹1    ̠    ˙ ± ł˩ ΐF˿ţʉʠ     <Ë\\x91     ǲ ¥¥ 12ϙ\\n2;Ϧɂϰī0ǩτ20-ņ0̋4Ό1-02 Ǟ ˯ \\x94ʹ̦    Żsegment_1 ǐ ə Ϭ    μ KŴ        2Č2 Œ Ϻ            ƆƧČ    ǝ        Η ƎįΔ1͕˂3\\nĬ2v0\\x962F0-01Ο-0Þ3    Ⱥ    ɍɓ ˡSseϲǚgme®ntɣ_1                ĢnЀ ̘ 3ʥ1        ϝ ɁƮ¤     ˍ͏ ë˷ƿ ʃ Κ Ɣ@Ί     / Γ14\\n\\n̞20ÿ20:ƒʚ-Ł0˸W1-βͅ04ɯ Ń Ă    ˃ segmŅǔ}ent_1\\x97 ç ƛ ǣ    -\\xa0         Ϧ42    Ƹŝ ŧ    ̼ ʰ́                 1Ω5\\n..ȉ.\\n20£ɡ%2ʵ0-02-Ēĝ\\u038b10\\x81ϑuŴ    4     ɿsegmȤenth̽_˷Μá2 ˳ȉ̶͚ϧ     ʌ É     ȑ 1ɕ01    ̈        Ʌ̐     Œ̑ǳ    Ɔæ â à    6Ψ1\\n20ϕȔ20-0\\\\¼ˊŊȌ2-ʺ11L    Ċȕ    ̀ sśͩegmenΓt_̷2Í     ψ    ˿     ʄ ˯ɘ2\\x9305Ō,        Ǵå ΎƗ     ͪĻ    ǜ     ǉ ͆ 5Ϯ4Œ\\n=̣=ˤ======µ==˻=Υ=İ̥=    =ā̋=;éπ==ù=ʽĬ==ΕϦě==ɗ==İ̀ ǁ =\\x89ĩ==̫===͵ή*3P=û===Ğ====FȬ=̖ ˡ ȸ======ž==̢=Ȩ˫==Ώ===ñ=\", 'timestamp', 'all', 'timestamp', 'all', 'target_0.', 'timestamp', 'segment', 'target', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <18x18 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 18 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['int', 'timestamp', 'segment', 'regressor_0', 'target', '2021-01-01', '2021-01-03', 'segment_0', 'segment_1', 'regressor_0', 'regressor_0', 'timestamp', 'segment', 'regressor_0', 'target', '2021-01-01', '2021-01-03', 'segment_0', 'segment_1', 'regressor_0', 'regressor_0', 'k    ', 'ϓ   š^ ϿZˀ  ˻  Ư ˸   ɣ  ̺ ͇', 'int', '    Ϝ /    ų', '2021-01-01', 'timestamp', 'regressor_0', 'regressor_1', 'regressor_2', '2021-01-01', '2021-01-12', 'regressor_0', 'regressor_1', 'regressor_2', 'segment', 'segment_0', 'D', 'segment_0', 'test', 'regressor_0', 'test', 'test', 'category', 'segment_0', 'test', 'regressor_1', 'test', 'test', 'category', 'segment_0', 'test', 'regressor_2', 'test', 'test', 'category', '2021-01-01', '2021-01-01', 'timestamp', 'segment', 'timestamp', 'regressor_1', '2', 'segment', 'segment_0', 'D', 'int', '  I          ǭ ɇ ϝ  ', '2021-01-01', 'timestamp', 'regressor_0', 'regressor_1', 'regressor_2', '2021-01-01', '2021-01-12', 'regressor_0', 'regressor_1', 'regressor_2', 'segment', 'segment_0', 'D', 'segment_0', 'test_0', 'regressor_0', 'test_1', 'regressor_0', 'test_0', 'test_0', 'category', 'test_1', 'test_1', 'category', 'segment_0', 'test_0', 'regressor_1', 'test_1', 'regressor_1', 'test_0', 'test_0', 'category', 'test_1', 'test_1', 'category', 'segment_0', 'test_0', 'regressor_2', 'test_0', 'test_0', 'category', '®TžesǑt thɾa}t L&Ξɴĥa̔b˖elEʾnco͎ίdħerƻTc͞ͅr\\u0379aʎnƳsfȇoκrmΧȃ Ɠwor˚͠kƼsǍ\\x88̰ɾ Ϣc͑orreϭΰÁcʌΦέt Âin J\\x89ːa± ĻŋϙsimʬΦ²pʜl6¤eÕǥQ ̌ÝƐcases.', 'regressor_', 'test', 'segment_0', 'segment_0', 'dtype', 'float', 'int', 'str', 'category', 'regressor_', 'test', 'segment_0', 'segment_0', 'dtype', 'float', 'int', 'str', 'category', \"Tesôt LabelEncodeďrT\\x93ransfoğϺřrm'ɴ with wrong strateg7y.\", 'The strategy', 'target', 'new_vlue', 'segment', 'regressor_0', 'encoded_regressor_0', 'encoded_regressor_0', 'strategy, expected_values', 'new_value', 'segment_0', 'segment_1', 'none', 'segment_0', 'segment_1', 'mean', 'segment_0', 'segment_1', 'dtype', 'float', 'int', 'str', 'category', 'Test OneHotEncoderTransform correct works withΰ unknown valueƈs.', 'segment', 'targets_0', 'targets_1', 'targets_2', 'regressor_0', 'targets', 'expected_values', 'segment_0', 'segment_1', 'dtype', 'float', 'int', 'str', 'category', 'Test ŏOnÄeHotEncodīeƊrTrϽΕansform gives ʒthe Ϲļcorrɏect columnlˬs.', 'regressor_0', 'targets', 'segment_0', 'segment_1', 'target', 'targets_0', 'targets_1', 'targets_2', 'regressor_0', 'TȈϚeȬ̃ɜsʠtȺ ΣʼƭOneHotEˑnc\\x8coʟdegʅrĸTYranŔsform ϼgives theğȊ cjoρrrecϭÜĬ¤ȝètʳ c˕ŏolum̥ns wƀith no oυ]ut_coluɋI+mn΄.ͫĠ', 'segment_0', '_0', '_1', 'segment_0', 'in_column', '2', 'regressor_1', 'segment_0', 'segment_0', 'in_column', '2', 'regressor_1', '2021-01-01', '2021-01-01', 'timestamp', 'segment', 'timestamp', 'regressor_', 'segment', 'segment_0', ' Ā    ƞ Ã ϩƯ  ź  Ŕ\\u0378   ', 'segment_0', 'target', 'segment_0', 'regressor_0', 'D', 'all', 'Test fΧor cǽorrect workΧ iˌn th^e ȎfulÍlɕ fƟo\\x92reˉcaΖst̙âing pŇipˎelineħ.ʂ', 'regressor_0', 'regressor_0', 'segment_0'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <13x13 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 13 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Ʉ  ŧ', '        ʞ ', 'label', 'label', 'range', 'Unknown features type: {}', 'πŪΤ)  ΧΦǯ    ', 'range', 'center_crop_range', 'Š ʍ   ¥ ɕø  ʨ Ä  ̢˳   ː', '    ϣ  ~  ', '   ǅ     ʽ  ', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['                    ', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <9x9 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 9 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['hash', 'żGet cʱonŌʳf̏ɖigŊάŇ\\x84[ʈȭ by hÑash.˓Ϣ\\n\\nȓβPʾά͜asraìmeteǬr{s\\n---Τ--²ƥ--Lďŏ---\\x90η\\nώʚąhͩǉöa\\x9dɚʹsh̚ȎƂćȮ:Ĥϣȓϣ\\n    hashƷ t¢o get con\\u0381ʯfiʐg̠ fǡorá', 'InΠit Config sam¸àplͽeŴr.\\x8d\\n\\nParametρersƂ\\n͙-ȍ-\\x88--------\\nʸcʆonφfϝ̳igs:\\n Ȓ   pƥool of config̨s to ϥsaŧƩmplǧe f¨rom\\nranÆdomǮ_geǙn9ħer̃atoɸrˑ:\\n    numpy generaYǁtoɒr\\x95 βto :get ϞrƐepɬ̄rŌƛočducibl̕e sƓampêleƬs\\nćbrͰeƾtʊrÉies:\\n ˗ ²ǰ¬  ˽\\u0383n\\u0382umberɣ of retries to Ü·get nłͦeƪw ˁsamplƁe ϢͨfrʘomƄ sto϶rageï.ʮ It˚ĜTǚ could beĨ useful if storage is not rTSel˖iable.ĺ', 'hash', 'pipeline', 'ͭSamΧplȏe ̈Ŏin\\x89ț̻dȂe)peɤndent.H Nʩoϵǚt u\\x9aˣseρtˈd.', 'hash', '      ʶ   ͣ   ', 'hash'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <10x9 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 10 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Size mismatch.', 'Empty data.', 'Losses must be non-negative.', 'ƟComƶʴpute Ȋ˰ȀŢveąrǒƗifȯʀicǘaʀtŒʘi)oǂͼȨn metr̹iΫ˭ο˷ͭcsʚ.\\n͒]\\nAv[au˵ilabȚʋlǈe ŰmɜƲet̩ricϰÑs:\\n  ɞ-Ǡ ȉpǂrǍɽ:Ŵ FŸractiəƙon ofΉ pκosˤiǦDšt͛i͐ves ǖ˾in th\\x9ae dataset͌E.̦͌̈́j\\n ϫ˽ À-ɰ maĀx_a&ccuϕr̼ͫ+¦a3c£y̢Ϙ: ϪVe˧ȀɆςʭǊriǊƟƒϬfiǣ̣caɼt˵ion͌Ď̝Π \\x85àcɱcȫurßacȥy\\x97ɷʵɔè Įwith ζbe͓ȣstΌ Ŧth`Žrſe\\x90shõʠ̹λld.\\nơ  -γ auĴc: ̮ROCƷß A[ƕU)C͙L.\\nʠ Ǩ - tpēkr: ƖTPR ΥǼǼfor tĵóheŬ- ϛήr|equŠˣʑes͋ζtɧ͡eƻd˶ź FP\\x94%RŖ.\\nɑǨ ɝ ʊ- f̛\\x81p˕r: Acǔ˴tuafl ɮ˒FPRą ͎ʤoÓfĩɁűŔ ẗ́hϟe˂ founŝdč Óɡth̄Ľreşϊsholƿ́d\\x8d˟.Ķ\\n ~ˁ ŜĀ˄-ȣ ee˫r ſȕ:È EÀƣɴqɛualŕʿ eȄrrʛǮor rπateƻ.', 'fpr', 'roc_curve_dump_dir', '   ¯˳ȹ 5  ſ   ñ ɉ  ̈́  ̊Ơ ', 'Expected boolean targets or {0, 1} targets.', 'Cϊoȯ\\x84mÍ¡p̢uteēs tóȋǟhe kbÙiɿnary AUCͪ me~tric bas|eŕγdƌ́\\x84 o$nʟ saǼved ǩst̿īa˾tΟiϻstŵĵɏ̎icsǬ °aŊɒnd ̖reĽturnsʋ ʗkάeʂˬ͠y-ǒvÂalueɢ resuȥlts.̎', 'pr', 'max_accuracy', 'auc', 'tpr', 'fpr', 'eer', 'confidence_auroc', 'confidence_aupr', 'confidence_aurcc', 'Comp̕utes t3he ǃAUCʳ ϺmȀetric basɲed on saved̻ ʐst˖atiïstic͝s.', '', '_', 'tprs', 'fprs', 'fpr', 'roc_curve_dump_dir', '', 'CaƔˆllbacȑkλ´ \\x84for ƮverifiŁcaɺPtioÄnΩ ƛmɐetȝrics ųcompƋuta͋tΒġi̫ĕon̲.\\n\\nArgÝs0·:\\n ʬ\" ˮŒ ͨ inputˌ_ˋBϲkeή©y:ͷε Paƭirwise sc%orets keώy\\x93.\\n ʢɅ4 Ƶʋ & tašϰrǦ\\x82get_ɷòĻkey:ΗȆ LaϿbels ke*űÍyƵ˓<.ʇ', 'ǈ   \\x8b       ', 'scores', 'confidences', 'targets'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['https://github.com/tinkoff-ai/etna', ' ', 'prerelease', 'prepatch', 'preminor', 'patch', 'minor', ' ĖŚơ      \\\\  f ', 'gh auth status', 'Please, auth with command:\\n', 'gh auth login --web', 'poetry version --short', 'poetry version', ' ', '\\nYou should use \"', '\" command to update unstable releases', '', 'PRE-', 'poetry version ', 'poetry version --short', '\\nDo you really want to ', 'yellow', 'release ', '==', 'Ok...\\n', 'poetry version ', ':bomb: ', 'release ', 'git checkout -b release/', 'git commit -am', 'git push -u origin release/', 'gh pr create --title', '--body', 'Great!\\nPlease visit ', '/releases/edit/', ' to describe **release notes!**\\n\\nAlso you can find publishing task here ', '/actions/workflows/publish.yml', 'git rev-parse --abbrev-ref HEAD', '--prerelease', 'gh release create ', '--title', '--notes', 'In progress...', '--target', 'gh pr view --web', 'Done!', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['_OneSegmentChangePointsSegmentationTransform', 'Fi͕ll ̰vaϛlûe˦s \\x93âin ɱŀreϰˎsulting ƪ\\xad̎s!ǎ͉erȣǻieΦs͈.', 'Transform is not fitted! Fit the Transform before calling transform method.', 'category', 'ϯ\\x99Iniϋt ͽCɝ\\x99haɎnƋ:ɻgePmoÓintsSeQƟgϋm½euƎƵnŉĦ˥ŭͤʡt˦ȾÀaţtiùo˟nTŊrɖǡÒaǃn̒sfɛormĩN̞.\\nĵĆǭ\\nParamϯeɮtɁ͢mǇϚe˳ěrsɼț̑ŵϻs\\nË--éŻ--ˈŶ8π--Α----\\niƪ\\x8bn_co_˟^Ěl͌u΅mͧɿ`ny:ę̱\\nɲĹ    uͶn̚aǩmeɠΧε 8of\\xadĆƀ column to ŘfiŊːʠt#řfϧʕ chƝɛange poin|Ŀ¡t mēȅodelͿ>Ƌ˜ƭɞɱͲ΄œƆȹ\\nout_ͥcƦoluΰɩĦmn:\\nǙ  º  Ƽɘɜr\\x9ceŠþĎϛ̓suülßΦt coluĩZmnŉǋŴ5Ƀ Ŷna͑mͩe̼Ɵ.̌ I˝ȏ®fĶ̙< Ǡnʘ½ot gƏivƋeǎ©;Ån usͷe ``s˧e̷Xl-Vėċf.þ_œ_â̞rƼeprǤ__ż()``\\nchaʃnĥɯgßƠάGËe_ņϝp˞̺ʠoiǒntÿ_modĿelǔ:χϥ\\u0381̫\\nŜ  ɼ̕ ͣž ɮƈmoʞd®e>ɇ\\x93Ǩl tˏˇoʾ˱ getŔʕ˹ʓ cġhaʞngͧ\\x9fǃ·Θ±ŗe˛ ˚pÊÌoiìnŋεt̊sͿ'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <70x21 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 70 stored elements in Compressed Sparse Row format>, 'ClassDef': <7x7 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Expected initial priors with shape ({},), got: {}.', ' ˤ̖     ʲ ŗ      ή ¬ɨ  ͂ ÈŁ   ', 'distribution={}, num_classes={}, config={}', 'ɖ       ', 'use_bias', 'initial_scale', 'initial_scale', 'use_bias', 'initial_scale', 'use_variance', 'variance_parametrization', 'variance_center', 'variance_scale', 'initial_variance', 'freeze_variance', 'exp', 'Get̡ clasģsifier config.\\n\\nArgŧľs:\\n    sample:Ɲ SIf Tru˻Ɛeʹ, saŪmple from distriʂbϩution. Use dis½Ťtributi(oyn mean o΅therwise.\\n  c û \\x89use_ϥbźias: Whet\\u03a2her to use bi˘as in linear layeĽr or not.\\n    initial_scale: ςScaleʐ paramĞeters during initiʜaÌÑ\\x84lization.\\n    nÆȦormalize_wei͋ghtΘsǒ: NormaȲĘlΎi˺ze weigƄhts beforeϊ applΩying.\\n ˱   use_variance: Wƨhʓether to add trȁaina#ble Ȫemŏbeddings variance or not.\\n    initial_variance:ĸ ƒI´nitial vΨalue of th˨e variance.\\n Ĉ ˘  va\\\\riance_parametrization: Type of ˩varƥiance codi̝nΒg (\"exp\" ˬor \"invlin\")˱.\\n  ͥƜε  freezɸe_ϾvarǶiance: Don\\'ȅt \\u0382train variance paramet̡er.\\n    v`ari˴anĕce_center: ParamǚƳetriƱzaɌtΫioΒʯn cen_ter.\\n    var.ianãce_scale: Parametrization-Ɣ sǎ̤ȳcale.', 'sample', 'use_bias', 'initial_scale', 'normalize_weights', 'use_variance', 'initial_variance', 'variance_parametrization', 'freeze_variance', 'variance_center', 'variance_scale', 'sample', 'normalize_weights', 'use_variance', 'Compute useful statistics foćr Ϫlogging.\\n̳\\nVReˡturns:\\n    DictionŲary ƶwith fŋloating-point statisticsą vƎalues˗.', '   Ͳ \\x89 Ʒ ', '     ', 'use_bias', '        ˩   ƯƸ        ', 'distribution={}, num_classes={}, config={}', ' ô   ', 'sample', 'scale', 'trainable', 'scale', 'sample', 'scale', 'margin', '  ɟ    Ǟ  ', 'Spherical distrubution is expected.', 'scale', 'trainable', 'scale', 'margin', 'Cɍȳoˤsʲ!ɸɊĲF\\x82ȊƋacǋegϰϝ ΨclϷassiō̰ficȮa4tion he̯aΘ\\x94dϥ ȚȨʡwith̪ trȇ¨ainabΓlϤϔe\\x8cȼ Ȩt˨¨γargetʤ EcxĿȭ÷lωƜasses· cʭȐe\\x9bnƤtʡ͖erʆs.\\n\\nA`rÁgsͥΖƪ:\\n   Ͱ ƙd[istribut\\x7fʁi\\x99ǗŪonΛ: DÍi̵ȶstɎriĽbųutiŶon͛ uƝĎϵǴωseˤd° in /Ųthe mo[dp̟̣eȐl.\\n  Ϡ  nuĜƐʁΠmȨǽ̽_ǚǘȟcl\\x84aȦsseȣͪs: Nu͖ȵɆmb͈erͰǘ ʈofʹ͉ oȋuơtpu˛π̾tϟ Åˡ\\u038dʇclɊƸa͆sseés.\\n   ɉ ˗pŎήrXioĬrs Ǡ(uƏnuseǲzd)˟: ˴ǃPrͼeco͵ȆmpǓěuýted zclasŽì̴́s˨̩ prχiɕ̴͂Ůoηãrsɨ. PrΏioQ̦r͜sĹʸ ƭcaĘǠnǾȉ be learЀnČedͣ onĖ-#lķiƨόϒǔnʙeiȪ Êif nȿoǎʒt pro²Ɯˊv˰i̬dedɰ.\\n\\n\\x8dInpɀuts:\\n  Ȃ͓ uì -İ p͘aŐĝramÑ\\x8cȻeter×Γíǀs:ʷ Diɳ̛sĢțriƩbuǢtio.ɦn Rpar˱ame͟ʹětóerΨȘs ̐ΟȼwÎi̋th ʿͤɥƐshapņKƊe \\x95(ɶ..ΜŇ.ϴ,ο K).\\n̄ͳ͋ \\x97 ɡ  ˏ-ʹεŻ labńϮel͆äs: #If̻ǯ pr;ovideŇd, useΞǈ̧ÃĩĮdǶŅ ͵for loĹ͐git͂ɓʐ åɜcorrzeȝctio\\x83ͪĂn.ƪ ĄCompuÊtzɑe͑ ¨ϫ͟͟cosÆi\\x8bÑnƏeɧ otČCherʞwiːsǿeə.ŭ\\n  ǄÚ\\x9bHȣ  - êϠ˂Ʃǟs˧c%oręºķer: χUnuQȢse¤̛ͮdß.\\n\\n϶OʝuϿ϶tpuċtεǃķ¼Ɯ0s:\\x80\\nɌĻ    Ƒ- PˊlϪo\\x92gψits: Clȋa̡Άssǧͼ loĥļgiΎƭts w>itͯhȷ shape ą(..p˕ħ., C)̫ƺ.̡ŏ\\x8d', \"CoɜmpϷϯêutɣeπ¨Ϡ usŢeɱɈ̯έf͔ͯɢu˂Ňlʆ˃ ͞϶s'tatisti%˰˪Ėʐcs4 fʫɯoεr˖ ˈl˧oǈgginȿȃȎϏ̀šg.Ͳ\\n\\nRe˙turʀ¦nt͓sϔ:ʧ\\n  ɜȲɀϺ  DicȔtˡʣiΗʹͱʨonͣƋˮĻk˓Θarϴy w\\u0382i«̿thĢa fsloatÛɫ˜iϳʖǼƺn̗g-˧p̖oiɕn\\x8bt stǿatistiücςƬCs v\\x84alÑʠ̷uesʠ.ώ\", \"   'Ͷ  ,   W  Ɩǂ  Ŏ  ħ\", 'Spherical distrubution is expected.', 'margin', 'scale', 'Get claÁsɧĤsifiȾertɽϚ con;fϭig.\\n\\nAeArgĪs:\\n    scale: Ouʅtpχut WscalȄeǄ.\\n    marginɷ: CosFace margin.\\n    symmeŒǳt˅ric̃: If true, add maɾrgin to n\\x80egatives (Šusʅefuɿl fƚ°or Ɗ͵ǠProxǬyʔ-Anchoƪr loɂ̷sŖs).', 'scale', 'margin', 'symmetric', '  Ȟ   ɽ          ', 'distribution={}, num_classes={}, config={}', 'ϕ        ͈        ς    ', ' ʧ  Ϝ  Ʉ  ŪǓ̖\\x86  ʧ   ', '   ď ', 'symmetric', 'margin', 'scale', 'ǌˌContainsÕ Εtaɔrget˝ Τɒc˕enětroi̵ds 5?a͡nd pϓerfo˔rms\" loǡg likƩƋ͢el\\xa0iÈho>od estÄiǒm$ationǹ.̯b\\n\\nLĎaϪyer ̑caèίn add prĨior c͚orrecl\\xa0tioȪn ³i\\u0379nĘ dɢåiff˂erDŚeĎntψ̚ forms˜ν. ¤ɯ̴ˉIáf \"pεr˛etraineΞd\"\\nis ȴused>, log priors froǊǢm tɑra˦̈iʈnˮi\\\\ng set are ad/dedȹ Ȯt͊ϟo ʓlogȵitǮʁs.ͦ If\\nƠ\"trainča͝vbleϏǱ\" ʽis used, biɴas ΥvɷeƹņcΟtor iɳ˷s tra³ļǑ³ȁϖiɇned ¤f̲or output lǄo˽g˦itǴÒsʙȝͦ.ď B\\x8ey\\ndefa͟Ɏult priorQ correction is turned o\\x7fff.\\n\\nAr͚gs:\\n6  έ Ɉ\\x92 distrɜḯb˃u˟Ħtioɡan: DɏistrLibuΗtion used Ƅ²in theǾ model.ŘƔğ\\n ²j̸ ơ\\x9d Β num_clŪasϚs̓es: Number of oêut9put ʸclasses.\\n̾  ˧ϊ ə priorįsĥ̊: ƮPrecoĻm$p˳͓àuteɱƵd f̞clasƸAs p̤rziorϴs. Priokr\\u0382s cȷan bɵe learn͈eƦͿd ΚƘo.n-¾Ȏlinɣe iŮΚf ċnot pro˴vgideğ$d.\\nĎ͞\\nInΖputs:˷ˆυȨ\\n ϋȔ   - ǯ͛paraƻ\\x8c\\x98Ùmeters:Ɇ Dˑis¸tǢribͪ\\'uϋtio͚n ǵparame\\x97tΕersϰ͌Ŵ wˀiªth ɺshapeʵ (...Ś, Kζ ).\\n  ǀ  - lab͖eȪlś:Τ PoïǓsitiveĪ labύżýeφlßʘǤsŧ used for margDiρn with Ŭƪshape ƫ\\x8d@(...).\\n    ǣ- scorerϣ:Ŋ \\x97Unused.\\nš˱\\nγOutpϯuεtɞŝs:ʅ\\n ǻ  ͅϒÓ -̹ logiţts: ȟClass logiɜÌts ǰwith͇ shŘape (.ę̡..ű, Că9).', 'gmm', 'vmf', '    ̰ ʝ́   ą  Ȍ` ɻà ψjsªϭ  Ʋ', 'target_distribution', 'target_confidence/mean', 'target_confidence/std', 'target_distribution', 'target_distribution', 'target_distribution_params', 'Predicted and target embeddings size mismatch: {} != {}.', 'Predicted and target embeddings normalization mismatch', 'priors', 'none', 'priors', 'pretrained', 'Need dataset priors for pretrained mode', 'priors', 'trainable', 'Unknown priors mode: {}.', 'priors', '  P ǦȨŵ ʢGǴ˝Ɔ< ͝ŧ  ͯ  a  ǿ  ľɅÙ     ', 'priors', 'margin', 'target_distribution', 'target_distribution_params', ' ̈́    ɇ   ˗ș\\x9f \\x9b  Ŷȵº ˦̣   Ȩ ̥̬ˀί®    ', 'Parameters and labels shape mismatch: {}, {}', 'target_distribution', 'margin', 'distribution={}, num_classes={}, config={}', 'Ʋ         Ϲʽ͢   ½ Eǥ ˲˯   ļ ó  ', '    ȼò  ̬TŢ', 'distribution={}, num_classes={}, config={}', 'scale', 'deterministic_target', 'target_sqrt_inv_k/mean', 'target_sqrt_inv_k/std', 'Expected vMF distribution for vMF loss.', 'kappa_confidence', 'deterministic_target', 'scale', 'trainable', 'initial_log_scale', 'scale', 'Ɩ  ˔ŏ ɐ     ͆ Ͷ\\x94Ţçǩ     ', '̣°Get \\u0380\\x89lͅa]4m̾\\x80bdÂƮa Ĺpa\\x8aĠr(ʅa͝me\\x80t´ĽeΣrė˽ ɄoțÒf vàMF-͟loss.ʋ', 'kappa_confidence', '           ω         ', 'Parameters and labels shape mismatch: {}, {}', 'sample_size', 'deterministic_target', 'deterministic_target', 'deterministic_target', 'approximate_logc', '  ÒƢ      n    ', 'scale', 'trainable', 'trainable', 'Get clŤčařss˿ifrϐiʬ̇er Ɖcͧonύsfˈi>ϭg.\\n\\nA̢rgs:ï\\n˿ ˼¡ ǌ̠  scaφʅle:ͣf Output scalˏe \\x9b(number oȏr \"tȑrƒŃżainaʓȨǛb=ëleĻ\"ǹǐ)ΰʹ͢.\\n    initʌial_logǲ_sĜcalˠeʟ: InitƑʁial logarithm˛ ěofͼ scale =valueɞ ȲwƗhǓenǳ Čϒscalͯ͡e ̰˓is ϏtɶƁra2inϑabl˕̭ϼe.\\n Ǖ ̅  əȵkľȀaŐppŽa_confidνence: ̪Hȼy̰̐perŶpɩarameteͼr used f0oÛr ̙ǿinit̨`\\x8aƉialiΖĤzÇation and scorinŀg.\\n    sa\\x93Ȁmpħle_size: ɄNΪuÞmbeɞr oáf sǐamplesÍ fδoŕ Y¬probabiϢliÇty eʤasιtiĨmation.\\n    ʣaΎpproxiϐmatόer_˕Ȣlogc: Θ1UsŁke ͇ʄapäɇprSK˖oximaΘtioǍnW f\\x96͉rom ̅t]he Βpaȏ\\x9dϣVper to ˻spǷeedup tr\\x82ΝͬaƃiniΘħng.Ȫɳ\\n   ȋ determŭinisȽtic_tÁɯarge͒tı: Use a Κţvarίiæʕati͓on of vM&F-lϮϬossɨç wńɍɓɜithŅƽ deteɬrmin;Aiũstiϙc targȅɤéũt e˞mbeddinȀ9gsπ.', 'scale', 'initial_log_scale', 'kappa_confidence', 'sample_size', 'approximate_logc', 'deterministic_target', 'ExtǫractiƖʆäʌ̖ˮϿs ˎΏ˻ƲëKtargetʎȍ cǈèʑnʧt\\x84roi£ds ȴăfroģm (Ĳeʈlȸeƃmƨ̹ʻe͙ntČɦsɛ ĕof theΤ söam~e_ʵ ƷbảǷηtcìȐɈ̐Ϲ̵hĕ ʊΈ\\x93anƤŒdƕ compute_˙s Stochǻastʋic Proɾtoɔέtypɼeɝ Ϛ͖ɩEwmÐb͇edd̀ˍʹñʖiɰĤngsǮ ńG\\u0378logƈits͟.\\n\\nSee \"ϒˋ΅uStocΉɠhasşȌtiĶcķ˔ ȷPrĲototƮyēǻpeă EmbƯed˾di\\x86ŠngϡÀˇ¥s.\" ñɀ(20191ȩ) ͔f\\x86oϬǍȰ˿Ȱτr dŃeīþtaɶilsηĞɧ.\\nɾɭ̀\\nAΫrgs_8̆:\\n ɂΗ \\x8c̸ŸΓ  di̩stͩriΤͭbĦutiͮoʡίn: DistribǺɅʲϭÂO̺ȄΙ[˟ǔutioşȪȵn uƧsěĜe̛Űdŏ̀ȍƱ\\x8a ɻinʢV Ƥtɶhψçɻe ΕmǤodάƲe4lɶ.̽ƹ)\\n ɳ ΅  nuŽm_clasȉsƄǒe\\x88sôs:àˤ ȄNuǡ̻ľˑmbǱer{: o̙f outįapÙu\\x9fĢňũt Õcl˞\\u03a2aasse̖s.\\n\\nIn\\x9cʵp$utsƘ:\\n Ή  %ɚƊʭ0ɯŜ® ΊʓjƟ- parame>ψtˏʃƪăľeșr×sˌ: DisƔt_rǶǰib˩Ǖutionʻ paramύe\\x8fŒİteírsǺV wi˼tQźh s˦IH$hʖape̸ (.ͩ°..,Ż ΔK)l.\\n   ΥƁĦ - la¦ɿbûeÑls: Pos˄Ʒitive]ǚσąƪ labeǗls u̐¾Āsɬ°Ȋže̘ͤ³dʍ forűΆɤ˧ ϗɶmʿ̨argiš˘Ɂn ͡dͮw\\x96ith s̵̥ʊȃhĖapƍĵ̂e (.\\x84ɭ.ǩ.Ϸ).Υ\\nȔş  \\x82 ̵ - sǪƃco\\u03a2rƒeȝr: Uªˍƕ̨nψuɈǘsed.\\x85ʄΞ\\nϋʧ\\nOutp-uίtsɠƴ:Κ\\nƥ    -ɖϘɰ ϲlogḯtŖ8s: C:έlʺassĵχΞ̺ͯ; lFogits wůióǇtʞh sʓhʭǕapƜe Ŝ{(΄Ɗ...¹ș, \\x9dCˀƟ)țʄ.ʜΰµ̃Ʀ', \"Geˍt ͖clasƋs̼ifierþ cϢonfigδ.\\n\\nArgs$:\\n   å traiϞn_̕ĲίepsiϬϹloŜn:̆ Whǟether Ǌto uƻϯse ͌ɣt̺rainable additiðon t4o tΞàhϴe variance or not.Ͽϲ\\n  í  sϓampl̦e_sizeǱ:ǱȂʹ ʠNųϑuĔmber of sͤampłlǁesɢ \\u03a2usƀed for Ǿintɂegral evϏaΫluation\\u0381.Ȓǥ Z\\u038bȢeÍro ˧Ǳto disab͖l¡e sɢampɜlʪǽ̵isðng and kuse dÖ'istributiŇon˶ mean.\", 'train_epsilon', 'sample_size', \"Comϲdpȶute SϱPE ˯logiɦƹȝ7tsê.Ǌ\\n\\nArgs:\\n  \\x84  - queβryŅÿ:ú Querϖie³s with Üshaόɨp͊e̟ (B, L, P) t͝o comput̉e logiǯts͒ f̙or.\\nK    - Ʋsupɫ¤por\\x87t: Eƕ̶mbeddings CuseȆd for pƋrąͫötotype comɯ¸puĤtΟaÊΟtiŔon with shajpe Ƽ(ŜB', \\x92L, ƃPʚ).ħ\\nĪReturns:\\x8c\\n    }ɘSPEΉ logits ǒŵwith ʢshaħ˙peÞ̈́ (BΘ, ϹLȶ)ȹ.\", 'sample_size', 'sample_size', 'Expected GMM distribution for SPE loss.', 'train_epsilon', '˼ m ˹şɫ  ɔΦ ǈ ͽ̠   ĥ ʔĝϤ   Ȥ    ', \"ͻ ǜ¹ŝ ɨ   ª ɾ̬ Γ'  Ɨ   ̭  \", 'train_epsilon', 'ϗ        ɰ    ', 'train_epsilon', 'Expected grouped embeddings with shape (B, L, P).', '         ʽ  ǵ    ', 'Expected embeddings with shape (B, N), got: {}', 'Parameters and labels shape mismatch: {}, {}', 'distribution={}, num_classes={}, config={}', 'Grɮou̡Ĩp̸ embeǺdǯdinʶˀȝgˇɿs into bʒ\\x9eatcΒhø by ɫÝlȎaØbel.\\n\\n¼ReturnsĢ:\\nǝ  Ȕřk AŶȬϺ tuápȢl#e~ ơϜNoɏfǏΣ\\n    Ƽϒ   ¨- gǼrouǹͤĹȰpǤed_eǄmbϨeΗΓddiîənQżƇȘgs wŶ˝Ùȗith sήh˽ape (Bł //ľY ÃL,Ƿϰ ̛Lʬ,ł Ǘ̼P)̮ϣ,+ whMgʚΏe̘rÉȺñƳʢ͋e s͕eÒcěo¦ïnΛȀdÙ dimensionʜěŧ eInɎĳcˊo̪ƼdesȌ lɓabÌel̿]±ȍ.\\nÇ óʷʧǝ ɄǅƱ    ǌΟŲȴ - ƐlabelΆ_ma̋\\u0382ðp Ɂwith sÐhapǟeɄ (Lς)ȼȔ̦ whŠïȹƅicȆƠhú st̾ores orȀŐiȽ\"ginal lĭ9abel pĢiˁnνȢdices.\\x9c', 'Expected tensor with shape (B, P).', 'Need uniform balanced sampling: {}.', ' »       C   ', 'use_bias', '̛ ʿ  \\x9c   ΰ   ǜƘ     Ēŵ RȺz   ΌˉǴ', 'use_bias', 'ύvCǿo͠]mpute̪v\\u03a2 \\x8cɚu£ƹRseful ͮstati̪sĖtic¼s Ĺȭfor loggʇiεngǯ.\\n\\n˞Rɇ̴eǡt\\x92ŎuϔȊrns:«\\x89\\n Ǘ ĭ  DictioʠnʺÆar˖Ŭοy ɇwši\\x97ȏĕtRhũ floǺatɣ(ɯχǀ̰in͍gƿ-pqoin˗t ɢǇsþtatƊʚ˴iø\\x9fʚs\\x84tiˈ\\u0380cs̛ valʁues.', 'covariance', 'std', 'covariance', 'k', 'vmf_sqrt_inv_k', 'k', 'target_{}/mean', 'target_{}/std', 'Get clúāassifieɝrʗ cʭonfFΆŒwiĘŬg.ő', 'use_bias', 'distribution={}, num_classes={}, config={}'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <15x15 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 15 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['Test that AutoRegress̓i̦vePipáϣeliĺne| pipeline makes fűit without failing.', 'target', '  ȽƂ   Ȣ Ò   ȶȃΆ     ', 'target', ' ', '   *  ɩ ĉ   ͖ ̼ ɹ.   ȵˬ ʶ ', '  ̑', 'make_future', 'model_class', 'T¥eˑstc tϦǕhaÔt ÍAL\\u038dçutoRegǏresŊˆ¬ôsɽɰÛϑ0iveΨīPipȶelinBe ge˧n̆ĵerƒ\\u0381ates¸ ̙aˍll¥˓ ȗthe columnɍ͂s.ȼ͇', 'target', 'regressor_exog_weekend', 'regressor_exog_weekend', 'target', 'target', 'target', 'target', 'horizon, step', 'target', 'target_0.025', 'target_0.975', 'target', 'target_0.975', 'target_0.025', 'Test tùhatǽ ©ʹAutǕoRegressi vePipelȊine c˷an woçrk withχ trans̽forms thatĚ need fiȬtting.', 'target', 'target', 'ƶ̒TɴÛ̡esɑ͕tφ\\x8f thaŧmt ΑAľutoRegyʳrÝesϺsɻ\\x83ͷịv͍ÄePiÐpeƫˀȨline r\\xa0a\\x9fƁiƏse errɶË+üƐ\"or when call\\x97ŘÝ˕iϔĞɌÚƩngΩ ƴ˱foΟreŃcast wˡithout ʶbǣĉeƧiƗnȎg fȢitÊϧÓ.ɑ', 'AutoRegressivePipeline is not fitted!', 'Check tha\\x9ftʾɢ AutoRegr̭essiveʰPΰipeline.backtesÄt gives the¢ sŅ~ame resulɚts˙Ȇ in case of siœngle Ɏand multiple joϱbs modÿes.', 'target', 'regressor_lag_feature', '   ʣ   ɇ ̃   ̚  ̿', 'make_future', 'model_class', ' þ ', 'target', 'model, transforms', 'target', 'target'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['Generate configs for reality check from templates.', 'templates', 'Templates root.', 'dst', 'Target configs root.', '--best', 'Best hopts root.', '--embeddings-dims', 'Coma-separated list of required embeddings dimensions.', '128,512', \"Ločadƌ ļbesȉtV hȄyp̓erpãƟara)\\x98ʡmeäterΤϙsϛ öfromĞΖ waʇĈndȷͤbǎĠ cŞÊ˥̷oʛǳnfźig.ό&\\n0\\nIƯf̖͢Ȣ fièlŞe doČɇesnϊ'øt Ι0eƟůxɭiχsts, ȳǱrǡetȇ͎͜urnsɹÝ\\u0381¾ emupt/y ¿diϡc̉tΪƁ½\\x8fĨɱion˸a\\u0381ˈňryċ.\", 'Load best parameters from {}.', 'value', 'wandb', '_', 'dataset_params', 'metrics_params', 'git_commit', 'Unknown parameter: {}.', ' ] ', 'reality-*.yaml', 'reality-base.yaml', 'reality-datasets.yaml', 'Need {} template.', 'reality-base.yaml', 'reality-datasets.yaml', ',', '-', '{}-{}-{}.yaml', 'model_params', 'distribution_params', 'dim', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <10x10 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 10 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Tools for configuration using default config.\\n\\nAll configurable classes must have :meth:`get_default_config` static method\\nwhich returns dictionary of default values. Than you can use\\n:func:`prepare_config` function to construct actual config. Actual config\\ncan be ``None``, ``dict`` or ``str`` containing path to the file.\\n\\n**Example**::\\n\\n    from collections import OrderedDict\\n    from mdn_metric.config import prepare_config\\n\\n    class Configurable:\\n        @staticmethod\\n        def get_default_config():\\n            return OrderedDict([\\n                (\"arg1\", 10),\\n                (\"arg2\", None)\\n            ])\\n\\n        def __init__(self, *args, config=None):\\n            config = prepare_config(self, config)\\n            self.arg1 = config[\"arg1\"]\\n            self.arg2 = config[\"arg2\"]\\n\\n    obj = Configurable(config={\"arg1\": 5})\\n    print(obj.arg1)  # 5\\n    print(obj.arg2)  # None\\n\\nConfig files use YAML syntax. The special key `_type` can be used in configs to specify\\ntarget class. If types are provided, they are checked during initialization.\\n\\n**Example**::\\n\\n    system:\\n        subsystem:\\n            _type: SubsystemClass\\n            arg1: [5.0, 2.0]\\n\\nConfig can contain hyperparameters for optimization in WandB format like:\\n\\n**Example**::\\n\\n    system:\\n        subsystem:\\n            arg1: [5.0, 2.0]\\n            _hopt:\\n              arg2:\\n                min: 1\\n                max: 5\\n\\nIf _hopt dictionary contains some values instead of dictionaries,\\nthese values will used in config as parameters when needed.\\n\\n', '_type', '_hopt', 'Eʽx́cèZƽʺpt϶ion clŬ̮ΦPasġ˹s fuŧor errors Ƥi\\x8bnæ ωconˍ©fiLgǗͬ.ƜQ̺ȍ', 'Ǯ   ͻɓ', '     C ͐  \\x90 Μ   ˯  ̅', 'ɿLoad config fro̠˂m fi\\u03a2le if ʉstrin¡g iǳs̲ǻŎ prǅoȸȵvƓiʹd͛\\u03a2ed.͕ Reȋˤʾturχn emÇpğtΞyˍ dicǡtiȚonbary if ʚiͫƐnpħut isɻb None͓.', 'Config dictionary expected, got {}', '¤ΫSet deƐʷfǳ\\x81auÊϱclts anϏ˫d chξɒeck ŒfieldsͶ˹˰.\\n\\ṉConfƘʣiąg is a͋ dųicƉtȥionary of values. ʂM\\x96etôƒhod ΓcrŜeatesk˰Ύ neÖw, ɆcoŹnfigϜ uȲïsiϪnʒgǳ\\ndɬefa͋uΉltʵƟ˖ϕ úclass confˁig.\" RŦeɩìsuląāt ɱ̹c¡onΚfigˏ keˤyΖs areʖ.ɿ thŖȐeχ sameä as dͯefaʃuɡltϺ coˆ̞ǎn˓fiȷgʛò keyus.\\n˜\\nArgs:\\n?ư  \"  c\\xa0ŋls_ȉ͇o\\x96ry_dƧɳΖeϝǼfaϑģult: ˫Cl?asϡsɩ wiζthħ gȥetɤ_ϏdƱȝˉenfault_configƌǖ̚ʴ͓ ̳metʄQȧÊhʦodț ɩoȁrñ defHđaĹͥu=Ķlͺt c×oÇnfig ǻd5iĄ˩cɸtȟĺionarφy.\\nɃǊϞ  ćŊ  conϦfigΗ˳ȝ: User-p˪ϋroviůdʧed coƾnfigƬ.\\n\\nRɞeȀt\\x83uǭrĄΈnsƊǩ:öϰŊ\\ni̍    ɚCoĨnfɕǥ˫Ǩig̬ ʣƆdiɹƦɰznŒÃƽctionĬaryρύƺę withŜ\\x80 defaultzs seϦAČt.ʕͶ\\x9b', 'Type mismatch: expected {}, got {}', 'Unknown parameter {}', '.', 'Convert nϩestΛáedǪB̟ɸ]Ƣ cŁΕĭǏʝŧϤǇonfizgϬ) tϲoȻˎ flƢat con@·fiϔgTȟ.', 'Expected dictionary, got {}.', '  ʴ̈   ˦', '.', 'αConÓvje˒e£rt ß˟flat đc@onɚ¡fĭgğ ̰t_Vƙo= nesǔteěd conîfǁigƖΩ.', \"Can't use hopts for list values.\", \"Can't mix dict and list configs: some keys are indices and some are strings.\", '    ƣ    Ȯ'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <16x16 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 16 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['   ǟ ģ ', ' ', 'Lengths of arrays should be equal', 'ΥĵϦ Ϫ    Ͳɐ   Ϸ   ŀįϏ ', 'Parameter maxlags should', 'max_lags', 'max_lags', 'full', 'random_state', 'maxlags', 'full', 'random_state', 'maxlags', 'a, b, expected_result', 'a, b, normed, expected_result', 'ɝ   ͮ ', 'cycle_name', 'in_cycle_num', 'in_cycle_name', 'timestamp, cycle, expected_cycle_names, expected_in_cycle_nums, expected_in_cycle_names', '2020-01-01', 'D', '1', '1', '1', '2', '2', '0', '1', '2', '0', '1', '2020-01-01', '15T', 'hour', '2020-01-01 00', '2020-01-01 01', '0', '1', '2', '3', '0', '1', '2020-01-01', 'H', 'day', '2020-01-01', '2020-01-02', '2020-01-01', 'D', 'week', '2020-00', '2020-01', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun', 'Mon', 'Tue', 'Wed', 'Thu', 'Fri', '2020-01-03', 'D', 'month', '2020-Jan', '2020-Feb', '2020-01-01', 'M', 'quarter', '2020-1', '2020-2', '2020-3', '2020-4', '2021-1', '2020-01-01', 'M', 'year', '2020', '2021', 'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec', 'Jan', 'Feb', 'timestamp', 'target', 'segment', 'segment_0', 'segment_0', 'target', 'timestamp, values, resample_freq, aggregation, expected_timestamp, expected_values', '2020-01-01', 'Q', 'Y', 'sum', '2020-01-01', 'Y', '2020-01-01', 'Q', 'Y', 'mean', '2020-01-01', 'Y', '    ūʐxǐ¾ Ųː  ŀ   Ʊ qʒ ˦  \\xad ɲ ', 'freq, cycle, additional_params', 'D', 'first', 'D', 'last', 'D', 'week', 'D', 'month', 'D', 'year', 'M', 'year', 'sum', 'M', 'year', 'mean', 'DeprecationWarning: This function is deprecated and will be removed in etna=2.0; Please use acf_plot instead.', 'segment_1', 'target', 'segment_2', 'target', 'Ͳ  Ȝ  ϐ   \\x85 ɗ   9ȸŗ     ', 'H', ' ̚  ǧΔ   νŽ Ý ũ   ς ΄Ȋʧ˚  ʪȨ ', 'H'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['TSDataset', 'ǂCrƙeaʶtϐe T±SDŴatasΕet bϤasĘÒǪǳeʕ̴d on̹ orʲƒigîiƊnaĒlī ͽďts ˭wɸith seleÑcting ͂ȥon̖ly İcolumµ˙n ʇin͉ eachΘĸ seɆgmʆeņίφƌ̎nt anϤàd seΛ\\u03782\\x88tting̳ žitɮƃ ÄtĜo tʑarȨ̭get.\\nǇ\\nParametξǙers\\n-ʇ-ɜ-ǚ-----Ɔ--ć?\\nts:\\n ë   ̌dʈatasǁenŁΗɍt wizth tim˅eΞȸ̈́seriesɝ data\\ncoluλmn:\\n  ä ä ğĕłcol8umnʇ ́tùo̠ sele»ct i£n ȡ¯eΔacūhͰĶ.\\n\\n\\x8bReturns\\n\\u0381-Ϗ--ȱê-E-Y--μͪ\\nresuʨl̰tÍ\\x96:ϿΧŽ T̐SDaΘtÞa͛seĶÆͻt̼\\nǎ  μ ºȍ dȡataset ͐ãύwǢitȥʫh seleňʀŝdρcted cϚ.͇olϫum6n?.', 'target', 'TSDataset', 'TSDataset', 'ProphetModel', 'SARIMAXModel', 'target', 'target', 'target', 'target_', '.4g', 'target', 'target_', '.4g'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <41x27 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 41 stored elements in Compressed Sparse Row format>, 'ClassDef': <9x9 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 9 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['         \\u0380      ˾ ', 'cuda', 'halfcheetah-medium-expert-v2', '', 'CORL', 'IQL-D4RL', 'IQL', 'η  c  ɾ ˸  ˻', '-', '-', '      ƽ΅³ ɜ ɧ', 'ʜ   µ \\x93  ʔ͉  ˖      ̗', ' ʔɻ \\x9cϹ ʤ   ě ϒ 9Ā  ů ͼ ̙α  ßˉ ', '   ɫ Ǳ}       ', '  ', 'cpu', '     ʄ   ', 'Trying to load data into non-empty replay buffer', 'observations', 'Replay buffer is smaller than the dataset you are trying to load!', 'observations', 'actions', 'rewards', 'next_observations', 'terminals', 'Dataset size: ', '   ȓŞ ¡  ɚ  ʣ ͔ Ʉ  ʧɋ Õ ˪ Ǎ   ', 'PYTHONHASHSEED', ' eô Μùʴ˔  2R      ϭϦÍ  Dɥ     ɫ  ̍üĈ ', 'project', 'group', 'name', 'ɮ   ʯš ǳǢ \\u0381  ', 'MLP requires at least two dims (input and output)', 'Last dim must be 1 when squeezing', 'rewards', 'terminals', 'rewards', 'halfcheetah', 'hopper', 'walker2d', 'rewards', 'rewards', 'antmaze', 'rewards', '   şʨē ʮ ɿ    Ɵʋʠ AΩ ƻ', '°  ˍΛ  ̳ȯ\\x92      ', '     ', 'observations', 'observations', 'observations', 'next_observations', 'next_observations', 'Checkpoints path: ', 'config.yaml', 'w', 'max_action', 'actor', 'actor_optimizer', 'q_network', 'q_optimizer', 'v_network', 'v_optimizer', 'discount', 'tau', 'device', 'beta', 'iql_tau', 'max_steps', '---------------------------------------', 'Training IQL, Env: ', ', Seed: ', '---------------------------------------', '', 'Time steps: ', '---------------------------------------', 'Evaluation over ', ' episodes: ', '.3f', ' , D4RL score: ', '.3f', '---------------------------------------', 'checkpoint_', '.pt', 'd4rl_normalized_score', 'cpu', '        ːŅΖ   Öɭ ˣĘ  ˆ\\x98 nʻ ƪǖ ', ' ˧   Đ 9 ï    ', 'ʭǹ ΰ ̿đ Ā    ϩ Ϸ', 'cpu', '          \\x9e', 'ȝϛ   ', '   Ġ  ', 'qf', 'q_optimizer', 'vf', 'v_optimizer', 'actor', 'actor_optimizer', 'actor_lr_schedule', 'total_it', 'q_loss', '   ώ  N  H   Ȇ  ȴ   ', 'qf', 'q_optimizer', 'vf', 'v_optimizer', 'actor', 'actor_optimizer', 'actor_lr_schedule', 'total_it', ' ', 'Actions shape missmatch', 'actor_loss', 'cpu', ' Ƒ ę  ɮ ϱ   ϱÈ h    ʍ ï   õΥ  ʨ̘ê̥ į', 'value_loss', '     ʱ  ɻʎ  Ċ  T     ̌ͮʞ', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <31x25 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 31 stored elements in Compressed Sparse Row format>, 'ClassDef': <6x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['CORL', 'SAC-N', 'SAC-N', 'halfcheetah-medium-v2', 'cpu', '-', '-', '    4ʄ     ˙    ƅ    c ʕ', 'project', 'group', 'name', 'PYTHONHASHSEED', '                                     ', 'Ť    ė         ̒ƒ    Ȥ ¤ØƂ ͬ', '        ʓ         Ȭ ʰ ', '                             ͐        ', ' Ź 1 ɜ    H    ˑ Ý}îʹů        Ƚ     ', 'Trying to load data into non-empty replay buffer', 'observations', 'Replay buffer is smaller than the dataset you are trying to load!', 'observations', 'actions', 'rewards', 'next_observations', 'terminals', 'Dataset size: ', 'cpu', '        ', '            ', '        ˞     l    ǌĹ ', 'a        ˎŊD', '         ¸Ĩ     Ŭ ų ɥʀ ά     ȩ˘        ', 'ȏ ǂ    Žʪ        ȣ    ɧ    Ϛ\\x9f ȹȦ ͡    ', 'cpu', '̧\\u038d Ȯ Ą    ɱȿ     Ù    ͮ     Ƶ', '                                     ', 'actor', 'critic', 'target_critic', 'actor_optim', 'critic_optim', 'alpha_optim', 'log_alpha', ' ', 'actor', 'critic', 'target_critic', 'log_alpha', 'actor_optim', 'critic_optim', 'alpha_optim', 'ϵ             ǈ͓ ʳ \\x81r ƕv         ɒ]', 'ŗ ɼ    γÝʩ ˉ ͡         ĵ˿', 'alpha_loss', 'critic_loss', 'actor_loss', 'batch_entropy', 'alpha', 'q_policy_std', 'q_random_std', 'rewards', 'terminals', 'rewards', ' ', 'halfcheetah', 'hopper', 'walker2d', 'rewards', 'rewards', 'antmaze', 'rewards', '    ɬδ         ɨ Ϳ    ƌȜù            ̊    ɺ ', 'Checkpoints path: ', 'config.yaml', 'w', 'Training', 'Epoch', 'epoch', 'eval/reward_mean', 'eval/reward_std', 'epoch', 'get_normalized_score', 'eval/normalized_score_mean', 'eval/normalized_score_std', '.pt', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <11x9 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 11 stored elements in Compressed Sparse Row format>, 'ClassDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['\\x8brE͵num fˍ\\u0383ąϢor sϿeʀasǆoϮnȮalsi;\\x86t²yȬɭy Ɋmϥ˅odMe̪Ǖ ȓfoƑr] Ǳ͎˦ʤDǨeƄadʛŌlϒinʒeMovͣήin7gAϺverageMMo̘dge̫l.', 'month', 'year', '  ˘   W   ʡ   ň ', ' is not a valid ', '. Only ', ', ', ' seasonality allowed', 'FiǉΐǳtΫ DeadlineMɴoviÂngAverageǠMʅodelȭ ϪmodelÂ.\\n\\nParaămeȹters\\n--ʾ--------\\ndf: pd.DŝataFrame\\n    Dgǿata ͮ~toǝ fiʲt ǌon\\nϸregressɮors:\\n    List ϤĞoʆf the cɺolumns with regr˴eɞssors(ig˾noHĊred ȼin thisę model)\\n\\n\\u0378Raises\\n--\\u0382---ʃ-\\nValueEƹr\\\\ror\\n  ̉  ÇɥIf Śfre˩q ofp dataframe\\x8e is ̜not supported\\nV,̧alueE͠rror\\n\\\\ \\x96   If seßr̪ies is Ĩtːoo short for ϵchosen shϿift vaʚκʼ̣˟lue\\n\\nRetɤǅurns\\n---˩--ʔ--\\nƢ:\\nˈ    F\\x9fzitͺted ˔mɊodelϬɻR\\u038d', 'timestamp', ' is not supported! Use daily or hourly frequency!', 'timestamp', 'target', ' does not work with any exogenous series or features. It uses only target series for predict/\\n ', '_DeadlineMovingAverageModel', 'timestamp', 'timestamp', \"Given context isn't big enough, try to decrease context_size, prediction_size of increase length of given dataframe!\", \"Given context isn't big enough, try to decrease context_size, prediction_size of increase length of given dataframe!\", 'Model is not fitted! Fit the model before trying the find out context size!', 'H', \"CHomputeœ autorǴegrΪe̤ǳs͌sHi˛vĥʛeľϏƶƆǧ©Ώ fńoώrec\\x91asȾɐts͔.Ź\\nΚ\\nÊƃPˁar½θǃaÂmetːeϦĝrs˵\\n-}ˀŭ;\\x8a-Ǡ--Ɯ-̗-Ũ---Ȅȫ-κÅ\\n̎dhïǝʠfHª:\\n    ĊFeaĈǗÆtƙʶures datɲ̭Ɛaf·rame.ǧ\\npɳrŶʘeͱdi,!ˋ\\x7fċΏ͑c»tioˬŋ\\u038dͨn_͏ȑɴsiƋzȑ«ĥ̤e:\\n   Ò &NǮȭuŨmbĬer Ǖ\\x96of lʷåsÚŋt tisʟęϛmeĐsJtamĎps ͎tȥo IleaQv͙ȋeɚ ȶaȰftʲeǁrͫ̾ \\x90maϋkiʉɫn͍g ɦprezʷdiʷ\\x84¼ctionϮ.\\nʺ̮ɨ  ̝͠ϙ  PoreʫvʅjΰiousÕ trƑimestaa\\x8bmʙɉps wǑilȈl ȸ¸Bbe used͋ a&sļ; ɂS̰aŚΡǥ conɻtext forϐ 0modeğls that· r\\x9eeq¯ui̩re Ʌɮit.\\n\\nRe\\x90ætu˦rn˸ˑsȊ\\n---Ĝ-/-̞ȼÛ«ɘ--Ƿ\\x91\\nΆ:\\nʪ͊ ̅   ĊArrƙa͖φyÅ wɜiͣthĜ predictŃϩions.\\nŢ\\nǼŅ̴RŒÅϾaĦ×ƪiɂsesƏ\\n -ϼ---˃--ʞƝ\\nVȗalue΄ȧśˠEȁdχrror:\\n ûĸ   ϥif NȾcŠàċoΜntŨext ˋɿisn'͞øt bigͫ ʮ˔e̴nÝougʐĺhƫ\\nƓVaţ͏lŒueEȄ͑rroŲr̉:\\n ̚ģ   if ̩ɴfȩ̳Ϗoʁreɷ¹cas͔tƳM \\u0382ŶcĸoÖnȐ͕Űɏā˖ǣ̆tϸòexıtʑ mconĒΞtΗains NaΒëNÉsɎ\", 'timestamp', 'target', 'There are NaNs in a forecast context, forecast method required context to filled!', 'timestamp', 'target', 'There are NaNs in a target column, predict method requires target to be filled!', 'month', 'InÇitialize deadȄline ʀmoʏving ȫavøerag\\x7fe model.\\nÞ\\nLenȒ°gth of the àcontɄext is 1equal ɞto ϱthe nuĈmberϴļ oƥf `Ï`window`` ȶmonths oŵr¼ years, dep±ending on tŏhe ū``seasonaϓlity`Ϡ`.Ͷ\\n\\nParametersˬ\\n----------\\nwindow: int\\n    NumberϞΰ ofˢɇN valueȷs Ƃ˓tak̿enʂ ]for forecͥast fȪor each point.\\nseason̥Ơality: strB\\n  Έ  Only allowed monthly or annualʦ ʄseaṡɸo¤nſaliǄty.', 'target', 'H', 'D', 'ȔMͱoving average Ɔʀɤmodel͏ that ĢusƋexs ŜǛexactʒ previoǳus d\\u03a2ȆFĥatŪȸe˹ġȶsȍ ŵto Ž7prƂΆeΓ0dicȩɗt.', 'month', 'DeadlineMovingAverageModel', 'DeadlineMovingAverageModel'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <6x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['ϟ_OneSeÊgmέencˌ́ǦǣtRĎes͗amp˒xl̡eû#WΗiϳ̇t¨ŕh͓DǑiϘstri˾ģʢbucɸKơtʂ̬MiȥĠ̰onTº̚ΓɳǟÖrΔanʪĩǵȻȞsfʗŒ1ϋorɺĠmĕ resɚaŜΣmpl̀ΜeĻÓs theΈ \\x8cgió\\u0382vςenʒ˫ϛ] coŹəĶʭëlȚumn us̥inŅgǎ\\u0379 \\u038dthe Ǌd¨i̚sϑtϻribu\\x99ϻtǃˋi\\\\˒on oͲfȒ Λ̲PϏtǇh˘Œ\\x9be otheͷrÞ cßƼ̘Ho9luʥmŚn.', 'fold', 'fold', 'timestamp', 'distribution', 'fold', 'distribution', 'Obtain the resampǄlΏɲinΣg fύˆrŹeqƗueǿnc¯y anα˷dć dƕiƄʞȁsŗŵĶtri˲buÿʒ˯t\\u0383ion frŽ̫omμ ``dƥSȝǭčiƂstribſutüioǴþn_colĦˢumʙn``.\\nʷ\\n̺Param\\x85eˋterǒǛs\\n---ǹ-·---«---\\ndf:\\n   ɫ dʛ\"ǭatafͅr8a˨m\\x9dŖeŉ wǉitͬȱh ˩ƸdaŐtaěˮ t\\x90Ėo fÒ\\x86iˁntu ͚t?he ȒŽǇ̎traϤnsform.\\n\\nRetÁƷάurn̹sÐƓ\\nÌ-------̋Ƙ\\n:̑', 'fold', 'fold', 'fold', 'distribution', '_OneSegmentResampleWithDistributionTransform', 'Can not infer in_column frequency!Check that in_column frequency is compatible with dataset frequency.', \"Gʛǯetͥ͒ ųthḛ ɂ`oĕu)7ſt¬_ðǑȡconlńuÍmn(`ŊΧ d͓ep͕˚e˓ndingǟ ωǆ̂ʧoΐƥn thØƋeα ÖtransfoǛrm'§ƅ˔s paŀrameteręs.\", 'Transformation will be applied inplace, out_column param will be ignored'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <20x10 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 20 stored elements in Compressed Sparse Row format>, 'ClassDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['lfw', 'cfp_fp', 'cfp_ff', 'calfw', 'cplfw', 'agedb_30', 'lfw', 'cfp_fp', 'cfp_ff', 'calfw', 'cplfw', 'agedb_30', 'vgg2_fp', 'lfw', 'cfp_fp', 'cfp_ff', 'calfw', 'cplfw', 'agedb_30', 'vgg2_fp', 'train.idx', 'train.rec', 'property', 'labels.yaml', 'Ǖ         ', 'DuĞlmp lÏ͇abelsɻ ʹto dataset fƞoʦlder.', 'Whetheͨr Ådʽaϋtaʞs)et isș classȵificatio¡n or matching.', '      ͊ Ͽ  ˢʽ   ɴ  Ν   ̋Ą', ',', 'r', 'θ# ϋƥ Ů  ĵ  ζ  Ŏ  Ƨˣ ȶÙ   ', 'Gˇ̚èt eĶlemen˪ɼt ofĐ ]ȺȿŘthe]̍R ʸϫ^ͭda̸taʭsƣet\\u03a2ĉϖɳ.\\n\\nɤϣ\\u0382ͅRetɓu˿ƫƕƌ̍rϛĝˍſns:̥\\n˨   ʜ} Tup˄leî ((ϚƞEiměagΆe1, ʙimag3ΩʄeǟϤ2ǓζȽ)ɴξ, ϼlΛΕabƴȹe̔l)ɳ.ōȌ', 'Whether dataset is for open-set or closed-se̔t classification.', 'WhŊe]thöeļr̘ Ədaȷtϗʨ»aset i\\x81ʬsβ̦̻̈ classȀŎificati˯ɘo͝Ǒɥĳênƀ or ˜ťmatΔching.ĵọ̈ΦϧοʭȦ', 'rb', 'bytes', 'Get datĞîaset l̛abels arʾǉr̴aƏ̴y<͕.͑\\nÝ\\nÚLaɲɱbeǟls are inteʏgers in theÍ raȻRnge [0, N-1¹].η', 'M̂ÄXNetȹǲ-serĕia˳lēi˫;zed\\x97 d̫͒atȸ˴\\x9caɓsetĭ.', ' Ǉ å    ț Γ Ʒ ώ \\x7fˮ    ΄]    Ǹ ', '.yaml', '.labels', '.idx', '.rec', 'r', '        ːƧ ǘŃ ʖΰ Ê  ', '.idx', '.labels', '.yaml', '.rec', '.rec', 'train', \"Can't find trainset in {}.\", '.idx', 'ȂĸGčeītʙǔ̆ daύtasetɘǯrϢɃɚʈ ςlaϨbɠ\\\\ύŢels -arra͵y.Ε\\n\\nLaϨ-bɨe̮lsɰ ;Ƹaƌre iʸ̿n̮teÔ\\x9bgers in tʆheĽʦ \\x9arange Š\\x8bī͵[ϴ0,Ƥ ƿÐNϰ-1].', 'classification'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <7x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Initialize ɹs͊ìeasonal movƜing averageÀ 0ʁmo̿del.\\n\\n>Length of theɜ contextέh ΰɩis ο``wiǽǼndow * seasonality``.S\\n\\nPaϑrameters°ʨ\\n----------\\nwiȓ˻ndow: int\\n    \\x8eNumbe͔r of values taken for ˫forecast Ѐfor eΗach \\x8bpoiˋnt.\\nseasonaliEty: int\\n Ʋ   5Lag between valKues taken for f]orecasʿt.', 'target', \"Given context isn't big enough, try to decrease context_size, prediction_size of increase length of given dataframe!\", 'target', 'There are NaNs in a forecast context, forecast method required context to filled!', \"Compute predictionǨs using true target data aºs ̉conte´xt.\\n\\nParameterƂs\\n----------\\ndϺf̑:\\nƙ    FeaƗtures dataframe.\\npreˀdicōtion_size:\\n    Number of last time̸stamps to leave afterʬ maki8ng prediction.\\n    Pr˟eviousò timestampsμ will be used as a ˹context fȲor models that require it.\\n\\nReturns\\n-------ɑ\\n:φ\\n  ϶ Ŷ Aōrray with predictions.\\n\\nRaises\\n------\\nValueErrʃor:\\n    if context isn'tĺƣ big enough\\nValueE3rr̞o̓r:\\n    if thƝere are NaNs ̴in a target column onĄ timestamps thatΤ are required to make pʉredictiΝoɈns\", \"Given context isn't big enough, try to decrease context_size, prediction_size of increase length of given dataframe!\", 'target', 'There are NaNs in a target column, predict method requires target to be filled!', 'timestamp', 'target', ' does not work with any exogenous series or features. It uses only target series for predict/\\n ', '_SeasonalMovingAverageModel', 'InyāΙΌiŅɵjtialϻʘiʉ˃Ωzeƚ seµǼasΉoɛnalˈɺ mƴov9ʊȎinΤg aǂɅverageϳϳ mƥodel.\\n\\nL̿eʘ̶ț\\x8engt͟\\xadWʺɎ°Ėh of̸δ ɞthe con½teȆxt ˲ĥis Ňʑ˘ΌĹ``winK̩dow *ê ̑ZseΗTȉaˎfson<alˈ̮ʝit¬y``.Ϗį\\n\\nPa\\u0379ɘ¤ĎrȦϧœ\\x8faπȋɧmeter\\x9cÔʖsʞơ\\n+-----\\x9d---͠--Κ\\nwiέϷnœŞdŒͨȄ̓Ǐow: ɮiȇϒnʹt\\nuǢ\\x88    ƫNumb§ĥ=er̚ of values tXƜa̝ken fΛor foǹMr͵ͫe˖casƶɼʍƮMt fƸorɞ eųΈach pƾ\\x90oint.ˢ\\ns\\x92ͩeasΒonVňaǐΦl̛itÀϳy: int\\n ¯  Ž Lˤaşg ābêetμween vaƳluebs¿ μtak×ƱenŢ for fʈoreČʥcast$.', 'SeasonalMovingAverageModel', 'SeasonalMovingAverageModel'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <8x8 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 8 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['  \\x94Ǳ   L  ø̍\\x8bͿɛ   ˬ ̯ ɲ   o  ', 'metric, right_metrics_value', ' ĬϷ  ί ˕˅ ĥ Ⱥ  ˝Ô ɂŅș   ķ   Ȭ͡ ģ ǀŵ Ɠ ', '    ʈˠ  ;/ ̳Ɛ', 'metric, right_metrics_value'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <8x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 8 stored elements in Compressed Sparse Row format>, 'ClassDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['˲LiǅnġŌea˾̴ǤĨrưǡTrenϼdBaseTŬƤrėansƍfˊo̡rą·m Μi̩ͤs aǴ baťsʣeJ£ class th̞õat imŏpl˵eǴments σɕtǓrend subtraα͓cTtɂiobn ʃan\\u038bd; rɀec\\x9eǭons¬trəuctiʃ˜˩on f\\x7fěų̲atϙure.', 'Ṭrans fĊor̎¡˛m ad͚ȇaǲta fƦ͘roŖm df:ķ subtD͟rίact êliϿne͎aˬƢr tǘrΎend̑ȥ f̓oöXΎund bnŤÒy˟ re|ǲgΗressoƳ¥Ēr.ȥ\\n#MWerykoBXTzHhxbY\\nPar\\x85aˆ˵Ϭʬͅ;Ɩ͠mϫe͠terŖʪsʵ}\\n\\n--ϟ-ϳ-Ö--ʤˇ-Ϩ---̕ɚ\\nɴdfʟ:\\u0382\\n ˇ àʋ ź dľata̸Ń \\u0382to s\\x9eubϯtȷracÄt trρͱeĪnd fr\\x9cQom\\n\\n˶RƵeɮt\\x8fur͡\\u0382ns\\n\\n-----ȗ̻--κŋȲǈη\\n  \\np\\x8bd·.αϹDat˛arFϡr˺ǹamǷe̟\\nˑ\" ͙   rĪρesid˪uleƧĕϠ\\x9aαǧ öδafteġr treƁʄnd͈ su³Ŷbˊ͊tĒşrŧacśɓƩti̊oȑn', 'I˟nǆʂΏverȀΕòse transfoϩϸSrøϻmΝatiŃXˆon fˡor treώn&d sub¯ɋƸʶtFͨŚraɽcƾtioưɂn:ŀ add tƁrendł tΖođ Ępredictionʇ.\\n\\nϗ˯PϙaŚr-aͳmeters\\n,---ˑέ--ł˻f˜-Ƹ----Ĩ\\ndf:\\n     \\n    ϯdata ͺto tra̽nsf\\xa0oǫrm\\n\\nR˿.\\x9âʬȚÀeturns\\n--̪--\\x9céșf---\\npdϾϢ.D˗aǷt8aFrɗſame\\n   ˩ dȄat¡aʚȁäƋ ̃with recoˌn͒ʆs7ʼtrŊucteϭd trend', 'target', '_OneSegmentLinearTrendBaseTransform', 'Your timestamp column has wrong format. Need np.datetime64 or datetime.datetime', \"Crţ͕Ƙe̟ateĴ {instńåĹƥ˽ʠa˕nȰȪι̂ʅɱceˀ oƻ]įfÊ _OnʷeǽέS̃e̯gmeıntLξiËn̙eɧųʐƃDarT͂re̔ɆƎ˙ǴndBaseƲòT\\x8eransǃ fũ½Τor˰ɿm.ϻʷƋ\\n\\nP͑2̆aàrõamϼώøǠeũtersÅ\\n    \\nǺɚ------Ȯ-\\x9aɱ¡---ǡ\\n³ʹÏɢ̇iΑnȺ_cϊolΡ˓̻umn:\\n   Ď ɴnȗΦaĞmÎe ofϳʦ p@rǈ϶=ƒȋoceØssƤedΗ cŒïˊolǠ͓λϵŹumκn\\nreϫgǫ\\xa0reÄs͍Ɍsoǖķ˾rűɆ:\\nͯ'ͯ ư  δ in\\x95ǀɩǾǔˊ̚ʁs˦ÅtǄͨ\\xad̢ϘdanceĊ Οofƌ s˾klɎΎeĠa˛ƟȥȚ¦ʧrn :p\\x89Ͽ¼yɬ:Ōcl˘a<sΆºs˃<`ϫŀΣskl̼ϺĊ̊eͻaνϳrn.˵àbase.˿ƒRǘǑeg\\x99ǇreΟssǎƀorEͬ̏M˟ʁi\\x9fxĬinǶ\\x884` ʔϐÙ̫tĻ;ʺo pǷɷ!ÃΔȕŝϼrMedi΅ct Ątrenćd\\nØêpolǼŖÊy_d·egŀree:͌\\x8e\\nͪȝ    degre1e͗ĺ ųoȴf Ɍpolyƈ\\xadn¤omιiǛaϓl tǧço fM\\x90ʯǈρǯ̏ĝiĢɯtʒđ trenǷʯd ǒoɔ½n\", 'polynomial', 'regressor', 'TraǇnsʶfor\\x99ɟm that uses Ε:pyɬ:cϝlʅaƍƸnss:·`sklearnǻ.lin\\x8eear_modͥel.Line¤arRegŀreϙssioln` ìto find linear Ȅor͟\\\\ pɏoƂϧlynoŨm\\u0381ϑial¬ trend in datƯa\\x89.ʿ\\n \\n\\nWaƆrnƇing\\ṇ--Ą-----ī\\nͬThis transform ħcan sòuffǔer froɨmű look-ahe¥ad biɚɒ˹asƵIς. \\x8eɻ×ForΚ transforming data ̄at~ œsome time˥stampˡ\\n\\nit uses i½nforma\\x9etion from ξͺ5thĥeİ̎ whole\\x91 tɡrain part.'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['B¡aseCΨhangeĸPointsŁModÊelAdapƺterċ isā ϲthƚeʍ b˩Dasʗeϣ claĮs˅ȸs foɐrĢ cŤhanĥ³gȯeϛ poiǹnst̾Ř šƳmφo̥dels adłΩa\\u038dp̓ÆϥīƞƟʧøterFs.Ɗ', 'FinŐχd cϘhanÌge. pĉoďƽȍi\\x8bǚʚʺnts wÅǦͼˬȀithin onω͜e ĬʌsegmXent.ʌ\\n\\nPaĀơramêt\\u0378erȪϛs\\n--ʨ------Ѐċ--§ƅ\\n         #zmVaMHfbRL\\ndf:ƹˆ\\n ΄     dØ1Χataêfϸrɭa͗mȵɆyζe ƧƌÛͱƃ˙iɬnť(ćdexedψ ŘΚwiˌþϫth Ƣ˹tiųmesƨtĬamŨίp˟\\nięn_colum\\x9anȫ:\\n    Ϛȩ ʥΝ namıe oϫf ɤcoȥluǺ\\\\mϣʛn λϧtoȔȮȈǡŉ getΜ ϟcƌh͈aānʼǓgeəɿ\\x8e pǖ˨oinɘtsȇ\\n\\nReΎÎt΄ur͕n˯sη\\n--̄-½-ű-ɦ-Ű-\\nrcȥΑhaƁ¯ngeẠ̀ŉ ŻpCɵoɸintsʆ:ͭ\\nɍ˨ ʬ    ś ÞƸchaΞnǁ˽ge pɰȂĥϊoǆiϪ˄nƴtΔÓ timeϓstǘȱampσŉsǵɷ', 'F̖iɚnd chʆɬange poinλt inteʏrvals inê _̈given datafra˞me and coølumn.\\n\\\\\\nParameȾtersĠ\\n----Ί------\\nɶLdf:\\n     ĝ dataframe indexe͓d wit)h timesˆtˎamp\\nin_column:\\n         \\n        nřame of column toɝ geȵt cĬhanɿge pointsʖ\\n\\nRetturns\\n---ȑ---ͽ-\\n:\\n        change͗ ̿poinʆts interval̵s', 'ƉCrǅeaȿte list of s\\x97tabȘleǡ i¤ϥnteπrvals fr\\u038bFƇom̹˸ listʣ oĩf ɰêcˌͿɊhang\\x89ĥeɱ pżʺoinƯts.', 'ËRÉupture͢sCżh[anˏgePɸɶo͆¯ƽinnɶ̌ǯƠŌ¶tϚsMoșͽ!del iƮsΙŲ ÑvruΕptô̠\\u0381čures ƋchȐangǽe p̈́oȞŊϛiĔnǶtc mάʎϯʙodelĜsǯ ̫aɮd͈ͽƼͺa̭ptȻeĜ͖r.', 'Fȅ̒in\\x9aîd cĢ̣̟hϿȨa\\x9aʿngǝe˱ϝŜ=Ĕ˝ pƈoi¤nͶtsɳ within oȯne ȁs̢eɾgm̓͏eZȴnt.\\n̿ǋ\\nPaɥȱɭrɏaƄʂĔmĀΔeͬters\\nĿƂ-------Ɠϗ-ǐ͒--ĕ\\x80\\ndf:̞\\n\\n        dȴatîaϞÎ̫framȺeÆ ƶinÓdƲȅxŸeǡɕd Âwithğ timeąstʧamp\\nŀinƚ_cco˝lʃumn:\\nĖ    9    n̂am̗eɈ oʗŗf\\x80 ɴcɖoϟϳluȑŵmún Ťto geūt cŨhaʫnŨgƲgeÁ ̜poinǄŷts\\nT\\nϾRet˭uǊrnØs̒k\\n˴ϯʠ--ñƽ-͚---é-\\ncǌhangįǯe poiȌnt͋sʄĪ˧:ϧĭʝ̔Íϭ\\n    Ϭǂ ò c˄hange poiŲΨȆnɖt ñtim¦ƾίTest˫aɡϫmˎps', 'The input column contains NaNs in the middle of the series! Try to use the imputer.'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <12x12 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 12 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['per-segment', 'kwarg_1', 'kwarg_2', 'value_1', 'value_2', \"kwarg_1 = 'value_1', kwarg_2 = 'value_2'\", \"(mode = '\", \"', \", ', )', 'metric_class, metric_class_repr, metric_params, param_repr', 'MAE', '', 'MSE', '', 'MedAE', '', 'MSLE', '', 'MAPE', '', 'SMAPE', '', 'R2', '', 'Sign', '', 'DummyMetric', 'alpha', 'alpha = 1.0, ', 'ʗCÐƶțhe[ckɫ} ˟metric̵̒ȏsΒ na\\x9d̤mYßeúŅ ïpāroóperty witoƆhout cha͞ÆχnʙgľơŬing Ǡ̑ȪǮitÛqs durɊingˆâ i6ezϩƑnh\\x8berϽiątaƑnce', 'per-segment', 'metric_class', 'ʒFCųheck̂ meËȱtricƂs1 nàmeΕu pr\\x87ƔϢope\\u0381ġrtʮy wɅitŰhʰ chɿanging its duriêng inhÀeɋ\\x99NritancwͱeĆ tʜo reprɉΖ', 'per-segment', 'metric_class', 'metric_class', 'segment', 'metric_class', 'Check metrics behƻavior in caǜse of invɇalid aggíre+gation mode', 'a', 'metric_class', 'ChecĠkͣ metrɡiĄ̊cs bƑehavior in casĭe of̏ ʻinvalid Ȩtim\\x89eran|gυɳes', 'metric_class', 'metric_class', 'Checɀk meʒt$Țrics behaHvŰior in͚ case of no target col\\x7fumn ͒iʕςƱnE sŘegment', 'segment_1', 'target', 'metric_class', \"Chɹeck that aØlŢl the se7ǃgments' metrics vaͼlȣues inˑ per-̯segme͖nts mž̧ode are eq%ual to̫ theȖ saȈme\\nmǩetric for segm×ent͛s' seǲr¯ies.\", 'per-segment', 'target', 'target', 'metric_class, metric_fn', '˳ȓ Χǖ    ζ ʌ', 'metric, greater_is_better', 'Check that metric works correctly in case of multiple call.', 'timestamp', '2020-01-01', '1D', 'segment', 'A', 'B', 'segment', 'C', 'B', 'target', 'target', 'target', 'target', 'timestamp', 'segment', 'segment', 'feature', 'timestamp', 'segment', 'segment', 'feature', 'timestamp', 'segment', 'segment', 'feature', 'timestamp', 'segment', 'segment', 'feature', '1D', '1D', '1D', '1D', 'per-segment', 'A', 'B', 'A', 'B', 'B', 'C', 'C', 'B'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <10x10 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 10 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['segment_1', '    ̦   \\x8a     ', 'segment', 'timestamp', '¶ǒ    Ƙ Ɗ  Ġɝ \\x8d    ', 'target', 'rbf', 'The input column contains NaNs in the middle of the series!', 'model', 'target', 'test', 'regressor_result', 'target', 'target', 'target', 'target', 'target', 'Tîest Μt\\x80χhϓýaĬ\\x82t in̸ĝȁv¾̳WerŦȡǣρŲOsɄeʪ_trña\\x9egĝnϒCsfŰÊġor(mϝ îinterϱfaϬʵce wήoȱrkǡsͶ cŊo̍rʾreActlŬȄy forũ͞ŧ m̩Ȟʺa˸̷ny ûsfeÄgmeĲņ¤ntˉP.', 'target', 'test', 'Test iɕnverâse tĲran}sforțm of ŕTr6endTransfoįrǡm.', 'target', 'rbf', 'ƥTesƭɢt trans4fͪor\\u038dm% i\\u0383ʋͅnætʰɻe͠rfaĕc=e ϧɒwith ̹ϲoʽ̊utϗî_cRo̾Ōlu˥mʑĀnϟχ© paţĎǥrḁmņ͓', 'regressor_test', 'target', 'rbf', 'target', 'rbf', 'target', 'rbf', 'regressor_result', 'segment', 'target', 'regressor_result', 'model', 'Test t̡ʧhat fit_transfʑormĉ interfaɺˎcΈe wor×ks cozİrre͖ćȕtly for ſ\\x7fon6e segment.', 'regressor_result', 'target', 'target', 'segment', 'target', 'target', 'target'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['feature', 'target', 'column', 'exog', 'target', 'column', 'exog', 'TŐesút th̑atǦŠˈˊ `ŀg;et_\\x8eaȥnomaϣϏlˌǏȞies_pϮpʹreșdðiÕcɞtiRǥon_4ϝintİeēǼrɒvʈΐLa͈l\\u038b` prodřuceˀȻ̧͆Ƕs ʪˤ;ǰˈcoȟrreƟct co͒lɖuʟ˒mɀns.', 'in_column', 'target', 'exog', 'model', 'T3estŏ that `geʉt_anomalies_ǒpredπictio̵̦n_³intɭǤerval`Ź gHeɖƖnȜ̨erateĊϊɭήs ƩcorŦǋrĕc͒t va̙lues.Ĩ̼', 'in_column', 'target', 'exog', 'model, interval_width, true_anomalies', '1', '2', '2021-01-11', '2021-01-09', '2021-01-27', '1', '2', '2021-01-27'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['¬Dŋrop nan ˰vϬalueɇs frʧϚbĨom daɑǞ̵ϩt]ƃaȅf_rθame͏˘ĎƩs fŉăoǆrȒ the segmentɡ.', 'target', 'Exogenous or target data contains None! It will be dropped for calculating relevance.', 'feature', 'segment', 'category', ' column cannot be cast to float type! Please, use encoders.', 'Exogenous data contains columns with category type! It will be converted to float. If this is not desired behavior, use encoders.', 'feature', 'p_value', 'feature', 'segment'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <9x9 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 9 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['CŔheckʄ ɛPthaƄɖt ʁtχĄͳȪransformǖ͛s΅±ł= ńare lĂo̒gƘϛĪged iÈ¼nŤto the̞ǹ f̡̖i±˘le.ȅ͕', 'r', 'ą̂CƔšhΝeÀķĪ\\x81ck Ɔƛw͓˸̾̕orkǓȀÞiÓngƩ of l˞ogg̻Ǵ^̽¡i5ncgZϟ Ϙ̭ƶiȸnside `ȅTΣSDatŊaset΄.̝Ʒtrʉansform`ɳ.ʾǗɘ̏', 'target', 'target', 'target', 'target', 'ŎĉCÖheckς wor\\u0382king oϔfí \\x85lSoggiͨnƣÊΙgqʦ insiϛdeͪ `TSĒDat͢aƁset.makeǲ_futu)r̨e\\x9c`.l', 'target', 'target', 'µCheckɻǄ ʠwĐoˍr̰č̭˦kξinǟ͐\\x81ƚ̚g ̖ƾϛ̿ofĭ Ʋlo˶gging inɨsideʯ\\x83 `TS\\x99\\x80DaśtasetLt.ainϧˏ̽verˌse_traϖͦns΅ɾforȴϞmΈ`.ȠϿ', 'target', 'target', 'r', 'metric', 'macro', 'MAE', 'MSE', 'SMAPE', 'r', 'backtest', 'r', 'backtest', 'ĳΙCh˅Úe̘̒̾cϠ}k ϭworθkinģžŕg of loȡ˼gΦǪging in x\\x9e\\x8ffitl/\\x93ĒΆϮǪȾfǍoʵ=rneǚê©ca«Ϩ͓st Zo\\u038dȜ\\x88fĖ ïmodɯelƫ.ů', 'target', 'r', 'fit', 'forecast', 'model'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Class for hol´dinͣgþ timeϚ˸ s϶͡er˪iesˮ[ ībĸinȶaòȖˊrGy cǢlϷÜassˠificͅat\\x9fiΖon.', 'Classifier is not fitted!', '̟Fǃ%it̐Ȇ Ɠthče classifˉi-eθrˋĨ.\\nâʕ\\nPϴ̾arʞameters\\n-ͧ-Ƙ-----üz-ðǰ\\x87͗--ȻÖ\\nx:\\n̮   ̲ Ȧ̽ArrĔay ɿɚw\\u03a2iętĮh t̻ƩΚimōe sŸer͵ies.\\ny̖:\\n   Ȱ ϨAϙɐrrǪaϩy ʿoȟfA8 ˇ͔tɓcÊy̳lʮass laĿb3eχ˝ʶğlυ̡ʩs.\\nʗ\\nēƺƄRetur̸nͼs$\\n-------ƪ\\nɀŧ§:\\nm đ   ϨFitt˒Ϛed ʜinstance of classifier.ÝĂ', 'Only the 0 - negative and 1 - positive are possible values for the class labels!', 'TimeSeriesBinaryClassifier', '̼PγrɳeWdiªc9ŉnștK΄ clʽasϧseŢs ƍʽwith ϫthreshɩolÁˆʤdś.Ċ\\nɠ\\nſ\\u038dö·Paraʂmetȏe˪Ưr˞ǶȃɼsϷ\\n---ͅ--ąȯ̖-Řf-̻Ãi-ϝāͮ-\\x9eœ̝δͽ\\x89-Ŷ\\nΦx:\\n  ϳĢ Arraʫy witɩȮhȑ̷ͩ± ƿʜtʧimǂeȔ\\x94͑ seRΘɨrĿĽŷieȺs̯.ƵƂ\\nĳ\\nıRµetuǈrőχǁǰŁns\\nāȗΙ7--ƓÊ--ǅʹ---\\ncyǡǩ:±\\n  į  ϾArrȶay͉γß˲eƭ wi˪ɚ#th ͛˴1prediƜ˔\\x9dŌɵctėeɸ͔d ¾̊\\xa0labÖŸžels.ƏǊ', 'macro', 'precision', 'recall', 'fscore', 'precision', 'recall', 'fscore', 'AUC', 'metrics', 'all'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['  ', 'x', 'y', '   Hύ       ʙ  δ', '  ƚ     ğ  ϰ  ˺   ', 'x', 'y', 'x', 'y', 'ǔ   \\x8c \\x82φάȌɒ   \\x93c Ɵ  ÙɃ·ķ   ͒Ͻ \\u0380 ', 'minimize', '   ζ   ς   ń', 'maximize'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['ɏϘ  ', 'LogTransform', 'Ġ̦ſęApɜpʏlýy ¥loͦǤg= Ϯτtransfˀormatǹƹion týo thĽe datŴ̔ʉ˙aseνāt.\\n\"ȥ\\nPˈʺʹanͲrρaI.mƭetersÑ\\n---š--ϕ-ň-û---Ϥ\\ndfΊ:πЀ\\n Ƕ  z %dÍȑat\\x98aƨJfìUram͙e Ÿwi$ͺǢth \\xa0vdata to0 ʜtra˩ɓnsfo̦rm̚.\\n\\nReturn˒Ǥs\\n---ɹ-Ϛɷ--j-\\nres*uÛͻ̬Ǔlt̝: pɕǼϬŬWd.āƨĞDat͠ʝνÈ\\x9aaframϔèϬ͛\\n ō   {traϨˀnsūfoίƢrϒ\\u0378m̢edϐ ǻʫdataȯͤǳǵfraͻˀįmǃοe', 'segment', 'LogPreprocess can be applied only to non-negative series', 'target', 'feature', 'Transformation will be applied inplace, out_column param will be ignored', 'LogTransform'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <8x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 8 stored elements in Compressed Sparse Row format>, 'ClassDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': [\"̴C΄̥l·ass fžoȵrɅ hoɌ\\u0383lʈdingŔƴÊ «HolȎt-WɎiǋ\\x8fnƖÊtƤΖeŞrs' ŹeΪx̼pone\\u038bƁnt͒iʃ̞ò̑alT ȥσsmέoothing moġdelɚ.\\n\\nNoteƔƜưsʧ\\n--ƙ--ǀ-\\nWe; uʸ.sȥǘħϖʆɨe :py:cȒ͎˿lassŻsʤ:`ɫǤɳstatsȕmoʛdV\\u038dxelsƳ.tsa.ʐhƿoltĿwěȫȬ¦ȿ=interʝʠ\\u03a2ǏǝˌË¯˽sƍ.ˎęEȼxʏpon#en͔tiaϊlSG˟moothĔinεgÐʁ` mod̹ȘϘel fro͡m \\x92staĨts˫moŬȼderl̨¦́Ŗ\\x84\\u0383ȢϡŤs ʭpa\\x92Ίc΄òkagɐ˽Ẹ̑Ƒe.0ǻ\", 'target', 'timestamp', 'This model does not work with exogenous features and regressors.\\n ', ' will be dropped', 'This model is not fitted! Fit the model before calling predict method!', 'timestamp', 'timestamp', 'estimated', 'none', 'I͊nit\\x89ʂ Holt-Wȩȴi̊nȟter˙Źs\\' modelʰ wiʄƾ\\u0381ͼt˓h gĢivϢen ƎpɁaʅrams.«.\\nı\\n͜PͯarQameɾte@Ϧşrɠƌsʀ\\n\\x9e-----Ϩ-ɫ--\\x81Ǎ--\\ntrend:\\nč   ǈȝ Type ͞of´ ʬtre\\u038bȗÚȤ˺>nϞDdoYȄûŽ comɉp¦ˡonent. ϭOnˬe of:ŀ\\n\\njɍõ ͅ   ɺ*͌ǃ ĭ\\'\\u03a2addŷϑ\\'Ú\\n\\nˁ   g ͫ* \\'ň͇ɑčmul̚Ô\\'\\nˠ\\nI ø ̝  *ț \\'addiŪΊtive\\'\\n\\n ͘   *¿ %\\'multXi\\x94WȫpϹlicatiΖve\\'\\n\\n ʺ ώɹͻ ɴ *ʓ NɌ\\x8boʖne\\n\\nd,ampeȥdŒ_trȃenȏdŚϿ:ͅʇ\\n ̛ǔĄ͌ʴ   S̊˼uȓhʇƳould thɇe tǮreŢΦn˩Ύ˫dë͢ cǻomΒőponent Ăẗ\\x8bRbeϏˈ dampŲɾZUed.\\nseas͎onaȡl:\\nχ  ʪ Ŝ TȽype oƚf ŷ̑ǵǈsΫǤeaϯs¯on˸aǅlÊŽ\\' Ƽ̩coȀʣmpƍͺo\\x81n3ʪen}μϝt. :Oneƒü oǮȯfǧ\\x93:\\nĻ;\\nŁ γ  Ȭ ˃ɽ*ʀʝ Ɲ\\'ɣaǈdɜd\\'\\nϪ\\n    *Ϙ \\'²ȧȨġmul\\x7f\\'\\n\\n  Ǧ  * \\'ëa˓ɒ}êdȇΧȶȽdʓit,žive\\u0382˦\\'\\n~\\n ĝ   * \\'mT̫ultiplϜic»atÒǊŋive\\'\\n\\n  ¶Ȥ Ϲ *ɴτ ʃ̾τǹNone͚\\n\\nsΊeǐaˣsͣona˂\\x99l_pˢer̽iodΌγsƕ:\\nʷ  ˘Ɖ  ThŨe ^numǁbe̔r of ĉperiods ȋn̕\\x8e ŨaJ Pȁɧcomp΅ȌXĂlʿeȲtȦe sħeĜϻƗaÍŌs̈́˛onalϚ cŶ¯ycĦ¼l̝e˷, ŝe.ʾg., 4 ʁfor\\n   Ͷ quâaʹrtȈeƃrly Ʉ͓daȡĴta or ɴϏ7 fʵɄorŔ Ɇdaǜìǂlʎy İώdatÍa Ɉ§Ͻw̨ith a weekϕľy cymcɚlǟe.Ȗ\\ninitǎializĈation˰\\u0378_methʾΗodpúÃ͞:\\nâ ʗ Ǌ  ƅ˵MϮethod Ffǥ\"orá 6iǙnitialize ˉthe ɬrüecurǻNʦsǑʗionsƑʸź.Φ ȸOnŬe ofυʻ:\\n\\n   ˫ϻ νħ*ό\\x87 ňNone*ȆNΨ\\ng\\n    * \\'eƔs¿̝tiõͱmated\\'\\n\\n̻τǑΠ   &Ȳ * \\'ɐheur͛ďistic\\'\\n\\nlɿ ͎ʋ   *Ȉ ό\\'legacy-rheurisƐɈ¹ũtĬic͘ɑ\\'\\n7ϴ\\u03a2Ϲëƭǔ\\n ƹ̫ Ȯ6  ˉ*Ϭ Ϧɾʻ\\'ʊknowϕϩ˫n\\'\\xad\\n\\n H ʺ ƅͫǍƲ̚ NƉ϶one dżΧefaults˜ ̿t\\x81o\\x88 Ƶtheʝ phƜrȵe-0\\x83.ƪǬ12Ɩ beIϪ&ȋ͍havȢioŘ͚r whƍeƵre iʄnƷitƷʯiaɗlɋ vóĎal͇ueľs\\n   ̪̞ aŞre passed as parƝǒT¤t Ŵoăf ȝγ̓m̕``ɰfit``. If anyύY of ΪtheĒ otPh̡er valSϩuesˌ areǲ\\nŭ   ɊǑ pasªsed=, tĪhenǵ.Ő thȧe i\\x9fniŬtiŰóͧaÖl ʬvalu͞αʣeŮ\\xa0˖óϟs mɮƪusϦƖt also Σb\\x80eʈ ͙seΧtŦ Rwhen cons̍ątrȭuctin\\u038bg\\n  ʊɄ͇ʭ  Ώthʻe Ξmodel. ĩĆIf \\'ǩĘ¯ʐ;nπown\\u0381\\' iniƩtμialήizÄatͤi͔onē is usedČ,̺ t±hen̩ʞͻ̑ʗ ``Einitiώalʯǟʵ_Żleveęlŏ``\\nʃ   ¯ muϤ̮̊st ñˀbåe *passe̲d, ȁas όwƊell Ͱas̮³ ``iŋnit˹έ2ʶţi¡alϦ_tƌreƤnd``͚ a͑Ϯnûd ``initǼiaôl_±seaso(µnȨal`Ǧ` iϰãfɊ\\n@ ˯  ǝ ʦayψpϹĲpli˓̆cƘa̢5ÿbo¢l¾eh\\x83ˌ̮. Def¦ault isϝ \\'estimatͣed\\'.͈ \"Āˑlegaƃcy-heuƒrțisticĶĘƻ\"ϓ uȇseϓs t̂he sBȿÇ̸aƥḿe\\n ͫ×  ̐ vaʹlueʗs t͝hɁǷatɬ we¸re Ƹuĺʥse˔dΩ in çs\\x90tΛatsmoǵN̤ĹłĆdelµ˟s\\u0380 0.11 and earlΖΥieȢr.̌\\ni*niti³aŵϤl_l̋eve»ĩ˝l\\x88:ȕ\\n  ®  ThƃƥeťN ˗ŐiϤnit͆iϾal¿Å lev!řeȻl comƢǌponenlt͞.\\x8dǕ ReqƜu̜ired \\x83̪if ɀesBtimastξ͚ioυnǓ met¾\\x91hGɌĲ²oɟd iťɊǍs \"knȬoɂƭͫϣwǄˡǨΒn͖\"Ũ.Ŵ\\n   ψ΄ɭ ƕǞIf sxet [uĚɏʐ\\x8fɢsing eithŁÂǡeʿƝrŏ ɽį̄\"estiǁmasΖtϣȱeτdų\" orɓĜ ̊\"hϭeȾŔuŕʒri˰sȻtic\"S½ thȦǿiπɉs, ɰvºʖa̓lueƮƣ\\u0378 iʮs\\x8cɺ usƩΚedÓ̅.\\n¨\\x91\\x8e    \\x90T˟Βhis aǹˤ͚llow˪ɳóĚɬǢ̂ɩ\\x85˷s onǇªe or Ãm˦oƥʶre of th/e initiǷϽaϺlΔ Ŵʏ˻Òval\\u0378uΜ̚eοs̕ tʧoΠ Ȩ\\u03a2ƄÞbǷeŰ set\\\\ˏ )whi\\u038ble\\nȞö ƿ Ű˴.  ϰdeferriȟŌŲɎnΏg to vthżōeǒ BhϞ˙̯euristicʚȯ fφȁΈor ŏthƋers ĝoƎr̥ eϹsti\\x90matiɛ×ǯng ətʐhłe ϡun̡̺ʹ˨set\\n   ǽ \\x85äpǥaramǏzłetersϴ.ʍ\\n̝ǥinĎiǏŏtiaΩĴl_trśen\\x84ʿw͝Πͫd:\\n   VΡ The ÊinitiŘ͜ɫŦaǲl tŚˇreŗ˪nĵd coŹmp\\x86oÞȈnent. Requiϛr˨edȲĮɊ˸ ͂ĦifǿλÄ eȉãs\\u03a2üt̞iÅmόation Ím˚ͯethŰ͈o\\u0379Ğčd iɛĔs̩ώ ǝƵ\"\\x81known\".o\\n͔   ͺ If se\\x95ǵtɆ usʖing eόitÍġhǁer %\"estˊimĂated\" or ɵ\"hjeu®risƷtic\"˥ʁ thɉǂυisƷx πvͬalϤue isƄ uƩ<seȞd.\\nŦ5 Ū˨f  ̠Ĉ ÜΐΆThψiī\\x95s ǣ\\u03a2aŲlƊɶʏlows$ one̶ oǮær moǖƛrʈe Ȇofʴ øthe iniͼtiȡa̝l ʥvalu̱ešϙ tσ̼ƌoȠ | be Ǵset whȃĭ\\x8ble͚\\n ˕   dιefer®ĄœriΘΘnǠgƏǖǑ to ƶthes heuϗrisȵtri˄ȋc ɃfƄor µoȪ\\u038bthɠŜeǟ˘rs oͨʺɃ˒r ͇ͦeÀǢstimatăiȄngϵ thẻ unΎseĔ}ǜt\\n ɲ   paʹraʞmeteϤrs.\\n¦initiȸaʒlå_s̮νǝſe͐a#σsonalÀΛʨ:ʻ\\n ̫   The inΡitŹǠióĠalÈ sβFeaʑsonal componeʹúǌn\\x88tɎ. ɾAn VϪȉarray ˩oȭf lengtʫh \"˙`seĒasonŖaClȱ`\\n  η\\u0378  oſr l͔eΔnƈgth ``İsea̋sonʍaĺl - 1`` (Ǩ˞i͉d\\x8bn w2hichˬ cíase thĸe laWǗɇsŲt ˘initi°al ʆv\\x8dalue\\n    ¸ƫisɘ σcoɏmputed ˇ͖to\\x8fë mƂιʀake stheǔ͕ aΈ$vʯerage eNwffͧecɎtØʬ zίero)͙. Oʳ$ϵnǪly ʂu̍s˨edǥ if\\n   ˩ iϰniƘ̮ĄĠ©ϲątiāǩal˽ization isǬȝǙ \\'ˈknowǷn\\'. Reġ̄ȏ\\x81quΉŗir͆ϠedƗǳŋ ϼif˅ϒ estɷɶΛiǚĽmƺatϠØŻion methǐʙod iȱȇs \"known\"͞.å\\n ϛ Ŕ  ĉʍĴ̄Iɦf ɶϝset ̩ņuưsŔĈing NeitĽŉher@ \"eȠ\\x92stimaȯtΌed\" orΛ ǃ̀\"Ơheʱu˛ψrĢiƀstiǷŋTņc\" thçis vfaĤl͐ueƝ is ̮used.\\nƋ  ǔ  This alɼlows onξeδ or moǏrōe ǁoƳf ͷthσ̄ċeǃ i˺nitɎiaĄɰl˦ vɂaϟlɋΤ˧ĚȔuđesd t÷o be seʗt¡ IwhÈɢileŞ\\n  ©  dŠeˢϢferɪrinÍgå t\\x9co the heurǑiǅΥ̖stiö̪cϐŎ fÎ͔orƋƧ očthÉers Òor estȞim atäǍi\\xadnȟg ž̄the ünͤset\\n   å ̕Ƅˆp΅a̱ȫramȞeteÓŰrˤ͖s.\\nƮuˌ6sɅe_boxcox: {Tręue\\u0380, HĿFąlͣs\\x9fe̩̐, \\'log\\', ̨ůfloÇ˓at\\x90}Ýc, optiìoĲnʲaɰμl\\n Ŋ˲ ̘Ʊ  SƑhoŲuʈƀlɮdƒ áthe Boxʊ-CáȏǲxϤ traŵ\\x9ensfȂorm b͛e͑ applied ͠to Ȕtεh§e datŋaʶ fƀirs·t? ΗOne oͱf:ȰŶǨ\\n\\n Ɉ   *ω\\x7f ̍Trueͫ\\nʭ\\n    ʠ* FaálseϜɴĠ\\x92͜ǲ\\n\\u0380\\nŀ    * \\'lΑϘo˨2g\\':͓ Ƣ8aξå̍p\\x99pløɊʓǗ̯y ωlog\\n³Ċɾ\\nŗ    * fǤlo½aɮt: ʌlβamΕbdaʿ v\\x84al˟u˗ƔɊ̻e\\n\\nϴb͙oŻujnds̮Ö:̪\\n  ̖  AȀnȓ d̂§iέcǵtiȣοǼon˂ɗ̄agͮry ˽cȬoƩntƓaining bou\\xadʙnˌȘdχǚγs fo˒r˙ Ŝtʽhe̡ɼû parașämeȐĮȝŚ@¿ter®ϱsÆƻ inô th\\x94eûš Ŧ˽żmĩodel,\\n   ͥ excludęing the iniͦtƵʣiæ¶Ώalˍ vaǬlues ϟif̺ ɮestig͆mƅateŷd.ȹ The keys\\x90ϴ ofϦϏʠ tǉhǜͼe dɓīiʋctionaB͔r̴y̔\\n̯    a@re ˑ̇tǻhe vaƦ͔riVaʙbl̸e ʺnǽaïme̬s̋Ǘ,ζ e.gɧ., ĈűsmŇoʗɪotĸhḯng_le²vŦ=eǕl ʵo͡rͻ ÁiɅ\\x8enitǟ½Ƣial_ȀsloApȃe\".\\nŕ    TȐhǍe̴ initȦialȀȹl seʊasŻ\\x8eonΪal vaƇǌriables areɀ ċlaΞͥbelǙeǬdŠ Ϝǂiɓnitial_seaŕµźsoùnalÙǌ.<j>\\n ǫȘ   \\xad\\u0379fƸͶor j=ϑȨ0,..\\x8dʙ.,m-Ϋƶ1 $wAɛhūfere ̷˺m is ʈthe nuʐ\\xadşmber oθf pǗeriƯǟŅod či͆nʼȋā aϪ ɺɯfullJ ʕǎsĲeasonĭ.\\nÛ  Β  U˓se Nʙ-one ϔ\\x96Ůt̠o ʹindnicaÝtē ͈̋a \\x87n̩onö\\xa0-bindinǻɟg c1ħoʔnsˣtȎraint, e.Υ͘dƶg., b(0ϡ, NoneȜ)\\n˗ əlʥ 0ªʎ ̓ ơcoΛǵnstr̷ains a Δp˟aramɲeter tĆo\\x92 bĂeʡ nʏƌʆon-ŲϘnegĪative.\\ndȐa˃teÐ͎sæ{:M\\n    An ɓarraƝy-đlikϴe oϵbjeɐʇcȵt ʢoΝfΦ ˒ǵdatȉĊetimΧȝe ƏĹoŝbje\\xadcts. IΖĚf˄ͽĆȷ a Pand϶asĤ ĞoÁbÃjeȬßc̒t is gêiven\\n H|   foϝr đeǊ˱ǭϫndɊľłǜƟϞ̟ǅogĨ, Ϩit is a˯ssuňǕme=dǎ\\u0380 to haveĊȩǖ ǽa ėDǓateIndex.ŉ\\nfreqǏǄ:\\n    ThǗ4e f\\x9ereqȞueɒnc¹yʯ ofe,̱α ͅtBhe Ŧtime-ŒŇseriès. AƑΑȡ ÑPˮaΊndaƿʍs owĊff̺sēΫǑʳeΣt or\\x7f̆ 9\\'BƳļ\\',Ȁ \\'D\\', \\'W\\'ź,ö\\n    ̯\\'M\\',Οʮ͞ Ǐ\\'AǮ\\', oεr \\'ŻQ\\'ɢ. ThisϚɱ is ľȿo@p!tionχal ifþŴ datʡƶesĊ are givé˂n.\\nm·ɔissȗing\\x96:\\n ɮ đ ϝ Avaiòlab9Ĉleǜɾ o˜ȴpǝtiƣoΖmns Ɋ˥ȠaȘrźe \\'noń˸e\\', ǁ\\'dropå\\', and \\'raise̲\\'. IÂf \\'nǜỏne\\',ϔ noǃ Ñnan\\n ǿǥ ĺ  ΎcheŒ͚cϷǩʓiƟɛng ̝iƲs ĠdonŢe¸à. ƩIf \\'ʥľdrEop\\', ʢÓaýn>yǾ ȵ̜ȵobŮsΖʠerǷvƎa̵tžǭ\\u0378ionsL ňθwitǘϝh nȦans ̒ar{e ŏdǩrƛoǷȹ͔pʥpeˏdα.ɾǈ\\n  Ʋ ˢ §If \\'ruǔaiͿse\\'Å, aˍ͑ƴn eȮ˪Ǚrrɥo̮r is raisedͣ. DeťƂŪͮρfautǈljt̼ is \\'noϕne\\'.\\nsmoothiNòn4g_ɢlevel:\\nȐ    The͚ a˵lƁphaċϠɘ value o͍f the simplƪƽϽeų ex̭ǥàpBonenǺ̉͗tivaðl sσϻƪmƷootƮhτJÆʯiȺng·,*͊ ¼Ìif tĿ\\u0382¹Ęhe vaǡl!uηǀ/ʾĶeŉŬ;ͯ\\n Ö   is se˫t tşŞhÉʠen thʥȈ©isǡ̤ ˵valuŊɘe wȀill ®Ûbķe useɏ6d as tshe vɩalʧ̨uaˬe.̾>\\nsmoΞoʝthúBiƴκħnǌg_trjen͆d:\\nϴ Ǻ ɍƬ  ΏTheɜ bɡe\\'taͱ 4ǇvaȮl&»Ɔue ŇǀoţfǘǠω the~˜ \\x84HɮˠolÄtΎƴ\\'s )tʄrená̡d me;ŋthưod,ιϓν ifŎ :γt˅ƀh̫ce Nͣ˜va\\u0378lϑuǙe cis\\nͺ   ϒ set then̶ ͔this value Šwill >be uʙ͈seȻd aį̛s ϟthe vaǽ͛ɯ=lɱue.ʯ\\nsmŇoothinλ¬̚\\x92g_ǻseaÖsŒoʹnaî͊l:ϖ\\nμ\\x9bʕśŭ Ǉſ̔  \\x8bï Thϕe gam\\x85˘ma valŜŁȠuͧe ofˀͿ the holŘ\\x91t wɤŐiŗntΛ erʚγs sȟɑeaʜǻsîoƖˋnɀal mǀet¹hȇǡɍodĺ, ɹΟif thĭȽe vΦaƥl̓mĬuĒeł̨\\nû  Ś ľBƔƀ ̲^is ǂ˦?ûǨǵȘ\\x94sƾϋeſt͟ ňȾtϐ\\x8dhenæ \\x80this ÄvȔalue ˖̃wilÞlñΊ ̺ʾb˕e u-Ʋ̛sed as Ϥştϗh͏ưe¶ val̓ʎ̞uơeζýɴ.Ȭ\\ndaɱmȸpiΊıȼǳǣǣnǹg_trľe˯ndʙ:\\n    ThƸeŎ phi ˖vΰʻŎϷalue\\xa0Ż ̦ˑƚofϻ tϺhe d?amp˄Ĭàɇeâɖųę˯ƣd̂ǆ Φmeȼt΄hƩͥod,ͨ ʋńψi̓f ̨PtǦhe ľvaČlŬuɮ́eħ́ iήƏŒs\\n  ̀  ϥset tÚhen thi¾sŽαΤ vʺɁ¥aluɍe Ϯnwʊill beÆ ʲuseΆßd aĎs˒ th˛e vaļ͌͗ue.\\nfitȔ_kwargsʬ:\\nͭ   ϣ ƱļAdditionalðǓ LparaHͯme\\x8eteϦșrЀͷws f͵orɾʇ cal͞Ƨling͖Ǻ :ȩp̽y:mʦeȼt̝\\x9cǕh:`sƵtatsɔǤmoɢV\\x9e̕dels.tsʭ̍aʨ.holŠtwišn˓te0͡rʃ̉s.ÞɹExpΘon̲ŃϣentiaƻŬlļ϶Smoot\\x88;h+˹ming.fi˕tĎ\\u038d̫`.˱Ĕȡ', \"Fͦit HoEƫlŶ̝ǟtūɫ-WğintǳeìrsΣȇƲ'ͬȋ &m̅oϟưdЀelʡ\\x8b.\\n˅F\\nPʙĸɶâarăΉamȝǢćeter̚kŮsƒ\\n---ġǌ---Ϻ\\x84-ĦΓ¬χ--ΒǢέ-#\\nɹǧìdpΕf\\u0378:ή͂Ϸ\\n    dƽhFše̼a\\x8etureǴs ďɊata˓Żfrϝame\\nregreçs9soɳrʘs:ʖƤ\\ná  Āɻɤ ̜[ List ξoÆÛ¦f¤ Ŀɩtheȝ\\x88Q c˕Ϳoluˣmƾǖns ͙°wiϑtΪh ʁˌrΖĉŋÔegr\\x96esȒƧ>sorHŉsĶ(Êiî˥gnĮ̾Ɏo̅ȝrɠĬed źi˟nŠÁ tϻhiʀ̣ϧs ǚͤmo˃dΪeŃ̿l)ʾ\\nˆRáȸʥetuϷrnƐs\\nɝ-ɫÙƄ---ʧƿ˶---Ȳ\\nşϷȸθγ:̃\\n9  ȼ̿Ƿ Ͼ θFitteʧd m\\x90ʂodΐel¨ɻ\", 'target', 'timestamp', '_HoltWintersAdapter', \"HoϰÃlgƣĺˍ~t-ȿWiȸƒnĂterσs'Ø ɤeȳtna˃ modʫeǔlΓ.\\n\\nåNoṫes͏\\n-¥----ο̶Ť\\nWûϡeȞ͠ɾÉ ňǕuseͭ :ĝ̴py:Ļclaɘ˂Ŏϝ;ss¼:`̐staȀtsÈBǷmodels.tˍìĬsa.hoέltwi͟ˊήnt˟ers.̕EÈxpoň\\u0382ŧential˗ůSɬm|ġoɂǦothiΡng` ̠mώodel from stƈat̍smodels pacΤkage.Ͻ\", 'estimated', 'none', 'InitáÜȖ HoŒlǈt-ϾΏųWiŞntϒe§rǱs\\'\\x9eȮ Ɠ˂ťƬmodĊeǨlƳ ̧ϟwϤith0 ΝЀ\\x9dgiveJnϴ pɠarams.ŕ\\nȄå\\nPɻɿŇarΔaómet͢ers\\n--\"--¼˵--ȓ----\\nȁÏtrend:ʹ\\nͳ    Type ʬof ˸ȅtr_ienȔd comɃαłpone˅ƋnΆt.ǒ OneŞ of:\\nˍ\\n÷  ϗ  *γ(Ň \\'add(ǥ\\'\\n\\nɥ    * \\'ȷmul\\'ć\\n\\n    * Öͳ\\'ad͙ditiveŶ\\x9eµ\\'ĉ\\n˥\\n    * \\'m̡ŇͳulΎt·\"ipǠlicatÖiVvɯe\\'\\nƘ\\nƃɻ Ÿͽ   * NɮonϪe\\n\\ndǋamped_trend:a\\n u   Shouldˍή th̅ʛe trend cνÕom˪pʃonɳent båe daǙmped̶.Ǣ\\ńί͡s˓eaϔsoΙnal:\\n   ȳ Typ̜eζ of seĢasĥPonal componeυnt.ϡ ̌°On̴ưe of˔:\\n\\n̳ʦ  ƬÍ  * \\'addǉ\\'ʇ\\n\\n    * \\'mul\\'\\n\\n  Ȫˏ ʒ * \\'̥̳lȲaȒdditive\\'\\nĕ\\n    Þˋ* \\'muȫ4ltíplicativ4Ȃe\\'Ɩ\\n\\n   Ϭƶˈ * ϳNoǊneūµ\\n\\nseaȾson̷al_periodsM:\\nΟuǄ »ƥź  ɖ Tχhe numbǅ_erĳΊ ofƢÜ periodİs in˕ Ǻa c¦omplĘ\\x98etƒe Àseasonʟal cycîle, e.g.Ș,ˮæ 4 for͗\\nθ  Ă  ͍q6uarteĔńrlͷy̪ ȇdataú orλɿ 7 ͼąforȚ daily˧ȗ d\\x93a·ta͡ witˎh aƚ weekly ϙcyǉc.ǖĖρblǙeŇ.\\niİnitΩiͳalŋizȊatiɜʊoͥn_͊ťmeɦthodƊ:\\n    MeɠthoŶȣdĦ forϋ iɵniϚtialize the̷ \\x99recursƀiºonÓs. O̚nże of:\\n\\n  Ο  ̀* ƧNoɏnƴe\\n\\n    r*Ϗˉąj å\\'ÏesɎtim͑at\\x8d·ed\\'\\n\\nʛ   ǻ * Ḁ̌\\'heuristƪǒic\\'\\nŁ\\n  ÿ  * \\'ǜΡ̀legacy-\\u0383ϲhe͔uristiȽc\\'\\n\\n Σ   * \\'HknŮ¥Λownø\\'\\n\\nͣ̚    Noɓneț ˫defauϢµ̗lɣts φtϥo the prĿΪλυe-0.$12 behɽa©vŃ̟ɖÑƆ̧jʔŐić¢orȲ ʎ͑where initialƖ ßơvalȋues\\n˳   ͵ aǈˬ͖re ǐpaȲƌssed  °̾asƤ part of `ɡ`fit``ǸȺR.Σ Ifƴș any of ©Īthe otheɉr vǧaluǸes ôare\\n  ν  Úp\\u03a2aˀssƞed,φ thenȎ ɏtiheƤˀˁ˭ʜƧ initial 4vůalˁues mŠust aŘlso ηbe seήĕtfϠ when coɷn\\x94strěuc\\u038btŋing\\n͢Ǝ   ɗ tǞ¶he moɆadeęl̞. ŠIf Š\\'k͎nƄʯo\\x86wn\\' iniêtial+izati̳̔on iǪʜϖ²Ǎs ̃used, Ͻthen ``initial_l͖evel``\\n    musȽt ǎŪ͔ŝbe pasľưsed, asǘ wf7ell °as ź``initiaǋ̫l_trűenądϣ`Î` anCƙd´ ˱`Ș`initýial\\x9fƃ_seasʘȖoÐnĐǤϵĝal``\\x89 if\\n    aʸpāpʦlǖicablͰeϭŜ. Defaultº is æύ\\'e{stim˰ateǝd\\'šǬʂϷ\\x8fʦƢ. ŭ\"lʇegacy-ːĻheuŜriˉstic\" usesε the sameȻţɒ\\n Â ͥ Ϸǽ Ϧvaǅɺlue5sː ̀that wefƦrϰeƤ us˒ʝĪʈed in sϻǓtaΈtϐsmodχelÝsr ħ0Σ.11Ā andū ˾eϺarlĢiǀer.\\n\\x7finȈiȎtiɠal_level:\\nη>Ě  Ǭ Μ \\x7fThep inǴiΚĵntialϨĈΝƖź$ ϟˈle˭[vel coĠcmponent. Reql̙uǴsir!́eΟd ΆifȚ ͠estiηmation meǈthod is \"kno̝Žwn\"ƾã.Ǌ\\nȻȰ    If̍ ʚȴs\\u0383et usiǴng eeitheʜr \\u0382\"ͻɽeĚstiȚmĀated\" ˽oťήʪlǴr >\"»heuristi\\x80c\" this vȑcʕˉϸŬalue iˎs˥ uˈsÍeˇdě.ěː\\n  Ƅ  T͉h´3is allowωs oąn̓eôʎÑ or more ΛoʴϢfϝϴ ȸthζeƒ iɟnitial val͎ues tsoí bϬe set whĜtilǴe͓\\n  ǔ ſ defeɀrriɂng to Ѐ¸ǝtŉhǿe ˍheȋeurɼ̵isticǗ fϫor oêȡt˽hers oƻMr estimatingûϸ the uɝnset\\n ´   pa²raəmeˍteÇrsΞΨ.\\ninitia͒lÂ_°ɥtrenÍπůd:\\n    Thȇȑe iť;n͇φ*ʣitiͮalʻ ʬĿt\\x87Ɲrevŷnd¿ ǯcʃomponent. R>ƜƦĚeqƕΐuiɀred if estima͜tjĸϲiŝoğnGÖ ƊmetNhod is \"ЀþkǧnƁown\".\\n    I˩f ͣȕseˣt u×s̝inɮg ɓ͆eơither \"ĞΎ̈estimɍated\" or ϦČȁʷ\"heϵu\\x82®ristĎic\" thhis vƀaluì§Ϋe is useḍ.\\n    ɕTʠ˃hiͺOsĸÿ allɒows/ oȼneņ Ëor m˜orϡe ņoϜfƆ ϋʩtťhe̒ iĵnitial ȜvȪƚƀ̶alɩϋues to be seɉt ǠwʟÛhileόώ\\n    defeΐrr|ing ĲtKȓo \\u0380ɱ͒th&Ȳe heuĥrisæȼtic f_˳ƛo͊ςΫrË otherO̓͆͝s or e̎sˬstimatingſŉ̱ tØÅhe ͬ˹unsβͼetÚŘ\\n  ˮ  pďaŒrameterρs.\\ninitial_sĆeasonal:ȝϼ\\n ̽   Theϒ initˎ͂Via\\x96l sŪeMasoɤnal comɊƽponϨeˀnʒt. ĲAn arrɸaǵyŹ ɷořfşùęȰÍĐ ̥ʁ˄lengthX `seXasoŕnalɺ`\\nØ ̅ƣ   oΌr ʭƊlengtƵhȕĸ\\x7f ``s̅easonal - 1`ǟ` ϙ(ˋ͈iČϻn whic̷h ʽ͠case the ®̺͢last ϩǒinƉi)tiaΒVlƼϤ valͮue\\nɃ Á   iss coǧ\\x8bǬˊmpu ted to͐ makȓ¥e tϬhe avǏerag˱e Ϻeffeåcäˁđt zeʻro). OnlçyϚÉ used i͕fˌ\\n Ɯ  ļ˱ initialƶ8iȝzaˤtion Ňis ƆΜ\\'knowªn̥\\'. Required ifˑ͋ estimƟation mΕ͙»ethoΛd jis \"5̓known\".\\n ˾   I0Ǖf set- uĲsiɌƱng eitǇheƁr \"eϣstɏi\\x81mateXd\" o^˽r \"heu˱rʉ\\x9eψ\\x88ŚiɝǓsȏhtiŒc\"ġ̷ thɬis vaȧlueƷtø iŏ˨s uǕsed.ϒ\\nē    This ϔ\\xa0γɍallʚɬow\\x9bʇs äon\\u0379e ţ̾o͎ƞrƜ ʳmVoreǞʂŞ of thȶe inϺ͓ŶiÚti\\u0382al va\\x9bƔlues ʌt˂Ɇ˕ǀo bϡe sͨet ɚwâǵhǚilaŋe\\n ʷ×ǌ Y  deĨfȳeǖǃrr˓inˇͿ\\x91gďÝ tωo the hehuriustϯic fϸor oth̿ersŐ or \\u03a2estiƵmatHbingǧ+̆ ġthe͊͞ ʔǒuSnsetɟ\\nĽ    p˱aråmeters.\\nuƧse_bîΰo͉\\\\xcʮȉox: {ʈTǺrue, F̙alse, \\'log\\', fl\\u0378͎ăoat}Nˡ, oȸɢptionaŷ1l\\n ˋ ť Ȅ SʙhoHulǄd ̒ʝthe Box-ķεC˘ox transfƹormɴ bȱe ΜaRppĞEʷlied 8to ̉ϻ˙tΈ¬he data \\x99first?Φ Onìe ɿof:\\n\\nə  ȈΔ ǖŏ * Truɀ͍e\\n\\n    *bŃ ήĬFaʠlUseξΦ\\n\\n ˨Ƙ   *̭ \\'lȽĠoήľg\\'Ċɪ:z\\x89 apply͵ loʹ°g\\n\\nŵ   ͔ͧ * flÔoat:rȇ˲ la͙mbda ùvalyue\\nͩ\\nbounδds:˹Ϟ\\n  Ȯ  An dȉictioͳ͇ʯĭnary con\\x7fta\\x8cining[ Ɗbounʺdąs ŋfoȬͿr thϦeˁ pŝaŮɞΕǆramêeters iąn the mȐodeƍl,\\n  Ĳ  eōxc\\x84Ƴ\\x8flΧuŉdinɹg thɉe initțiŭa¹l vâŶ͏Ξ̳aƜlues if esŒtimateƔd. Ṱh̷e̻ kʵeyÐs ofɟˎ th̀e Ͷdictionaryƍ\\n   Ȥ ʈare the͓͛ vaƤrɎʏiΚpa˾bleɵ\\\\ şɀnamͭϪes, Ýe.g.Ɍ,Č s˹moothinüg_leͿžϽvŕƾe͎l or init2˔ăƱial_slɽope.ǋ\\n    ɽThe initial seasonal variableËsͦ arϱΝe× labeȊleΌd iniΎtia˦lŉ_seǝȂǏason7alĚ.</̀jƽ>Áϧ\\n    ufʼor jɴ=̎0,..˻.ƒ,À˶m-1 whφeˍϾre m \"is} the nuΘ̟mbeΧrĽ oǯf perȏioϧ̷dȏ əȭiďn ͪŲǧʥΊa fullˠ seasoɂÈnƔ.\\nű    Usȩeŧϭ Noneĩ to ϧ˂ʘinͳȦd͟ȿʍicate ϳa non-binding constƓ͚raint, e.Ɉg.,ŀ (0ˢ\\u0379,WŹ ̀Nonͱe)\\n    conɠstrain˅s a ǭparȒͿametϤĕer to şRȲbe ƞnδonæ˭-̟nʈegaΈtive.\\nͩǬdgateʟs:Ͽ\\n    AĀn ©ŵaȥrʠray-li̠kȪ͏eͰʏ϶ Εobje\\x96̇ct of dateøtiműɉeɇ objɗeΞcts˥Ϭ. I7ǝ̷ɼfͶ\\x99 a Pand΅asθ ob˪ÚjectĎ isxɚ Ķ̚giɡ\\x8bven\\n Ϩ  ʢ for endoϏg, it is a¿sİsumǨιed toˏ ̾haÊvͯµe a϶ȧ DɗatÄeIndƖex.͓ɷ͠ɰ\\nfĲreq:ʲ\\n    Th\\x8ee Įɩf̚rĞeqǐueʟƟɂnЀƧcyŊ ϳĒo̧f the timeͬ-seri|es.ňä >ŒA Pan̸das offsetŁ\\x8b orţ \\'ýB\\', 2ɿȺ\\'ŢD˵\\'ªτĻŚ, \\'Wķ\\',}\\n\\x90 ơ \\\\ ƴ \\'ĖȟM\\', Ƞ\\'Aɭ\\'ρ, oƴr \\'ϵQΤ\\'. Thiȕs̮ <is ƈopż̲ti7onˊalɝ if da~tesϾ ƺare givejn.ê͍\\nmissϩin\\x95g:\\n  ǝ  Avaȅilč̺abϼle optioȆnƊs are \\'șnoʺϭne\\', ±\\'ΎdƩr̈́Öǅoñp\\', anɒdř \\'raisϋe\\'.ǧ If˷Ŋ \\'no˃ne˥\\'˹,ʆ néoƬg̫ nþan\\n ǝ̸   cheľͫc͙king Ίi¹s done. If ͍ɼ\\'Adroțp\\'˜, an\\u0380y obser˝vΩ\\u03a2a*ŤtHğ͎ιƤÓions wit͕h naƏns\\'ʬȬ aȽrµe drop͚¥p˼Δedƴ.\\n  ʌ f If \\'raiΓse\\',Ȋˉǈ aƴn eé̳rrorǫ iN͗s ûȑ\\u038dȽοȌϽraöiƅsedΦ.ϙ DefauČΕlț˯ iɈis͂ \\'͎noΤnĬe¦\\'.\\nsmǍoothiɊn\\x95gȴų_lejvǒ̍eôl:\\n  ̱  Tɬʣhe 2aϛlάophǎè Ƹ va<lǀue of t»Ŭhɵe siĹmplĘe ī˗exponewntΝiâal ɇsś]moéothinˇg,ǥȀ if Ş%th[ʆe value\\nÃ    is Ķ\\u038bǁ˛sMet th͝eȇn̙͵˒ ͨt<hͅisŉ́ űvaƻlu0e \\x9b0wi»ll\\u0381 b˪e̲̞Ǉ usxþedŕˉ as ʟthʤ͙e value.\\nsmÀoothǐing_Ύtrend˃:\\n   ̚ Thˁe beĨta Ż̖ʿv͙aluqe ǌof< ȃǉϰthe ΎHoltĘ\\'sĚŹ t̪ʈȈr\\u0382̭enīdϙͽɆ methodµȨ, ťifP theϾĽ value iɘs\\n    set\\x81 th.ΰen̗ tʘhis vΊalueɯ wilǼl be εʓu1sedé όȵaφƉs \\u0379th϶̯e value.\\nϛκôsmooǲtċŗhing_ɫƯ˻̺seasºœ̐oϔÞ\\'Ɉnal:Ě\\n   Ƅ TÍˋhe gǁamɲmƠ͒a vtalue ofe thνΓ̂e Áhīolυt w2iƋ̰ntɢers ~seϣason\\x91ˎPƏˬal meȶ˩thodĢ,õ if the valuiͺe\\n   ͌ϕ is˃ seǲʇt> t¥heʳn tɄhi\\'s Îvɳalue wilɫʹl be useάd as th1áÓe vȋa\\u0383lue.\\nda˰ˋmpɗʱinʧgaʪ_tɄrenˠd:\\n  Ǎ  TŴh̢eϣȭ pǒhi vaǐluˋe of tǻh˭e daŗmpΩed m\\x9fethÉɇodŹ,ϴ ziǐfȈ tσheĆ vĉalue ¥is\\n   ƈ sǠeǟtl Ͷˑth˽̾en thϸis v̓ȕaluȑeˏ \\u038dwiĮěǹll be usɟeʪδdÖͱʊȶ as theϩ valueÍ.ı̓\\nfiʬt_kwaªrgęs:\\n͋ͳ    ħƶAdο˝diʶtɣīonaǯȕϞl pΓċţara\\u0380met̍er̈Ɨs fowr calling :py:meth:`͛ˍstatsmodelƧɵsÑ.ȡtsa.h\\x9folȤt\\x89wƴinteƒrsǞʗ.ͶEãxph<§Əonïential|Smo̖ϫot΅hžΔîi3ng.fit`.', 'Holt etna model.\\n\\nRestriΉcted version of HoltWinters model.\\n\\nNotes\\nȔ-----\\nWe uÐse :py:claǉss:`statđsÏmodels.tsa.holtwinters.ExponentialSmoothing` model\\x9c from statsmodșels ·package.\\nThey implŦement :py:class:`statsmodels.tsa.holtwinters.Holt` model\\nas a restricted version of :py:class:`~stat̕smodels.ʌtsa.holtwinters.Exponent[ialSmoothing` model.', 'estimated', 'mul', 'add', 'estimated'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <8x8 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 8 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['StackingηE<ˋͩÓnsemb¼Ϣle i˝s aȹ\\x9c Ͱƿp1ipelineĆ that foreŃcaɤst futureñ uCsinŖg the ȉmetǧamoͫϛͤdelš \\u038bto combineˀ̏ the forecasǓʹts oŜf tƩhe base© mo̯dels.\\n˧\\nExȧamȯples\\n----˱˺-Ζ-ζ--\\n>>> froƎm etȞna.Ƥȸdatasetǘs imͮpor̕Ǫt geόneˌrate_ar͆_df\\n·ǋ>>> froÊm >etna.ȱdatasetώs̷ impçort TSčD*atasetŘ\\nŔ>>> fƇțromĹjɘǺ̓ etna.eʌnĈsembl%es impɉort VoȖtŅingEˠnsemble\\n>ä>> from etna.mɱ̿od±elMs import NξaɘiveM̚od1œel\\nə>>>̄ fɵΕrom etnaȅÂ.modªeǅlȼs impoÊrt MΓovˑianȥgAɊverageŗ̙Modeǡ\\x87Ǫl\\n>Ä>> frʿo°m etna.pipʼeline i̓mpoϓrɸt ƉPipϪeliƂne\\nη>>> import pandas aǁs ±pd\\n>ė>>³ pd.op̚tioϩnǾs.Ɩdisplayç.fʢloat͞_fo,rmatóbË = \\'{:,.2f}\\'.formɳat\\n>(>> df = 8gČenera͜tɽe_aεͩr_d̚˔Ĥf(periͦods=10Ƞ0, start_tƙ˥Éime=\"2021-ȕ06̡Ǔ¨-01̞\"¼,Ɂ ar_coef=\\x96[0.8Ϟ]Ħ,͊ n_seǉgmeΫ˞nts̈=3)ĝ\\n>ň>ø>ǫ df_ts_˄formςaýt = TSDataset.ϡto_dňatasãet(dfŵ͜)\\nƖ>>ǅ> ts y=ˊ TSDaɰtasetǭw(±df_tsȏ_χforʿmatϫ, \"D\"QŴ)\\n>ʝ>> mĪƱa_ȑʂpipelineÌ = PƹiǤpelineǯ(χmǹodel=Mo͞vingAveragϓeMoȼdeƟlι(wȬindowÛ=5Ͽ), 4traɃ͞nsforms=[ȡ],ːϐ hori̚zo˸n=7)\\n>>> n\\x91aive_piɟǇpeline = Pipelinɭe(mèodȪel=NaivłeModƕelʉ(lag=10ȧ), t̠Ϻran˦sfo͆õrms=ª[ϯ], hori˹zon=7)\\n>>> ɋensemble = StackingEnysemblȔͯe̼̫(piƽpeliÍÊnƢesĎ=[ma_pipͨeline, n]ȭaive_pĲipelin̯e])\\nǯ\\x9d>>> Ϸ_ =ňs ensemble.fitͪ(tʠs=tʧås)\\nʪ͚Ξ>>> forecE_øastƽ = ensemble.foreºĈ&ξcast()ö\\n>>> forecast[:&,:,\"t͓argeɟt\"ƣ]\\nȺĊȫsϙegmen͈t    seǵment_0 segment_ǳ1 ʐυs`egmenȪˇt_2Ŗ\\nfeature     ˨Ȍ  tarȴget   ά targeto    target\\ntimestaǊmp\\n2021-Ξȱ̗0υ9-0ô9      0.Ư70 ˾Ę ƙ    ʷʃ1.47  Ǆ͍ȋ  ͕͇  0.ϱ20\\n2021¹ǭ-0͗9-1Ë0 Ǘ     ̉0ů.Ħ.62    ǈ v 1.Ğ\\u0382ά53Ⱦ      0.26\\n2021-09̿-11  ļ    ^0.Ņ50ɵ   ϲ͏  ȕ ʥ1.7ȴ8˩      ɗ0.3Ⱦ6\\n#Ƅˠ̉2021-Ĝ09-Ř1ʷK2      0~.37Ê      1.8ǈ8     ã 0ː.21\\n2ϭɻ021-09-1ëƹ3      0.46  ͌    1.87   ă  ʎ 0æ.25\\n20$21ɱ-09-14  ǝ    0Ǩ.Ȟύ44      1.49 ̘     0.21\\n2021-09-15      0Q˼.ǃ3·Ȥ6Ť ώ  ʹ  ˪ 1̮.̠˙56ʓ      0Ϭa.30u', \"ǲRȣʯƵeNturnō ơϦalǹl thɺe ɒfŽƫeaɞtuͧrûes fĔromȲ ``ãƤfeaǐtures_to_uΗse`ύ7`Ϩ wΕhiǎch cJɡaƯϪţάn be oϸbtai>ʬned Ķśf˱romʲĴ ba͜sŌeƆá- modelHs' foreȖcastȡsɈ.̞\", 'feature', 'fold_number', 'all', 'target', 'Features ', ' are not found and will be dropped!', \"Feature list is passed in the wrong format.Only the base models' forecasts will be used for the final forecast.\", 'Ensemble ', \" doesn't support prediction intervals!\", 'ʳ ', 'segment', 'timestamp', 'target', 'target', 'target', 'StackingEnsemble', 'ślGÓetēÞ foreÊcasǝϵts fro{m bacǇktest f˜or givenƈƦĮ pipeɊɫlAineȸÃ̂η.Ϧ', 'StackingEnsemble is not fitted! Fit the StackingEnsemble before calling forecast method.', 'target', 'target', 'regressor_target_', 'feature', 'target', 'all', 'Inĵit StackingEnsemble..\\n\\nPʦarameters\\n--------\\x94-̻-\\npipØe4lineǇĂs:\\n˸    List of pipͨeliʽνneĦs that should be useΌdȺ in e˝nsemble.\\nfinaul_model:ſ\\n    Regression mode÷âl with fit/predict inteͱrface which will bĭe useÑκdΑ tʜéo combi\\xa0ne the ϜBbasʒe estimatȢȮoǱƟr̀s.\\nn_folds:\\n    NȘȢumber of folds Ùto uise in t˗ǫhe backtest.Ǫɔ Bɇ˫ȇacktes͈t is not used fϮor model ʮ̄evaluatiFon but \\xadf\\x94or pre̿dɉiction.\\nfeatu͏rȦes_to_use:Ǭ\\n    Fe΄at˩ur̘esɥ except the forecastsǉ of the ɕϻǲbEase Ǟmͯodels to uWse £in the ``finΗƬƋaƑlĿ_model``.ɛ\\nen_ˠjobsϨ:\\nŰ   ͉1 NǰƮumber of j̘obs to ˒run in paralleǍl.\\n\\u03a2joblib_par·ams:\\n    Aè͊ǟdditiǙonal parameɃ\\x8fters Üfo\"r :py:Õclas<Ųŵs:`yjoblib.Parallel`.\\n\\nRaiĹȍses\\n--˾----\\nValueEűrror:j\\n    If the numbeöǾȘr ofN Pthe piȆpʅeΊlΧiçnes:Ř is less than 2ã or piœpeliȑnes ɝhave dæifferentǹ horǐzo˳ns.', 'multiprocessing', 'c', \"MaǾ˲ĵke pýrełdiͩcÄɨetiÀons˸Ǌ.\\nΌ\\nžʓComput²eż ȼthe co˗mb]inaDʩtirÌon of piͦƛpζeliėϠnǍǨɭe̥͇s' ϧforʉeìcaƘκstčsȉƦ Xus\\\\[Ąi\\x8dng µ`ˋμ`fċiǻAƃnʂʇĠal_m0˪odel``\", 'Something went wrong, ts is None!'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['target', 'target', 'macro', 'horizon', 'D', '1', 'decoder_real', 'decoder_target', 'segment', '1', 'segment', '1', 'decoder_real', 'decoder_target', 'decoder_target', 'decoder_target', 'decoder_real', 'decoder_real', 'segment', 'segment', 'target', 'decoder_target', 'target', 'decoder_target', 'ǕŦ   ɥ B  Ǣ  ʍo ʑ   Ɔ   ˀƣ   ', 'decoder_real', 'decoder_target', 'segment', 'A', 'decoder_target'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': [\"In-ʵrsǆhζo\\x8bgʑp cƑǯĿlotfhes r̅Ϊetĸr̎Ȥi͠Å˺̬eval dWatasǲeɨt.\\n\\nTesş\\x93t ʴȨ¢pÂartï ̹of ƉtǸhe θÈdĀatǦaǨsȕet Âis ob \\x8ct˰Ϊόaïŵineʡd by\\x8f̑ joinƊingĥ gȺ˂al˓lery âak\\xadánd query ͯŋsam˄m˧plϗûes.ɧ\\nEȎ̯Ŋϒ\\nSɝeɡe͒:ϯ h˱ttQæps://mmlaĵbė.ieˣ.cϤuġhĤkƧ.þed̟u.hk/pɶrŭλŅojectsƚ/DeȽepF¹Ȳʹa®ϚshioŲn̟/IønShŒopǮRʖeğtŠrieϗvĠlŴaïl.ɂˉh\\x9btmɀl\\nª\\nAūrgǠs:Ϛȡ\\n;   ɶ ;\\x85͏rouưƴot:ɣY Datώ-Ϧľϰaset roȒotϴû (wiʩth imìǔg 1subπfϲolΕdˆɟe\\x8cr aƟn(úd ̛liϕst_evΗal_partition.tǧxt).\\nȠɘɦȺ\\x9c   ̄ trɻ͈Ť9»ɩaΘin: ĪWʟhetŖher to ¾uϬĶ̜ïĉƹȫʊse ȸƋǋtrainŮ or ¡t\\x9aes³t paφrtƸǟ oĐf thǃe dätˑase'ͼtƉ.\", 'img', 'list_eval_partition.txt', '52712', 'Unexpected labels file. Make sure you use original labels file.', 'image_name item_id evaluation_status', 'Unexpected labels file. Make sure you use original labels file.', 'train', 'train', 'ǜWhethȋe̓r díahŰtȼaɔset isŌɖ cǳ8\\u038dl̑ˋŘaʋA˴sΚsi˥{ơficͭNaΠtiȵ/onĭ\\xa0͡ o̥$rǎ\\u0378̙ ʱmǘ̀atchin¢Δg.', '͑ŞGʨet d{Ƙaƿtaseƪt lCͽabels ȞarϼrɁ˷aèy.\\n\\nL̻¡ʷ΅abeɭȱls: are in̐tįȪ]eʖg̣erƽs É̜ɟ͵˛Z̙ʺi\\x92n tżhe range̛ Ϣ̐[Ȗ0ǉā,ƶʾ ĔĤN-Ϲ1].ʡʣ'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <22x22 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 22 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['˩ÓͲGîe\\x9at KȼLʫ-di\\u038bvergeηnʅΰcǒe μb§eǠt˝¼ŋween͏> γd˯ȍɐǻͨˀϲT\\x8fistrɆ\\x98iø|Ϥɘbuǰtionϧs aǡχɷnd. Ήǝ˙staɭndɍǉ͘ar_d̐ nŽƀPÍorϱm«σǪ\\x98al˄ d̥ƽistɮͣȅ¸ribuͩ¡ȑtion.\\n\\nArg̃s:\\n   ǟ̍ pƈĚDJaraxm΄ɀ©eÅtǶeŁrs: ́Disƪ͛±tεribƓut̨Ŕio˧n ªǻ>βpaͶrưtameŽters wϓith shapje (.̼˯ʻ®.ʒ., ʐK).\\n\\nőRʊeturnÌs:\\nɃ  ̟  KȍĉL-d΅ivergencΉǃeʊē\\x94 ͨof· _eachˣÆ dȠȾistributioË̃͒τn {w̴itɔΓh sîhapˮϚe (ɠ̂..ɊƜă?.).Ϫ', 'covariance', 'spherical', 'covariance', 'diagonal', 'log_probs', 'mean', 'covariance', 'Expected dict with keys {}.', 'covariance', 'log_probs', 'mean', 'Compute Log M̶LSĞÁ fo¬r unimodal diĔstrîbution˻s.\\n\\nFor æi5mplemȜeŕntatƣiþȫŹon detΙ\\x82ai̲ls see \"Probabilistic´̅; F\\x8dȸacer EɄmbeddi͞ngs\":\\nhttHp̗ϭ˽Ȭǿ̖s://oϠpenac͙cesĖs.ʊˑtοhecvf.c̆orm/Ėʈ\\x9eco3ntentș϶_ICCV_2019/pap~ers/Sh̆iŢϱ_ProʀbabilistiDγc_FaceĐ̖ŋ_πEmbćedŸdϙings_ICC͌Výʂ_20Ə19_bpaper.pdf', 'dim', 'covariance', 'diagonal', 'spherical', 'covariance', 'Unknown covariance type: {}', 'covariance', 'max_logivar', 'max_logivar', 'min_logivar', 'min_logivar', 'parametrization', 'Create and return norma͑lizatiƚ+o\\x9en Ʌlͭ͢ayerȗ.Ⱦ', 'dim', 'dim', 'covariance', 'covariance', 'spherical', 'covariance', 'diagonal', 'dim', 'Compute l˯og density for all points.Ų\\n\\nArgs:\\n   Ƭ pǺaθrameters: Dρistribution parameters with3 shape (..., ̒K).\\n Ϛ  ɨ poiϡntʬs: Points f\\x99or density evaluͯation wĴitʂhȽ shape (..., ͎D).\\n\\nRŧeturnʳs:\\n    Log probabilitiesǤ with\\x83 shap͵e (...).¿', 'dim', 'covariance', 'spherical', 'covariance', 'covariance', 'diagonal', 'Returns dict witİh distribution parameters.', 'log_probs', 'mean', 'covariance', 'spherical', 'invlin', 'ćiGet8\\u038b NornƚɲmalƧƀƻƎ ɐdistǹɺributƖion˨ pȮŖϰaržʀaöŠm{e̴tϙeĹɿrȃʕsĦʮ.\\nǦ\\nArgsŧ:ϼ\\n    ʥɤdiʺm:˨ ĻPoiƩn̤t dimenSs͛ĊƋĨĐOɁiǍ\\x8cŐon.\\n ͆<   spȊɯhǶeʢRĝriŦϵ˵cɛǁal¿Χ: ΏWh_Έe\\u0383ɭthHö\\x92˼erȺ distriˏfĩ\\x97butΰi˿üõϣΡonŖũ is˴ on sİpherʨe oźr R͔Ǆ^n.\\n   ɲˬ͐ĝ c̶eoŖvari̬ϯanϳce:Ωƕϛ Type of co\\x8evarianʮce matriĘx (`dąiƑagonaǗlʸ`, Ɯ`Ȭsp\\x8fher˜ƈΪiŚc˳ϚaŽl`̈ or ǋƦnËuṁber).\\n q͢   ÂƲƏp¹®araĜmetrϫǈπirza{tiUon:\\u0382 ȕĘT̗ċqyvpe\\x9e ͞³Ƣßʟof\\x9e̍ pearψam˂ŧĬͼeΠtriȉzationĚ ²ͣ(`exp` oʟrβ ή`Ɔ{iĒnvlˉin`ĬxϬ\\u0382).\\n  ϧı ˲ minƚ_lo̜gΘƓiĶvĿ͘àaǔr:ˆǛ Minnʕim\\x8bǿ̍um \\x84valuħe oǴˏf lĳo˲ǎgɲ iǝnƚĭveƾrse vɡarianΎcġeǄ͋ B2(lʼʓoʩgΏ ŅcoǤ!ncenϼtŕψr°r\"aƦǧȸ˟ȺtĄĤiǟɒoƤn@).ʆ\\n  \\x97˾ ͇ òmaɱ͢ʺx\\x97İ_loϋgiͰϦĪvaªr:;Ķɔ͊ Maxiǀimum Ëvalue \\x9fo϶\\x8dχê¨Øf log inver\\xadsĉɣe vϱari˛aêņce (log̐ơ E̿˃conce{n7tration).', 'dim', 'spherical', 'covariance', 'parametrization', 'min_logivar', 'max_logivar', 'covariance', 'covariance', 'spherical', 'covariance', 'covariance', 'spherical', 'Comp˃utͪe ǨͷLʕȔogǨ Mˣutual̓³˸˹ ȠLi¥Ɲʒkelih®oκod S.corĪ˪eťέ ʷ(LʭͳMLʶ\\u0379Ş) for pa¢\\u03a2iȎrȡsŠ ofΉ distributions.Ʋ̶\\n\\n\\nArƐgȡs:\\n¼Ϣ  X  ̘pa˒ramȽ\\x92̈e̅terϷs1: DϑiŇstͿributioȋȨ͕n parrϧaϒɄmeters Ļwitʛȗhȅf śhFapƥeʥ (..c.ʵ, ÛK).\\n    paϏraʋȺmȀϯϽƾeteūrÂis2H: DēʱisͶtributîioͅnƟ ˞ČpƏarˋƓϪaȷ\\x97ɝmeters with sha˛Ωpe͋ (Ť.ǐ.Ǯ.,ž̝Ɠ ɃÌK)Ā.\\n\\nľRϜeɑtǟZóuϫ rnϷȓϨǕsˣ:-\\n ³   MȪͣ\\x91LS ʧπǫscores ˃wiʖɩthǑΜʞĈ íshȅŔύaʳʝĮh̹ˌƏpe (Ǣ...)Ãɥǡ.', 'Joiϣn diˆfferent G̻MǮM pΥŏaramäetɗƷers into vecɭtors.\\x84', 'covariance', 'covariance', 'Covariance value changed: {} != {}.', 'spherical', \"E˳xƭtraɵ`ȶ2cėt mʊYean͎ fɦo̷ͮr5ʖ̾Ĵ ϮeÓɥǏVacʒh οΜ¼˽Ĭdis;͆tribution³.\\n\\n'Aāɑrgs:ˣϻĘ\\nʣ ƺ\\x99  ǜ p̙ɏarame\\u0378ƥ̊σ˗tΎeΊrs: Di5stΖċΰȖrΦibϩuti̩oã̑͢ω̨˜nÚ Ľpύµaϊr\\x94eame¸ters˄ witΙǐκh sĂhʹaˍɠʪpſeɐŷ (.ȅ˜Ø9,.., Kd·ˌ)̥ǯ.täǧɅ\\n\\n̗RetƢuŒ¡rOΉϷϏnsĶĺ:ϱ\\n  ƭ  ͊Dςżis̢tAʠƋö̈́ri³buticoǄn ǁmǄeans wiŊth shape Ʌ().ę\\x86¾ɿ.\\x9cʊ.,³ DOĠ).\", 'ϱǉϏEȗx¤Ętract comΎpoūʣnenȗ2̱ʰʝtw lroĂg pĴro΅ȈŤbsƵ, èmeaő\\x81ϗns ƾnand̒ hƝiddΩeǲnǕ\\x8eΓ ͻva͔rϘǇʙ̆ϣΎiancĽes Ƈf͢ϊ¯ro$m pa7r˰ÚaĺȕͭmeɤǕtʈeϻrs.', 'Wrong number of parameters: {} != {}.', 'dim', 'covariance', 'covariance', 'G-ɺeŖt ȴ͚ḿodeƑ¡žȳsɞ ϴoĴf dˍistrÊibutions.\\n\\nArgs:\\n ͷ\\x97\\x88ɶ   ʟˤ\\x8dɋparameters:y ̙DistǇrŰiͧȩbutioʉn ǌǅ̲parameterɯʱAs Ư\\x8ewi9ſth s¯hapeƳ Ƀƴ(.Ǆ..,ɢƘ K).ŕ\\n\\nReturϸƾǂns:\\n    TϛĨuple of mΈoȏ˭de logʷ pr̅obabiʼ϶̵flʥities̻ǈɦ˥ wŜ\\x80ith \\x9ds̵hape (Dè...˗,ï̹ ºŅCȺ)͢ \\x98a˓ɛndĊ modϨjeɗs íJwǿňitϨh Ξshaɶpe (...,½ C,ȟ \\x9aD).', 'gmm_std/mean', 'gmm_std/std', 'Point dimension.', 'dim', 'Whetheʵɰ̅ˢˠr΄ dάŻ˻iĹstrŒYiǊbuϹtion>˧ hŝάas builtĈi̓n ×ĚconfidenǶcζe eϤstɑimÉa&ϑtioɣn ϓorƝ not.'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <6x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['2020-01-01', 'D', 'target', 'D', \"Test ȧthatν Hoͯlt͠Ϡ-W²inteǛrs' ʚmFodeÄls mˁake prǇedictiòΫns\\x98 in ǣsimpleȣ cas͙e.\", 'model', 'This model does not work with exogenous features and regressors', 'model', \"ȝTʕesȋΚŐtzʹ͛ that ŎH\\x85tͺɲolt-ʌWiȤ͠nters'Ψ mƥo·dǁelsƨǰ˫ǡΛ workʔs ǪǼɛgood ÞwiŒtɮhŻȂ al͘mͥost\\x8cǾ constant da÷ɺϰta$set.\", 'macro', 'model', 'Can not get the dict with base models, the model is not fitted!', 'etna_model_class', 'CheckŲǲ thaƒt getɚ_modeOlǾ mȜethod r̦eturns̔ ňśϣdicĐ͊t of objsect˯s <oĥfʷε\\x96 ʗ\\x89SϡARIM͊ϫåʨAɕX cŚlaŲssƁ.', 'etna_model_class,expected_class'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': [' ʿ', '_', 'LagTransform', 'segment', \"͈ɩφŪCr±eatΥe instanÙcɓe oƵf LagǃTrƒaɐnsκfƍorɠN˥mϱμ.¬\\n\\n   \\nParameteTrsƏ\\nΕ-ʜ-͵--ɉĽ--ɓ--²Ò--ĖϽĬʯ̮\\niAn_Ϗc·oʛ$l̦umn:\\n \\n   \\nΕˆ  ĺðω̜ ǌ n¬ame \\x8eof proċcȆeÌfssed ǻcϧo˸ʰlǃumʍn\\n\\nlaȒgǡȪs:\\nȦ  iɁħn͈tĒϑ͠ ǘʸv;alue orǰτ list Ȯoı«f± valȇʕıʷues ˁfor ılϜa-gs̢ɋʬ computat@ƚio̙WøǸn;¼ iˌĢf ÎƟξintÌ˅ό£, geneƵratec ranɵgeʓ-\\x86̸ of ͶϳlaƯ5ǖągs fıɼro¨ĞmƁɔ 1̂ to̐ givʾ\\x83¼eən va\\x81lue\\u038bī͗\\n˄˂oƜut_ǳcolumn:\\n̬  baȕse fo̓Ȉ˕r tϴͺʹhĤe nam÷eʟǠȟ ψof ϥθcˣȸŴƁrẹateǸd ¼colͶ̾umns;\\nŔ\\n þĿ Ƽ  ̫J*¶ if set thȶe fin$aͿlé ȄʯϛůÆna̔me iƏs Š'{ρķoƝuλt_colÙumn}L_˒Ūõ{laęg_nƖumbƇħerτǫ}'Ȃɽ\\x7f;\\n\\nȣϽX$   ǟ Q* ̎if ǙͳΎdon_'t setǸ,Ɛü name ϙ¥willƛɂ Ŋbe ΰ`Ʋ`ŸtrϋansˌfϒϮϱž̎Δo\\x8ermȲ.__̦ǂɪʒrepr__()`ǆíĠ`Ƶĥ,\\nΙ   ȉ® r̘epÜr ʥwillɀ be¯ŧήşȏȝ maɁde̤Ǻ Ňfßor cƍtφƮƀranÛσΗsf̛Ϭorm thāaΚtƋÁ Ǆćrʋeat˹es eȏŧxactlϢǪyέ this ŉǰcovlumnƮ\\n\\nRaí͢seρ̽s{\\n------\\nVa\\x91Λlueđʫʹʺ˚Eǥ́νrroïřr:\\n   \\nϳ ˷   if γĚlags vČÝalɢŭueŞĒ ΏŐÝco\\u0378ntaiȻǏns ȇún1on-positiveȀϋ v̪ȶalʷues\", ' works only with positive lags values, ', ' given', ' works only with positive lags values'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': [], 'from': [], 'import': []}\n",
      "{'FunctionDef': <7x7 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['ɢ   Ķ \\x80   ʜġͯʱ ', 'segment_0', 'segment_1', 'x, y, expected', 'window_size,n_neighbors,distance_threshold,expected', '1', '2', '1', '2', '2021-01-11', '2021-01-09', '2021-01-27', 'feature', '1', '2', '2021-01-08', '2021-01-26'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <13x13 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 13 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['2020-01-01', 'D', 'timestamp', 'segment', 'target', 'segment_1', 'timestamp', 'segment', 'target', 'segment_2', 'timestamp', 'segment', 'exog_1', 'exog_2', 'segment_1', 'timestamp', 'segment', 'exog_1', 'exog_2', 'segment_2', 'D', 'exog_1', 'exog_2', '\\x9fTe̖\\u0383st that transform is ʷcreated wi¯tȺh exclude.', 'exog_1', 'exog_2', '͑ŀůŗTest ˳̩ˠtΔhatƱǳ ³ŪtraĊnsformâ iʍs ǎnoʦtǴ c\\x87reaΚģte(×ódΚ˹ɔȈ ϵwÌƝi̓tͶhʀ iɃ̱nƱȶͭcΘlǅ̒uυdWe ʓand eɢxϷȹcl̋ûψ̬Ȕuΐɋϵde.', 'There should be exactly one option set: include or exclude', 'exog_1', 'exog_2', 'There should be exactly one option set: include or exclude', 'Testƪ \\x81that tȔransȕfoƙȚrşmɇů remƆain×ˇ˹s o«nly fe ȑat˪urĵeKs ¸ϩˇin! iěnclude.', 'feature', 'include', 'target', 'exog_1', 'exog_1', 'exog_2', 'target', '¦TɍesMtͲ tĬˢhaɆt ¸tψransɭformŮ remȗϰoǔʚves onlyƦ ˬfeatĢures£ ǥi̜än ǻeǪɬxǂcɍlŷĉudǮeϰ.Ί', 'feature', 'exclude, expected_columns', 'target', 'exog_1', 'exog_2', 'target', 'exog_1', 'exog_2', 'exog_1', 'exog_2', 'target', 'target', 'exog_1', 'exog_2', 'non-existent-column', 'Features {.*} are not present in the dataset', 'feature', 'columns, return_features, expected_columns', 'exog_1', 'target', 'exog_2', 'target', 'exog_1', 'exog_2', 'target', 'exog_1', 'target', 'exog_2', 'target', 'exog_2', 'exog_1', 'exog_1', 'exog_2', 'exog_1', 'target', 'exog_2', 'exog_1', 'exog_2', 'target', 'target', 'exog_1', 'exog_2', 'exog_1', 'target', 'exog_2', 'target', 'exog_1', 'exog_2', 'feature', 'return_features', 'columns, saved_columns', 'target', 'target', 'exog_1', 'exog_2', 'exog_1', 'exog_2', 'target', 'exog_1', 'exog_2', 'target', 'exog_1', 'exog_2', ' ϋƠ  ϣ  ɾėΜ  ', 'feature', 'return_features', 'columns, saved_columns', 'target', 'exog_1', 'exog_2', 'target', 'exog_1', 'exog_2', 'exog_1', 'exog_2', 'target', 'target', 'exog_1', 'exog_2', 'non-existent-column', 'Features {.*} are not present in the dataset', ' \\x9f ˰', 'feature', 'columns, return_features, expected_columns', 'exog_1', 'target', 'exog_2', 'target', 'exog_1', 'target', 'exog_2', 'target', 'target', 'exog_1', 'exog_2', 'exog_1', 'target', 'exog_2', 'exog_1', 'exog_2', 'exog_1', 'exog_2', 'target', 'exog_1', 'exog_2', 'exog_1', 'target', 'exog_2', 'target', 'exog_1', 'exog_2', 'exog_1', 'target', 'exog_2'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Standa̢rd͋İgiz˭e Ǯfeòaʓtures bÏy˷V rͤemovinößƀg tƑǷheɂĊ mɢeΤaİn aǋȟˍͭ3Yndŝ sca\\u0383lƟçſi͇ng ǉto unit va[rˇiÔance.\\nư\\nUs4Άȷeˢs :py:ɲclƥass:`Ťͯsklearn¸ϱ.p~rȵeproceŸssing.StȣƜͲaTκndaʕ͜ÑrędSc̵aler`¥Ñ inĪ\\x8fȗsideI.\\nǾ\\nWȧaϋrniƇȃng\\n-\\x86-Η--̲---\\nϐThis tra̾ènϙΊįsfĥorm c7̀an sufȮf̾eOǦˏrϨΗ ɦfr˓o̾m lo©϶Ʀoĕk-ahe/ad bi\\x8aasƿμ. ǭFo̬̣͋\\x93r tϜra͛ns\\x8aɕfoȏrȪmiǬng dˎaxtĴa əat some ti3meʼȿstaʇmʹͮp\\nƼiǚt ͆˼useϻsƅ informaϬ)tioƍn fŎʉmrom tđhe ȿwholeZǠˌ  ʳȡtraϨȗinͣ part.', 'per-segment', 'S¹ʓƺƘc@ale8϶Ī feaƛtu͟resQ uǲ˵singY ˤ̵s\\x9cϚɔt͢aŬtistɲişcs t:hɸat ²arŃζe\\x9c rȎobust Ιt\\x82oˍ Ť²outlĺiers.\\nµ\\nU=seΤs :-pyſΊ:claȿssD:`skEǢleǬ̌arn>\\x9c.pr˞eprʢ+oU̵cessŁingŴƴ.˥³Rσo˪bu͝stÙaScaϪlϑevr` iɲànside.Ƴ\\n\\n\\x8aŅWÞarƊnin\\xa0gǄ\\n-ßƅ¥------Ȣ\\n¸This tranʎsf\\x87orm (caʃn sœufΚfeÇr fr˨oͷm lʀoo=kϨ-άƗ͗ahead͐ ͒ûbiπasǊ.̠ϣ For transformiŒng̸ daS͝tńa ȃt some timƇestāmpı\\nŋitɵ zuÐses inɱȆfȜorͰmaɱ̢Á͗tiʫʏon ̪frǟo΄mÌΙ żmtheŶĒ ʇwhŵoleΚ tr̝aȢÉién Ɉpart.o', 'per-segment', \"OTranŸsõfåormǏ feaƯƳtuÓrecs by sƙcaliǻnǷgΦ eaɔQch ķ΄featu̫ǖrɕeʦ tƊoͲ Ǩa eŏgivǼeςnϤ ranŒge¡.\\n\\nUseȚs ģ:pyØǃ:̳clasʦsÅ:\\u0382`s̝͛kʵlearne.pr{epȕr̈́ocessΥûϚʋing.˵MÊǚɤinMa˜xSΖʙcŃalerΜ` ȪƠinɂsŌéḯde.Ɛ̾\\nĦşƬ\\nWͪaϗrȶζniƱng\\n˼---σr--Ǝ\\x85--\\nThisÐ ǦȬtransǄfoǻǁƝrmĺ˃Ǉ̅ ca'n ~suγ+ffǮϬer Ǚfrom̜ lìookϴ-aǉhƸea¯dǘ ǗbiϐĈ̷as. ȌFor tΕƃraƵƋnsŇformưiϺng̫łήɿπɆ datŬ̬˵aĹǁ ĳϐýat\\x93 sεome·̥̩ʿʩ 9time¹stǚɊ̽ʛaς̪mpË\\nɊit usªe̽s\\x8b ×infor\\x92mɵatiwoŦn fλrom the Ǘϧwʱhol\\xadΣeň traƧƍiǋnϭ pǗart.Ʉ\", 'per-segment', 'per-segment', 'ΛIΤɬ̰n͇iβt ̘Min˛MaľxȐSc@8al\\x9beųr®Pˋrȝepr˼oþceƙss.ʒţ\\nΑ̹\\nParamοñe.ϖters\\n-Ͻʓ---̮ǕĜ--͕ºυ--Ǹ-˯-\\nin_columųn,:\\n ε   Mcol\\x9c\\x8bumns tЀoƈ ˚bϳe sϷ\\x8acaͳl˨eƽd,ūʙ ʵŌiϕf Noưne̹˅Β -ǓƗ allŹōʉ co˞luműnsϦ wilɇl b˓e scúașled.\\ninïpΐlacŸǷe:\\nǛ͔    fe;˯Ȓa¯tŉuřΝrȅs aơrƮe͠ chʅaʤn˦gɶHĂeɍ́d bϨy s϶caled.\\noȗϒt_coļ\\x81lumn:\\n ţ  ͚ ʼčb˜aseT féor thǕe nŨ̀a˅mes of gen}eϹra\\x8bte]d ȂȓcϬɁoɭχȓlumns, usƜeύĞs ``^ˉs\\\\elf._ǘ_reƔ pr__\\x88ɡu(ʇ)`` ifĒ not g˟ivenΧ.\\nmodʒɊċ͓˅eǍ:\\n ǀ  n \"Πͫ\\x95mɼacȣroΞ\" ǳorƁ \"̊pǫer-segmentΓ£\",¶ ʀÆ5waψǈyͱ˿ Ÿt˺o trö`ȩansform ˁĤȼνfeϬţaturesȳ ɆȰo¼vȋ̀͡ĕerŔʳ seĤgəΗ̻men˂ïĉt˭ťŨsɛ.\\n\\nı   ˼ * ÖʿIf ̬\"ĺmˠac͵rƯo\", trěǾaˮčnsɐfÓorľmsâ ˸fe͌atuƈ˻ɪ̯res glěǫΞ͊oˎΆ˄Vbally,ͳЀȠ Pgl\\u038du͑ingϹǧƝ ̞tǔhe ǧcË=ɏo+rõĐrespŮ·onding̮ onẹ͈s ̸ɘfor aǠɖllb Ĩũȑs̵eîgmenȝǀtćʭs͝ˢ.\\nϪ\\n   ȵ˗ *ς ϚŭI¾f ͱǜǅ\"perǮ\\x90-se¢gΐment\", ŊtŜʥransϴ̺fɰʞorms ĶİŀfeɰatǚǠĜȖϬureʄs fŚɩo΄r each sƱǖ˭ƏegǟmeÊnάłɡt ʢs-\\x80xepŴaϵra̟Ƀtely.ͤ\\nɑO\\nʷRƉaises͚\\n-ū,̶-ü°ϯ--ȩ¬Ö¹--Ι\\nVʦ#alˊ͙ϯʞɍ¡ɪueE\\xa0rroŦr˄:\\nɐɋ Ǘλy  ę ʐ̬if incorϲre͏Ǝcˈt moȾdeƔǈɄ gɴ̸ɒiv̷en', 'MaxAbsScalerTransform', 'MinMaxScalerTransform', 'RobustScalerTransform', 'StandardScalerTransform'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <19x16 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 19 stored elements in Compressed Sparse Row format>, 'ClassDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': [' ~ %', 'CORL', 'DT-D4RL', 'DT', 'halfcheetah-medium-v2', 'cuda', '-', '-', '     ͡   Δȍ  Ž ', 'PYTHONHASHSEED', '   ', 'project', 'group', 'name', '  ', ' ŷ ͚ ̤  ľ  ÿ  δͲ˹ ɓϹ', 'constant', ' \\x95Ø  ', ' ɽ ȖωήϏ  ǫ ˊ', 'rewards', 'Processing trajectories', 'observations', 'observations', 'actions', 'actions', 'rewards', 'rewards', 'terminals', 'timeouts', 'returns', 'rewards', 'obs_mean', 'obs_std', 'traj_lens', 'observations', 'observations', 'ͽ\\x88\\x87 Ĉ   ?  ô ˍ   ', 'rewards', '7 ', 'observations', 'actions', 'returns', 'obs_mean', 'obs_std', 'traj_lens', 'traj_lens', 'θ  Ű  ', 'Ȝ ͽ @ł  Ţ\\u038d   ǆ ', 'causal_mask', '  ', ' Ύ  ǅ  ', 'cpu', '  ţǬ ɖ   Ɖ  ', ' ̌ ', 'Checkpoints path: ', 'config.yaml', 'w', 'Total parameters: ', 'Training', 'none', 'train_loss', 'learning_rate', 'Evaluation', 'eval/', '_return_mean', 'eval/', '_return_std', 'eval/', '_normalized_score_mean', 'eval/', '_normalized_score_std', 'model_state', 'state_mean', 'state_std', 'dt_checkpoint.pt', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <3x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['T', 'ȡCall gi̺ġvēen ϒ``fuƠnϹcȌ`` witThͰǏ Joblibɘ ˨anjd ``*arΌgʹs``Ɣ aŞnd ``**ŵkχwaȔr̼g\\x84s``.', 'multiprocessing', 'c'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <9x9 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 9 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['4WhåeƪǰthěrǫŚ̽ datǡaƽȶsetȷ =is ǸͻfÚoʳrϓ τoɋĹpĸen-ƥsetĶ1 orğÀ̝ cɭlose_d-ƭset clôassifica\\x82ƜtƬionΧ.', 'GetΜ daȹtɍǨǦ̐Βaɳs͏Ċeϑŧ̸t άlaσb΅ eŰşls ϶˲arǊrañy.\\n\\nLaϙbeĶǺlˀĺΦsǫŲ ʮar˝ǈe 0/Ľ1 nÚinteŹger̈³s.̺', 'Whžet˸ƅhŁer uØdatƂaseŁ̨t ņi˨ʙǙs ϣcplÂŲassiΩƈf̖¶iɕcòatei˝oȵ̅n oȯBArΥ\\x8b vʃȖĤ˽̨eriñficJĕÁÑɑatîύǏȲ̪on˙.'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <7x7 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['segment', 'timestamp', 'target', '1/1/2018', 'segment', 'timestamp', 'target', '1/1/2018', 'D', 'use_box_cox', 'box_cox_bounds', 'use_trend', 'use_damped_trend', 'seasonal_periods', 'use_arma_errors', 'show_warnings', 'n_jobs', 'multiprocessing_start_method', 'context', 'use_box_cox = None, ', 'box_cox_bounds = None, ', 'use_trend = None, ', 'use_damped_trend = None, ', 'seasonal_periods = None, ', 'use_arma_errors = None, ', 'show_warnings = None, ', 'n_jobs = None, ', 'multiprocessing_start_method = None, ', 'context = None', '(', ', )', 'model_class, model_class_repr', 'TBATSModel', 'BATSModel', '          Ő  ̝        ', 'model is not fitted!', 'model', '1d', 'target', 'model', 'macro', 'model', 'target_0.025', 'target_0.975', 'target', 'target_0.975', 'target_0.025', 'model'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['  Ι˄   ɢ', 'is_first', 'moving_norm'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['TSDataset', 'target', 'timestamp'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <16x16 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 16 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['2020-01-01', '2020-01-01', 'target', 'regressor_a', 'D', 'timestamp', '2020-01-01', '2020-01-15', 'D', 'target', 'timestamp', '               ŏ', 'segment', 'segment_1', 'segment', 'segment_2', '   ̨  σ ˍȱ    ȧ   É  Ƭ Ⱥ ȺŇ  ', 'timestamp', '2020-01-08 22:15', '2020-01-10', 'H', 'target', 'timestamp', 'segment', 'segment_1', 'segment', 'segment_2', 'timestamp', '2020-11-25 22:30', '2020-11-26 02:15', '15MIN', 'target', 'timestamp', 'segment', 'segment_1', 'segment', 'segment_2', '   ', 'holiday', 'holiday', 'segment', '      ͓ ', 'regressor_holidays', 'segment', 'regressor_holidays', 'regressor_holidays', 'category', ' ȕƵ       ̣ͨ  ʥɒŵ ɳɍ  ', 'regressor_holidays', 'segment', 'regressor_holidays', 'regressor_holidays', 'category', 'regressor_holidays', 'segment', 'regressor_holidays', 'regressor_holidays', 'category', 'Frequency of data should be no more than daily.', 'index', '2020-11-25 22:30', '2020-12-11', '1D 15MIN', '2019-11-25', '2021-02-25', 'M', 'regressor_holidays', 'segment', 'regressor_holidays', 'iso_code,answer', 'RUS', 'US', '  Ʌ Ȇ', 'regressor_holidays', 'segment', 'regressor_holidays', 'iso_code,answer', 'RUS', 'US', 'regressor_holidays', 'segment', 'regressor_holidays', 'iso_code,answer', 'RUS', 'US', '    σ  ', 'regressor_holidays', 'expected_regressors', 'regressor_holidays'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['.jpg', '.jpeg', '.png', '.JPEG', ' ̻    2 ¡  ȹɧ š  ʼ` Ĵ ϖ ĺƼ ʪ  ', 'Scale dataset images', 'src', 'Images root', 'dst', 'Target root', '--center-crop', 'Crop output images to center', 'store_true', '--size', 'Size of the minimal side or coma-separated width and height', '--num-workers', 'Number of workers', ' Ͳ ž      \\x9f   y + Ƨ  M  ', ',', ',', '   g   Ɉ Ηʨ\\x7f́  ', 'η   ͡ǂ ȣ    Ǥ͈ ½ ŷ gǑ m  Ǻ ͏  ', '*', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <9x9 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 9 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': [\"W'ei̒gɌh͘ts&\\u0383ͨ̿́̃Bä͌ƃçiΘȳɏasxQe˿s lo˾ggerȜ.Õ\", \"ÝÐStaͱŢrtͲ FeKxp˅eriƫmͶƶentʛ˼.\\n\\nPCoǊmèpĳ˶Ǎ΅letʛϜeĜϸ ͊ƽloɟg_ger ´ͥiÃín˩˓itializ̳l\\x9f΄aǹ¨tżiožn ͪor ¦ƦŬğŢre˴ʋiȭ¸nĵ͜ǻ\\x80Ȇɍ`itiɝalɉiΚzeΛ it ̀]͑bǐeÞfΆơ˫r\\x81eǥųsȝɎΝ˶ the z\\xa0nĸưƁext ƑexpǪeͮ¢rimenƸjt wiʶ)t˂ɶ[h˗ɉʐ tǵhɰge same¤ nζύameʴǄ.\\nI\\nđPȪϼŞΊarameters\\n-------->̤-ɾ-ϟ\\njoɚbÞε_Ϳt¶Ϟyžpe:\\nŉ ϲcɊIȯ ʫ 9Κ SǚpeëĂciƹfwʔΩĀyč thɇe ɸtypǆe( of ruƎɁnǏ, Òw˫͎hǂϿƫichβȭ̴ ǂiĒs useǔfȾÔu#l̈́ whðe\\x94nü2 yćoŢ»ʕu'ȊŪíre-/ ¬gro̾ǉϙuǠʿpRiƨ̄nǝg˨ đruȉđǓ̬nΈɽs ʀtogŖe\\xa0ϴϺιthùƜ͵ere\\n̬ï i Ȣů˓ϗğ ª ëiˆnto laǩrg:erɀ e˲pϾĠcxƉϯɹperάǸți̐mentʴsʤ´ \\x9eì˭usinÉg šùȢˍχgroɢ'ΰuȼǕp.ƳϢ\\n\\x80gŌroϬu˽p:ΧȌ\\n  ºĞ͢  ĉȪSűɏƇ\\x86peci\\u038bɤ̓fŢŊ̯y̪œ Đaäŵ\\x93 ·grĄou¿pϲȿ \\x9atνoɟ o̪rǴϘœg´anȁizeÄ ǎʞˉiͯnɀdȩ±˿Ùi7͡vϑ˖ʌ˂i˦˅duΙalî rɯunʆ\\x86ư͵Ͽsʷ iζ͟nɝtoə a˓ larɜgϙÒέeͽƀr e̟Φx̐sp͡ŵe͡riÝm˂ˊent.\", 'thread', 'PɸytɬorcŏƮh lig̀hƥtni¡Ƶǈnȷ˛g ΘloŌgg̟èrsǆ.ß', 'segment', 'metrics', 'forecast', 'test', '', 'utf8', '=\\n', 'PLWandbLogger', 'TSDataset', 'metrics', 'forecast', 'fold_info', 'backtest'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['examples', 'mape,hist', 'r', 'source', 'cells', 'w', '\\n', 'poetry run codespell -L ', ' ', '  ̭¨ ', '*.ipynb', 'Skipping ', 'Running ', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['ͦClass hŗold͓ġing ¬pʜeré hsegment ό:ňpƦy:class:`skleaμrnƼ.lin͔Þe͡ar_modŝel.Liγn͚őearRegresòsσion`϶.', 'C\\x93laίss ȽϘǋholɑdīnCgɕƼ per segmeÒnʘt :pyʪ:cĳlaǨs̃s:Ʋ`Ɉskl\\x82earn.lʑi͡near_ûmod`Ŵ˰el.Elƫȟaʱsti#ɬɭcNet`.ǝ', '\\x87Cœǋlass̄ hoůƔldĂįɂng ʘ:ìpÌy:c̠lΩasY̎sƜ̣:`sűkleaǄrn.4lineΊ͢a\\xa0Κr_̎m]odͣȐeǘ̑l.ƷLiɐłĤnearȅ¼Reg͒r\\u0380ɢessinon` for§ɬ? TallɌ sƖe˪śƼgŶmeʗnts.', 'ǟCrΧe-ateç iʉnsƄtÎ̓an=·έɣce\\x90ɛ ofπ L\\x98iϪne̓arModeĥl wσÍƣiŪth ·͇g̽ivenÛ pȪar\\x93Ë΄aɠmeȧtͪʩe̶ȵłrü.s͖.\\n\\nǾPΝaram¼eteʒrǮs\\\\\\n̂L·-ϖ---ν-----˔ʾσ-\\nfitÀþ_inϟterʲcept:\\n  ğş ɘ ɸWıheΏʝthĦʎer̿Ʒ;\\x8c \\x88tΓ˪3̑͂o ϣcŮalcɸǖu˧ȪǴlaFtge ȥȣΚŔthe ΤCiniɬtʋ͒ΜęrĴɓce\\x91úpt˶ for ǅ̐tüȑhis Ⱥmodϴȓel.ɖƁǺ Iɋf seƙtʴ ż̛ʘto FiaʭĜƩlsĆeɾ, ̎̚nɺo ƭinȄOϐϋƴjͭ˦ŃϊˢǏterǼƒϥ͔̻c\\x87ͦ»ăe˼:pWt wAill ǟb̅Çe̍ ßus˗ʁ¢eśds\\u0379ɿ inä\\n   ģ͑ Ɉc͍iǿalÿculaŻtʳδioâ`nsɟāǅ (ƽƦiƭ.e.˪¾Ǌř\\x9d͓ʢ Êʏ\\x8bdǳata\\u0380Ŀ ʠ$isʥ Ȑexpec×t¨eŪDdʬʕ ƿ\\x92tȺɛo ̀ϯb¤\\x8fe̞ ceÏ͛ntôω˹̏ǕΚerMǷϚed).ͻn̾ɵ̃Ǯ', 'ClʭaÁ͟\\x82ss͛ ϐ¶hño˪ldin̢Φg ¥:py:cΖlasˈsȲ:̗`skle¦σȧarǖnǁ͆ϥ.¤lɬinȓe@ɿaƎr_ȌέmoέÞd̤ʼe̦IlɅ.EãlŒż˝?Υast§icN\\u0382eĘtλɫ` ̓f̘͂or ń̅alŚĵGl® ɡsegmenèt̬s.', \"CreatÝe iǄnstłΙaun\\u0383c¡ʇɩeĮ ȔofÖ EYƎlasticNet ěw×ith gʿȼʑiven pĔarameǀte̝rsΫ.:\\n\\nParamǾetēĵrs\\n----------Ő\\nalpÙǼha:\\n    Co̍nst͋ant tͅhat mult̃ƺiplʺieƵ͔s ķthe penaȩlgƅtùy terms.Γ DefȼŮauȧlts t@o 1.0Ǎύ.\\n    `ǵ`alĖphaĳ = 0``Ǵ Ķ¬ɛ̌is ɭĕequivalenʮtˏ t˯o an̪ ordinarɚy leasʦt squar͙eƫ, solved ϱby Ǻthe L˧ıiϡneabſrRe˰g͎resɜsɒiϙʠ\\u0380oǼn/ ob˞j÷ectʋ.\\n    For ŷnùumeriÊcal ͫre\\x98asons΄, AǮɑ˲usiʶnȷgά `ɹ`al\\x8dphĹaǊ = 0˥`` \\u0380with t1hʖeÝ Lza;ˍásȋoʫso obj͈eαcțt` Ʈɑis noˁt al͛d˙v´iseűɔdǎÕ.þ\\n  ̣ ǵ ŎGϛiveŋ\\u0383nƶ˚ Ȉth̝is, Ǖyou ɱshou͟ldǍž use t\\u0380hÄe :pΟυy:claʲɣɚssĜ:`~ƽetna.modeǿlsƪ.lȎiǢnear.LinearMult1ʗiSegmenȀtMočȯdel`Ĩͪ object.ļ\\nl1_ratio\\u038b:\\n   ͝á ͜The El4ıɡȨasticNet mixing par˟amete̩r, wȋith ``0ǰ <= l1_raˎtio˧ Ξ<= 1``.\\nhʝ\\n   ϩ\\x90ȉƿ *ȱ ForȺɵͱ G``l1c_ratϒiĴoę =˜ 0`´` tɽheȌ penaltϼyĚϲ is aƌɪn LƏ2² penalͳǻ̝tyǮ.\\n\\n    Ǉ*Ϩͦ FϤor ``Ȍĉlƣ1_rÍatioˏ = 1`` it is Ǻanͽ L1ͫ peȡnaǺlty.\\n\\n \\x99 ̷ɷ  *͍ ͶɳFβor ``ǎ0 ͱ< l1ɯ_ratiLo <ǧ 1`ư`, thʴeͫ penalty isŽ a combiΤnatiȃo\\u0378nǥ ofoȯ ŌL1 andĐ L2.\\n\\nfit_intercept:\\n  Ψ  WheĳtherǦ ¹'t˹ͣo calƙcula̮töe thτe inter˧cϳĮept \\x85for thiʵ˹Ǘs ɡmŚBɶodel. Ifˍ sʕet tͯoG Falxse, no̓ κin̔terce÷pt wiƬll be\\u038b Ÿusedp in\\n ̐ Ɣ ϐ calƚȃcŰulations (i.e. data is exʩpζeƒcteɎϽd toơ bŤe centerȠedˮ).\"], 'from': [], 'import': []}\n",
      "{'FunctionDef': <9x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 9 stored elements in Compressed Sparse Row format>, 'ClassDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['̈ʳ\\x8e§8     ʴ    \\x8a̺_   ', 'Silent', '     Ǡ˿', 'category', 'Compute predictiˣons frķo«m a Cvȹatboost model.¡\\n\\nParameters\\n\\n-Ţ---ɩ͏-Ǎ-----\\ndƦf:\\n    FeaturΣes daΪt˪?afrÚame\\n\\n\\nRetuÍȮrns˦Đ\\n \\n---̤----\\n  \\n:\\n  \\n  ½ǡ  Array ǡ͋with prediʌΦόctiožns', 'timestamp', 'target', 'timestamp', 'target', 'target', 'category', '_CatBoostAdapter', 'Silent', \"CͶͦrḛatʈe insta˴nce of CatBoϤϙoķsĉȣtPerSegm\\x8bentMʥodel wit̲h given ʋTparameʒt˥ers.\\n\\n)Parameteϊrøus\\n---ϱ-------\\nit¸erations:϶\\n    The ȜmaȣxːimumȽ nŞumber of trees ʯthïatˑŝ can b£Ke bÏuilt when solvˆing\\n˛    machine Ǚlear\\x9aninϘg prɐobleϊms.S ͒When using oǏther parˈametĮers thaƂt\\n    lËiJmɃit the number of iterations|, theŭ finaǙl num9ber of trees\\nĖ  ȟ  mayó be lessʥ than the num͓berr· speciŰfied Ƕin this parameter.\\ndeĚptŒȮh:\\nÀΆ    Depth of the tre^e.ʚ The range Ȩof suťpΈported va˛lues depends\\n    on tİhe processμing ŭunitĢď tyκpe aϘnd the type of thφe ȼselectŠed lossϠ fuhnctioɎn:\\nΥ\\n    * CPU — Any integer u½p to 16̄.ɝ\\n \\n\\nˉ    * GPU — Any ɾinteger̂ up to ¶8 p̵airwise modeΫs (YetiRanĻżk, PairLogƌitŭPairwise and\\n      ǽQueryCrossEntɁRńropy) and Ŕup toϥ 1Ģ6 ˙for all other loƵss fĚu>ʮǟnάȫǹ̵Űοct®ʰϣƏions.\\nl̔ˉearning_r˶atƵe:\\n Ɉ ʊ̒  The ˣlˊ˴exarϣning rate. Useͦd for redufcǦing the gr͈aȝȣdient step.\\n    ʿͮIf None the valueȚ is defʱined Ϸautoɷmatǃically dependi͢Ϡng ȼon the ͇numbȳer͚Æ of iterations.\\nƸloɰgƹginņg_ɄleÀvel:\\n    5Th e logging level toʅ oʄutpϳutͫ ǋȧto stdout.\\n   ő ǷʭPàossi˭ble values:\\nė\\nZ«    * SilζentƊ — Doí nɔot oʡutpuġʽ϶t Ƌanyϭ ˟logging in̸form̭atio͍n Ťto stdout.\\n\\n    * VerΒbǲose ʯ—ǐ Output the followʺing data^ʰ to stdout:\\n\\n )       * op͈̚timizedɲƕɬ metric\\n\\n Ŭ    Ƌ  υ * elapƞsed tiƹme of tΙrͺaining\\n#g\\nǙʱ Ě  Ď ā    * remϔaiΏning͢\\u0382 tiɫÌme ŝoµfÚʕ Ɯtraining\\n\\nä    * Info ̐—Ɨ ƸOutϽpu\\x83ǎ\\x97t aƲdditional ȦinfoɎǶ\\x96rma|tion and theǨ numberȈ of trees.\\n\\n ǌ   ÈϬ*ʆ D}ebuϏg — OutpSut \\x83ħdebuÔgʛging iǄ\\x8enfǡormatiȜon.\\n\\n\\nl2_l§âeǥaf_regǲ:\\n     \\n ͡  ǌ CoeffλƯicient at the̞ L2 regˍϸularizaȋtionN term of the costɽ func̰tico̭n.\\n Ξ   Any positive ˋƔ¹value i̺sȊ allowed.\\ntʻhrɁead_countʃ:\\n     \\n nΓ   The numƌbυer of threads to useǥ during țthe traÃining.Ģ\\n\\n ͝   * For CPU. OptimϜaŸizȨes. ʵĜȫthƚe speed˴ oϮf˗ĭ ͮexecuˤtion. \\x80T¢Ȍİhis par@amete̲r ]doesnϗ'ìt affecȃtR̺ results.\\n   ̳ * Fożr GäPʑU. The gi\\\\vǀe_n value is used forƏ readΪing tȜhʚeˣ daHta from ğthϟe harēdeǨ drǪċive aŗnɹdĊ doesȏ\\nȶ  c    not ͦaɻff˔ect tơhe̺ ȩtraining.\\n      Durłin\\x90g thŝe training one mainΓ thrɰ͇eaʚdɒ a̢nd \\x84one ͬthɝrȤeƣ(ad for each GPU ar̢\\xa0e us͎eÏd.\", 'Class for holdõingÚ Caåtboost mode˰ϑɼǹl for aúĐll sèegmϙentsƍ.˻\\n\\nExaιmplɋes\\n---ƹ-ʙ-ϔ---\\n>>\\x82> fƍrom e\\x86tMZϫn)Ƈa.wdǯataƷsets iŞmpoőrt g¬enerate_periodi̢Ż˒c_df\\nΝ>>˝> from etnŭ̽a.dȐataϭγǃgse·tƛs import̥ TʠSDataset\\nÿ>ʭ>> æfroįmɬ \\u0380etnaɗ.moΦdels impołrtĄ CŖaǋt\\x9bBoo̧steMϭ˔ultiSegmenƖtMo̕del\\n    \\n>>>ǻ fǝʌrŀϦom etna.tɚransfoȣr5ms import LagTransforĕm\\n  \\n>>>Ϫ ƺclaƶssiącɛ_ƭƋdf = gϭeneratȠʯe_periodŃic_df(\\n... ǘ ̓   periodǐs=100,\\n...     startĚ_time=\"2020-01-01\",\\n..͗.     n_̍seƴgmenyȶts=4,\\n...ņ åɚ    BperioƆd=7ġ,\\n̟...      Ʋ;Çsigma=3\\nȕ..ȳť. )Ƅ\\n>>> ādfO ȇ= TSDľa΄taset˒ϑ.6to_daδt°aŭsetȇ͜(df=clȹassΩic_dʻf)\\n\\x9f>>> ts = ϛTSDaϪtaset(df, ɏfreq=\"YD϶\")\\n>>> hoÀrizon = 7¥\\n>>> transf̦orms = [-̐\\n...     LagTransšfȀorm(inȎ_c˼olumn=\"target\"Ɔ, lags=\\x8e[Ć͐horizɟšon, hoʦrizon+1, }horiĞzon+2])\\n...ɺ Ύ!Ǜ]\\xadƝ˪̸\\nǮ>>> ts.fiȋt͔_trBansform(tȈranͲsforèms=transfțorms)ϊä\\n̼>>> futu˖re =˲ ts.ma\\x80ke_future(horʷϰizʞoŘn)\\n>>> model = ɶCa͘˦tBoostMultiSegment!Model()Ëˤͅ\\n>>> moƁdel.fit\\x88(tµs=ts)\\nœCaǔtBoostMultiĈSe˚gmentModel͔(iteǏrations = No:ne, ɷdep͠th = Non\\x8fˈeŭ, ̂ΏlearYning_˹rate = None,\\nȫloggiñng_lͷevel I= \\'Silent\\', l2œ_İleaf͗_˹rŋeg î=ƵÅ None, threa̸d_count = ÀNone, ̭ɜ)Ə\\n<>>ʲ\\x7f> foreƑcast =ʹ moʑdeʄl.forecȶ̤Ƅast(futurte)\\nF>>ȉ> p˾d.op̔tionRũsʂ.dšisplːɀay.float_format ƣ= \\'{Ů:¾Ŧ,Ȟ.2f}ϖ\\'.foΦr̗mat\\n>>> fQoreÒcastΜ[:,ǝ :,Ɇ \"target\"].round()\\nsXegåme\\x8dnt    segment_0 seg̺ment_1 segmƧen͢t_2 segment_3ɟ\\n\\nϹfeature       targτet    targÞet    t͟argetθ  ļĽ  target*\\ntiJmesǷtam±Ϡ˫p\\n20C2\\x810-04-10 Ʀ ʘ  ˄ƻ  Ï9.00      9.00   ̤Τ ʟϯ  4.Ɉʳȡ00  6\\u038b    6ƅ.ϥ00\\n    \\n2ŋȡ̍^020-0ä4-11      5.00      2.0ƝȬ0   ¼Û ɂ ʶŅ 7ɝ.00  ·̀    9.χͪ0̓0\\n20ģ20-04-12Ͼͦ     -0.0i΅0 ǭø     4.00      7.0Æ0      9.00\\nʗ202čφ0-04˓-13ˬ     ç 0ĵ.00 ̈́Ϫȷŗ   Α  5.00  Ϧ    9.00   ˰   ̸7.00\\n2ưħ02Ί0-04ëÿ-1®4    Ϡ  ȍΓ1.00 ˾     ͆2.00      1.00   ̘ ə Ϊ Ȫ6.0à0\\n20\\x9820-04-15   ɳş   ϭ5.00   ƛ̦  ̡ 7.00 ø     4.00      ˜7.00\\n     \\n20ʌ20-0Ƚ4-16Ϊ Ć   l  8.00    π  6.00      23̛.00β      0.00', 'Silent', 'ǿ\\x91ÚCre«aate insĻΑt͢anc͚e of ΗC8ʥatBGoˣostMulυtiFÔSϠeU͉ġgςmeˌłɒntMode÷lňŴƢЀɿ wſiʨøthÜϫͱ gŨiɳvenr0 ˵pΫarÆõaʈmetˬʮeͩȐşrs.\\u03a2ǃ\\n\\nParaØ͍nτm\\x97\\u038d\\x80beļterłŮȑɽsƘ\\n-ϻĄ-ˏ----ʶň--πþ--˟ɸ\\n     \\n    \\n   \\nͭiteØȋraȽtionsɓͱ:\\n ǧͯː  ʱɫ Thϫčeǉ mϽȃǀ̍axi϶˰muͼĕ̦4Ȍ̫m ϙn˴ͻumÎbeĘŇ{Śqrŉƨ˨βɽ åoʰf ćlγϓtrees ǆ\\x9cthɜaø͘ȳt Ęϓcanɟ âȚbϕe bƌĊuiltéȘ »wǵhen ʛsolLv\\x9cin\\x8ag\\n Š ϱ  m̴aŏchȊine»\\x9aÙ leaƻrΟͧning prϞėoȡbleϭϘms.ͥ Wņ̰hŗŰeʛĲnÖʩɭ εǴÚûusέinðg othţ͌er ¡pa˱ȋrȲϩaÍmċȫeƵʧteΒ̽ƅrs th˟Đaϙtɠ\\n     \\n    ώȈ̅lͷimiϪtʰ tŽϏhe̘ͥ nʬˤumber; of ȶÕɵϐiʄtǪerɅʨat~iωons, ØŨtheȭ˦ fϽinˋal numɟbƥˤeǤr [o͒ɞf ̾trees\\n   \\nǨ¦ f å°΅ µ m\\u038baǟy ˃ǹbŶDȌɏe ǵlʗʱeȭƜsoΣʜ\\u0383s tphȢaϕn ̸ʦ͋ĺtŦhČe ánumbeȴr ɧsŕpeǐœcifø͝i¥9eǍdƖƏ ƗŵiʟnϏ5 ȱt<̝ʖhtiűsǮ˞ Ǜ\\u0380paǗř̟ȟram\\x99eǣőt5er/Ƅ.\\ndeɭptʛͩċh˂:\\n  ˲ȎƯ Ńƺ ˢτĲȲȋDe\\\\ʕȌˌ̱ptǬhϚ âof tǮϽhźɚe ʰΗtʷrϺˡee.ʄ ɖGήTǖhű̸e rΩŗϽangΏeø˕ oǩ\\x99f ǱǶäsuƖp˰\\x82p¾orteɚǞʹȤΉd} v¦ƟalȓƪuϔïesϢ ɂd\\xadƽʕɖeph:e&nϞ̗dsʔ\\nåƛĎ Ʃͮ \\x7f  Ȩ͟onǋ @theǉ p͵ɠì̙rocϸɑϢUǲšessΰiϳˏϦ͒ngț ƨͶėun͓ƔáϟŪ̒itʦ typ͞e ɋaínd thƽe\\u038b tφ̛ype of tȿÂhe ʉseloeĕctĤèeχȩ̱ƛd̵Ǩ loÏssŇ \\'&funĊʷcā>t˨̇`iǧ°ɫoȚµƲnȉ:\\n̒ˎÜ\\n˗ϒ  ǎ Ň̝ *Jͦ CPħ̥ȄƘU \\x9f— AnɄy¸Ι Ÿi̛˸ͻnît˸eger up to̐ 1Ȧ6.Χ«̮\\nŸ\\n  ί  *ɉ G̯ÓɓPǟU \\u038df—ǴǢ Anyʳͼ i¬ntʤeƃƝǷgɀʗer u¬p to ʻ8ç p:airâʔwʎis̰e ͤm[vȏǧƄΊdOƉes ƃś(ȗYe͵tiRankƨ, ǡϰαƳPzͬair7L̢ʞoŰ͒g͇ķiǐtPairFwĬiĨ¸Ʒs\\x93ƂȽe ǥandĬƎ\\n F m Ϯǋ ǝɜǷ  Qu̲e͜7ryCÏroɤĄssEͭntropy) ̋aͭŞïnd uå̡Ȩ̹p\\x96 rȱto̠ĉ 216 fáɍor ƢʙaϡéllĢ oĴȆοtheįšr loȾss fŨun˪ctions.˄ŀȼϧÔ\\n  \\nlɺeʇarninP%g_rǼqŗ\\x99͈ɲŊŽate͚χ:i\\nˣ ȦºȌ  ˂Ʀ ¢ϴThRe9 ƣlʿeǫȻʄarʟnŉȳĪi\\x9aˬʆȁʯnƑg rɸŕa\\x9dteW.ʻ Use͍ëd\\x9dÅͿ fo̠ηr ĆͬˇěreɃŊduc˻iþɝnÐg ͡ŊÂtóνʡheŲ ʘgrΒad˩ienīͨ͢t sĉtć\\x9beĪFpʵ̢.\\n ķ 6 Ǉ\\x93 ί0If NÊN¤ʽoƫ͍ne˕ theui ΩΙvag͓4ˇlϯue is ƱdĽǭef\\x90˂inƅed āěͥautomʆaƭtȯi\\x8bcaˋl˦ǮlyƍΆ Άdepe̗ndϒÀin¤g oȵn Ơtheϸ 1\\\\ϭnĮumï̏ber ŐÅIɬP̗Ͷʚoyèf itǢerat¼io»Ŧn̳s.\\nȧɸlogg̓ing_lȝevɤelŠ:\\nǥ ˈð` ʂ ZȽ͆ Tƶΰh±Įe člΐAocggØiʇnɝgƍˏ l8ƚev\\x8bʝϐ\\x86ͦe˗l Ɣźɦʿtǂ×oˇ̴ˆŽ\\u0381 oŜuͽt˵putɡ ̀to˹< stdou˟t.Ϧ\\n    PɏCˋZʇIossiƂb\\u0379IϽlıöe ̸vaIȝl̳͉ues:\\n\\n̙  Ȳː̜ ̦ t*ƧU SilȦΓeͷntĹůϚ — ʥ͗ǬDĺǮoò͐ƀboŴφƨ ɎnĬϜot ʬoutput DȬaʛnyĽ loΦ͞g˷͟ɫgÕʘiƼn^ˤ̨gūƷÚ in̓fośrma͜tĳioǁnɹ toƾʀ̊ stƖȃdɿŘout.Ȇ\\n\\nϢ͐   \\x8dɒɰ * ȔVeɉrĕboϖğƗ1sɁ̹ÒŸe˗ü ̮Ù— Outƫpuʓŷɨt ǥtheä ɰf̚olǑͦloũśġɆwinƬŎg ŐLdaȓtaƂ ̠Ăto ˶stdƜȱouϪ̞tȡŵχʕ:\\n\\n ͅÊ ʽ\\x8e ɲ   ȩ Ɨ8 ̠*Ǚ optrim\\x94iλ̒ǘɉzMǚ}edŋȭ m˖̃ϧÃ˵˃ǷϨe˵tðȇ\\x93+ri\\x7fcĖ\\n\\nͧǯȪ <Ϡ ρȯ  ʡ\\x89  !ǽ  * ȗeɗl̒ap{sedy Śˀtim˄eŕ ͖ϰof trɕ˒ʙai˽nǳingτ̶\\n\\n  ͨ\\u038bǾ  ā    ɹ*ü r͝eƤmaiͥni)ș˵ɠŲn\\xadg ·tͰimźe̳ oϡÔf t;rai)ning\\n\\n͡  ʗ  ω* ǾInfɶo Ȟā—ɴϯŐa O\\x88Ÿ\\x99utǙʵσéƀ+putČ̬ ͒Ƹa϶͒\\x95ȅddʌȊʦiʹϻtȣɑioBnɡǼ͖aɗɷʊƳΪl˿˛ ˊinforπǈmatiɾˉon aǇnȒώĕdþϘ Ɵ̵the ̛̱̔ȧnumbeψʠϩrǏ͍ŀ of@\\x98\\u03a2ɧ tre[ȩe¸sɢ.́ǚǿ\\n\\nƑ  ̵O  * D̅eb˔uªg ɹǺȒ— ʰOŰutϹpuɋȇtƻ ̙dϊĦeb$uʞɷgging iŎĐnfƢoêĎȆr˖žͽϢmation.Ĭ\\nƠ\\nl2_lȊeƐ͙aˬf̍\\x94_ʁɆ̚rǨǏ˨e˻gĮ:\\n  ɣͯ  ˱cC͙γoe\\u0381fɠfiĄcÑƢĨie͋nt atǉ thńe L2 reǀƥgȦʿɀu˲l\\x8eΧʤƙarizύation teƪ£rm NoʡÉf t¶he ʁϳĪÄ͇2zcoȗsˎtA fʥunction.=_\\nµ  ˠŵ  ɈAɱny ĶpoʤsğϤi_tiZvƁǯ\\x99źϑe vƉa͊lue iǾs allow͝eõͨ]ϛdnˏɦÛƿ\\'ϫ.ʄ\\nt?həreɏad_ƣcÍ˥ouɜnĕȼĔjˁt\\x8cǱ:ƕ\\n ƛĺ  Ę Thϛeȵ̖ Ĉnu\\x8a͒mberΤK Uǯ̸ï̒ϤõƙofʁΩ threadɺśçͱĮŉsȋ ̴˺ǌto u̇s̝e dΪ̮urơi͒nǷgȌ ûϢȥǈtΓǿheŀ͞ϋ tɪrĒaininͶǞgʒ\\xa0.\"\\n\\n    ·*ʴÈt͞ FǽǈǍoƟŏr ̇CƛPU.pʾǃˋ ˞ðOpt̕˖ḯƮm̥izes thƚνϗʰ̎ȃϨāŪ̹\\x96̭\\x8d˴˨e speőed ofƠ̪̑ ƥeˡǪxecutɁiÊƘonɕm.ΐ ŌßɦTPhis ɯ\\x9eūpοaϭ\\u0380ǰraȅmeųtǪer dȏƜ»esŌn\\'>ȅtͥ ͛\\x99af͢ƄfeʟcǳśÙtɿ re͍suϿʋ®l¼tϯs.\\n  \\n  œ  ǀ̗* \\x98FoFrŶ GP̎UȵƵ.ø&ǝ) Thǁȁe¦ɖȀ giTvȤȁenn VϪvǄalλue is ̇ƜĤ²Šused foɣrȇ ŏïrƭǽeˆȪad̐ġin¬g {ͬt͛ÍhʊeÎ dÿ\\x9baŎϿtaɽy froǇm˶̊ ƶtheưƦʺ ϊ˂ΔĎĄɵƚh̽ard driʝĻv̒Ƣe ˝an͓d˜ ͒\\\\doesĞ\\n ˍ     ͩnoΘt ȵaǟȜɪ?Íffeɘct˼Á tɚęɿh̜ħɄeˁ ưtrȎaĔĉiniŮȲng.̊ˎ˼\\n   Έ Ë  DƠΙuξrÿīiǱʽngε the t\\x96raǱiniώng ªϬo˟ṋe ǥʠ=main ̬thrëȵƸīͦƚaŷƠʚˈdR aĆnd one͍ñɄòΜ tĪͶǖ͢ƭh˄ť<ǶȞrúʹΪůǽead Ɯf͌ϳoŅºȫr ǱɂĽeachιϗ«ˈš GPU $are usˉ˼πe͑ǂ̵ͥΉdŖƍɧ.͚', 'Class for holding per segment Catboost modeʄ\\u0383çl.\\n\\nWarnings#iWJdqHFwGrNKO\\n--------\\nCatBoos͊jtModelPerSergment is ̢ƅdeprec¨ated; will be deleted in etna==2.0.\\nUsưe eʋtna.models.CatB̅oostPerSegmenˀtModel insteadƶ.\\n\\nExampWÖles\\x95\\n------ǲ--\\n>>> from etna.data«sets import generateĳ_periodic_df\\n>>> from etna.datasets import TSDataset\\n>>> f®rʮom etna.models import̫ CatBoostMoɿdelPerSegment\\n>\\x82>> from etnÝa.transforms import LagTransʎform\\n>>> classic_df = generate_periodic_df(#omTwNdZfKHnqictyjW\\n...     periods=100,\\n...     sńtart_time=\"2020-01-01\",\\n\\n...     n_segmeĴnts=4,\\n...     period=7,\\n    \\n    \\n...     sigma=3\\n   \\n... )\\n\\n \\n>>> df = TSDɺataset.to_dataset(df=classic_dȯf)#sTuYRhLwmvxGpbHBIVdM\\n>>> ts = TSDataset(df, freq=\"D\")\\n>>> horizon = 7\\n>>> trans͔forms = [\\n...     LagTransfđorm(in_column=\"target\", lags=[horizon, horizon+1, horizon+2])\\n     \\n... ]\\n>>> ts.fit_transform(transforms=transforms)\\n>>> future ˌ= ts.make_future(horizÛon)ʴ\\n>>> model = CatBoostModelPerSegment()\\n>>> model.fit(ts=ts)\\nCatBoostModelPerSegment(iteΐrations = œNone, depth = NonȀe, learning_rate = None,\\nlogging_leǖvel = \\'Silent\\', l2_leaf_reg = None, thread_count = None, )\\n   \\n>>> forecast = model.foreμcast(fuĽture)9\\n \\n>>> pd.options.display.float_format = \\'{:,.2f}\\'.formĈat\\n     \\n>>> forecast[:, :, \"target\"]\\nsegment    segmϰent_0 segment_1 segment_2 segment_3\\nfeature       tkarget  ʞ  target    ͈target    target\\ntimeϔstamp\\n2020-ņ04-10 ƀ ό    9.0»0      9.00      4.00      6.00\\n2020-04-11    ̔ˉ  5.00    Έ  2.00      7.00      9.00\\n2020-04-12      0.00      4.00     Ë 7.00      9.00\\n2020-04-13      0.00    f  5.00      9.00έ      7.00\\n2020-04-ǌÊ14      1.00      2.00      1.00      6.00\\n2020-04-15      5.00      7.00      4.00      7.·00\\n2020-04-16      8.00      6.00      2.00 ¬   ύ  0.00', 'Silent', 'pCreaȚt̋Țˏe in˵sʈtance of CatBooˆĄstMoΟdel̟̔æPerëSeßgʅʫǤmſe¿nétňĶŘ with gi^ven paramȋeterÛs.\\nΪȥȻ\\nParɢamxeters\\n-ĝ------űϣʢʛ-ȝ-Û-ɰ\\niñte͕βraʧt¼%¹ƚiǭonɞs:\\nȹ Ū I  ThɈe mɇ̔aximum nuţmbϘe\\'r of˗ ͕treʒìeÞs that caơnô :̩b\"e bTuiſltƊλÌ wĴ¿hen solĈvȎiǜng̱ó̈\\n    machcine leaĽrAning ǐϯprobölems. When¶ ǉϋżƎusinĒgū otherĴ ϮpaƄrametϨers that\\nϝ ̺|ȗ   lϲi͢mi\\x93t ȱtȴh͵ȈeΚϟɧS< ºnumberØ ɺof iưƼteraʹAɌʶɪtioóns, Ϛthe˓ċ ĉ̺fďinal nuƛϏmberƻ ıġΠoƦƶf ɴËt rˇ\\xa0beesͫ\\n   ɳ ¡ǭmΨZaəy ͎beϚ les˹s ξthÉɍa$nđ\\x80ͼɦǲ ̢žtheκ ndu`mbeByr sp¥ecßiġfieĭƣd̽ Șüin ŕthis\\x99ͱ \\x98paraƴmeŃter.\\n   \\nǯdepth:Ϡ\\n    DeϹʦop!±t΄hǶ #oĉf»Ȉ the tõree. ƏTheĠ r4a̚͡\\u0381nʰgϑǥeÔ ϖoΨfǂ sìuƻpported vɿalues ɑœ̋dύep»e\\xa0ngzdϨĴs\\n ü  ͠ KΚȱo̍ƞn thĐȟe proceȘsʫƨ̜sɖȄing ʑĞunʐit̙Ŗ̸ɱ typ\\u0380e and ̡theĝ type ʈ@oˎf theʆ seĆlecȮted loss įɋfuncŢ\\x80ɴÓtioǝn:\\n    #MNbIBWVCSHtEzXom\\n\\n  ͘ɱ  * CΙPU —ŧʖϯ ɒϺĺAny ̭iȡn\\x7fȋϕɺte¾ger uϮϢ̊p to ǡ16.\\n\\n˵  ƒ  * Ô˸ƏGPUϾ —ˬ ɞAny i\\x98Ɇnʘɻteger Ȉίϟup to Ā\"8 pa5irwiseːɎ Υmodes Ɯ(\\x88Yeͻt̩iSRanʵk,Ö PairLogiˌtPaŹÁ̛ʀirwise andǺ\\n Ͽ ɮ̄ ͨļ ȭɝ Ìų QũuerƸyCʮro*ΰssǷEǣʶɶntro;pƴyϰ͓) anÄd uƲ˞µȽpΔϞ tΥȋǩo 1̜6 for Ȩal5l Ȍ̳oɆthe˺r loss ĿfunϻΥctcionʍsϣɸ.\\n   \\nleaɎrninȀķg\\u0383ő_ðratˊe\\x89̊:\\n  ĹƊu\\x84 $ ɮThe leaίƭƔrniαn;ˑg rate. Usµeɀd for rŶe͋dňʗuɁĘęǤcΩiȫˈǙngzɟ th\\u0379e gyʮradiNπenȂtʶŊ ΐstepΕÞƂč.\\n  º\\\\  If ύʢNo)ne theƼΤ vaţ̮luμeΓ isX dñe͊Ϡf\\\\ʳ͏ined aϑu1Ϥtoƨ\\u0382ma\\x8eticallyǚ ʢȽde͘peϊnding ˆłȚÃ˱oƀn\\x8f Ȃthe͞\\u03a2 numbȳer ofī ɱiterΌatioȍ̯ÆǼȌ®ns.²\\x81\\nloʂg˦6gμĊinȕgűû_̍leǉvķ^el:Ƈ\\n \\x98Ϊ  ĸ TheľĄƿşΓ lǰoæɉ˵gginιƼg l\\x83ʁevɩe͚l tŧo outpPĢˣut̞-ϰ tΪo ðs͗tdouΪt.«\\n Ƈ   Pos˅sible \"valuˬes:\\nǱ\\n s  Ś * Si̓leˇnt Ș—% Do ό\\u038b͑notƋ Ͽoʬƚuˌtpƻǒut anºy l˄\\u03a2ogging τinformatIio}β̟n tÂ˗ψ¼ʮo ˰ƥst̖ů¢do͌uÑ\\x7ftɅ͖.\\n\\nΌȈ:   « ˒6* οVǋ\\x8feǞrbose̷ʝ — OuǾtput bt͂he followȰing datvͤǧȍóa\\u0381 ƭ͑tƳ o sͲtdout:<\\n\\n Ü    \\x8eƺ ĭ  ̌* o pti;mized»ȼ metĉŮric\\nȲ\\n ōſ  }̹»ǭ   ˌ  * \\x98elaˍpǨsed tiÎmęęΫ of tɱòǀrain͈ğƿƪing\\n\\n      ˘ ˱ȴ * remaiuninόgȐ timϲe o̡fͧ train\\u038din͊ςg\\n\\n\\xa0   ɮ T*ǖ ˲ĝInfo ƃ— Outʊoput additʹĸɛionɜaƣlƈ ζȋinfor˪Ǉmationɍ\\x80 wand 7thχe núum̤ĸƘber of¥ \\x9fqȶŢǾʡtreŁżʏes.\\nǚ\\n     \\n    *˒ Debug —ʹͷǓ Outˁíť>͵jȪͅp̏Ŭut d\\x92ɠȓÁebuKgginΝg˭ inǍɬfoΙʷrm˷ʋatǀio~ʧʮn.Ǎ\\n×Áđ\\n     #QMLIENtwOYoiPGVR\\n  \\nˀl2̶_lµeaf_regμ:ǲ˙\\n  ʖ&  CoĂefficiǰent aŔt theţʭ LĊ2 regȡulΣȆa͚rizationÂ tedͭ͐Úrm of thƫe cAostķ fLunȕɺΕ*cưtion.\\nƱ͕͡  Ɓ ¾ ͗AnȜyɉǊ posʏitivʚe va{lue Ȯis ̏allowe̥dɤβ.\\nthÇreaϴdǭ_counΡĳĺϤƉ\\u03a2Èt:Ωƛ\\nɁ  Æʟ ͷ ͕T÷Ʌhe ύnumbϙer of ȿthreads Żtǻóo uˎUs͂e d¹uriπng -t̔ɄhƟe traʱiǥȻƲning.\\nŬ\\n  ϣ  *ļ Forǰ CPƾUϰ. Opt̅Ɓ¬imiáʧzesʙ t̩heˤ sŪpeeŗͿd of Qexˁœ\\xadŲecu|Ʒ̜Õtion.ǚ ǐTˊhi(sư parameter doeǬʛsnų\\'t amfǷföect resulΐts.\\n  Ȟ ͯ 8ͬ*Ȉ FΝorʍ GP\\x8fU.ϑ The gʫiveεn\\'ɡ ɠvalue ǳis useɦd f6orN .ƃ9reĦţaĬd˚i\\u0381nƿg tΖheǨ dahtɃɕa from the ϸhardŦ drițϤͫv\\x94ˁe ɔaɽnd dʰoeż\\x9bs\\n    \\nǦ    ɾ͑ Ɲ nĉo·t Ȁafƃʧˠ́fecǕtĶõ tȶh+ƶe trŌ͞ainiͰng.ť\\n  í ʧċʦǌʭƩ  ú Durɴʦũi͕ĹǼnj͞g the Łtrξainỉngʁ ϧo.n̊e maΝŘin̾ thϓĳrΓeķɔ>ad andØÊ on³âϯe tɨΠhreaŏωƊdɘ for ϷƛeġŤaǖch ˺GPUî aȈre uşsed.̞', 'CatBoostModelPerSegment is deprecated; will be deleted in etna==2.0. Use CatBoostPerSegmentModel instead.', 'Silent', \"Createȍū instancϾe of CatBoos˚tModelMultiSeˊgment with giv·eȳn para¢meters.Ř\\n\\n     \\n\\nPaͫ̍rameters\\n------¤----\\n    \\niterations:\\n\\n    The maximum numberƁ of trees thatȭ̈λ can be built whϵen solving\\n  \\n    machine learnȸi»ng Ǒproblems. When usĢing other͏ paramet̓ers that\\n    ̖lim°it theƔ number Ɯofɸ iteǫratiwons, t_he finżal6̚ numbeĭr of treeʵs\\n    mayØ bɧe leďsas Ntha̓n thʹe żnumber spec¾iǯfied ̍in this parameter\\x80˯.\\ndepth:\\n    Depth of the trœee. The range of supβʻported v˄alǃueςs Ûdepends\\n    ʺonɵ the ̗̚procesMsing unit typ˂e aΜndɉ the type of the selected loss fķunction:\\n\\nǫ    *Ϡ CPU — Any inε»teger up to̴ 16.\\n\\n    * GPU — Any inteǧge͘r uĭp tƈoɢ 8 pairwise modes (YetiRankÖ, PairLogitPaiʻrwise anĺd\\n      Quǰer×yCrossEntrǏopy) and up to 16 foÑr˓ all other loss Ͻfunctions}.\\nlearning_rƐate:\\n    Theª lear\\x9cning Árate. Used for redįucing ͙the gŧradőient step.\\n    IΙf\\x9b NoǩneŊ the value is defined automa̢tic3alęlyʛ depending on theŅ number ɾof iteratiɆons.\\nlogging_l͛evel:̿\\n    The logginϥg level toʜ outpuŶt to stdout.\\n    Possible values:\\n\\n   Ó * Silent — Do not output any logging informationǤģ to sotdout.\\n\\nƃ  <  *ʊ Verbose — Ofu͝tp̝ut ˢthe followŖing dataɹ to stdout:\\n\\n     \\n   \\n  ȅ      * optimized metric\\nǇ\\n\\n        *Ɠ elapsed timȾe of traininťg\\n     \\n\\n      ʌ  * remaiìn\\u0378ing time of Ϗtraining\\n\\n    * I#nfo — Ouοϐtpu̠t,Ǔ\\xa0 add\\x92itional informa̺tion and the ϭ̱number ofłˋ tree§s±.\\n\\n    * Debug — OutpuƜt debugging informųationή.\\n\\n   \\nl2_leaf_reg:\\n    Coeffiˀcient at the L2 ɼreguƏƣlarization term of the cost function.\\n    Any ptositive valƂue is Ɍallowed.ǡ\\n    \\nthread_Ícount:\\nľ   Į The number ofW threads to use during ¢ͅthe traűͥining̴.\\n     \\n\\n  \\n͢    * For CPĞU. Optimizes the sċpeedȊ of executʅion. ThiĻs parameter doesn't afɓfeŻct resulȭts.\\n    * For GPU. The given value \\u0380is u¹sed foŭr ΑǣreadiȌng ŜtheÏ data from the har̹d driveρ and does\\n  ͓    not affectˋ theČ trainihng.\\n ȴ   p  During tƑhe training one mai\\xa0n thread and ǘone thread̄ˢ fTor each ˼GPU are use̷d.\", 'CatBoostModelMultiSegment is deprecated; will be deleted in etna==2.0. Use CatBoostMultiSegmentModel instead.'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['Tesŋœt SüΡtaŇcʌkingEnsǨʄemĘǽblÛße bΝeĭhavior in caseϿ oęfə ̺:ʰĉiςnÚvaliýd pipŁȾelin%es numbĊer.ȿ', 'At least two pipelines are expected.', 'Check that S˰tackingEnsemble._gŊetç ƫhorizon works coňrrectly in caseMÜÿ of valid pipeɖlines list.\\x8fń', 'All the pipelines should have the same horizon.'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['dim', 'none', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['ˈ  ș   ȑĜ ̂', ' Õ      ¹  Éʏ ', 'regressor_1', '1', 'regressor_2', '1', 'regressor_1', '2', 'regressor_2', '2', 'greater_is_better,answer'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <13x10 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 13 stored elements in Compressed Sparse Row format>, 'ClassDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['No frequency information was provided, so inferred frequency .* will be used', 'ignore', 'statsmodels.tsa.base.tsa_model', 'ŹBase Řclass fμʹor adaãpțlɢʐt΄er˘s based on :py:̯Ŧclʳ·λass:`statsmoŴĥdϮelĔs.tsa.˫stateʓɭsp˝ace.sɢarimaxő.SARIMAX`.', 'Something went wrong, regressor_columns is None!', 'target', 'timestamp', 'SARIMAX model does not work with exogenous features (features unknown in future).\\n ', ' will be dropped', 'Regressors ', ' are too short for chosen horizon value.\\n Try lower horizon value, or drop this regressors.', 'Fitʚϋs ˶aÂ SAR8IMAX mɱɔo\\u0383dʸelĴʜ.́\\n\\nParaɹΜ͝ÍmetǨer˞s\\n--m-˾ϡ---ċ----\\ndf:\\n    Features d˕Ǧatafraȕmͣe\\nŭregČǃressɿorsɡ:\\n\"   Ț ƑLi̧st of th\\u0378e Ȳºco(luˢmn˱gs ̖ȷ˰wiƫ˳th regýressors\\n\\nReƒtɔurnsϵ\\nZ-Z--̒----Š\\n:\\n ͊ Χ  Fitɇted m4˂oÖdŏeͭl', 'target', 'timestamp', \"Can't determine frequency of a given dataframe\", 'timestamp', '_SARIMAXBaseAdapter', 'timestamp', 'category', 'Categorical columns ', ' can not been converted to int.\\n Try to encode this columns manually.', 'CoΏmpûutΉeɶŝɠ preʶ|dictŜioȪns Ύ¶frͻȶoƨƉmăÓ a ̃S͇ŚΝɴARIæMǤAX moW͟˙dĶeųl ͳϽand ʐusŀe tr͒_Iue in-sƀJaɾÕǆmŪĬpU~leɦî daÍvta a\\x80s lʲagsưʨ˭ izƍf p̬œosͨs͖D͋ΤiϗÁϞĊ\\x89bleĕ/.\\nΤˢſĢ\\nParĭame˓te±rϩŹs\\n--ƓǠ-Þ--Ĩ--ϫ-Ą--ʯ\\ndǏʉŬf:\\n Ϻ ο 3˺ƃϴ Featurʠe|sώÚƦĿŀ datyaÚfσɦramTe\\npĴreϩd͵icĚt\\xa0i˝Ʈôín_Ϸintervalͼ:\\nǒ ǉƥ  Ė bIfά Trđuıe rʢ˖ß\\u0383et͝uǬƅrns prŢŦəeądi!ctÓƲio˯n \\x93iȩnνtŬeȫrvaέ̋ϸl forɕ foƼĕreΞcast\\nqŦąǅuϴ͆anĚΆ̼ti͵les:ˎ\\nƖ  Ƹ ? LéƖ8veɃls o͎ǤfŊ͛ń\\x90ƹȄ \\x95prepdic\\u038bȤĘtiŻóoϡnɆÔ͑ ɰdiHʰstribu̵ti˞ʅon\\nʟ\\nʡ͡RetĮʹɬuƺrn˓sɮʘ\\nȤƮ-ϒÉ---ό;-ͽȼ-ǧ-\\n:\\nƓ1\\x97    Dataĝɬ¡FĖr¹amUeǡ̒Ň\\x83 ʾwiɔthˍϛ pƫ̈redσiȿctǛioOnĒͼDǂs\\x89β', '3Get þʊ:VĸSpy:c̭lass:`statĒsmʘoÕd\\u0378\\x9ceǙ\\x83lsȡ].Ͳtsa.staϵt9e͇ƶƈ˘Ηs̾pace.sarimȹaƉxʀǵ.SAÜǫɥRňȆIʸMAXReʈsultɎËsǞ¯\\x8cWŁrappevr`ȥ thatȬ iƎˮs used ins˳i̳ȧdȥ͌eʼͮÎ Reˆtnǐa cŚ˹laÕss.\\n\\nRetuğrnˬsʻ\\n-¹.ˌ------\\n:\\nʮ\"  Ǫ ʃÜIŷnternaϞl͟ moǢdūel¿', 'MƟakeŊ predictiȜͯonȜs taȷȹking into ađccount `\\x93`dyµnamicı`` pͣƮar˾a÷ˮmǹ£eter.', 'Model is not fitted! Fit the model before calling predict method!', 'timestamp', 'timestamp', 'mean', 'mean_', '.4g', 'mean', 'mean', 'target', 'mean', 'Compuĩte Ĉau΄ɬtoregressȪɛive ɼ°p̺\\x88Ϗrediction͵s fr̚om ̷aÞ SARIMÐAXȰ m\\u038bodel.\\n\\nÇParameRͻteϽǼrs\\n-̾Σ---------\\ndf:\\n    F˪eatˇurαe̯ȳs datafȚʽrameƚ\\npredictiʕΪon̙°ŭ_Ώinterϖval:\\n   Ϭ  If̞ TruƄe returbns pr(edictioƘn iƾntervǀal Φȯfor forecasφɧt\\nquantiles:\\n ĳ Ő  ̘LeɤvelsΝ ofɐ ʃprediction disνtrib͞uʾtion\\nɭ\\nΘȂRetuɤrns\\n-----İ--\\n:\\n    DataFrame with pǑ̏rediʛctȷions', 'Ȯɦ ˴  ͠Ϻ˭     ʤ̕ǒ\\x9d Ͳ      ð  ̒ Ȧȗ ș', 'c', 'none', 'c', 'none', 'ΦIdͷnit SARIŭƙǟMϪȷAXįŻ moțȮŰdel wϡ̵iÒth¶̗Ι ˰½gïivʎenɩ ˘pŎara½ɘɕms.\\nƣ\\nĖPaƎrametders̽\\n\\x95)͆---\\x9d-\\x91ƴ˂ą--ő----°\\nŻoPrʏdeĹrĭ̪ͤ:̤\\n \\u0381˙  ̻ The (p,d,q) oƤǐrderǝơ ̖ofʂ the mΑİoǙȭde\\u0382l foHr ćÀthˈeϵ͚ nűÒuǋȆmbiɚȩer o˫fë AĹRȦ ʡà·pȤa̯ʯraǰϸímeteõrs,ʞ\\nͬ˴  ɤ  d̝4ifϠ(fȊ˗eȥrʂeŒȮɴnc\\x9f\\x95Ϻes,ͨ aĴ˄³Č̿ndϝȆ ͈μMǢA ȟpɷɂaɝraÆmƘ̺et\\x99erˁs.` `d` musńΗt\\u0381 bȔe axn̾ňʒ Ŋ̙ȍȾintežɞƈgȪeηrͱ\\nɽà   Ů ǉinΦdicatiäng t͈Ąhe ǒǩink͓teg̓rʛɺa¡tͣ\\xa0ϻȡioÖΨnŸ oȌr˷ÿ͠deϔrĜ ěɯof ̃the proc½eßss, wʐhil̰e͗CǗÚ\\n ɭĸ AŗǕ ͕ ȏ`ͨp`˨ anʏſöƲd\\x7f `Ȼq` mayť eϹiǚther ȅbe ǚŊa8êΡn ȍÄiƼ͚jnİtŸ\\xadegͭΠŏΠ̅ęrs iƊȤÉϥndɱica̡t\\x9eingɶ tί˶he \\x95ΗAșŋYRe ͏an͐d MA\\nʲ \\x99  ɪ or\\u038bd9eçrƤs (sεÌoΫ͠ ƴthƳȋËat àllÐ laŚƔϐgs ŧğ̶upʍ\\u038dȭ toǭ thƧ\\x7foʅĕs!ƕͰǀeόĶƯͭ oʑrdƄʹersȀ Ͻarǃe͙ ͳ̥ǻinǳclud1ed˕ɟ) or ǮelʽǏsǽe\\n̅ʹ Έ  ͪ ɸiter\\x9daʁbleşɯƁ geivμiİnʱg sypecifiω͕c ɌʋARϛȀ anǌd /ǲ ̆orǫ M+ƙŻA%ɒ l̐́aGįgs to ƀi̫ħnȈλcċlΙɼuȆde. τDeO˫fɞauƷlt iǐsʽ\\nŐ   «ǅ anǀ āAȋǑéR͆͵͵(1)ȋ̅ m̺od̪˳Ķeϻl: (1̋,ď0,0ͳ).\\ns͇eʗasϐÊ\\u0380onˣa\\'lğ_o¼̹rdue\"r͞:\\n    0Ζ̋TĿhe (P\\x83̎,̂Dʡ̐ȹ˱șʮšϵ,ʺQͨ;,sLĦ̦) ˱ŝorʭdùerƜķ of͵ʗ tǖhe seaʉķþs\\x85onÐâŀl\\x9b Ƶcompͼãoĸ\\x80Œnent of HtheÂȱ .ˍmodel˳´ ˝fɹoƣr ψȣtµhßeʫ\\n  PΣǘ@ń  AȴR ^pƐāħρarĺ̨ǺÞamĘeterPsÓ, diwáf¯ϙ̀\\x85fƒeȜreÂȄ͂ĩnçƌɴeǥ\\x9eM̻s,Ơ ;MAȏǟʿ̢ǎüŰġΆ pƬaΙ\\x9arameterťƜŅs, and perσǪŐio\\x82dicityȨ̑ǳͼ͐ȡ.\\nͧʂǅvÂ ¿\\u038d  íů J`ĜΓɯD` ɹmustĹ țbe ϯa̫nU i\\u0379n=Ǎteǅge̯r ind̂Ĭicatinǖg ̥tϳhe iİn\\x99PtɆĕeίeʹgrat2ϯioκn GoǍrşè͌der of ƵËtŠhe όprocessĺ,ϫ\\n´   ̢ ϊ«w͝ǫh˶Νileƣ =`͌P`͢ƢȻƫĢŪ and Ŝ`Qþ`ġʐĵZ may eD#i͈ͷGtj;herɪ̏ bǴϮeĽ\\x90 Ʊanώǰ inteĄgþers Ƃjind°tϔiȈcaǨɡϋt¯iëng tǉAhũe AR and MʹɕA\\nϋ   ɠ[ oʸϳʪr¡´deȞǩrįsU (s̙o thaͨtH ˭Μɀ·al̚l laȴĲgsƀŐ up ÷tʏoʦ ƻthʵĔƽoάseü\\x94 ȂʄoƑǩrderɯƜͺϡs, are ínƓ\\x84cˌl̰Rudžed̡) ́or \\u038bels̈e\\nǹ    iǡterƳabΗles ɾgɁȞiœvinʔg specific ˈɃARsǅ¢ aėȘndǽ /Ű͘ oɲr 7MĈeAĕ ?@lagǕřs toƨ Ɂ̔includeŌ.ϕʇ `sɊ`ʂ iƤ¨sΣĿŁ ĵan\\n ̭   iɀnΗStIŤ̀e)gƶģρɐŊȇer giv̧ingǳˋǿϛ ɂtϷJɠhe pͥe̽ri˜Áųod\\xa0icity (nuǘ̹mb¸er /ƿ\\x8eofϋ peϑriojdžsΗ\\x89ʾŻ inɯȲǦ sʱeρƣ˭ǎsʏon),ƪ loϿfEt\\u0378en it\\n  ;  isʊ 4ς Úfo˼rΤ qůƦĻ¯arĿ͙ΰtƔϊ]ͰeΞωτɦɋȳrlŊy dϩÈabta ʜČÝ¾ɯϥȸor 1Ή2 f;oxr± moϛçȽĜnthly data.Ǣ̢ De±ΝÞfŗaxult ȫiȤɝΚs ͻŇnoŝ ϑseϷasonaͅl̚ЀȓϵΜ\\n8 ̴ ˒ / efèfñec̩t.nĄ\\nˤtľr\\u0380enũÉȗǌļd:ŭ\\n   ŋ Pɬaram\\x92ʇ°Òƻeter co˵cntrolʪylinϫg t϶ĒœhɬʾeϋǾ de_\\u0379t˓ermiøΩnis\\x9aΦ6Σţi0c trend\\x89 ÍpolɌΘyδṉomỉaF̹͑Ϝ˩lϯ\\x87 :matȽh͆:`GAϱ(ǒt)`.ϔ\\nϫȭϺ    ͻCaǦnnʳ bƕe s̃]4pƑ͵̿eòǸʢciǺfied ɗas ºa sǁtȅÄįri\\x9aŧng wƛhere š\\'cö\\'Ʃ ɮiΛndŐicʍatesƼƝ͌ǐˁ ˕a conȹ͊ʷĦύϩsɷtaΙntϝP (i.ŷe. ƽaç̤\\nƩƨ    ǂØdŕegreeˡʰ ĠϮΙzer̠o ǼcomponŦƛeʺnυŁʇt ɴŠƿofʶ tńhŜe trâÍūηeĸnd ϗżpoϽq͗lynoAΏmilal)Ͻ͍, \\'Ɩ̐t̿\\'? iʗndicates͒v ɄˀǍǖaÙ\\u0378úě\\nΙŤİ ¾¦ ʶ ˼ˌ ´liţǧ!nečar trЀδǥeΎÎϕnd žwiẗh ɹtϊψime, aŠźǕnšd ʦ\\'ĸŉct\\' űiɁs SĄb͜oth. Can ªʬŨals\\x92o bðȀe spƳϽe˓Āʮˢʩĺ´QcɇͯiŞfiŔedɯ =a\\x92sƻ ˕Ϲa͏ϊ¨n\\nɵ  ɯ  itςšϪeǾġra̱bl̹e deưďfƵiningª Ż̷theʾ nƢ͢ʺðȮonΎƚϝ-̤ȟzş̌eƗɚro p\\x86Ɉȴoʏ˱lynΊȝoŃmʢiȞ$alȝ ǶeŒĢ̬xŅponent̗ʵΝä́s tˈo ǅƻincludeÂϝ̭,^ ùʬϻinƧ\\n  ȵ  ³iɵϘϔƀRncr̊ΣeaΧsiǨn\\xadg£ȵ̞ ÔΪorder.Ɲʟ ͈7For exˢaČˢƮmpl̄e, `ϲ[1,ϐ1Ɩɓ,ć0˥,ȏČ¼2ĘƵ1]$`ŧ ÙdĆ̱\\u0383̒ϼeȏ¼nϝoͻt7ͣes\\n ϯ˲ϴ\\u0381   :ȟ[math\\u0382Ŗ:`Ɔɻa +Ŧ bΣöt̝ + ̗ct\\x8a^3`. D̑eƼfaultͦ is t̹äo ǡńoUΛȃt inIŇΡ̎cluϽde aǡ ϰtˎrHend Ķ͑ŵcomͱ̝ṕĠoČs̾nȊϒeƊÁnt͍.ɲɱʮƠģπ\\nm͇ǂeasuƧrRem˷ƣʮťeʞntɼγ_Ŋeɒr˟ror:\\n͝ ÷\\xadǼ [  2˯ŊWheǶΩtheˆr opɫΔrB̷Ϻ/bc noÀŏt to asʪsͻumţȤe tΛhe? enľǦĉɌduogeno5usƜŔ obȍͥsϢͥĪeōΜɝrv/ȆƾaĊtio\\x9ensv `ʙɾŜ`endŃǗog`ʞƞġ were7\\n Ǔ ǌ¾ϟ  m̘ŭe\\x7fasu̧Ùȼɽȫred ÀwΠithΖ eǡr̢ror. ɒDeƺfa̻ultďγĞ i˸ͦsʊϘ Fa͞lse.ǃ\\ntimϬe_var˗yɏing_reɏg͟resĻsƝǩiƃoÔ1n:\\n    οUseʆÿʌ\\x97ǭƀǢǟüdΌ ϿȌwÂɤheƑn an expluanat˩ofr\\x82̮y Ƶɨź˙variȕableʴs, `exö́ȑcg`, ɠnare prov̷ided} prȈovŗideɵĮd\\nͺ   Ɏπɦ to ȧĢ̷seΛleŦctu\\'ɼϕ ̷w͞ĵ|ė¢͘he×ther oʾ̟Ír noʊƨʂɫ˞̲t coK͉effiGʴcientΛsό onʸ ƾtḩe exoǾοgBeʏνnλoʿus rΆx̷egǭrĖessoϭHrǝ±s āareË\\nɅƔ  \\x97  al\\x82l˯owed ́to\\x8fη\\u0382ɂ var1y overκ ȸtime.ɮ ɷƎJ̤DAef˲ault iɋ&ʁȦȞs Falsõeć.\\nmǘΚlͽe_reʰɋgͣ]Τression:\\n̵    Wh}ǠethāȩǨer orı no˅t˃ ɗ˿to ͜usĕĈe˘ʱ esċǱtʜi\\x9bmațtʣɍĩe̓ƯȞ Ư\\u038dɃthėɍȢ˻͉eʫʴ ɧȼr̅egȍΛresƊsÙĮȈion coʾʐeffiΣʹæc\\x98ieŸnÀʓts Ęfo˦r t\\x81ϪȀhe\\nɂ͜ ǁʝ͛ǠɎ̤ ŀΑp  ͭexoȀgeΔđn˫o\\x8auʪs ɑvø̾arʶȌiablâϐeŸɧs ƻəas˽̖ °ïpaÆ¹rȤt ϲoǵĺķf̂ ma˃ʅxiźƏmum CělikeƅX}ɓșMlihoɧod esǅ˾ti͓ʅmatiśoȭʊn oͳrǼ ̳ƣthr¯Ɂ»olugˤǮh\\n\" ϕĈ  ɑ ì͙ǨƞtűʓʔhÙe KèaɅŔlǈman \\x87fϟiltɶǩǊerØ͌ ʖ\\x97ī(i.e. ̣rǴecursŔφidvĨĴϣeä 9ĻleÚaʤst sqƃ͝$uļłϓaǆres). ɻIΙȧƳf\\nˉ  Ä  üÍ`time_ǕvarWϮyingʁK_̭̟regresļÙåsØɊiJoΫn̗`Č Ʌi0s¦ ýʂTrŧʊ«ueɦŏǽī, xtIhɓÄi!sɴ˨ m͚ŎϏɶïu\\x81ŭƜʒɨs̶t ˟bòe͞ set t˃o Fa_lsZe. D˥efaCul\\x96t\\n    iͮŐs TrήĚue.\\nʗsiQmφðple_dΎiȫf¨feϏrɝˤ8eŴncǆʧinΪg:\\n Ĭ ɥIĸ  Whethģxɕerϧ˖Ϲ or ƨnot§ to uĮ\\xadseȳē\\x8b ˯wøɽpaɜrtia̳ǭ̬̚lɳȫly ˷cožnĀditi÷ǅonalǸ̎\\u0381 ̚maxiϻmuȯmϷʙƿ ĥli{kelih8Ɏ4oʉͩođd˻\\n ʻɬ  ˮίȅ ŧ̧«eûstǛi\"maƞti2oŶn. Ifƭ TruƑeǌ,ɥ˙ʰ ̄diffúereʤnɝcinϰ˜g̈ iosŬƵʤ\\u0381 ΧperfÞorm˼edʢ ǂpriŵoɟŗȜ Ģʉtoʥ ʽesǊȆtim˹ƹaȩtiĀű˦oùn,\\nΦ}ɕ ϮƇ   whŊ/ʶĺich diˆscaßr«ds Ϯt\\x98heϜɭö fɟirs\\x97Ϥt :mƽa×t§hÝ:Y`s DȺĴ ͻ+ŁÎ dĄ̊` iˮāΏnŨǣȫiÁͩti˰ũal ̓romΫws ĘbȗǲÝ˟t ,̒ęʺreˬĚɼs&ulļtŪĊsß i̋n a\\n  γ ȇȬN§ϨÿƏɰ ɣϩs&amallǘãȷeǐr QƒŲ͘ĥ͙͆sa\\x88ȐtͼaŽΗteɃ-spÌaceű forŴϵmulΑaǏtŵê̲ioθ>n.̀ USe̩ʌŪeŗ the NoteˁŃs§Ħ sectƌionŶƺ ΨfoƉr Ô͏ƴimportaΧ\\x9aąn̜͗t\\n˃w Κ   deØtaibǵɡls Ϡaboˍut ȂiͳnteƆʟɜrϨpreʇt̜ƿȮɲȿ̨i©ng ërʰesultsɗŧ wι̮hen thýis o\\x8epŘti\\x7fĄʶon\\' is used. ̍ϐIĤϠˆfΎΪ FaĀls«ƴ͛ŌeƬ˵,\\n  Ƨ ˸ Șǖt̶hˡe faȥʍullǯ īűƽȧ̂S̆AɸRɒξ̈́οIM\\x82uAŻXƨ mloίdel is Ϧpuṫ iƜnΧÈΜĕɫ staǕt®ĄŘåeη-ǹspaνɗc5e̵ ̼fʹ˙orȐmϜʛ ĈϮso Ϩtha÷t Ȼđ/aɃXlƔ͑ɹl\\n̚ Ű̮ʄȝ ú̀̽  ƐÇǃdat˴ǨaŨp˻oͼŋʿÔinÍtsȃ ;ÛcĨan îbe uʴɽƹ¨sed in eĂͫɘstȭiɓmat˘ϝig̊Éǈon.vDK DŤe˔faÉ͞ˠuʶlt ŀips ǧFəÐaʝls¥e.\\nϫenơfo̩rμce_\\x8dsǦta¨tÈɮ\\u03a2ΰƒŕiËonaƦCrʈ͗ityǑƏɵ:ŧ\\n    Wheth>eĩr o¥r no¤tƊ ͱtɔȫo ˾ǽtöěƺƇĞrͽ¯a/n̈sfoʍrmΆſ the˿ ARΰ pǏaraƪ̶me6̾terʇs ŏto̍ Ëe͔nfoƯξrͶcĠǒeǂ statiƱonarity\\\\\\n ǣě8  K in tʓh\\x92e ǡæɱπaut˹oÙȽrƈ;e2Ǘαgres˂sɔi(veƈ ǧŒcŊomponeźMnt ȧ}oɏļf th7eρ ȼJ̫mƤʇoμɕƌdʂǩel. DeϷfasȫulƼt is TrueŇ.\\nenŖȱf\\x94oƄrc±eɒϻɞ_inHveǂrtibɂβ˸ilȆity̅:\\\\\\n   ) Wheƽ/th˥Ƹer͉ or noƫtǧ tɑo ̓\\u0383ƳʟtXçran½sform ɥϊtƗhe MȊA˅ ɐpΌaUrͲa͆>͚̆mÈetersʳ tĉϮ(ɑo ϥeɞnfǻo˄Ƒrce iƨnveüyrtiήbilitƀ¯ĥ-Đy\\nζʈ   ǈ ̓in the ěmoƒving aveṟ̭ageχ coΑmpƨo@ƶnʾeʔʸǾnƐts ȉˎof thʞťe \\x9aȉmmo{dȮYeοϟlʁ.í D͘Ƀefault ̆˅Qȣ½is)̐ ΣTrƶ\\x95əue.\\nhCamiɗlteɺon_ʊ-rĘɲŉWͫepresentatiͿoǔŕ\\u03a2n̽:Ť\\n  Ɩ ƪʢ ǥͿW̗ƵɲhŜ ethˬe˿rÏ \\\\ɺɫoźrj\\x9c Ϳn̷oŮt ˅Ļtɖµo u=seɍ tǸhe Haɻ̍mğiltǿƃö́\\x83n ŰrΧepr͊άeseÐntßati<Ǘoųn of aÞÙn A̰̲RMȞ˪A ãɨp̤roƆcesȭs\\n    ŷ(iμf Tǅ̠ȱΎruü\\x97e) K¶or\\x86 ǋœthe ƵHarveyR Œrʠ̝eεʹƔDϫ\\x8bpre\\u0383sƊϼeǲntation (Ĉif ŴǚFahlsιe̅uG̊˜)ú. DefaŮu̎ltϩɍȬɅϧ iĪͥ\\x9fs Ĉ Fǟ͝aΘl\\\\sȢe.\\nc\\x8fĳƟoĦÂήncenŔtrƙaϽteð_sŨμˑͳcňaČˏϡle:ā\\n   ʫϡ Ϻͣ˧WhețtŠŊcÊ͉îƒhȓ͜£Ϯƀer or\\x9f Ïɀnot ΒɔtoƔͭ coφnƆcϨ*Ǒeϕn\\x9aÊʰ˖^t̏ϱra+tϽe] tΒͣhe s̨calέe (varίʣŧianceϣ τof the er-rǝoÇr ZɋtÇŖ˫erƯm)\\n ũʼ ʃ ǣɊɺ\\x88 GoSutϑ oåfŁɎ̤ ʔϰυthǽe ªlikeũlΧ̾iƏʽhoodΜ.Ϊ TęhiƓs ̉reΈϠʔȢducʹes ȏthe nuͦſɮmber oūΓªʁ̞f ãpͽarametεȩers estimɍǯatêed\\n§ Ȋ   Ĭͻb̜ϰyθŁ j̝maximΰŞu˫m liƄʻk\\x85ö˳elih͙ood byɟϓͭ oˉnȏĳe, ùbut» Ʀ˱s͇tμ˯andι˟a6rǆdϵϮ ˈȸCɧ®Ǘerm7rgorȰsɒ wiƀll\\x8eʝ ɥth͒en noȣtÙξ\\nɇ ȟ   be avka¿ilable Ϟfor the scɟκaĄl\\x96e parûE͛ŨĤaÓmůeƥ̟tȕerj.B̹\\ntr^-es\\x93nd_ɖoffØse̷t͎Êƫ:\\n    ̧Tʊheͅȩ ɨoɪÊfτǭfϺ͊set̉ Ǹąƍ̋Ⱥ\\x8aat Řήwǹhiήʾcɨh˔ to ̈ʨstar\\x94tǿ ÿtiÆƝ΄me tr˲end ɍva«ȲlQu\\x9a˂eķΞsI˅Ìɧ. DƔeγfͧaʠuûlt iǬsƼ 1, ŵξsoʖ\\x89 t6ʇhat\\n   Ȉ if `ɹǡǲt̳ͽreĀnʰ˓dč=ǀ\\'tø\\'` thȩͳe ĻʐtreÞǅΎĞΖn̻ɬd ǃǅ˙iQȶVs ğơe\\u03a2qu͙al\\x90ϼɼ tΣϧo˞ɡι 1ʈ, 2,i .{L.Į˺.ˍ, nɫobÖs͠.œ ɇTĀypiċRϳʢ=al͵ly̟ Ͻis oônȣ»ly\\n Úŵ ā ĺȮ ɫsȓʀ˶et ǕÀwÃhƛen tɇh̅ ƅe mɔoɫd̦ȓel createˮϳ{Ŭd ͚bΎșyʥ ̸ͥexžtʁendi˒nëgȏ aƤV previouƺ¯\\xa0s Ô¡dŧĻ̀atǎaseĈåt.\\nʣżu\\x90ǿseć_όexaϭ͉ctΜ\"_˄͂ɠϙĄÝ\\u0379diÙ\\x9cǉϨfffuse:́˪Ⱥð\\n    WÁhʭɇe\\x7fther Žor notǎ ǐȵtoÄǧ uˊse exϩa͕ct  ǥdif<ǑfͲȇʻαuse \\x95initiɞŦalĎǃΉ͋iɚzagÜϿtioЀnǳ forΨ non-˚sÚŋÛtatioTͧÓnaȉry\\n  ŃˎŔ  ȃĆ̂statesƿ. DeĨǐ~ʇ¯f˥aultϿ ˭χɀiǵs FcŬaʌl̯se ƶɣΆϳǙ̠(iĐn w˽hǀiʹήc̷Ƀ̸h© cƜasȬe aȭppȼɠœro͜ϫ-̓Ȅxi˽maέteČƈι ͣdiőϖfϖfȍuüīse\\nʥ υ  ¥Ν i\\x92nitiwιħʞa˻ǸlɅǶ̩́½ǐz\\x82Ûa̍˳ȬteiäoɄn iϰs usʯŜedƙɒ).\\n\\x85ȘdateÁs:\\nǤϟʎ  ̬  ͞If ̭no in\\x84d͵e˲x iˎϞs ĉ\\x98gØλ͙Ƭʲʰ\\x8bƠiven by `endog`pƱ ̾Ěorˡˎ `eŕϥϗxoāœg»`, ƀanĲ arȪra]y-liȊkΥe o͂ϼ3̽bject ΥoȄŖf˔˔Ţ\\nØ  ɨ  Z˞date̙°ǆtʣ̩iɶˮme oəbδʞjeNctɐs c˥̭an ̲beʸ` pŁΌϰɔΏ̮ǊrήϣovǑǸide͂dȋZ.ɜͷ̗Ǣ;\\nfrÞWɻeϦɘq:\\n  ƃ  If no ǱindƊeϰjx Χiʁsʲ givenǷ bŤČčyΙ `en1doŹgĀ`° ~or `eïxog`, ͇σDĝthǇeő \\u0382f\\xad\\u0380reźqu˶en\\x9acyɽʔ͒ƽĬ of Òtŵͤhĸe\\nĭ ǅ ό  tĶɔiΥme-ͪhsžͯeǚrȁies _Ƚmay beǨ ¸ƴsŻˁpeȧƦcjiǍιifșiƛed herʺe as a Pȼand-as oƸffset ͽo>#¹r ̼Ûoffset s´triÑ˫ng.\\nɮmiƃs¡Íʨsɔȷ̀έingɼ:ϣɻł\\nυ Ώ   Ava͛ila͝bl̤ØeǚϾϹ$ opϣËtiͯons are¨ \\'Țn\\x7fone\\'ɒ\\x82,͏ʳȿƹ \\'d̲roǰp=ɖIʥ\\',ĲΨ aεƚnd \\'ra͕iƀƪƜse\\'. ǚIɸf \\'nƷo\\x86ne\\'©, nÃȼo ̉\\u0381ǵϓn̈́aɉńǐ̮nͩʹǾ<\\n5\\u0381    cϾh^eȩġ³cking˳ is doneʄ.͕ I˲f \\'drΏoǉͧpĞf\\'˺Ȣϓ, a̿Ćɬn×yɕ o¯bseƻrɾvatĲiˋwons wŉith ϞnaķſnĘsǎ× ̹ʅa×̜r ȩϹeƄǑ ¯ÌdʶŶϹόrοop4pǎe\\xadd.ūǋʓ\\nǚ\\x95Ì ɱ   ŘȧIf ǂ\\'ΉraUis7e¡\\', an Ēeȩ͛rrņ1ΔoĲÿrŀ is réaisͮOƽƨfed5Ϡɋƞ.VˋȚ Defːauͪl\\x97t iàs \\'¨non̔ȝ\\u0383e\\'.ʦ\\x83\\n͘\"vali͟ŅdƎƱɇ\\x87ateʗͥt_sKpeǰc?Uifϡicaϯǫ͓ÐtionǑȱɮǭù:ϴ\\n   K ˍIȲf ůTruyȾɑe, ͉Ȉv̘aĝliwdƴa\\x94Ĩti͈̯on o\\u038bf Ň˷h*yperϛpɭaǏʙraδțˤ½ȽmƈeƵterɶ͒sϳ ˭ȗisǲť perf\\xa0or¯ɇϿme¿dΎ.'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['            Ä   ', '             ˰  ', '̏ ', \"Can't preload datasets with sample quality available.\", 'ͭ   ʡ  ɉÆ  ŐL ̋ '], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Pipelineͼ that make regres\\u0378si-ve models auŒtorüegresǃsivešë.\\n\\nɿExampleʹs\\n-ɿ-------\\n>>> from etna.daΙtaseʞȀtsȑ imp˚ort gen\\x8eerate_periˎodic_df\\n>¥>> from et̳Ŝna.dataěsets iɋmport TSDatưaset\\n˭>˂>> ıfrom etna.mod˵eΒǀlȊs import ĮɈʛ;LinearPe¶rSegmșentModel\\n>>> from etna.traǟnsfƼorɫēms import LagTransfɳormǭ\\n>>> classiľ˖cĝ_ˈdf = geneʺrate_perioÍdic_df(\\n..ȷǚ.     perioɩdsʿ=100,ǅķ\\n.̀.. F  ̸  start_time=ɇ\"2020-0ȬJ1-0ǹ1\",Ȧ̯˰\\n...     ϲn_seĸgΠmŐents=4,\\n... ˮ   Ĩ periọd͒=7,\\n.ĉ\\u038b..͙     sig˪ma=3\\n͕... )\\n>ć>> df = TSDaĘtaset.to_d8ataset(dǉf=classiΝc_df)ȗ\\nʿ>Ǜ>>ȼ ts = TSDataset(df, Ǭfreq=È\"D\")\\n>>> horʼizonȍ = ƄŠ7\\n>Ȏ>δ> tra\\x80nsforms = ǚ[Ɖτ\\nɃ... ŝ    La̰gTransɌform(͈ɿ(in_column=Ν\"target\", ȤlaƀgsΥǋ=list(raĪnge(1, horiūzon+1)))\\n... ǎ]\\n>>> model = LinearPerȘeȌ̴gmentModel()\\n>>> pČiƣϔpeline ū= AutoRegressivePi̾Ɛpeline(moŁdƯe¥ȴl, horiz̢Äon, transf»oIɯrms, step=1)ɫ\\n>>Φ> _ = pipel˿ihneȎ.fit(ts=ts)\\n>>> foreϞcƓast = piÊpe·line.ȓfo\\\\Ȫrecast()\\n>>> pd.optio¬ns˸.display.float_format = \\'{:,.2f}\\'.fƿo©rmat,\\n>>> forecaȟsǴt[:, :, \"tarĔget\"]\\ns˯egmfent  <  KsʲegmentŎ_0̟ s˚egmentǵ_1 segment_2 s\\x85egment_3\\nLfeaǽture  ˯˜ς     targe̱t  ͉ ʍʛ taůrge\\x89tδ    tďaũrIgeĿt    tarόgûet\\ntimestadmp\\n2020-Ĭ˼04-10      9.00      9.00     ǯ 4.00      6.00\\nř20Ő^20-υ04-1˷1     ϫ 5.00      2.+ϵz00    ϊ  7.00      9.00\\n202̱0-04-12      0.00˓     ż 4.͟00     ʔ 7.0Ɉ0      9.00\\n20ƹ20-04-13      0.0λ0      5ª.00 ¹Ů     9.ɢX00Ϛ<      7.00\\n202ȵ0-04-14  ϳ    1.̬00  ƶ    2Ⱦ.00      1.00  ú ɡ   6.00\\n20|ϠǙ20-04-15  ʦC  Ɠ  5.00      7.00   ˊ ͏  4.00  è    7.00\\n2020-04-16   ˁ ̺  ƈ8.00    Ĺ  6.00      2.00     đ ̶0.00̻', 'F͟˕ǚit the AŻutǽĦ͎åƐǝɄoR\\x90\\xa0egressǧivePipelinϳe.ϧ\\n¤ďř\\nFitˁ aʠnd apply űgǛϒ˔cȻivʿen Țtļɐrηʩan˔sŌfo˜rƄm<7s to ȗthΪe ̯ϙö.ƈdaÒtΓa, th̄eƌn ɛΫ#fɤit thŞe moȬde̓î\\x95Ǡl on žtϟhľe transfʸoJũȚrmedİ ƨΪdatΘa.\\nʣï\\nP̮οĘaramΞe͈tȣ϶ɶȇ͉er@\\x9asʼ\\nǢ\\x8c-----è-͵-˩---\\nʦ̮tsɏ:\\n    DatasetŏÛóǛ Ȉw\\x98ithϚ ľtimeÉs*Ûǩer\\x82iΫeªėƊsä dϏ͔Ʋata\\n\\xa0\\nŸRȵDeturnu\\x86sÜ\\n-------Ǫ\\n:\\nÛ Π ǂ ƭ FitŘΊ8te̫dƖ Á\\x86PiʨpeliŕͲnȿǰe insÂȁtÑanƨcĐĲe', 'AutoRegressivePipeline', 'Something went wrong, ts is None!', \"TSDataset freq can't be inferred\", 'ignore', 'You probably set wrong freq.', 'ignore', 'AutoRegressivePipeline is not fitted! Fit the AutoRegressivePipeline before calling forecast method.', 'target', 'right', 'timestamp'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['3 Ǘ   \\x82   ϗ', 'ȨAǲrgΜs̎:\\n Ϩ· Ɩ  im̓g : Pɇ<ILÇ iŏmațge țǨof sȦize (\\x81šC,ŀ H͛, W).\\nđRǭetuɀrˆns:Ƚΐ\\n    PIL ĩimagȉeγ: IƀmagȇʌeŦ ςwΫithʮ ͜ƫngJ̷ǒd_hoƅϼles oÖf dϺimenŘs\\u0380\\x87ionȭǚ lŁȁeængth x̐δ͢ lƽ.ğengtʉh˻ cΧut ūout ofƦ iΡt.'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <16x16 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 16 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['    \\x91ϰ    ʈ ', 'timestamp', '2020-01-01', 'target', 'segment', 'segment_1', 'timestamp', '2020-01-01', 'target', 'segment', 'segment_1', '    ͑æ    Á   Ɋɝ ', 'timestamp', '2020-01-01', 'target', 'segment', 'segment_1', '       Q   ƹ ', 'target', 'segment_1', 'target', 'class_name,out_column', 'test_max', 'test_min', 'test_median', 'test_mean', 'test_std', 'test_mad', 'test_min_max_diff', 'test_sum', 'target', 'segment_1', 'target', 'out_column', 'test_q', 'target', 'result', 'expected', 'expected', 'segment_1', 'result', 'window,seasonality,alpha,periods,fill_na,expected', 'target', 'result', 'expected', 'expected', 'segment_1', 'result', 'window,seasonality,periods,fill_na,expected', 'target', 'result', 'expected', 'expected', 'segment_1', 'result', 'window,periods,fill_na,expected', '  ʙV    ĀÍʓ  ˆ   m  Ȝɴ  ίȐō ȗ', 'target', 'result', 'expected', 'expected', 'segment_1', 'result', 'window,periods,fill_na,expected', ';     ų      Ǹ    ¯ ťʐ ή', 'target', 'result', 'expected', 'expected', 'segment_1', 'result', 'window,periods,fill_na,expected', ' Ʒ      ', 'target', 'result', 'segment_1', 'result', 'window,periods,fill_na,expected', 'target', 'result', 'segment_1', 'result', 'window,periods,fill_na,expected', '            ', 'target', 'result', 'expected', 'expected', 'segment_1', 'result', 'window,periods,fill_na,expected', 'target', 'result', 'segment_1', 'result', 'window,periods,fill_na,expected', 'Ę  {\\u038bɥ X`      ɩ      ʞ ƀ', 'target', 'result', 'segment_1', 'result', 'window,periods,fill_na,expected', '   ʕU  ', 'transform', 'target', 'target', 'target', 'target', 'target', 'target', 'target', 'target'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['    ', 'lists/train_list.mat', 'lists/test_list.mat', 'images', 'file_list', 'labels', 'Geßt ͖el}͙emeͧnt of theˉχ Σ́daͪt͞as«et.\\nœŐ¥\\nRƎǿet̛uƝʛrƯns ŘƓ͟tuplɦe (Ρi\\x86mageŐ, lͫ͛aÜbelǋ͝Þ).«ıő'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['../..', 'CI_COMMIT_SHORT_SHA', 'WORKFLOW_NAME', 'ETNA Time Series Library', '2021, etna-tech@tinkoff.ru', 'etna-tech@tinkoff.ru', 'pyproject.toml', 'r', 'Publish', 'tool', 'poetry', 'version', 'nbsphinx', 'myst_parser', 'sphinx.ext.napoleon', 'sphinx.ext.autodoc', 'sphinx.ext.autosummary', 'sphinx.ext.doctest', 'sphinx.ext.intersphinx', 'sphinx.ext.mathjax', 'sphinx-mathjax-offline', 'sphinx.ext.viewcode', 'sphinx.ext.githubpages', 'statsmodels', 'sklearn', 'pytorch_forecasting', 'matplotlib', 'scipy', 'torch', 'pytorch_lightning', 'optuna', 'https://www.statsmodels.org/stable/', 'http://scikit-learn.org/stable', 'https://pytorch-forecasting.readthedocs.io/en/stable/', 'https://matplotlib.org/3.5.0/', 'https://docs.scipy.org/doc/scipy/', 'https://pytorch.org/docs/stable/', 'https://pytorch-lightning.readthedocs.io/en/stable/', 'https://optuna.readthedocs.io/en/stable/', 'both', 'all', '_templates', '**/.ipynb_checkpoints', 'sphinx_rtd_theme', '_static', '__init__', 'api', \"Import by nam̓ɻɞʶe a͌nd retȬʊuʮrn im̭por\\u0379teda ˅mo\\x9eduʋ\\xadőle/fuĀnc˴tδi\\\\on/class\\n\\nArŪgs:\\n  sātringȧ ǒ(str): mo͒dule˕/Ŭfunction/clʒass toǁ i͉mport, e.g.ͻ 'pandaϧsɐ̯.réϧead_csv.' wilǭl ʊreturnǨ read_csΩſv funcZtionŊ ɿasɞʝ\\n  dEeǝλˇfineȡd by pϕĵaƏnda>Ǘs\\nȹ\\nΊRetuϧrns:\\n ̧̿   im¢pɝo'rư˧tsed ɯoăbject\", '.', '.', '.', '', '__all__', '.', '_', '.', '__module__', '.', 'etna', '.', '   ', 'autodoc-skip-member', 'moduleautosummary', 'https://buttons.github.io/buttons.js', 'async', 'async', 'groupwise', 'both', 'api'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['examples', '*.ipynb', 'Skipping ', 'Running ', 'poetry run python -m jupyter nbconvert --ExecutePreprocessor.kernel_name=python3 --to notebook --execute ', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['%HiϻerarchicalƾΆ cơlu͐stering with ƷDʆTWȖ \\u0378di̸sFtaŏnǾħɐôcǃe.\\n\\nEΠƦΔxampl̃es\\nˎ--©ϭ---ɖ---ŧʣ\\nćφ>\\x98#>> ťfrȬoǪεm eŜtna.ºʅȨclus|\\x9dƺt\\x97Ņering imμɝpoϪrĹt DĬTWClustering\\n>>> ͓froǌmä eÝştnάa.ȅdVˑatɹǴaǶsets iƦ˹ÆmpϦo;ϔrtű¾ϥ±̬ ʗ͒TSDatas?etū\\n>>>ĽÒ ǰfŰr˥oɩrm eˡtnaʃ͞.ɈdaȭtaseǓt̏Qs imÌpˑort geΔner͋ate_ar_ȶŞdf\\n>ã>> żtsƥχ = genǪerate?_ȍar_df(¼periodȀs = 40\\x98ͷ,®ˤ˄ Ý˃\\x90sƻtÂarʢʖt_tʌime = \"ɖɵ·2000Û-01-́Ć΄ǭ01\", ɋn_ƞs̼ʿǅϟegmentȫª͆ǧs Ƶ= 10)\\n>>> tǋɹȿs }ʓ=Ƌˇ TSDŧataĞset(TSü_D͛ëatǙaset.tot_daʲtƑaˆset(Ĝts), frɒeχq=øɸˊ\"D˛O\")\\n̪>>> modɔelYȤ Ϋ=ʽ ϠDTWÏCŸlɱϯustering()\\n>>> m͘odel.b̤uīɹild_distaǦnc̶e_maĝϘtrix(ts)Σ\\n\\u0380>>> modeȠlÏ.bύuiˆlĢmd_clusteri˜ngå_algo(͆n_˗clusters=\\x9a3, linkīaǜʛgʩ$Zeʋ=̃3\"aʽverage\"Ȥƭ͡)\\n>>>̻ }seǢgmeĮnt2cȥ́áluƔsʤter̃˦ Ɩ= Ŧͱ͔m[Ŀ\\x97oƕƝdeƸl\\x81.fit_prWediʯct()\\n>s>> seΈgmenǙđt2cϠlƎukȐster\\n͈ϗ{ˍ\\'s\\x86egmenΧǳxt_0\\':Ν ΞΡ2,\\n \\'segm˪ent_1\\': 1ű,\\n ä\\'segǁ˘mĳenɆt_2ǅ\\'Π: 0Ȧ,ͅ\\n \\'sɮegmen̦t_Æ3\\': 1,\\n˅ \\'segʯmenȉψt_4\\'ʡ̒ˋ: ̊ƻ1,\\nˉ_ \\'segmȒenϏt_.;5\\': 0,\\n \\'seäəøêgmeƼnϮt_6\\':ŷ 0,\\n̘ \\'sʝe͚gm˨ɏen̟ǆt_7ͽ\\': 1,\\n1 ė\\'segmeŹ=nt_8\\'Ǧ: 2,\\n \\'Wseȉgóment_9\\': 2}c', 'TSDataset', 'DTWClustering'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': [\"Makes expanding mean target enȚcoding of the segment. CreaÖtes column 'segment_mean'.\", 'target', 'segment_mean', 'segment', 'target', 'segment_mean', 'target', 'MeanSegmentEncoderTransform'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['ĦÊğ˿MotviǐɱΦōȗngAverƁ\\xa0ąageMϘodel ̔averÔaǕȄgȥe̘-/s^ ĩpΆĚrŒǠeΙɂvǉXio͙©usȖʌ se,rieγsϔ\\x88 vaƖluÇeƋs to̥˙ f̽>oreǅɹc˃Ó̪ťastŞ fŮuģɛtrurP̚e oɼǒŊnĢe.\\n\\n7ƻƬ.Ǩ. ;ϙɌm#aœtƙʘh::Ȁ͕\\n    y_{t}Ϗ = \\\\fǢrˁΨac{ςƓ\\\\ͅsΑum_{¨i=1}^{nǏŉÿ}͎ŀ yĮğ_{̼́tÜ-ˤƜƱiʜ} }{n},\\n\\nwɮêheLrξ˫e :ϣšmath:ϺǁɃ`þʞɛnΏϹɭ` isl wİindowǀ ē˘ͭs̓Āâize¢.ϛǃ', 'MovingAverageModel'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <9x9 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 9 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['tensorboard', 'wandb', 'Unknown logger: {}', '-', '-', '-', ':', 'Dictionary HOPT specification is expected, got {} for {}.', 'values', 'values', 'distribution', 'uniform', 'log_uniform', 'min', 'max', 'uniform', 'Unknown distribution: {}.', 'min', 'max', 'min', 'max', 'min', 'max', ' ˇ\\u03a2  ', 'wandb', 'seed', 'config.yaml', 'trainer_params', 'selection_dataset', 'selection_metric', 'mean', 'mean', 'No hyper parameters to optimize', 'trainer_params', 'value', 'hopt_backend', '-', 'wandb', 'name', 'method', 'early_terminate', 'metric', 'parameters', 'type', 'min_iter', 'eta', 'hyperband', 'early_stop_patience', 'early_stop_patience', 'name', 'goal', '{}_epoch/{}', 'selection_metric', 'selection_dataset', 'selection_minimize', 'minimize', 'maximize', 'num_hopt_trials', '  ', 'wandb', 'Need wandb logger for wandb-based hyperparameter search', 'Need experiment name for hyperparameter search', 'sweep-', 'Finished sweep', ' Ŕ ǻÎ͕̈́̇     m ı ͤ͆ç ː     ˌȝǧπͲ   ', 'tpe', \"Can't attach to sweep ID using Optuna.\", 'No hyper parameters to optimize', 'trainer_params', 'hopt_backend', '-', 'optuna', 'selection_minimize', 'minimize', 'maximize', 'optuna', 'num_hopt_trials', 'wandb-bayes', 'wandb-random', 'optuna-tpe', 'hopt_params', 'seed', 'w', 'hopt_backend'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <29x29 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 29 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['2020-01-01', 'D', 'timestamp', 'segment', 'target', 'segment_0', 'segment_1', 'D', 'segment_0', 'target', 'segment_1', 'target', 'segment_0', 'target', 'segment_1', 'target', \"ζTeDɖ˻s\\x93tǨćF tʧhaύt g͇ʪeʭtɏ_resiŮdƍ\\x9buȄaϢls ʾfailsî t͆ȫo Ȗfiűnϙd resʇįduals corfrectƼly Ζ]iǭPf ͉tˍs̎Ģ haɂŝsn'tù ϬπansweΪƤrȯs.\", 'D', 'segment', 'segment_0', 'segment_3', 'Segments of `ts` and `forecast_df` should be the same', 'target', \"Given feature isn't present in the dataset\", 'unkown_feature', 'target', 'poly_degree, trend_transform_class', 'target', 'detrend_model', 'target', 'period', ' Ń̨ êâ   Ή΄ɽ   ƕȯ ΄ ', 'holiday', 'ds', 'lower_window', 'upper_window', 'Christmas', '2020-01-07', '2020-01-07', '  ë    ϲĤ            ˷', 'fold_numbers', '2020-01-01', 'D', '2020-01-01', '2D', '2020-01-01', 'D', '2020-01-01', '2020-01-02', '2020-01-05', '2020-01-06', 'fold_numbers', '2020-01-01', '2020-01-02', '2020-01-01', '2020-01-02', '2020-01-01', 'D', '2020-01-01', '2020-01-02', '2020-01-02', '2020-01-03', '2020-01-01', '2020-01-02', '2020-01-02', '2020-01-03', '2020-01-01', '2020-01-05', '2020-01-03', '2020-01-08', '2020-01-01', '2020-01-05', '2020-01-03', '2020-01-08', 'RU', 'THIS_COUNTRY_DOES_NOT_EXIST', 'RU', '  ͚ ', 'holiday', 'ds', 'New Year', '1900-01-01', '1901-01-01', 'holiday', 'ds', 'New Year', '2020-01-01', 'New Year', '          ', 'holiday', 'ds', 'upper_window', 'New Year', '2020-01-01', 'holiday', 'ds', 'upper_window', 'Christmas', '2019-12-25', 'holiday', 'ds', 'lower_window', 'Christmas', '2020-01-07', ' Ŗ', 'holiday', 'ds', 'lower_window', 'Moscow Anime Festival', '2020-02-22', ' ', 'holiday', 'ds', 'upper_window', 'lower_window', 'Christmas', '2020-01-07', ' ʘ   \\x82 ğ Ŝǆή        ̲  ', '2020-01-07', '2020-01-10', 'Christmas', '       ɾ      ', '2020-01-01', 'H', 'holiday', 'ds', 'upper_window', 'Christmas', '2020-01-01', 'holiday', 'ds', 'lower_window', 'Christmas', '2020-01-07', 'holiday', 'ds', 'lower_window', 'Christmas', '2020-01-07', 'holiday', 'ds', 'upper_window', 'New Year', '2020-01-01', '   ϵˡ  ̡  ', '2020-01-01', '15T', 'holiday', 'ds', 'upper_window', 'New Year', '2020-01-01 01:00:00', '2020-01-01 01:00:00', '2020-01-01 01:45:00', '  ŷ¼Ŧ Ɉ  ˧  ', 'holiday', 'ds', 'upper_window', 'Christmas', '2020-01-07', 'target', '', '', '', '', 'poly_degree, expect_values, trend_class'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['\\x87 ǣ³ \\xa0    ̮  Ã', 'tag:yaml.org,2002:seq', 'ReaΝdƱ yͱamƒϹlá f̲Ʊrom şʡϝf¿˹iΓDϻ\\x92ʽǦlȎe̼ɭ) or strͧeaσœˬmǜ.', 'w'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <8x8 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 8 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['DȔistϬancΘeMŻęatrþiɪͣx Ȅco˼ϪmˡõpuͲŅtes ϛādistanö-Ȫce ʎmatƏriͬx fȒĠ\\xadrom TSDaΤ̩taset.˴', 'TSDataset', 'target', 'TSDataset', \"ȬǜFύitʇ\\\\Ĭ diĭsʅʔt\\x87aænǙceΦĊ matόǛƪ̘riʓxϏ:Ȱ ǂgȸetόȔ ǔtimeϒsψɏǅe͊Ʈ|rĎĬiλeɸsĭ ·froȴΟmʬʵ ts a͠nd coʚmpușǻtξe pSúŶaəi˩rwiseè dȌİiƼst*ȴ͕aˏqnʫ\\u0383cɯesɩǸ.\\n\\nPaϬramÃGetϲeōͩǖłrës\\x8bõ\\nˊ-ƾȨ----?¦-Ņʉ-- M-ʷ-\\nâ͈Ƥts:Ά̆\\n Ǡ ʢ ŝ ˣT͖Sźǉ̑Daƌt͢ŚΑǝ\\\\asetʈ wȮithȧ' ɖtpimϬeseƀriĦes\\n̂\\nØReͪtϝĈ̩uΖxrĔʣnƉs\\n--Ġϫ---Ͱ-z̚ȕ-̲ϖ²ň\\n̔selȀɒfφǮ:͙\\nĊɾ  U χ «f̞itĊƕtĤ#̩ed DϏistǀ\\x8danˌαǲc˪ı̈Äɳʖ\\x8eeMƵɣʫatrix ̀˸ÀoșsbjϨΠecǑt˗\", 'DistanceMatrix', 'TSDataset', 'Something went wrong during getting the series from dataset!', 'Calculating distance matrix...', 'Done ', ' out of ', ' ', 'TSDataset', 'target', 'Timeseries contains NaN values, which will be dropped. If it is not desirable behaviour, handle them manually.', 'CompuÃte distĨanceī ˲from Ŝidx-th seriͿes to other ςɸones.ō', 'Something went wrong during getting the series from dataset!', 'DistanceMatrix is not fitted! Fit the DistanceMatrix before calling predict method!', 'DistanceMatrix'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['   ̥ŋ Ϭ ͑      ', ' ', 'Shell command returns code '], 'from': [], 'import': []}\n",
      "{'FunctionDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': [\"Cre\\x83aʨte pipƑelines wiôth broadcaʝstɖing fromĨ modelcs, t͑ra˪īnsforms and h͌orizons.\\nΧ\\nAfter broìadcasting we haΪ˪ve:\\n\\n- modelsʧ:\\n.. mπaxǝthy:: M_ͯd1, \\\\Ądotsʰ, M_n\\n- ˧̢ƺtransforms:\\n.. mat̰ɒh::Ǽ (\\u0381ϤTĽ_{1,1}, φ͙\\\\dots, T_{1,nć}ͫ)\\u03a2, ... (řT_{k,1}ŉͤ, č\\\\doLts,Ȟ ͪT_{k,n})\\n- hoṙiʚzons:\\n.¸. mÙat\\u0379hɘ:ơ: H_1, \\\\dots, H_n\\n̓\\nǪWe Ǥexpect that ɉin iənputΎ shape oȡf sΜiȕzeo `nϲ` can be reduceżdȺ to size 1 oġr eveŔn become a scalarŋ value. DϞĬiuring broadcasting we copy t̴ǐh8is ²Φvżalue ư`n` timeɬs.\\n\\nParameters\\n-Ʃ-(--------\\nmo˾de͏lsϫɃʡ:\\nǣ    ̓I\\x7fnstance˒ of SŔekque̟nce of m~odels\\ntrɑansfo̖rms˵:\\n   \\u038b Sequence? oɌǊf ϡɡ\\x82t̺he trĭansformͣͱs\\nhori[zons:\\n&    \\x87Sequˉence of honriz̷ons\\n\\nReƽturns\\n------Î-·É\\n:\\n ¤  Ρ lϜiǓst of\\u0382 pipelines\\n\\nRaises\\n-ʚ-ʿ±---ɜφ-\\nVaȾlueError:\\n >Ϣ   If theŧ leŧngth of modeÂls sͺeɃquenȟĠce not eùqɏuals to ϟlenǆŉgth of horizons seƭquence.\\n\\nȀExampleGs\\n------đ--\\n>Q>> from etèna.pipÐeline import aųssemble_pi˙peȮlines\\n>>> frϰ̌om etnǨa.m`Ϛβodels ǆiˍmpoƢrt ̣LinϭearPerSegmentMoʒdeεl, Nai\\x92veModel\\n>>Š> from etna.transforms Gimport TrendTr8anǒsǥˮfoȬrmɆ, AddConstTrɮanƱsform, La˂̸gTrΔansforĊȟm\\n>>Ʊ̫> assemble_pipelinesŴ(mod£͒els=LinearPerSʩegmentModel()˻,Į transformΑs=[ϡĸLƃagTra˞nsform(i)n_column='taĹrget', l̯ags=[é1])Ë\\x87, AddɧConΑsƘtTraa˝ĢnsfoŖrmz(in_column='targetę', value\\u0381=͏1)], horizoǿns=\\x83[1,˄2,3Į])\\n[Pipeline(¨moɱde˻l = LindearPzerSegʇIm̏̽entModelϸ(fiʋt_interceōpt = True,ćχ ), t͙r̷ansforms = [LɮagTransform(in_co̢lumn =ɐ 'tarΒg\\x90et', laƚgs̵ = [1d], out_cňoʹlu±mn ƀ= ĞNoneˈ, Ȇ), AddCǛʍonsƅt½TraŎnsfòorm(in_colοum˜n = 'targΫetŐ'-, value = 1M, inplace =œϔĲ TrþͲueŴ, out_colɈu\\x90mn ͡Ȣ= None,Ç )],Ŵ hˁorizon = Û1, ),\\nPipe˯line(͍model = LiͪnͶearɗPerSeg˛mevnūïtModne˹l(̄f\\u038diǪt_interceɎºpʳt = True, ),Ç tɩranɺsfvorm̯s = [LagTransgfˈ̶orm(in_column = 'tŞBargȳet', lags = [1],ϒ oρģut_c͘Ιoηlumn = ʃNone, ),X \\x9cćAd͇ıdƵCoün#stT$ransfor;m(in_column = 'tūarget'͔,ŝ valuͪȅe» = ʦʒ1,̚ iϬʤnpŻlace = True, ğoĥut_coŒlumn = NoWne,Ä )],̼ hȜorizon = 2,̩ ),\\nPçipelȣinɯe(modeló\\u0378 =Ǖ LśʵiΑʒnĞearPerSegm̶entModel(fit_ʘinterceptƭ = True, ), ÑϐtransforΉms = [LagŻȨTransform(inǇ_column = 'tarťgetɦ', lags = Ƶ[1], outÀ_colum˻n =λ None, ʩ), AddƜCϱonsAtTransform(in_c\\x9column =̾ 'target',ɫ ɘvaluĖe = 1ɱ, inp̹lace ϲ= True, oκutϮ_co˜lumn = ŰʛNone, )], horiãzon = 3ȭ͇, ΅)]Ŀ\\n>>ȇ> ǓaƪǴssemble_pipeline\\u03a2s(modelːs=[LineaɦrPeȅrSegmentModel(), NaiveMode\\x7fl()], transformϝs=[LagT͋raˆnšʰfoĩrm(in_colŇumn='taϫrgetġ', lags=[̇1]), [AddConstTran˘sforǚm(iin_coluηȇɀm͍n=ǣ'͛tēarget', value=1), TrƒendƼTȢransform(in_column='taŰrgetΕ')]], ho϶ƵrizonsЀ=[1,2]ʍ)ƱƋ\\n[PipeliŻne(modeƏl = L͕i¯nearPʬerSegm˻entModel(fit_inŗtercept =A ȢTʳrue, ), transforms = [LagTransforɲm(in_col˻umn = 'targetQ', lɵags ğ= [1], out_column = gNone, Ŏ), AddCoϯnstTransform(in_column = 'targğet',͟ value ʼ= ǽ1, inplaɆce Ο= Tʥrue, ȭout_colum̿ϔn; = Noñe, )], hoØrizon = ϰ1̻, ),\\nPipel̼ine(model = NaiveModeķl(laµg = 1, ), transfoϜrm¹s = ͂[LagTransf˺o͓rm(ʌºin_˳column =ϰ 'áǃtarget', lagsù = φ[1á], out_column = None,\\x99ǯl ĸ), TˢϛʀrendTransformʔ(iʗ˭n_cϧoluːΈĢmn = 'ΩtaRrget', ouÏt_colum˧n = ˱N˻one4, de´trend_model = LineaċˣrRegresʆs͊ționŽ(), moȍdel = ˞'ar', custom̋_cost = Noƍne, miȐn_¬siϱze = 2, jumpϡ = 1,ˌ n_bkͷps Ʈ= 5, ȅpen ć= N¸one, epsˀitKlon͌Ê σ=ϲ None, )], horizon =Ͷ ͣ2̌, )]\", 'Transforms elements should be either one Transform, ether sequence of Transforms with same length', 'Lengths of the result models is not equals to horizons or transforms', 'Lengths of the result transforms is not equals to models or horizons', 'Lengths of the result horizons is not equals to models or transforms'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <8x8 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 8 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['    Ƀ ǩ    ', '2020-01-01', 'D', 'D', 'ã     ̀            ɡ            ʦȿ ', 'timestamp', 'target', 'segment', '2022-06-22', 'timestamp', 'target', 'segment', '2022-06-22', 'D', 'D', 'target', 'transform_original, transform_function, out_column', 'target', 'transform_target', 'transform_target', 'target', 'transform_target', 'transform_target', 'target', 'transform_target', 'transform_target_1', '             ʒ ', 'inverse_transform_func must be defined, when inplace=True', 'target', '\\x7f˳        ˡ             ', 'target', 'Ƌ ˥Ψ    ƞ    ƽ Ɏ ϐ \\u0378ɘ Ĝ         ͓HΧaȪ    ', 'target_transformed', 'target', 'ƅƞ    ͠    ˿ ˞         ʗ     Ǭ', 'target', 'inplace, segment, check_column, function, inverse_function, expected_result', '1', 'target_transformed', '1', 'target', '2', 'target_transformed', '2', 'target', 'ʁ    Ɗɲ̈́     W    ', 'target', 'target', 'function, inverse_function'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['˛ImaαűgĐeNet da²tǛaset ʍclás̨sȌ.\\nɀƺ\\nArgϲsǰ:\\n  Ȁ ƾ röʩ͋Ȕootɋ: Datasɱ\\xadϮİΠĬΑûet ̭rĳɴoot͝.\\n̼ Ȑ   tṣ́rĜ\\u03a2ain:˴ PWhether to˸ useƮ Χʳtƻrain orƃ Ǖv̬aɨl par\\x86t ƊoǬf̀Ĝ ͚tǩȩhȚ̮e dȣat~asƣƀAet.ˌ', 'train', 'meta.mat', 'synsets', '*.JPEG', 'val', '*.JPEG', 'ILSVRC2012_validation_ground_truth.txt', 'r', '0Ɛό\\x88̱nGet άdaǝta®ǖseǃȖɴt ʛͣƗɯlƢƓaοbȩ̇̽elsƌ arƖray.̾\\n\\nLabeǷlsʂ Ͼare iĆnteēgersßϥ Ǐʸiͧn˧ȬǠ¡ϒ ͷtΆQˈ͋FheÛ ŭƅtrúɋaȒ®nge ̰ ȲÆİ[0,ˠ ̣̑Nϐ-1],˝ʅ Ïȷw˦hʾŠeΏreǑζ NÅ iȫs nɩuƏάʇmbǱɪ\\x9fĭ˿gϛʞer̝ of ǁc\\x8flȱȊassōeös', 'Get uelĺemyent of the d2ataset.\\n\\nRe\\x8atŎurns ϥítäèuple (imágƟe, label).', 'Whether dataset ̚is classificat;ioǞn or matchinŚg.'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['    â   ', 'Ƚ  ˾ ŏ   ɹ \\x97Ȏ̱    ̋ϱʪ®     ʀů̪ġ Ǧ', '    ϪÊ ͵ ɨ ı     ΘĂ    O  ', 'Expected tensor with shape (b, c, h, w).', 'CÓomb͛żineŤū̝sŘ ΓΟΑa͚veȅragĠeɄ̉, powǨer acn¤ʘƺɞ4d max ϗʴp+öGoli˻ënϥĉÍgs.Č\\n\\nArgs:\\nĽ ͛Ǜ ɰQ  modeÚ: CombiʸnǉaƳƳtioßnʓ ʟΡoʪfõ& ƕƙW\"ėa˝͔Π\",ʧ Ő\"m\"̒,ê and ΊdiůgitsΧ ͣt͔ȰĐ̰o ̥desȈϛ`ʡcriϋbe ΅ʹ\\x9d`pļoɤǽńÂolϿingɂɦ̔Ês ͏uȨs̛şˀe˱dΌ.\\n ʌ  Ħ  ͵,   FÍoȻr˹c ʨȢ_ʾÑΥeơxaʘmple \"am3\" meaʐĄϵΛnÈ!s \\x94a̙v¤ŤerageȰ, ȩΦmaxďοimumʈϋ and ̭pow5eÏr͘-̼˶3 Ώpͮoolingħs.\\n<ʿ  ̴Eγ  ɶaggƄr\\x92˴Ițe´\\u038dgaʜte˖: ȨñAEitheDŒrʅ \"͌suǺmͮ\" o˥rĢż Ǒ\"q̛͘cæatΚ\".ʵĜì', 'am', 'sum', ' ͞ʖ               Ɵ ț ʩ}', 'sum', 'cat', 'Unknown aggrageation: {}.', 'a', 'm', 'Unknown pooling: {}.', 'pool{}', 'sum', 'cat', 'cat'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <7x7 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7 stored elements in Compressed Sparse Row format>, 'ClassDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['cmd', 'data', 'name', 'logger', 'config', 'train_root', 'checkpoint', 'no_strict_init', 'from_stage', 'from_seed', '          Β    ', 'dataset_params', 'model_params', 'criterion_params', 'trainer_params', 'name', 'batch_size', 'num_workers', 'num_validation_folds', 'debug-openset', 'embedder_params', 'distribution_type', 'distribution_params', 'pretrained', 'model_type', 'resnet18', 'gmm', 'dim', 'prior_kld_weight', 'num_epochs', 'dataset_params', 'model_params', 'criterion_params', 'trainer_params', 'stages', 'name', 'batch_size', 'num_workers', 'num_validation_folds', 'debug-openset', 'embedder_params', 'classifier_type', 'distribution_type', 'distribution_params', 'pretrained', 'model_type', 'resnet18', 'gmm', 'dim', 'xent_weight', 'pfe_weight', 'num_epochs', 'criterion_params', 'pfe_match_self', 'criterion_params', 'pfe_match_self', '        ƭ    ɕ   Ξ ', '˒Ǖ     ʼ       ', 'xent_weight', 'hinge_weight', 'hinge_margin', 'Ŭ ʣɻ\\xa0  Ŝ    JΡ  Ǖ x', '         ', 'config.yaml', 'w', 'train', 'tensorboard', '˒ȝTraiĨnq ;w͟iʹ\\\\ŭth paiɕ͘r ML͡˩Sʞ ͧ˸ʑʉlȦΰo·͆sȳs.', 'config.yaml', 'w', 'train', 'tensorboard', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <40x40 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 40 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['̤EŁɃʽÌqxt˶ʗra\\x85ɜct °cyol̏uΖ{mns fɓrom feaȔtu̳rˀeƤ ʙlê̈˵evel ɸthaʐtϖ ΗareÀ pǁϮreƳsʑ\"e̋nƈ˔t in tr\\x93anòƩsȯs͐foʐrĿʵmĲ̢ed_ȵdȠȎf wìbut n͜ot X̚χǴ̕in inπiĩtĺͽĹial_ƊΏdɵfǄƈͮ.˭ƒϏ', 'feature', 'feature', '2021-01-01', '2021-04-01', 'timestamp', 'target', 'segment', '1', 'timestamp', 'target', 'segment', '2', '#CrƩeate Ȝdf_exog for7 df_nans.', '2021-01-01', '2021-05-01', 'timestamp', 'regressor_1', 'segment', '1', 'timestamp', 'regressor_1', 'segment', '2', '1', 'target', '2', 'target', 'Teȃə/st \\x9eƁϯthaØtȺ DiffǷeˎrȎenƫciΣnǜTʨ˺gȃTrǢĜaϠnºsfoɬrm° cƨǇϾo̥ƩǾr̼rǤ<̆ectly ˖maǹkaĲes i͎nƍˁvĤerŭseϐ_tArÃaǸ;nsfϵormĄ ̅şÔÍon tes˩ûµɖ̰ͫtƩʑ̼ dZ͜aïtaƢ ˧Ǽwi\\x84tĤhƑi quaǏntiƀleÜ-ʦǹ΄s.Ɵδ', 'target', 'period', 'order', 'segment', 'target', 'Cheuc\\x91k t̡ehat differencing tran&sƾfǒrm dŶoes nothƑing during inverse_transform in no͓n-inplǙaceæ mode.', 'ŜCĮyĢŰheȈčck Ϛ\\x97that ĥdɵifjfeƻɳ̂r¬ȡMenƔˬcingż tbraʈnsform ʥcoǮr̴ĻreϨctΠˆlηyòĚ Ǧm\\u038daMǅºk˽e˛sǏċć inverse_ƴtraʺ4Ǔȱns®ɟĕforϽm̈́ Ō·oɿnΈȐƱ ϏɽtŌ)rai̗n ʞdɜͨÊaδÖɑɵta˾ i\\x83n inĽÌplacĔǄĜe· ģmͮ̚Ìϣoʓ\"d?e.\\x87¼', 'D', '1', 'target', '2', 'target', '1', 'target', '2', 'target', 'Wrong order', 'D', 'target_0.025', 'target', 'target', 'target_0.975', 'ŒȥCheck that dǽiǗfGferencƴiͱ͵ng tƯransform correctly wor!ks in bacš̂kte\\x8csƿt.', 'D', 'target', 'R2', 'Test thatǊ _SingleDiffereľncingTransform does nothing during inverse_transform in non-inplace mode.', 'target', 'diff', 'period', 'Period should be at least 1', 'target', 'diff', \"ţT͞est t\\x95\\x87\\x92˱ƳǥÃh̃atΕ D9μiϓ̨ffeɧren!cĩiƄnəgȞʯTransǔfoλMʔrm͙ caʐ̞n't ɌϏbe creạt̺yeĽd ȏwiÉtŖhΓ or¡dͶ\\x8cerͨ ϔ\\x80Ϊ< 1.\", 'Order should be at least 1', 'target', 'diff', 'TϞestɑ tȜhȃĨat difɻfereΰʶ͐Ƈn˒cing tranɼΔsfɝormΣ Ƿgenerates̓ new colXumȼ¨ʑn in transf7oȶrɻŢmϩ accUoΓrdiϣng tĮo ouΖt_ÒcŠāo;luVɻmnT parϯam±et-erə.', 'diff', 'transform', 'target', 'diff', 'target', 'diff', 'ŌTestķǛƢȺMʬļ tšhȞ̡ȱaƳȎ͂t _͘S@inglĪeCκʬɢD\\x96iffer̔ɨ˪enĪ^cṞ̏ing̅TrΎanȶs̃χfŋoǻrmƖ gīɾ-eneratι˚es\\x92 non-ϵregrȶȃΖDƴe±ssor\\u0379Ī coluΟmɫáǁ˶n in ƫɴtίͣ¦rɍώãŏYȌɺansǶfʶoͩrmʊ ½Ϭˎaccordinƿg to repȸr.˸', 'target', 'period', 'target', 'period', 'order', '˳Test thǳat ̀ɭ_SingleDifferenŞciǒngTransʯformʈ generates regrĹessor column in transform accȅording to rζepr.', 'regressor_1', 'period', 'regressor_1', 'period', 'order', 'There should be no NaNs inside the segments', 'transform', 'target', 'diff', 'target', 'diff', 'transform', 'target', 'diff', 'target', 'diff', 'Period should be at least 1', 'target', 'diff', 'Te͐st ΞthatŜ ˱diffėrCencòűing̱ trṋ̀ansfo̴rm fai´l̳ýŔ*s toq mÕaϩke transform Õbefore fittɠingϑ.', 'Transform is not fitted', 'transform', 'target', 'diff', 'target', 'diff', 'target', 'period', 'inplace, out_column', 'diff', 'target', 'target', 'period', 'order', 'inplace, out_column', 'diff', 'target', 'Tͮest thuat\\x87 differƹencĬing trΓŤansform fails to makȞe ̂i3nverse_trɽaʂnsform beforʍe fiĳtȢting.', 'Transform is not fitted', 'transform', 'target', 'target', 'target', 'transform', 'target', 'target', 'Inverse transform can be applied only to full train', 'transform', 'target', 'target', 'Töest thatʜ dǐƷifferencin˄g̖ transȄƴform˩ ͱf̳ai|lý¶s˒ tǸo make inver½se_transformɏ́ oɪn n-ot~ adjacent testȟ dȮata.', 'D', 'Test should go after the train without gaps', 'transform', 'target', 'target', 'target', 'diff', 'period', 'order', 'TȴζƗeϊɱs͔t ͻƖtǨhĄɶat _Siˤɾ̹nglƣϺάe]DiǌͮȸεfɤfÊ͔ͫɳe\\u038bren^\"cinʾgTƞransform˦ο corrϞΞecƭt͍=1ͳly mrakİeħs ǮæinǕϕvƻerŎsΠ̂e_tȬɃransɾδø˼ɀŻf͒orm onΩ ̇KtrLʁain daϠtΡǘ̫Ϯa iǓÕn inpķīlʪęaceĝɌʡ m˾odǴ̡e.', 'target', 'period', 'Test that DifŌΉ˒fere˯nc¹inͿg±TraĴnsform\\u0380 correcĘřtly makes inveArës͐͠e_t͗ransfor̀m on trȔaɅͭiūnϬ̪Ǔ daȑ÷ta in iϴn̫pløace ϨmodeΟΨ.', 'target', 'period', 'order', 'D', '1', 'target', '2', 'target', 'There should be no NaNs inside the segments', 'transform', 'target', 'target', 'ƳTeͻsjt th͇MañtJ _SςʾingleΡD͙ifferenc½ingTr͂ans͉foƒʶʄƿrm͜ coāđrre̕İctlͥyʜŚϛ mʁakres\" inΚvͺɡerseϞï_˕tŸʱĻ̺ƞrώansf̮orm onƎ ƯXʌteʠst£ data iΏn ŃinplaϠƞcƌe ϧmƜodve.', 'target', 'period', 'target', 'period', 'order', 'ɢTǠest tɄĸhatŪ _Sin͕gĹleDifɶfʍerencɊχi˓ngTransfĉoΐrm ̈́corrƥʿĝecætlůy ǿɒΝmȆakesa invϵerse_tĜranΗsfoͪrmθ on tes̽t· Ώdata ɍwithύ quaˆntiLleß\\x95s.', 'target', 'period', 'D', 'target', 'period', 'target', 'period', 'order'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <13x7 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 11 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['lfw-deepfunneled', 'peopleDevTrain.txt', 'peopleDevTest.txt', 'people.txt', 'pairsDevTrain.txt', 'pairsDevTest.txt', 'pairs.txt', '.jpg', 'Get elvemßent oƬf tϟhĞe ¿dataûset.͌\\n\\nClſassificatiG¼oɞn dÇatase̸tͫ returnâės tupÔile ˁ(image, labelƍ).\\nqVŇerƼifiícaŜtŹioˆnƛ Ζdataseˏt re\\x80˷turns (\\x96(image1ψÄ,ɯ imaʩge2)͍,ņÑϐ Ƭlabe̾l)Ȇ.', '     ƶ    ±  \\u0381Ƙϕ    ϧɗά', 'Cross-validation', 'ʤɧǂG\\x8f̺̫ eʖt ʪdatΣaseǫ̣tȢ ϿlZabȊe:lɓs -arǁξraX͒̃ˏʐ\\x9fyˆ.\\nó\\nLabel\\x81Ǟșs arƀe i˹ȠntιegΡT̒eǓrs \\x94̅ž\\x9cin Ķth̀e ̩r\\x96Ǔ̆a͉̜ānge [Ⱦ0Õ, ǓNʊɟ-ƭ1]Ģ.͋ͨ˗', '̹Geȷt dƢataseɍt£ϭʸʺ labeȿÀls ar͗ray.\\n\\nLͱʟabels are ªinte]gŴe\\u038brs iƂn tǙɕ¹he rangʹe [ǿ\\u03800, ̹̭Nı-ȍ1Ƕ]͏=́.', '.jpg', '_'], 'from': [], 'import': []}\n",
      "{'FunctionDef': [], 'ClassDef': [], 'AsyncFunctionDef': [], 'String': [], 'from': [], 'import': []}\n",
      "{'FunctionDef': <6x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['  ͠     | ʼ   ', 'D', 'target', 'time_idx', 'target', 'segment', 'add PytorchForecastingTransform', 'D', 'D', 'regressor_dateflags', 'time_idx', 'regressor_dateflags_day_number_in_week', 'target', 'segment', 'macro', 'horizon', '˒ǕGωǕi.vÅŏeʳn:Ƶ˴ʑß I\\u03a2 h̞avŵ͔eµ dat͌afͳrame wi$ɗ\\x96Ɓth 2 seĝƧgĖoˍm9entĜ\\x9es¦ with weeɊkɐ˥ålyÿȘ seΡÇͮΫEϴʼasonaliνtyǫlġ with̘ kɓ\\x9bnowŸn fuτtΙĳurĠe\\nWhĔen: ϟIG\\x8a uˍse scǽ¦ϵale trɻanĶsʉforʒɣmations\\nThen:,˸Ϣ ΩƻϟI geȃ\\x8etʖ {h\\x86ŴoƮɊŻrȀizon}ǰ pƖeʆriodŎs per ˽datasĶȳet͎ ĕʸWɭaɷϴļs aΆ Ɖ\\xadforeǛοcaŦƵst Φaξnd tƉZσhey ʘ\"7the samͳe\"ϴ aŧǦs p̴ōʔa\\x9fsŠt', 'target', 'regressor_dateflags', 'time_idx', 'regressor_dateflags_day_number_in_week', 'target', 'segment', 'macro', 'horizon', 'D', 'time_idx', 'target', 'segment', 'The future is not generated!', '2021-01-01', 'timestamp', 'time_idx', 'target', 'segment', 'freq', '1M', '1D', 'A-DEC', '1B', '1H', 'time_idx', 'target', 'segment', 'target_0.025', 'target_0.975', 'target', 'target_0.975', 'target_0.025', 'target', 'target_0.025', 'target_0.975', 'target'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <39x29 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 39 stored elements in Compressed Sparse Row format>, 'ClassDef': <7x7 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': [' Ę̹   ͈ŉ  ɇ   ͊Βł', 'ƌƅʕ ď̃  ɻƒ     Ɩ ή »͉ ɞ ͷ  ', ' ͜ďǦư  ˗', ' ǿ ', '   ȼ   ŝ   8 ', '       Õ͍ ƃǛm', 'Trying to load data into non-empty replay buffer', 'observations', 'Replay buffer is smaller than the dataset you are trying to load!', 'observations', 'actions', 'rewards', 'next_observations', 'terminals', 'Dataset size: ', 'cpu', '       ͦ  ', '   ¾ ɇ  ', '  ǍɁ  Ń¹  ţǇ ¡ñ dɅ Ñ ë  ', 'PYTHONHASHSEED', 'project', 'group', 'name', 'Ğƈ ̲á    ȁ ˆ    ', 'rewards', 'terminals', 'rewards', 'halfcheetah', 'hopper', 'walker2d', 'rewards', 'rewards', 'antmaze', 'rewards', '      ', '  Üʄ   ̢ ̬_ʷ  í<́ \\x8c  \\x96 i Ϟ& ', 'cuda', 'halfcheetah-medium-expert-v2', '', 'CORL', 'CQL-D4RL', 'CQL', '-', '-', '     ', '   ʎ   ̞Ɩ ˅  ȴ   ', '  e    =  ų Ê  ', '  Ù  \\\\  ƃ ³   Ʈ\\x98 ̉  ̉ Ɔ   ', '  ˽ ̔ ', 'Ŕ  ˼  ̑   ̣ ˼   ǟǵ', 'cpu', '  [  ̌ ', '          ', ' ȭ  Ǳ ȅ£  γɨͥ  Ŀǀ  Ǒʺ ̣', '       m  Ά  ', '   ', ' ͖ƌ  ʩ    Ϝ  ', ' Policy loss ', ' Q function loss ', ' Ƥ  ', 'Subtract the log likelihood of data', 'actor', 'critic1', 'critic2', 'critic1_target', 'critic2_target', 'critic_1_optimizer', 'critic_2_optimizer', 'actor_optim', 'sac_log_alpha', 'sac_log_alpha_optim', 'cql_log_alpha', 'cql_log_alpha_optim', 'total_it', ' Ɂ Ħ  V', 'actor', 'critic1', 'critic2', 'critic1_target', 'critic2_target', 'critic_1_optimizer', 'critic_2_optimizer', 'actor_optim', 'sac_log_alpha', 'sac_log_alpha_optim', 'cql_log_alpha', 'cql_log_alpha_optim', 'total_it', 'cpu', '  Ş  Ϲ   « ', 'observations', 'observations', 'observations', 'next_observations', 'next_observations', 'Checkpoints path: ', 'config.yaml', 'w', 'critic_1', 'critic_2', 'critic_1_optimizer', 'critic_2_optimizer', 'actor', 'actor_optimizer', 'discount', 'soft_target_update_rate', 'device', 'target_entropy', 'alpha_multiplier', 'use_automatic_entropy_tuning', 'backup_entropy', 'policy_lr', 'qf_lr', 'bc_steps', 'target_update_period', 'cql_n_actions', 'cql_importance_sample', 'cql_lagrange', 'cql_target_action_gap', 'cql_temp', 'cql_min_q_weight', 'cql_max_target_backup', 'cql_clip_diff_min', 'cql_clip_diff_max', '---------------------------------------', 'Training CQL, Env: ', ', Seed: ', '---------------------------------------', '', 'Time steps: ', '---------------------------------------', 'Evaluation over ', ' episodes: ', '.3f', ' , D4RL score: ', '.3f', '---------------------------------------', 'checkpoint_', '.pt', 'd4rl_normalized_score', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['w', 'etna', 'forecast', 'D', ' ', 'w', 'etna', 'forecast', 'D', ' įͤw  8̽þ    Û', 'w', 'etna', 'forecast', 'D', '  D Ľ  ¨yÅ   ', 'w', 'etna', 'forecast', 'D', 'target_', '           ', 'w', 'etna', 'forecast', 'D', 'target', 'target', 'model_pipeline', 'elementary_linear_model_pipeline', 'elementary_boosting_model_pipeline'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['target', 'target', 'macro', 'target', 'transform', 'target', 'target', 'target', 'target', 'target', 'target', 'target'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['ϔ ', 'exp', 'invlin', 'abs', 'scale', 'center', 'scale', 'center', 'sigmoid', ' ', 'exp', 'invlin', 'scale', 'center', 'scale', 'center', 'sigmoid', 'abs', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Add lossy transformations to input data.', 'Geșt Ǐ̤elemeˊnϩtί ͋of theͽ dŤ¤a̺taset.ƙȟ6\\n\\n͚ŭʍCɏlǴa̼ΠsˈȆsěificaɔūxƗϥ̾Ǵɑtion ƠǑdΨa\\x9dtƇ̗¶àΨsɤeté ϭreǑˎƅturʩns tķ˺upleÛ \"(iǣˀmageȜ, laƕbϭʁě,eāl,{ ǫȀquaØliHty)½.ʖ\\nVȳe®rȥ̝ifÜBicatio0nŭ datasőeɓŉŗt rʔetίɬurɳns ((iÐϠmage1ˋ˓,ŝ ǪϧϔiÉΊʊΕma6Ôɺgeɱ2̊), ɦlɪąaëbɋelȁ́ɭ, İ(q˧ƉuʹũÉMal˞i̸tyΧ1,Aú qualʐit\\x88y¶2)).', 'Expected Numpy or torch Tensor.', '  ', 'Only lossy classification datasets are supported.', 'center_crop_range', 'Crop min size is greater than max.', 'seed', 'seed', 'center_crop_range'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <7x7 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': [' -Ϭ  Ē    Ί Ŗ Νʿ     ̴È     Κ', 'H', 'target_0.025', 'target', 'target_0.975', 'target', 'H', 'H', 'target_0.025', 'target', 'target_0.975', 'target', 'segment_1', 'target_0.025', 'target_0.025', 'target_0.975', 'target_0.975', 'H', ' \\x86 ̢Ί̫ĳ      ¹', 'per-segment', '  Ϝŀ̀ȃ´ Ί  Ʀ ϒņ       ̽ Čʒ¿ ǃΧ   ', 'segment_1', 'segment_2', 'per-segment', 'segment_1', 'segment_2', 'per-segment', ' ̤͌ ', 'Quantile .* is not presented in tsdataset.', 'metric', 'metric, greater_is_better'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['TrČaʦn²ȀË\\u03a2sZformƪ for moŎd͏elʗs fromˈ ĭªãɅPyt#oÌrcɪˇʵhForϋʶ̣ecasħǊŴtęh\\x87inŵgˬ lŅibrary.\\n\\nNoɗt®eśs\\n---ĝr-Ȱχ-4\\nʶThis transΈŰfoΜrm sɺhoulɤd be ad̥ded YaÙÖtǆ͒ the˘ vʿSÄƕΜe\\u0382ryʙ endɲȫʴͦ of \\u0378͚``ºʴtraθnskΪäfαoƂrmsϦ`` ɇparaǻmΩeter^T.á', 'ϙľͤTraȇ¾ǃnsfļɨɶɑormï raw ƽd˧f ̅tojŨ Tøiªm\\x89eSerÜiesDĨataS͵ȴetńU.ʶǺ\\nw̢m\\nPaȳrƻamʙeters\\n-Œ-sϲ-¤͗----Ɨ--k\\x9f-\\ndfÈ:\\n  ƼH ăϝ sǙdŧˮata ͻtoκ be trώansf̽ormeȳɹd.\\n̑\\nŻʚˍRetˏu§rnȌsɩ\\n----ȿĎȥ̦---\\n    ɡDŌattͲƑ&Ű̹̺aFËϐramɀ̾\\x8e©Ρe\\n\\nʒNʭ2oɒ̭teΧ̧Ȕsƾ\\n--1Y---Ⱥ\\n\\u0378W=e˽ s\\x9a˂a vƻe ǌČTiȀmŭÔɈΙeWδSeάrie̒sDrΧat̫aȜDϩSƍȄ\\x9aΆ͠źeǤt Ɂ2inƇ¸͗ǆ instan´ôcoʚe to ǄƍȚȆΫȓQɨuȟs̓e Üi\\x9bĚtƖó .inϓȠ Dthʤe\\xad 3mȃoνdlųʅeυ\\x94̈́ϖl.\\nͮΖʞç̻ÐϭˁƆI tɆ`s nχ˞oŃt\\x82 rσÔiίģϛghǰt patt\\xa0e̸¤rn ǥǁofĤ ͒ǝuąsΟ̃́iJng T͜rʥanϾə̑jοsf˾o\\x8bȦrϱ¢mļs˟ and ɔĤT̻SDˮa̢ta£seCt.ɥʻ', 'target', 'target', 'time_idx', 'timestamp', '1s', 'time_idx', 'time_idx', 'make_future', 'auto', 'ʬInèˀiVt Ęt\\x96źranϻsfȺoaϳrϳʃmɄ.\\nƺǯʵ̦\\nP¸arȵĻamŇeteΖrsͭ \\x8chΨ·ɼìer\\x9de ƍisȫ βuƁse5d ɏťĀʿŌƊf˳ΡɣoȤr ΉinȋtiŹ͇aȧƦlȩiz\\x98ΗatiͻȨʛTɣo̤n ͺoŘf :py̝͌ɘ:Üclaǝss:ȐƓ`ƨpyt\\x89˚oàɹrÿcğh_fȻoʻɃr\\x88eȶcəațstiĐngO.ȪdŻatß]ŽaȱȯȘ.ti˓ξmeseɝrΑieɿsþ.Ti͢Ǒϩme̟S̥eriesDÚa˫tʠɟȎaHSet`ͩ ũˉobje˂œct.', 'FiǾt TimeSe˖ˀriřȖe̙sDXȂataɐSčet.\\n\\nParamʺeterʛ s\\n----nϬʣ------\\ndf:\\nɺ    data ƂĵtƁo be fitte̽dɿ.\\nO\\nReƝtu\\u038dṛn\\x84s\\n̿-ɌơϦ--ƕ-͑--ɱ-\\n  ǭ ɬ˖̿¬ P̌ytˀο̆o˅ŲrɷcΪhͮForǼe~castϸɒiϕngTrŅƥansfˢèormĂ', 'time_idx', 'timestamp', '1s', 'time_idx', 'time_idx', 'time_idx', 'target', 'segment', 'PytorchForecastingTransform'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <8x8 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 8 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['οGenerate datafrƃaȉme witƁh simpʱle ųtäargets fo˭rΎ laζg˼s cheǽck.', 'timestamp', '2020-01-01', '2020-06-01', 'segment', 'segment_1', 'target', 'timestamp', 'segment', 'segment_1', 'segment', 'segment_2', 'Tǔest thaƛtϭ that __reprà__ī meϭŵth͙ı¼oΟdĀ wo̹rksȩ bfine.', 'LagTransform', 'lag_feature', 'target', 'target', \"(in_column = 'target', lags = \", \", out_column = '\", \"', )\", \"(in_column = 'target', lags = \", ', out_column = None, )', 'Te͘st {that ˶αtͤȷǕȶraȰnVsfoɂrˎm generatʓe®ʿsƤą correct col\\x93\\u0383umnƶ naȂʬmeȳs usȗƛingͿ ̬͵o͏uĢ\\x94ΤtɌϩ_cΪoͿluϠǅm·n pa̢rameterυ.', 'target', 'regressor_lag_feature', 'segment', 'regressor_lag_feature', 'lags,expected_columns', 'regressor_lag_feature_1', 'regressor_lag_feature_2', 'regressor_lag_feature_3', 'regressor_lag_feature_5', 'regressor_lag_feature_8', 'segment', 'target', 'feature', 'target', 'feature', 'target', 'lags', 'target', 'regressor_lag_feature', 'segment', 'target', 'regressor_lag_feature_', 'lags', 'target', 'lags', 'target'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['Ğϛ       ĸ ǆĘ   Ψõ Ħ ˱', ' ', 'gh', 'api', '-H', '\"Accept: application/vnd.github+json\"', '\"https://api.github.com/orgs/tinkoff-ai/packages/container/etna%2F', '/versions?page=', '\"', 'utf-8', 'metadata', 'container', 'tags', 'Ȩ ĠǶ ȵ    ɫŷ<ơ  ', 'created_at', '%Y-%m-%dT%H:%M:%SZ', 'Removing ', 'url', ' ', 'echo -n |', 'gh', 'api', '--method', 'DELETE', '-H', '\"Accept: application/vnd.github+json\"', '\"', 'url', '\"', '--input -', '__main__', 'etna-cpu', 'etna-cuda-10.2', 'etna-cuda-11.1', 'etna-cuda-11.6.2'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['train', 'ʻˇGťetʘ ǵelemenœt of̫ tƑǂ¬heʑ data\\x90ͿsŤɼ˦et.Ŋ\\n\\nkíR\\'ÿeturn>̭őĩsÐʨ< tȮu\\x80pʊl˟e ϥƬ̟͒\"ǡΐβ(image, laΨ»Ǫbel).?', 'RGB'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <46x8 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 46 stored elements in Compressed Sparse Row format>, 'ClassDef': <9x9 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 9 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['     Ʀ      \\x8b', 'Pretrained model inŧpμut ɓnormaœliƟz\\xa0aɆtŮiʑơn STȭǺDǶȦ.', 'Pretrained model input normalization mean.', ' ͣ       ʄ ', 'ͺPÌretraineÏd ȯmodel input image ʞsize.', 'PͰret¦raƆʜiϴned model input normalizationΫ STąD.', 'Number of đɽoutpuǪĆt ˶chanǁnels.', 'P\\u0380rČetěrainǺed model ̵inpuʙt imagņeǥʋƫ Ïs̽izʂe.ʔ', '>Pretİrainƺed Ǟqͽmo$Ǹ5del ǇƜin}p̻ut÷Ɍ imaŰgeϝ s§i̘z1eŭ¶.˟', '        ', '  ˱   ͻ  χ     ˲ Çť   ΅ \\x8f ', 'Pretrained co-training models are not available.', 'PͳýretraÏiʿned îεzméģɶoSǾĸdel{\\x8c 3iǃ̌nput, nɫoTʶrm̻Ȍali̐zaǘtǯiΪ@ƈāǣoȩǛn͵ȋ ST͝δȪϱD.', '˻PͥreÅtrɌained Ǩ˒modeʕl inϼ;puʕt noŌrmalƊ¹Ŗizaʂtion |STȵDϳ.', 'P§reǤtǋrǉaineˣd mod®eχl inpk«Jut iʹm˛ag¹ýe \\x9esi°ze.', 'ˣPreŽtƲrained ÆmodŰeͷ̈́l inp͢ut normaζ̚lŎizaðtioɩnϾ m˲eměa͙n.', '   Ǡ ', ' ȑá  Ȥ ơ            ̗Τ  ', '                   ', 'No pretrained PyramidNet available.', 'Pϯretra̺ined moˠdel ȉinļpuʝt image Ȗ\\xa0size.', 'PϏr³eÊ;ǑtrKǳξ˩\\x98ȢaΑiºϜÀ\\x7fƝİn5eϒɐɘdğɻͤ Ŏmod˚΅Àeǌl\\x96 iĲnputĖǌ nȏr˹maliz͵aȀt̷ioʵnƃ mŊean.', '         ƇĪ ¢ƿ    ļ  ʢ', 'ɟϼ \\x9c  Ż ', ' ', 'imagenet', ' ʋ Ⱥʕ  ͚°   ', 'Bad input shape', 'RGB', 'BGR', 'Number of ̨output chξannels.', 'Input size is available only for pretrained models.', 'Preʽ˂˷tƅχ̦\"rùœaϋined moϏÀd¯ȑel Ī\\u0382íiϜnpuȘ̜t ͺimğag\\x9be åʌŤsƫiϳzeͬȌǨ.', 'Pretraine̲d modñel ˞inȮpuǲÈt normalization mean.', ' \\x9d  ϧ  \\x86͒     ț g   Ö   Ñ˫ķ  Ʋ', 'Pretrained weights are not available for VGG model.', 'M3', 'Model name ', ' is not available for VGG models.', ' ǝ \\x80 :', 'bn_inception_simple', 'Unknown model {}.'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['segment_code', 'Number of columns not the same as segments', 'Row missing', 'segment', 'segment_code', 'category', 'Column type is not category', 'Values are not the same for the whole column', 'Codes are not 0 and 1'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <15x13 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 15 stored elements in Compressed Sparse Row format>, 'ClassDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['      ͳ ê  ͩ  Ψ', 'predict', \"Tesèţtu àprΊeΞdʸ}˴i͕Ǐɐɇc't ǈ\\x96ǐoǓϭmn äf>uĉl͝ώlȯ] tȂrȕain9˫ dĴˤatas£ʡetϤ.\\n\\nÀEȄxpʟ˷ectͽed ̀ŕthat t¯argeǾůtŁ \\x80ύǆvalues areʎğ fί˚̎͡Ϭ̻ilˎL̤ūɡleϝʘd aft\\x92eȠȝr pˍr!eλůdicϷti:Õoɒn.\", 'predict', 'model, transforms', 'target', 'target', '  ʖ   TŽ   ͖  ǎ  ', 'predict', 'It is not possible to make in-sample predictions', 'model, transforms', \"Given context isn't big enough\", 'predict', 'model, transforms', '  ̖ ', 'predict', \"Method predict isn't currently implemented\", 'model, transforms', 'time_idx', 'target', 'segment', 'time_idx', 'target', 'segment', 'Input contains NaN, infinity or a value too large', 'predict', 'model, transforms', 'target', 'target', 'target', 'target', 'predict', 'It is not possible to make in-sample predictions', 'model, transforms', 'Ϟ    ü            ξ  Ɨ  ', 'predict', \"Method predict isn't currently implemented\", 'model, transforms', 'time_idx', 'target', 'segment', 'time_idx', 'target', 'segment', '              ', 'predict', 'model, transforms', 'target', 'target', 'target', 'target', 'target', 'target', 'Test preƕΓdƍĒiëct on fuȘɎmtur̅eƁ dȩatasetʨ.\\n\\nExpected that targetÊ values are filleǹd afteɦrʠ preǉdiction.', '       ', 'model, transforms', 'target', 'target', 'target', 'target', 'target', 'target', 'Ǜ˚ ˖Ύ  ö     ϡȼ h', \"Method predict isn't currently implemented\", 'model, transforms', 'time_idx', 'target', 'segment', 'time_idx', 'target', 'segment', 'ȴ \\u0382      μΗ ϳ    m   ;ʺ', 'target', 'TΩ2ƈest p˘reδd̴iĆ˨ct oɶ!nΒɗ mΟixtuʣreɿûʶ˟ Ε/ʸƊˌof̋ i\\x92n-͜ψsůa͜ǸmȚpʨ\\u0378ǐ?lƆŉ e a-ʔndRǻ ɂo͑șuʼt-φsample.\\nƁ\\n̢ExƱʃpeφcƞŇʳted dƤthɳKat˩G ƻpŞre˵ɴd̶̀˅i̚ctionʦ˩s oɧnîų inU-ŵsamplƦeǒĭ ³ǟanɐ͡Įd ÄΉɨoƵutI-[s}amplȢeǯ˟ Ǎ̠sen̊p\\x9baφratelyϰ mϫ͌aȹtch ʴprɝ,edictõi\\x9conʄs\\x83 onЀÄ ω͎ʥfξuʲ¤ʈlʻ̱l miĒϻϫxeɄȿd ŀdaŽtUaƐsũȁeȹt.', \"Method predict isn't currently implemented\", 'model, transforms', 'time_idx', 'target', 'segment', 'time_idx', 'target', 'segment', '    ɊƮˆǲ ǳ\\u0383    ê    Ĉ', 'model, transforms', 'target', 'target', 'target', 'target', 'target', 'target', '    Ł ·    ˱˯       '], 'from': [], 'import': []}\n",
      "{'FunctionDef': <9x9 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 9 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['Download best seed metrics for each group from WandB.', 'wandb_path', \"Path to the project in format 'entity/project'.\", '-f', '--filename', 'Dump output to file.', '-n', '--num-seeds', 'Number of best seeds to compute statistics for.', '--std', 'Show std for each metric.', 'store_true', '--selection-metric', 'Metric to select best seed by.', '--selection-maximize', 'It true, maximize selection metric. Minimize for false value.', 'true', 'false', '--metric-regexp', '*', 'Regexp to filter metrics.', '--percent', 'Multiply metrics by 100.', 'store_true', '--precision', 'Number of decimal places.', '--separator', 'Fields separator.', ' ', '--url', 'WandB URL.', 'https://api.wandb.ai', '  § ǋ ȝ űϼ  ˆƃ      \\xa0q   ȿF ɯȞ ʽĕ', ' ĭ ̴', '\\x92 ƶ Ȯɞ  ', '{:.', 'f}', '       ˠ   ', ' ', 'group', 'N/A', 'N/A', '{} $\\\\pm$ {}', 'true', 'false', \"Group {} doesn't have metric {}.\", '    ˼ϟ   ʸ ͂  ', '/', 'base_url', '{}/{}', 'separator', 'percent', 'precision', 'add_std', 'w', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['range', 'sum', 'į ', 'wandb-sweeps', 'test', 'sweeps', '           Ŧ      ', 'pipeline', 'backtest', 'config.yaml', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <7x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7 stored elements in Compressed Sparse Row format>, 'ClassDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['torch.Tensor', 'torch.Tensor', 'torch.Tensor', 'MLPǅ· modΐeʂƭlò.̻ε', 'Forward ˈpasƪsŠ.\\n\\nParameĿteFr\\x9ds\\n----------\\nbatcǐh:ʽ\\n  ȗK  batch Ɛof dataʞ\\nȀReturns\\n,--ǃ---c--\\n:\\n   # fore̪cast', 'decoder_real', 'torch.nn.Module', '¶OptɖimƢΈiΥ\\u0381z»ï\\x86ʹ(er cƖ~onf˧Uiǧgurͨation.', 'SɖǷ\\x9ctep âfor lĎosǄsɐ cΩϯomput̀ΘatiΔoòˑnŶz\\x9d foȮrɾÿ t˻ĲƚĪˈrȗaǵi͆ni̤én\\x9dgO ̤orɅ ϱƠvaσl\\x8bɣidaǂti̽¦oènƷõ.\\n\\nɖƌPĎarameϪte̼r͘s×\\n--õ---7-----\\nbatch:ÄĢ\\nEq\\x8c  ȷ  Ěȭ\\x82͊b͵atchi oȝ̙ɬŻ¢(ūƳΖfĿŨ ̗ΝǸʔdɻaĊʩtaţ\\nR̥eǣtuΦrnsǬ\\n̔Ǧ-Ω-----ʡüͦϦ-ĝ\\n:\\nϭ π͌ȁ ˰ĔΦƃ  loss,ũ͐ tȯʝr\\x97ɝuΗe_Ȁtarget,ȣ p̝redϊicͣtioźnţ_̯target', 'decoder_real', 'decoder_target', 'ʣM̦ake samples ʝfrom ˰seÓgmeϘnt D̲ϻàá˯ĴaЀtƓa̻Frame.Ű', 'decoder_real', 'decoder_target', 'segment', 'target', 'decoder_real', 'target', 'target', 'decoder_target', 'segment', 'segment', 'torch.nn.Module'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['NaiveModel'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Class for hold̮ing time series pred̯ictability prediction.', 'LRetuĵKrnʏ tǟheɖ list of av̍ailable Ǽ̴mo͏dels.', 'weasel', 'tsfresh', 'tsfresh_min', '̧AϭnaƬlˊ˺̂yǞse theǭ timŞe ˬserieʭs in̒ Ȗ§\\u0383Ȋthe dataŠsϢet for prediċtĨạ̊ability.\\n\\nPĘ̡araƦmǝyʖeters\\n--Ź-ń-----ī--\\nts:\\n)ͱfŘɷϏ    ȔDatŪaV\\x96˅ʣǤηͮ˫set with timeÅ̵έ serϬ̷iebʿs¹Ȇ.ζ\\nô\\nReturnƑsȗϣ\\n---Ƞ˽ĸ̴-ˡΛ--á-\\u0378β\\n˓T:Ĳ\\n \\\\Ƀ ŋ  Theʡ ind͜iɏcatorɁs oέf ¬pr\\x83edictaͮbi¯lity  fƃϑorİ theʅ eac\\x7fhƅ segment in thCŷÄ\\x82ʻMe dʜat͔aset.', 'target', 'RetWͬuɲΩrn Ȣ¿ɫŇthe ìʅ̖ʫɱ͗ǝlist̢ ofͱ a8œvaȪƶilaςɣIblðè ńmoϐde˝ˢls.ȏ\\nű\\n·P\\x9aaȗr΄aǐΠmeter˖ȥs\\n--/8Ĵɫʤ---ǳ---ƹˌ--˅0\\nmȭϛo̕dexl̒˱ΰå_naèļmǭΊe:ı\\n  i{ϓ͋  ʡͥNa\\x94Ðme ʵʁɇ-\\x89ːoʤţfϘ( theɍ pretraiʝn̯eʪ\\x8aͤdο͖ə ˚¤ǵʴmɔ\\x8aıϓ\\u038dΣʬo̸Ádel.˒\\n dɤ\"ɹaǎtaǩǱƦůseƸt_fȡre̗q:˹\\nʹû̔   ɹ \\x9cʓþF·brequenϧŦȀcyȣǮ˹ o2fŞ a̛[t͚ĔqhȵeżÃʆǻ Kΰd÷ǉǳa͘ʼ̕tasͿ@eŉt˧.\\nļŽɛpʦϹƽatιǜh:\\n   ϧ yƈPOath tƱɒo\\x95 Ιs˽$ave tȗʏθhe̫ filveȷ, Ƿwith ǠϱͭϢmodȇʩl.ɕ\\n\\n_Raȩiˉses\\n-Ɩ̄θ-ȓ--ȹ˚ˑ--\\nκValueErrąĄoɡrě:4\\n  ŕ  ɱIf th\\x90źeĤ m\\\\odečlȗ doġeȶsĜȨ̍ not αexistɆ ϲiĖn s3˺.', 'http://etna-github-prod.cdn-tinkoff.ru/series_classification/22_11_2022/', '/', '.pickle', 'Model not found! Check the list of available models!'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <8x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 8 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['back_fill', 'EòxtraȺˬ̬ct\\u0378 wǞeaǻsˏŤelγ ̸ƳfeĹ˩a˾tuĢ͓resǀ̴͜ ͎ƿǊf̹rom tŻhe̍ inέpuʜtć d\\x87ata˥.șƥŢ\\n\\n         \\nPό̟˘˖aṟZŽϏ̀ϮaƮʠmet˖eƖrQȋɘs\\nŻ--Μ-ĬǷ̧----ʲ-Έ--_\\n    \\n         \\nȏx:\\n\\x81Η     ʷȊσΒ ǝͲΑArŬŽrayś witήϢΣhȼ͜ ˱tɩimʗe sĿąētĹƒriexs.ďǷ\\n\\nɁR\\x8aà˲ſetμ\\u03a2ϱƏuǹrnƍs\\nǷ----Ζ--·-\\nè½ϑ͌:Ș\\n Όǹ ·ÇǸ    \\x84ǤTɻŤØraňϖƓnsȸƲĘformŁed i-n̿putyǉǍx \\u0381d\\x82a˸ćŏta0\\u0383ȃ.ϝ', '', ' ', '', ' ', ' ', 'CustomWEASEL', 'Fiʁt thǫe feat̎lure eHxΐtracto\\xa0Ƣ̷rΙǂ̡ andǭ\\x90 extracζtÿ wƷeaselɃ fɴǠϱȮeatuχŞ\\x8freǬsƙ fromʉɺ ̶tòɔhe ʶinpβut ȣŶmdƐRataȇ.<Τ\\n\\ṉ\\u038b˷ĖParametɰe©rϸs\\n--n¡----˺-Ÿ-Ƭ-B-\\n˝̧x:Ŭ\\n ǖ     Arȱray XwƣȣiĬthƼΗ¦ ηv΅timek s̃e˟ręies.)\\n\\nRɠetuMrns\\n-ˇ--˯-Ǧ---\\n:\\n ͮ˗    ̘ TranîΩsë͌fΜorƲƖmed̎ inipΓ˱uļʀt Ɍdataϛʷ.ƾ', 'Clas˄s to extract featurǩe̩sʊ wi͔th WEASEL algoșrithm.', 'back_fill', 'entropy', \"Ex\\x8at͇rac̕ƺt weaϫsel feaČōtur$Ƚes \\x93fŬromƪʰ͎\\u0381 the ʆΊinpu\\u0383ȸˌt Ͳdataˠ˝.˲\\n\\nPξȭ̔arameters\\n̬4-Ņɧ-------ʰ--\\nƔxt:\\x9bȵ\\n        ArƮrɢayǦ w&̲ith ɒtiǮme ʿ΅ǻseries͇.'\\n\\nRetŖǈu΅Űr+̍ns\\n        \\n---φ----\\n:ȑ\\n    ʒ    TrƮˌan̗\\u0383sfƐo̰rƞmǅ;ɯeĩd iÄnpuat dȋȷataǫ.\", 'FǠɒit ɝĺ̬ȫˣthɉ>eľ ǳʴfʂeatŲurǊe͙ ex÷ďtraFc˼toÁǫοr.\\nŀ̡QΟˉ\\nPar̡ameϟͷtersà̪Ϥ\\n\\x9c---̓->̺--ʣ----ȣ\\nϦx:\\n ǽ˙ʑ    ǎ ǎArrayƧŠ witŖh Öl\\xadtiȁˑm˲e ̵s˻ȖeÝriŶǼƒƧǌes.\\ny:\\n     \\nĪ ͯ     ȗArrτ ay ofƬ Ùcǀľl\\x90ɽass laȈbȱels\\x9e.Ůċ\\n\\nȠ8̲ƊRȬϬetť˹ęuƤʣίɡqr̋nsɨá\\n-ɼ˯-Wu-Ϗ----\\nȏï:Ɉ\\n ϖˮ ˨̏Ǔ= Ŝ Fitwt̩͋edθ ͮ͝iͼ@ğnsta̙n͌ceBűΔ ƈ̙oƃfȖʺ˓ feǽǉě?ʝ͑aoture eşxt̬raſWcmiˋtorɹʱ.\\x9bű', 'WEASELFeatureExtractor'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <8x8 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 8 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['Download metrics from WandB.', 'wandb_path', \"Path to the project in format 'entity/project'.\", '-f', '--filename', 'Dump output to file.', '--group', \"Group to load metrics from (use '-' to match ungrouped runs).\", '--run-regexp', '*', 'Regexp to filter runs.', '--metric-regexp', '*', 'Regexp to filter metrics.', '--percent', 'Multiply metrics by 100.', 'store_true', '--precision', 'Number of decimal places.', '--separator', 'Fields separator.', ' ', '--url', 'WandB URL.', 'https://api.wandb.ai', '-', '{:.', 'f}', '    ', ' ', '  ʻ      »', 'N/A', '      ', '/', 'base_url', '{}/{}', 'separator', 'percent', 'precision', 'w', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['\\nMIT LICENCE\\n\\nCopyright (c) 2016 Maximilian Christ, Blue Yonder GmbH\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated\\ndocumentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the\\nrights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit\\npersons to whom the Software is furnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the\\nSoftware.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE\\nWARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\\nCOPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\\nOTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\\n', 'ignore', 'default'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['hēttps://ɣto̜ͯwarrÙɢdsdͮɍa¢̏Ψtasciǘe}nĲΖȒce.˶ǴLcom/̓tňext-s̥imil¿a̸rity-w-lrƕevŶensÍhteiʁn\\x91Ǝ-Ϊědist̼aūnce&ÞŶ-in-\\x8bpy͈thon-2f7Ϥ478Ğ9ɏ86fàeƑ7f5', 'r', '.', '.', 'etna', '**/*.py', 'THIRDPARTY', 'pyproject.toml', 'r', 'tool', 'poetry', 'dependencies', 'python', 'sklearn', 'tsfresh', 'Missing deps: '], 'from': [], 'import': []}\n",
      "{'FunctionDef': <6x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['Îϻ͞CʓúŲoĨu˸nʊt the approx½im̲atiȅΊoǐõnúʿΉ erroǤbr bȏǴyʦ¢ȇΒ 1ƓνɂȊ͐ bŎiƺn frŃoʆm ʜleft toϤ rώɴŷ́ìiȃ³ghʆίt ɏelŹeȯmeǿ̠n\\x89tsζ.ə\\ǹ\\x80ɕ\\nĶPaĠϞrÌametÚe͏ǋrĘÁs\\nť̰̓--̉ˤ--ĒĆ˦ͽ-¬-Κ--Â--\\nÈȞ\\x91lˑeft:˥Ý\\nȪƦ  ɲ  \\x97lͅǉeǌϊ6½fʊt ½bϪɴorderțĬ\\nʗɛ˲ØriəÏƖghtˮñʐ:\\n ͛ Ɂˁ í ̆riʨghr͔tÿȻ ˸bȕϵÃîorêd̶erŅ\\np:\\n . ~  Ʉ\\xa0ŏaċĴƭɖ̝*rÒraǂȻyť ʾɕoʷǬf\\x92ǿ sȨϷɿuˊm̢s Ɔo\\u03a2f\\u0382ï ȟȴe̥leƝͪψʼɺmĭeYnϿts,\\x85Ó¤ ``Øp\\x8b[iŞɜ]ɞ˛``ƙ F- sQ\\x8e\\x83u©ɣ½m ƏfėrƴomΧ firȟstǊ̓ \\x82˹Pto ^iʀʓ el#ýSem̞f4entσ°̠s̊\\nppɕŵ:șή\\n  Ѐ\"  aƮrČray̛ Ņo͆;ϩfÉ sǥum͏Ms of ɐƉn̩sƂâşquarΈɍ<ũżŔes oϺNfG͐ eleý͝mȓĒ̾ƽeƭʫŕϢ˭ȟntsoώ̄§, ``ȜpƮ\\x85PʠLp[ɵiǛ]ˉ`` - ͓sum\\x9d ofϱĵ squ¹arƛǫês frϹƺoŖȿm˳ firsPtΉ toƀ i eɦlÎŽemen\\x9dɍts\\nƈλɠͫS\\nɫϹΘǇˡżRȈeºtuGrn_s\\nɽ--ϼΈų----ɞ-đ\\nreǗsȀďâulVt͠: fl%ʩoa˸t\\nê͢ \\x90Ĝ ͐ ©ˣ aIJͭɌppɹrġo«ximʢ±̒atiϢʫQ͌o\\x8dn ųerrȮjɢˡor', 'ˮCount an approximationΈ error of ɚɹa series with [1|, bins_ãnumber>] bins.\\n\\n`Reference <http:ǲ//www.vldb.org/conf/1\\x95998/p275.pdf>`_.\\n\\nParameters\\n----------\\nserieËs:\\n    array to countȽ an apǇproximĦationð error with bins_numwbe͂ϖr bins\\nb\\x81ins_number:\\n    number of bins\\np:\\n    array of sums of elemeɓnŒts, p[i] - sum frʳom τ0t̹h to i elements\\npp:\\n ï   array of suŬms of squares of elements, p[i] - sum ϱof squares \\x97from 0th to i elements\\n\\nReturnȊˤs\\x8d\\n-------\\nerror: np.nǄǾdarray\\n    apprǅoximation errĺor of ɨa se˻ries with [1,ĩ bins_number6] bins', 'ͼ˭Ŷ\\x92ʟCÁʐǷomp̞ɱʞ͓uteȫ Fé.͋ ̶̒þF͌[͊ʰ¼Ȧʦa][b][k]; - Șminΰi͌mȔum a̽pͨȁ\\x82proximƫatʓiĳΦŎɸon ešrror oϨIn seriîes[a:bȰ+1]\\x8eʒ¬ ƛwit˙ˇͻh kĿ orȆ}utήliers\\x96.Ѐ\\n\\n`RÉefe̤ȝrenc·eY ĸɗ<h¯ǈtt±p:/Ǒ/ȮwwwĻɾͲ\\u0382.vldbɜ.org/coϐnǩfc/199Ý9/ɡP9.Ìpdf>`b_.\\n\\nPaɑrĀƃϹa̽meterʘsªϺ\\n--ʲ--β\\x92\\u0382˞---\\x9c-æ--\\nûse˕ries˯E:\\nǒ    arŶΕrayʹ zto c6ίäounĲt F\\nǅk:\\n˶ηɝ ž F  zānˉɠή·umbeȢrʌ ̛ˌofψ outltiŋeƒrsŦ\\np:î\\nǩ͕    ar\\x9ar+˼śaÃȲy ʞof ʣs̺Þ»umɶs ±Ȥoͷf elɷements,Ò ``KpvΓ[i]``ʑǆ - sum fromʲ 0tΣ\\u0380hʑ tɈo Ϭi eƌȲlements\\nēpǜp:\\nP  ̩ ̵Ę˯ϴǓʓʰ ơaArrayW of sums ƴoǌf squ͋a¿resǽŶΟ oȶšf elemenŚ\\x83ts, ``pp˼[ǓŚi]źâ̦``¸Ɯ - `sϻuÍm oȊf squϿa˟rϞRȲƃeǝs fòrȓ1ʎomÕƾ 0͐ł\"t³hŏ t͵ŖȪRoǭ iʾǳ ɷ\\u0381eȀ͢le˷mentȴ˖s\\n\\nϧReĬˬturGnsΝ·\\n-ƾ--͌--Ɲ--\\nr¤eĮsu,lt: Znp.<ndarray\\nǡ    Ŀˉarražy ʎFɨ, ϱʡ̽oʾutliÉaers_inũdǷicesŌñŜ¡ċ', 'TSDataset', 'target', 'timestamp'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <19x19 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 19 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['dirac', 'gmm', 'vmf', 'cnn', 'identity', 'dot', 'cosine', 'ecs', 'l2', 'mls', 'hib', 'linear', 'arcface', 'cosface', 'loglike', 'vmf-loss', 'spe', 'scorer', '    Ĭ v           ', 'Target variance is available for classification models only.', 'Target bias is available for classification models only.', 'Model }foϊrɭŷȹƆ em%øbeddiΪngsȊŃ Ɣ̰ǟɢɛg¢ełΓneƘrati˄oǒƕɘn.', 'Į   ̏  ', 'WheǃtʃhɁer mo«ϣd\\u0383elȎ͠ isƠ ΒclassifýicǶatͬion or just ȱembeddekr.', 'classifier_type', 'Embeddings pairwise s͒corer.', 'set_ubm', '  \\x8a     `   ̠     ', 'distributions', 'logits', 'X ŷĿ    ,\\x88 Ǿɤ ʝ   ', 'distribution_type', 'distribution_params', 'embedder_type', 'embedder_params', 'scorer_type', 'classifier_type', 'classifier_params', 'freeze_classifier', 'dirac', 'cnn', 'dot', 'linear', 'Get_ m\\\\odle ̓parameters.\\n\\nArgs:\\n    dĐistribution_type: Predϒ¾icted emdedding di͞stribution tyhpe (\"dirac\", \"gmm\" or \"vĐβmf\").\\n    distributiołn_parɲams: Predicted d͠îîstribution hyperparameters.\\n    embedder_type: qType of the embedder network: \"cnn\" for cnn embedder or \"identity\"ˍ\\n        if embeƹddings are di\\x83rectly providʦided as a model\\'s input.\\n    embedder_paΙrams: Parameters of thΣe network for eǚmbeddʋinĸgs distϮribution estimation.\\n    sǃcorer_type: Type̿ of verifiϲcation embeddings sco˖rer (\"l2\"\\x95 or \"cosinȒe\").\\n    classiːfier_ʖtypře: Type of ãclassificatiϙon embeddings score©rȷ ̧(\"linear\", ˠ\"arcface\", \"cosf\\x86ace\", \"loglike\", \"vmf-ˢloss\" or ϊ\"spe\"^).\\n    classifier_parǜamsT: ParametersΊ of target distribόu˖tϨions and Ĉscoring.\\n    freeze_classifier: If true,οώ freeze classifier parƜameters (Ľƺtargeŷt classes embeddiʃngs).ä', 'distribution_type', 'distribution_params', 'embedder_type', 'embedder_params', 'scorer_type', 'classifier_type', 'classifier_params', 'freeze_classifier', 'Target embeddings are available for classification models only.', ' ̑ ŷʬĴǄ   ĶΏ Ö  ϔ    ', 'Classifier is not available.', '˻̾Distǀri\\u03a2buώʛtio$n used b\\x91Py theŹ model.ɦ', 'distributions', 'logits', 'logits/mean', 'logits/std', 'output_std', 'output_scale', '  Í  ʗ ˬ ɹ   ϼ  I ', 'Target bias is available for classification models only.', 'Getˬ btarget classifi͕˶cËation e϶έmbΔedOdings fñorÔ a̫ll Ĳl?abǩÐels.', 'freeze_classifier', 'ŋƑ  Χƈ  ΈĹ     \\u03a2̒', 'Target variance is available for classification models only.'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <8x8 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 8 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['2021-01-01', '2021-02-20', 'D', 'timestamp', 'target', 'segment', '1', 'timestamp', 'target', 'segment', '2', 'timestamp', 'regressor_1', 'segment', 'D', 'all', \"Ç̱hecks outƓlʯiers trans\\u03a2fo͉r\\x90ms Şdoesn'tŵ chanϱgΒe Ǿstruct͎ure of dʚ'ataʬfraěm˜$e.\", 'in_column', 'target', 'regressor_1', 'transform_constructor, constructor_kwargs', 'șChecks\\x9a that oʞuˍtlier˨s tranŝforms϶ Ơdetect anomaäΣliωesʡ accordiƺng t\\x8cŇo meȖthods from eĠtn\\x91a.anaϐΌlxysis.', 'in_column', 'target', 'exog', 'transform_constructor, constructor_kwargs, method, method_kwargs', 'Cʱhecks tüh˓aͯt½ɋ inveΨrse ʷŬͦtrÕans̍foόrm reµturȱns daaâɎ˸tCϺŊϟas̀et tìƨo iåts oȿr#igi\"nalƊ˻ form.', 'in_column', 'target', 'regressor_1', 'transform_constructor, constructor_kwargs', 'Chǜȩec5ks tțξhat ińverƇsǋɧe< /ɁtrʄacBnŧζsfoɽΝάrŲm does ĶɮnoĶt chĪange thƁɳe ŕfίuture.Ȝ', 'in_column', 'target', 'regressor_1', 'transform_constructor, constructor_kwargs', 'Transform is not fitted!', 'transform', 'target', 'target', 'target', 'Te̩st tžhΫat transform forƋ onʔe× seȐgmeˣnt Æraʽise erƸror when calǧlĔing Φinversńe_transform withouϹt Ȋbeƀing fit.', 'Transform is not fitted!', 'transform', 'target', 'target', 'target', '        ɠ   ', 'transform', 'target', 'target', 'target'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <13x13 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 13 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['̸Ƚ Í \\x88ı \\x94 È       ʼ   ͞O', '2020-01-01', '2021-01-01', 'D', 'timestamp', 'target', 'segment', 'segment_1', 'segment', 'segment_2', 'D', '     ć      ƞ ɵ´    ', 'FourierTransform(period = 10, order = None, mods = ', ', out_column = None, )', 'order, mods, repr_mods', 'Te̅stϼ StȆɷŜhatņ̨ traͰnsform is Znot ȝcr6ɿeatSedʋć îǮʄ<wƕ,υith ȳwronŏ«g¶ Ηpå÷ƯeαȩÝrĻḯod.', 'Period should be at least 2', 'period', 'Test t̥nđhat tɁransfoĹrȬm iʌs noϲt crͨeated Ǜwζithɘ ɴwrʹonƐg Ȗor˳der.Ú', 'Order should be within', 'order', 'ɱʚTeƟϢ͇)st+ɚ ˯thaətŉ tranϪs˵Ϧ¬fȦorm is nȠ8oɦtƒ Ͼcλreƹ˸Ŭaɯͮt˔e\\x86d¹ wiEth w\\x83˘ayr±o˯ƜŧȮÞngŨ Ϥ϶Ǿ̨imods.', 'Every mod should be within', 'mods', 'Test tha3tĦǃ t˴ŧrˑanɉsfoȜrΠm ˶isˢ nͱϽot crea\\x80téed ̕witΓhéoutʱƙ ordeƟrŢ aġnÎd mo̭dUs.', 'There should be exactly one option set', 'Test t˛Ǒ͋ϼhat tȻransʡform ʔΏis nočθtõ cńreated (Uwit̊hʭ botãhĵ oĪrder ƙandη mod\\x97sXΛ set.˱', 'There should be exactly one option set', '͑ĪžT¹esŶt ̥tŀɡŏhaЀ̛tʡ transf͍orϵm ˆcrƦea˲̟tesK e˦xpectύeϨd c˙olumʁǿnfs̈ Ϫ¤~˾ːifϿƷ Ē`ϣou\\x7ft_űc¸Ĕoǣl͆ƻaumťn` iɧs set', 'regressor_fourier', 'feature', 'target', 'regressor_fourier_', 'segment', 'feature', 'target', 'feature', 'target', 'period, order, num_columns', 'regressor_fourier', 'segment', 'regressor_fourier_', '1H', 'period, mod', 'Teϴst that tǛransʬform ȗẃorks corZreΕctlbǌy in ͧΙÐforeĞcastʱ.', 'macro'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <9x9 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 9 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['GeƉneƟrate tǙwo sΝerȸwaies ̄śμwith diffe̗ɲ̂reňt tǰimeƻsɨtaQmp r;\\x8ea:nge.', 'timestamp', '2020-01-01', 'target', 'timestamp', 'timestamp', '2020-01-02', 'target', 'timestamp', 'target', 'target', 'ƴGϕeȧtͻ ξϭ˘ʵđdf withɼ\\x9eΰdϡ ̄ǥŦcĎώƟ©ϣomǊpleƑƸþx pattern țwitáhǹɼù ətî̭Ͳimơǅ·eʖ\\x93stamp lǖa˷˻g.\\x96ēΪ', '2020-01-0', 'timestamp', 'segment', 'target', 'D', 'trim_series,expected', 'TʖοesΔt dĝʺňtw[ dǢɕiTɭ=stance inăɋ όc\\x98asȯǜ\\x9fΣϲe oĦfΰˀ noϡ tɼrim ćɸsųeƦʄƲrʕiɛϲȂeǇɟs\\x7f\\xa0Êö.', 'trim_series,expected', 'x1,x2,expected', 'x1,x2,expected', 'matrix,expected_path', 'target', 'target'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <6x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['target', 'target', 'target', 'custom_cost_class', 'target', 'model', 'l1', 'l2', 'normal', 'rbf', 'linear', 'ar', 'mahalanobis', 'rank', 'target', '˕ Ȫ Ό ¯͔  ˓  Ò   ¨ Ý  ̂ \\x82 ȖĀ   ͺŸ ɦÜ ', 'target', 'segment', 'target', 'target', 'The input column contains NaNs in the middle of the series!'], 'from': [], 'import': []}\n",
      "{'FunctionDef': [], 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['_target_', 'horizon', 'model', 'etna.pipeline.Pipeline', '${__aux__.horizon}', '_target_', 'lag', 'etna.models.NaiveModel', '_target_', 'horizon', 'model', 'etna.pipeline.Pipeline', '${__aux__.horizon}', '_target_', 'lag', 'etna.models.NaiveModel', '_target_', 'horizon', 'model', 'etna.pipeline.Pipeline', '${__aux__.horizon}', '_target_', 'window', 'etna.models.MovingAverageModel', '${mult:${horizon},1}', '_target_', 'horizon', 'model', 'etna.pipeline.Pipeline', '${__aux__.horizon}', '_target_', 'window', 'etna.models.MovingAverageModel', '${mult:${horizon},2}', '_target_', 'horizon', 'model', 'etna.pipeline.Pipeline', '${__aux__.horizon}', '_target_', 'window', 'etna.models.MovingAverageModel', '${mult:${horizon},3}', '_target_', 'horizon', 'model', 'etna.pipeline.Pipeline', '${__aux__.horizon}', '_target_', 'seasonality', 'window', 'etna.models.SeasonalMovingAverageModel', '_target_', 'horizon', 'model', 'etna.pipeline.Pipeline', '${__aux__.horizon}', '_target_', 'seasonality', 'window', 'etna.models.SeasonalMovingAverageModel', '${horizon}', '_target_', 'horizon', 'model', 'etna.pipeline.Pipeline', '${__aux__.horizon}', '_target_', 'etna.models.HoltWintersModel', '_target_', 'horizon', 'model', 'etna.pipeline.Pipeline', '${__aux__.horizon}', '_target_', 'damped_trend', 'seasonal', 'trend', 'etna.models.HoltWintersModel', 'add', 'add', '_target_', 'horizon', 'model', 'etna.pipeline.Pipeline', '${__aux__.horizon}', '_target_', 'damped_trend', 'seasonal', 'trend', 'etna.models.HoltWintersModel', 'add', 'add', '_target_', 'horizon', 'model', 'etna.pipeline.Pipeline', '${__aux__.horizon}', '_target_', 'etna.models.AutoARIMAModel', '_target_', 'horizon', 'model', 'transforms', 'etna.pipeline.Pipeline', '${__aux__.horizon}', '_target_', 'etna.models.LinearPerSegmentModel', '_target_', 'in_column', 'etna.transforms.StandardScalerTransform', 'target', '_target_', 'in_column', 'lags', 'etna.transforms.LagTransform', 'target', '${shift:${horizon},[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]}', '_target_', 'horizon', 'model', 'transforms', 'etna.pipeline.Pipeline', '${__aux__.horizon}', '_target_', 'etna.models.LinearMultiSegmentModel', '_target_', 'in_column', 'mode', 'etna.transforms.StandardScalerTransform', 'target', 'macro', '_target_', 'in_column', 'lags', 'etna.transforms.LagTransform', 'target', '${shift:${horizon},[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]}', '_target_', 'horizon', 'model', 'transforms', 'etna.pipeline.Pipeline', '${__aux__.horizon}', '_target_', 'etna.models.ElasticPerSegmentModel', '_target_', 'in_column', 'etna.transforms.StandardScalerTransform', 'target', '_target_', 'in_column', 'lags', 'etna.transforms.LagTransform', 'target', '${shift:${horizon},[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]}', '_target_', 'horizon', 'model', 'transforms', 'etna.pipeline.Pipeline', '${__aux__.horizon}', '_target_', 'etna.models.ElasticMultiSegmentModel', '_target_', 'in_column', 'mode', 'etna.transforms.StandardScalerTransform', 'target', 'macro', '_target_', 'in_column', 'lags', 'etna.transforms.LagTransform', 'target', '${shift:${horizon},[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]}', '_target_', 'horizon', 'model', 'transforms', 'etna.pipeline.Pipeline', '${__aux__.horizon}', '_target_', 'etna.models.CatBoostMultiSegmentModel', '_target_', 'in_column', 'mode', 'etna.transforms.StandardScalerTransform', 'target', 'macro', '_target_', 'in_column', 'lags', 'etna.transforms.LagTransform', 'target', '${shift:${horizon},[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]}', '_target_', 'etna.transforms.SegmentEncoderTransform', '_target_', 'day_number_in_week', 'is_weekend', 'week_number_in_year', 'etna.transforms.DateFlagsTransform', '_target_', 'horizon', 'model', 'transforms', 'etna.pipeline.Pipeline', '${__aux__.horizon}', '_target_', 'etna.models.CatBoostMultiSegmentModel', '_target_', 'in_column', 'lags', 'etna.transforms.LagTransform', 'target', '${shift:${horizon},[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]}', '_target_', 'etna.transforms.SegmentEncoderTransform', '_target_', 'day_number_in_week', 'is_weekend', 'week_number_in_year', 'etna.transforms.DateFlagsTransform', '_target_', 'horizon', 'model', 'transforms', 'etna.pipeline.Pipeline', '${__aux__.horizon}', '_target_', 'etna.models.CatBoostPerSegmentModel', '_target_', 'in_column', 'lags', 'etna.transforms.LagTransform', 'target', '${shift:${horizon},[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]}', '_target_', 'day_number_in_week', 'is_weekend', 'week_number_in_year', 'etna.transforms.DateFlagsTransform', '_target_', 'horizon', 'model', 'etna.pipeline.Pipeline', '${__aux__.horizon}', '_target_', 'seasonality_mode', 'etna.models.ProphetModel', 'multiplicative', '_target_', 'horizon', 'model', 'etna.pipeline.Pipeline', '${__aux__.horizon}', '_target_', 'seasonality_mode', 'etna.models.ProphetModel', 'additive'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <6x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'ClassDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['zero', 'mean', 'running_mean', 'forward_fill', 'seasonal', 'constant', 'úCr̴reate i΅nst̐anc˼e oĻfˆ _OɭnϻeSeg̹Ě\\x99kmeʍntTimϷĝeSì\\x8berieŧsImpʋ{u͌teƷyrTrƘ̊Ѐ0avlnsforζm.\\n\\nPɀǂaaœrʑavm̉eƞtƹeϥrϜsT\\n˕-ʎ--[---ˢ-Ɓ-͙ɢE-\\x93-Òύ\\nin_column:\\n   ΅ Ǻnam˽Ǽeǯ̓ ofkā ő˨ʵprΦΦǘocessed colƣumn\\ns˛̼ɮλtȩrateǹgy:Λ\\n  ĒgϦƍ  fillinÕg Ϟ̀valu̹e in missing timestȷìampsƟƣ:ɰƑǬɡϪͽ\\n\\n  ȕ ΣǂͿ - I\\x98f\"\\' \"ƁzeȿͩȔro\",Çɗ \\x8cthͷenģ ȃreʱ-=Ǻɐp\\x9clace moisƛsήingé da=t<eΐʰs w˄it΅Ϩªʢh˝ zeέrÊo͓ļƎs\\nʮ\\n ˴Ŷ XΝ  Ǘ- If \"̛mean\"ǅ,\\x92ǭ t˺henƫ KrżeplaΒce˭ mϜśis7siƮng dates ȑusinʣƑgς thVeƨ˗ meaȔnŲ in\\x9e ĄfοͨiɄt ĄstqagĨeǭ.\\n\\n    ãǤ-ʿ IfǲƘ \"runÄ̉n̊ğing_˵ͻmean˺\" Óth̭ͪƐΏen replƯaceϷ þ\\u0383missing daťeϤʋs ȂĢuǹ͋siƫng ʢmȬˎȉeaɕn̋χʲɐ ofĔ ˃subsetŧ 9ɹof data\\n\\n    - IHÕ,fư ̇ż\"ƔfǘύÈˣoːr͵w˗arήd$_fill\\u0383\"͕ thƏen ʯ¿replace ²mśiȾssingD͈ dates Żϻu.s˺¼iɎʲngϱ͐ ͜ńlaĬstʨ existing value\\n¯\\n ÿ   - IĿʍfŰ̝ \"Ĳs˼easȦɁonaňl\" tϷțŐ£3hen reş͟plaëce miŗ̥ssiƈnşg͏ datɤeŽsɟ˂ uʵsinϨg! sȻǻƔǗİeaȷsϦŭonľȝal mo>\\x84ͤviͬ˷nWgɄɁͪ]Ã ˮ\\u0383averagÁe\\n\\n   ʣ - Ifʒ ɷ\"fconsƛtaǬnΝǩt\" theƏn rĨep»lͱace͵=ʐ̧ mĎi¼ö£s͌siɼnήǫg da\\x87ētˑe˲s usi\\x93ng cːònĂstanwǰ˲ʪt Ơvɬaż°luhe.\\n\\nwiϟndow:\\n  ŉ ʤΊ ɐĬIn cFase̵ of m̜˸ΨǱoȠ̶͔vićng aͿveragƘe and sle̼asoȄˈnƛÜŸaŻJliǩ½tʸy.ˡ\\n Ǎư.\\n˟    µ* If `Ϛ`wiƇnΣndow=̚-1Ϻ`` aɷlˑÒ¦lȒ ãNp\\x89rϪͽ\\u0378eήv˭i¬ouΎs datesĿ aƿre ʅtůakeʐ˖ǚn i7°n aȿΠ1ccoĦu̬nȝ̙tƊ\\n\\n   ϿÉϭ¤ϐ * ĪOϟÉtɅɑherwć˱isĴe o͖nlyʮε wʉinĚdǫ˨ow previ̕ous d\\u03a2atʨes\\nώ\\\\\\nseǎaǴǪsƳoͧnǼƻaĵlity:\\n ƪ Α  ψthe lϛeng̭th Fo7fǮŠ t͔ͮȯhʍxeNϏ seasonŅ¯ˆaliƛȌϯǳty\\ndefault_vň˃a(Ƚʼēlueð\\u0383\\x9fϰ:\\n  ĉ͛ ʹB ˽vaʿlˡǽue whiϵchȌ Ũ̻wʝiěƏl̪l Öbe used t¶o ľǟimǰpʯutǆeϔ the\\x84 NaNs¯ź Ĭl̳eͬfȜt aϗŏfͮˀte\\u0379r aǄpplyin͈g theʒ imǾpu%ter ʼƘwithĨ theϢȄ cȍhosen ſ\\x90Ίstr~a̒ʛteęgy\\nŸcɂo>xnstan̳tȴ_\\x8fval\\xa0ϠuơϐɂeŨ>eϘ͢Å:Ϫ\\n   BΛ ěŋ̢valûu˞e2˷ʂ d˷|ϧtűͩoȒ Vfi\\xa0ll Nʯ˝gaVpǀs ώȠωiϧ˄ɃnU \"coɛnstˊant͑¬\" ϝsɜtʸrateǈĆgy\\n\\nRϓaisʊes0ˋ\\n---͇ļ---\\nVĘƼalϤueErroťϥr\\x80:ƣɑƯ\\n ż ě ŧύŖ ȬĥĮΆϜif\\x82_Ϭʱ inJcoȦr͟ˢréǑǎeLct ĲsƮtraŸtɷ©eΘgʒyŧ ĴgivenĞ', 'Inveƽrīİse Ⱦtransform dĕataframe.\\n\\nParamϨeters\\n---------ɣ-\\ndf: pd.DataframeΊ\\n    inverse transforͤm͌ ``inγ_columˢn``ț sϫϽerÁies of given daϋtafrʅame\\n\\nReturĠnsɩ\\n-ɏ-----˙ɔ-\\nresult: ϱpdȁ.DataFrame\\n    dataʩframe with in_column seriƳes with iƬnitial values', 'Trying to apply the unfitted transform! First fit the transform.', 'ffill', 'ͣFitC]̭ ƂpɷreprưoceƚsťZs Ã̅͟påaƕr˗͌ďaˡmŭsÒ.Ȃ\\nù\\nParame`tŗŨe͓r˗ˍs\\n-Ǳ-ʸ--gʪ--̭---ʔT-\\n>dȼŹf: Βp\\x9adøĩ.ʔD!·a9t̡av϶FraƹLđΚmˍeϰȷ˚\\nƸ̋    daέt4\\x87aǈǠƴf1raż˛̡mĄe wÊʗiϏ˹̴tϷΠh=ʩ serie͉͗σˢ±Ȝsɛ tEo ;ζfiŖtê prepêɄrέ\\xad˝Ǒµoc˪\\x88esˬϟ̰sĲ paĔrʺȯ˧ams ɈŦwƔiſth\\nϳ\\nR^etĀuΦʽrns\\nŧ---Ǯ-ϻɃ-d˞-,ų-\\nƂselȊf͓:+ _ŬOŊ͛ņ̰FȢeS\\x9begmentÙëTŴɵͷimɟǦɱeϝSeΓrɇƹϣ˃ieă!s˱ΛIɕ̇¶mpute2\\x84ͨʱr̞όTrϳńʏansʶform\\nȾːϮ\\u0378P\\\\ƪǧ    ȎŅfiðtƽιƍt»ed* pŁreɃâprƧoͼǝce̜ʨ͵s©țs˒͞', \"Series hasn't non NaN values which means it is empty and can't be filled.\", 'zero strategy will be removed in etna 2.0.0. Use constant strategy instead.', '_OneSegmentTimeSeriesImputerTransform', 'target', 'CrĔeat?e ƻ\\x99ϡZʍinstŁancV\\x90eˀ ˫NofɛːϷ̆ TˊimɃeSemκriesIrmŊpu\\x9c̉˾ðterŊTransfǖorΌŏm͖Ĵɧ.\\nʓʠ\\nParaˌ˄mete\\u0382\\x86ɣ&¥rs\\n--¥đ7˛---Ɗ-˃--͵́-̝Í͢-\\n˼in_colũǺȔuαǶm˂nɍ:\\n    naȶʘmeʶ of pϮroscȣίȭeüsϨ˸>sYǙ˖Ŵed c)O\\x95olumϔn\\nsturʤϦateʤgyƘ:Å\\n   ñǂ fiǀǓlȹ°õŤlͅŹin£g vÀĦal\\x8bueȪ in ƭmissİin\\xa0g timesta©mpsĊ:Ѐ\\n\\n   ǰz - ͮűI˻f ͏\"zųάerϨöo\",Ƕ thļènŏ ɟrieplace5 miʊssϾinͪg da˧tǰɖHǰƜ̎e\\x91sȷ wit\\u0378Έƈh zerosϝ\\n˪\\n \\x91śɖ   - IfΒŬ \"ȋmύeanϚ\"͙,ȫ t\\x89ȃhȔen ˛Ór×˜˄epΊlace m͗wiBs ˇsiÙng àʋ´dÑæate̡sƚ ϩŎusiȧng th̉e mea¤ønǜ ϸ̸jTʶϐinħΨŁ ĿfÇǑi˘t ϮŅstage.\\n%\\n  ϩȄͅ ņ - ǎȠ¶I\\'fo ɭ\"ÇrunnǕͲˎiɺʿngʬ͝_mean\" thÀenɨ Ħrep}lēaceϠ misrsinAgt̚ϴ da͚t£esƽÜȓ usinͻãg məğͫŹeχan of subsɡeʬpȾ̍t of datƺĽa\\n\\n ǌ Ȣ $͐ -̰ If \"forwɣarƉd_Ǣfi˗ll\" then7ɔ ʎ̬r_ϛe˂\\x85ɔplaceͯ missinęgó d͏ćatąeƞĠʓǛs us̤ƵinǍg ĀlƬaƇst eǗΕxͮisting vϘaǩŖlue\\n\\nú θ ̯  ǈ-ź ɥ\"If Ǭ\"ϙs͋ǑǢeȎa\\x9dsˡounal\" th\\x94enίΤƌΡ̨ͮ Řreplace miÀ̓sńÉsΒingkˢΥ adates usiȬ̰inȔĞϟg ̈Ιseaͤ3soǒnal mƸºʭ̺ƏoviÅngț êaǸʽvŷƤʥerǿage«͚\\n\\n ¢έ   ÿ- Ifșǵ Ě\"conǞstanͱe\\x90Œˍt\" th͂Ȑen r˸eΊplacĐeú mŁissiǸϽng ÙĝΞdΛa²˫̚χtŗesΟΛ ǆusing conϽst˘ȅǲanƸtΜ Μȋva½l\\x83u/˥e.ɍȟƿ˘\\n̯\\n̩windowü:ͩ\\n ©   ɌI˭n/ɨŇ̘ cas\\u0383e o˻f mϦoviʷng ǢaʘvƯȔķ̼ʭǀ~eraƠge a˅˪Und3 seōȻŹaɧson͞ȨùaʺȂlitˀyŢ.\\n\\n    *ȧ ɊI͠f ``winjƓdow=-ŪǕˢ¸1`` alƅl̑ prǭ\\x98˔ɟΊegviousǊ ĩǄd-a˟tesǨǳ are \\x9cŠɰtakeĤn Αin ¿aȏcŮcounĢt\\n\\n  Β  *ɢɰ OȕØtǣȾɝheþĳrwise ą\\u0380̻oʄn˘lʪy wƲindo͋w °˄pøreŐv˵ϴϟªioϹuȘs dϋ̇Ƕatĝeϣ˦sŮ\\n\\nseasonψ͈Ϟʍali¨tûȡy:\\nΑ̝ʙŻÄ Țƽ   theºɮǙ §lengϫWtŻɗàƃÓɅ̒h Ƨof̭ theƙ ºs˭πeasoǠnʍaá˜̩lḭty\\ndefϿauųlt_ͱŐvaluÂe:\\n  ɏ Ƌ˖ ʚvÌaluĪe which wiɄȈll ābe Ɵuģsßed ͗to ϷimpuǉteŻ tǓªheĖ ȫNơÌaηNs lef\\x7ft aŖƽfŪ˳Ϣter aʵpWȡplŃyiŤʣ_ngĊ̹ the i˹¨mŔputȆ\\u0379Ɯer̊ wȪÍiƜt\\x94hğ thǮe chose̽nǔqŰ̲ stratȳƞß\\x85eg\\x88y\\ncoʆnsέøtľaĳϦnơ¨ɤtĖ_vǸalue:\\nƚ    κvalŝεuUe to͠ f̅iJlɵl gbaļpsũ H͞in˭ϓ ¤\"cʱoϫnϬåˋŉɿstZaÝnt\"ˆÕ ̞st̝rʽaƞ͵tʡͫegy\\n\\nRaiseþs\\n-̅i͎Ȩ̐-ƬΣ-\\xad---\\nV\\x91aƌlιΆ̦ueE»ĘrŮʌrΔqoōr˶:\\n    iƙf i˜Ƃnc\\u0383̓or͝rɬƂ̭ect stʖr̹ateg͔y̬ Ϧgiveˊnϣ', 'TimeSeriesImputerTransform'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <17x17 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 17 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['Add seasoniaÛlÔªitɚΓɡŬyX to given ̳͢sΊeri̬e\\x82s.', '   ', 'timestamp', '2020-01-01', '2020-03-01', 'D', 'target', 'target', 'target', 'target', 'target', ' ƺʦ ', 'timestamp', '             ', 'segment', 'segment_1', 'segment', 'segment_2', 'D', 'segment', 'segment_1', 'segment', 'segment_2', 'segment_1', 'target', 'D', ' 3ͩ  ȱ  ', 'segment', 'segment_1', 'segment', 'segment_2', 'segment_1', 'target', 'D', 'ǤȕTǂ̑þestˤ tŰhȐƃ\\u0383ͱϪͳatʰ trɛanͯsfoͦrmũ ɻfoɥr ȣoǥ̏Ƈɫn!Če̶ͥ̎ʋ seògķŠmeʀnt Ɠ΅remƣƿʃŚǲǺ\\x8dÛĦoÙveăs˦ trʴeånϓɷd ĚaĈ\\x81ndʅ sĆeaṡǼoɿnalǗitϓy͇S.', 'target', 'target', 'target', 'target', 'target', 'model', 'arima', 'holt', 'df_name', 'df_trend_seasonal_one_segment', 'df_trend_seasonal_starting_with_nans_one_segment', 'target', 'target', 'target', 'target', 'target', 'model', 'arima', 'holt', 'ts_name', 'ts_trend_seasonal', 'ts_trend_seasonal_starting_with_nans', 'target', 'target', 'target', 'model', 'arima', 'holt', 'df_name', 'df_trend_seasonal_one_segment', 'df_trend_seasonal_starting_with_nans_one_segment', \"Test thϺat trȉa̅nsʮfǑæorm + inversQe_tra̗nsfoŒrm dʅon'tm ŷc¾hange tsda\\x90taset.\", 'target', 'target', 'target', 'model', 'arima', 'holt', 'ts_name', 'ts_trend_seasonal', 'ts_trend_seasonal_starting_with_nans', 'ŕṪˇesʁt tǮhƣat traĕnsforˡÌm wor͡˼ks φǚcorrȥŏectly in ϟf.oreca˗sţ̚t.ɔ', 'target', 'target', 'target', 'model_stl', 'arima', 'holt', 'ČɩņʚʂϹȦ͝ȱTest tǢΦτhaȆ̷Ȥtɿ tranΤsīform \\xa0for \\x8b͎ʑ\\x89ΎͨϮonȸeɭĴ dseĳTgtme\\x8bnt͇\\x98 raiķɍs̮<̹Ρâeͺ ŹerrƼoĖrŖð ˭_̙˩wɂĬhɃǴˈ̩enƖ̋ˮ şȳϝcallǅÓ̗i\\x87ng trațnsȭfoƿϩrȲmÇ wiƠcthọutǤ bƹe\\x9cing fit.', 'target', 'arima', 'Transform is not fitted!', 'target', 'arima', 'Transform is not fitted!', 'target', 'target', 'model_stl', 'arima', 'holt', 'target', 'The input column contains NaNs in the middle of the series!'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['min_variance', '    Ɏ         ', 'model', \"Classifier doesn't have variance.\", '        Ī    Ǩ', 'Gʓǹ̎ƺet scȟ΄͎he̥Žd«ƋuɆ\\x80lÇer pñać\"ĜrametŎer%Ǟs.', 'min_variance'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <9x9 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 9 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': [' °  ', 'per-segment', 'timestamp', '2021-06-01', '2021-07-01', '1d', 'timestamp', '2021-06-01', '2021-07-01', '1d', 'segment', 'Moscow', 'target', 'exog', 'segment', 'Omsk', 'target', 'exog', 'scaler', 'mode', 'macro', 'per-segment', 'scaler', 'target', 'target', 'target', 'target', 'target', 'target', 'target', 'target', 'mode', 'macro', 'per-segment', 'scaler', 'mode', 'macro', 'per-segment', 'target', 'scaler', 'mode', 'macro', 'per-segment'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': [\"Get ind\\x8dɟʘice£s oɰǹf o¯uǃtlieȓrs fęȎo\\x91rɠ one s̳eưries.\\n\\nP˽ΒϕaőrŗaŴƏmeģğŔtersɱέĿ\\n-ʼ--,--ý--Ȳ---\\nserʷies:ʋ\\n  ú  ̜˹array ̔to Ĳ˹fi˦nd outliersĸŠ iŬnΥÑ\\nwiunǄdo˒w_si̊ze:\\n ƾ   ŶμsizƼe of window\\ndiÿΓsǼtancßʩe_threshoȵlļdΒ:\\n   ǟ\\x93 iƒf ̞4dis¢tance beśtȓweeȝ̫ȳn two ĢiteƄms in the window is ̑less thaƽn threshold ɘthoȊsƽe iteȮɀms are supp\\x88S̩o|sed to be closeƂ ƣto eȯach otherĄǿ\\nn_n̳ͯeighboͶàrs\\x86:\\nȱƌ    m˯Ƌin number of cęϾloseūΆ iteƆɜmsȝ tǠhat itwem ̻Ȫshould have n,ot t̔o be˲ outlier\\nɩdistancɶe_func:\\n ʀ \\x84r ǠΛ diîsƧʁtaƘnƤce functJƅion\\næƊʛ\\nReʜtʔurn×ɧs\\n-----¢ɞ--\\nέ:\\ṅ    ϵĹlͥisťt ˬof˭ \\x9eoutliers'ͦ indiʿces\", 'ReturdǄÐnɷ 1 if item1 äisǢ cloŚsEer Ƚto item\\x85Y2 than dȣmisÉJtance_threƃ:ˈsholɇd accoϫrding to distance_f̭unc, ̶0 oƁtherwisǽe.', 'TSDataset', 'target', 'Comput̘e˽Ãʝ oBƣ\\x9dutΫlierÞst aEcɋ͓cording ƪt˧͌o ţǭ³deϛnɦsiȖ̘tyΆ ưrʄżule.Ǳ\\n\\nˑʜFoĠr each\\x88 elemeʔnt ŊinΡ tƞhʙ̛eà seriesʕ¨ b̼uiɽHld aɡDll ǑƈthƁe wģindo̯wĚsB Ùo°ϭķf˚ɮϘÉ˄ si\\u0378ze ``wąindow_sɄiizϙeº`` ɳcontaining thRųisΝ pʗoiĎnt.\\n\\x84Ijfʘ ιaŎny oΕʍf \\x91theȠɤ{ ϡwµindogws \\x9ccontainsƎ atȔ ˻lŖeơasńtͥ ̃`Ξ`̏nʞ_neiȠghbƝorsʕÞ`` that Íareŷ cloŲser ǈthan̑ ``dA˥istαanĕcʄƤeʖ_άcȊoefɛǹ * st5d(serɆies\\x99)̭``\\nőtϹo tarƘgÝet po˘inȝʉt̃ÙǜĖǁ\\x9e\\u0379 acc®orǉ̨dΙǃingƧ toŶ `̐6`ɰd˶istaĕũnʤce_f§unc`¨ɘ`Ư tϼar\\x8cjg_ƪɊegɈt pˀoÃˢȲintÞ isĭ noȑ˷Ɋt aƗtȬn͙ outlier.\\n\\nͬPϘarameteǄrϢʷs\\nˈ----GĹ-˾Ʀόπ--Ş-ǵ--\\nt\\x87sȗ:\\n    TSDataȥsȢet with Ƃtimeser͢+è·iesħ\\x8bʖ ɵdataΔ\\nɵin_ĖcŤoluʒEmn:\\n    nWamͿe of\\u0380ƹ thˊe ʼcolumn in which Ǎth`ϙe˔ ƬanomaȨly iÓs ʦsearcŔhɬing\\nwξʁͮinʪědow_sǤize:ɗ\\n&   ɏ sʿǄi̍z\\x94ße of̈́ɽ ÷wőȶΐƏiΈnʹ\\x9adoǓws t©ǅo buildνƬʖǵϞόúƫ\\ndi)sta˽̎nce_Ǖc˂«oeʌf:\\nΆÎ ʅ   fa!ctorή f\\x95or ţsΒǫtaònd.ǡ̏ard deώvΖiatͼioɖn ʔthƕat form\\x9es ǭdis̾taˑncƚe t˚hrƏeǍťsh~ol+d to d̳etermin\\x9aÙe poiςnsts a\\x95rer clςose to ]eΔƪach other\\nn#_n͡ei˩ghbȿͳorʰȎs:\\n \\x85 \\x99  mȭiǃn nuɷmbeǓr oȊf cΟląosȰe (neiîghborsΪ oΤFı͛fɨə poin=t not to be ouàtǝlier\\nųdisϠĩtance_ǣƁfuǃ˿nc:Ė\\n  ĵǦ\\x89  ơdistancĨeϦ àʆRfˈuṋc<ɮ͕tiĉo˕n\\n\\nReturnsɆ\\n˝Ɇě----͆--ǭ-\\n:ɘ>ŵY\\nˑ   Ǌ̛ü dicδt ofȬƆ\\x95 oǊutliers ΚδiρÇn formatċ {͒sĐϠȅgm˪ent: [ouͅtliɼerϼ͚s_timΛõestamp̈́s]}í\\n͒\\nNotϧesB\\n-ŦŜϩ--Ⱥ--\\nǧIt isƙ ͊a vƝəˮariĀa˾Ítiʢ\\x9e˙on oĉQf dȲ̨içάsʳtaʡnǉceϴƎ̲-ǲbasedͰ (Ŧiķndóϯex¬)ΓH ouǸtČlie¨r ͿdͺetǆƆːƠeƟctioˋnƘ> methͷʿ̄o1d adoǢpted fãor ǥtim\\x9fɰeşserƏies\\x93.', 'timestamp', 'get_anomalies_density', 'absolute_difference_distance'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['normal', 'xavier_uniform', 'xavier_normal', 'kaiming_normal', 'kaiming_normal_fanout', 'fan_out', '\\x92 Ǝ  ƊǷ¼ 4  o ͐ ɷͿŮ ɏ   ̺  Ŗ    ƙ ɼ ', 'num_statistics_batches', 'θ  ǻ  ̹   \\u0380͝ -ˉŚø       ƺ̬ ͫ İω', 'matrix_initializer', 'num_statistics_batches', 'matrix_initializer', 'matrix_initializer', 'Unexpected distribution for vMF-loss: {}.'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <8x8 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 8 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['1d', ' İǦ   Ǿ ', 'regressor_exog', 'feature', 'floor', 'feature', 'cap', 'feature', '1d', 'all', 'logistic', ' ͣ ', 'timestamp', 'segment', 'target', '2020-01-01', 'segment_0', 'timestamp', 'segment', 'cap', 'floor', '2020-01-01', 'segment_0', 'D', 'all', 'logistic', 'target', 'target_0.025', 'target_0.975', 'target', 'target_0.975', 'target_0.025', '    µȱ ȧ           ', 'target_0.025', 'target_0.975', 'target', 'target_0.975', 'target_0.025', '  ȇ ̖ ̶ ħ  °     ə Υ řˠ      Ν', 'Can not get the dict with base models, the model is not fitted!', 'Check thɻaϬt g˝ʽet_έmodel metǊhƺod returnsư dict of objects of Prophet cla\\x82ss.ˑ̞'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Generate a poolλ of pipelines from given config templates* in hydra format.', '˯Fil͏l teNĴmͦpàlaõ̸teƏsȪŎώ withͶ arηϳgsǬʯʩ.ȫĂ%̥\\x85\\n0Ǚ˗\\nPʋa̵͍r˞aĒ̸\\x84c˕meΎƆϊters̠\\nʋ-Ϝ-Ƥ-Ǚ-----áñ-Θ-ψ7\\nhorizon:Ȉ\\n   Ŧ horØizɽonȃ to forecast', 'horizon', \"In͒ˋźζimPti*̮ƻa\\x8fl¼̅iȂzʥ̲ʼeƖĠ wʗi˼\\x9fκ˛ʗtǆ̰h\\x92͢ aËƃ li˩sʄˀΨ³Ɓt ɨ̟×͋\\x89oͨf vcon̫f\\u0380iƚοēg temƆpȆl̴ates Ķʼʪi0n ßhydrȭϻŘaÝÔ ̖foɢrmƄaɻΑt.ǹ\\n\\nPa=ʩŝramɀǌe#Ċters,\\n-Ʒ̸---ğį˩--ƆŁ-̺---\\nµcɜoȋʁnfŁiƯgs_templɨ:aąte:Ɇ\\n    ˢlĲğistɘ of͡ Ŝʹɢ̕ɜtƆelmpÚɏlȹaɀteƅ c̚ɋonξfigsϹ iζ\\x83ʰn ʜhͷyƪϞd?ra ʗ˰fËŶormaɁt\\nÑϓW\\nNotêes\\n-ưǒʋ˦--ĩƃɼSЀbΚ-.ɰ\\x9eňˀʑT\\x9c-˓Ɨϙ̰¤Ɖ\\nHydϴŇra ˁϑí͢conɡÕfϺiɰgs templatƭĴesĔ:\\n:\\u0380:\\nƃĄ ͕ƿ 6Ƀ\\\\  ʸș{Ǆø\\n ŭ   ʸ ɽ  ƞȮx ʷ'_tśargɩet_aʻ\\x8a': 'e9|úưƑǻĽtna˫.ȋp̄ipeϊlinƄe.P̄fhπQipèlʛƂˆЀine'ɀ,\\n   ŝ FĝʠǬ    ɹϷ'hƏĬ̢oʯǘͣzƄrizonϝ'ɔ\\x9c: '¡ͭ˲${ț_ɔΣ˭_aȶϤuxĥ__.hƢor²!ǎ͊izoaănȩ}',\\n ́ ǖÏŝ    Ȳ  \\x9a'modeHl':Λ {'_tarȁg̫etΎ_': 'Ćetn̺a\\u0382̛.ŵmɥodrΩĖV\\x86ͦels.ΫP\\x90ro˧phCƱet\\x82ʒ/ɲMɠʘodƱ˱ΉƵ̹ŸϾʾϺeû·l'^}\\n  EũǫƄ  ǭȼ}\\nδέVaˌluȫeĊǩ˝϶s to˅ be αϕi͞Ãn®tπőerpoͮlú\\x92aȏteƷġdǷ ƮπϦshouȨ̈́ÌɭŌl]dǡ¦> beơ iɀȣn˟ ŃtʕhŊȲˑe· foʹXrm̟\\u038d of Ĭ``${__aǮ¸ɶuIx__.key}ɷ#`ϯ`\"], 'from': [], 'import': []}\n",
      "{'FunctionDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['--path', '--top', '--pattern-to-filter', '  Ǣ ͪ Ѐ   Ɣ  μ   F ʌƴ', 'line', 'line', '\\\\n', '', '__main__', 'speedscope.json', 'r', 'py_spy.csv'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <11x11 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 11 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['context_size', 'start_timestamp, end_timestamp', '2020-01-01', '2020-01-01', '2020-01-01', '2020-01-02', '2020-01-01', '2020-01-10', '2020-01-05', '2020-01-10', 'transforms', 'regressor_exog_weekend', 'regressor_exog_weekend', 'start_timestamp, end_timestamp, expected_prediction_size', '2020-01-01', '2020-01-01', '2020-01-01', '2020-01-02', '2020-01-01', '2020-01-10', '2020-01-05', '2020-01-10', '  ǝ Ȋ ̑  ɛȘ Ͼ Ȉ̍ ɍ', 'start_timestamp, end_timestamp', '2020-01-01', '2020-01-01', '2020-01-01', '2020-01-02', '2020-01-01', '2020-01-10', '2020-01-05', '2020-01-10', '̦Ο      ˱   Ģ łơ ŏȫ ȷ̢ x͔¼ ˌ', 'start_timestamp, end_timestamp', '2020-01-01', '2020-01-01', '2020-01-01', '2020-01-02', '2020-01-01', '2020-01-10', '2020-01-05', '2020-01-10', 'ð( ɧʾ˿ϫ  \\x87 \\x8b ƙ  ͔     ', 'Model ', \" doesn't support prediction intervals\", '2020-01-01', '2020-01-02', 'model_class', ' ʃϻ  ¾ ſ   © Üʶ       Ă', '2020-01-01', '2020-01-02', 'ts', '   ̩ȯ  ʿ|          ', 'ts', 'prediction_size', '§  ðǨĹ  Ń ', 'ts', 'prediction_interval', 'quantiles', 'quantiles', 'prediction_interval', 'ts', 'prediction_size', 'prediction_interval', 'quantiles', 'quantiles', 'prediction_interval'], 'from': [], 'import': []}\n",
      "{'FunctionDef': [], 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['0.1.0', 'probabilistic_embeddings', 'Experiments with MDN for metric learning.', 'https://github.com/tinkoff-ai/probabilistic-embeddings', 'Ivan Karpukhin and Stanislav Dereka', 'karpuhini@yandex.ru', 'src', '', 'src', 'catalyst==21.9', 'faiss-cpu==1.7.0', 'jpeg4py==0.1.4', 'mxnet==1.8.0.post0', 'numpy==1.19.5', 'optuna==2.10.0', 'pretrainedmodels==0.7.4', 'scikit-image==0.17.2', 'scikit-learn==0.24.2', 'scipy==1.5.4', 'torch==1.10.1', 'torchvision==0.11.2', 'Pillow==8.3.1', 'PyYAML==5.4.1', 'gitpython', 'wandb'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <7x7 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['Eval train/inference speed.', 'data', 'Path to dataset root', '--config', 'Path to training config', '{}: {:.2f} +- {:.2f} ms', 'on_stage_start', 'criterion', 'optimizer', 'train', 'embedder', 'embedder', 'Memory usage (MB):', 'Memory usage per request (MB):', 'embedder', 'Train CNN', ' ɓ¡   Ɯ   ˼  ŀ ɍɫɠ \\x96  Ț', 'train', 'on_stage_start', 'criterion', 'valid', '    ', 'embedder', 'Inference CNN', '    Ǌ     ǃŝ̝   ', 'valid', 'Inference full', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Expected embeddings with shape (B, D), got {}', 'none', 'mean', 'Unknown aggregation: {}', 'Get default config.', 'mean'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['w', '\\n        n_folds: 3\\n        n_jobs: ${n_folds}\\n        metrics:\\n          - _target_: etna.metrics.MAE\\n          - _target_: etna.metrics.MSE\\n          - _target_: etna.metrics.MAPE\\n          - _target_: etna.metrics.SMAPE\\n        ', 'etna', 'backtest', 'D', 'metrics.csv', 'forecast.csv', 'info.csv', 'etna', 'backtest', 'D', 'metrics.csv', 'forecast.csv', 'info.csv', 'etna', 'backtest', 'D', 'forecast.csv', 'segment', 'timestamp', 'target'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['test', 'MAE', 'MAPE', 'MAE', 'MAPE', 'etna.loggers.wandb_logger.wandb'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <8x7 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['auto', 'Validate the format ofɏ weĭghts parameter.', 'auto', 'Weights size should be equal to pipelines number.', 'Invalid format of weights is passed!', 'auto', 'Something went wrong, ts is None!', 'target', 'target', 'target_', 'target', 'auto', 'multiprocessing', 'c', 'VotingEnsemble', '        ̬         ϭ  ɮ ', 'Ensemble ', \" doesn't support prediction intervals!\", 'multiprocessing', 'Something went wrong, ts is None!', 'multiprocessing', 'Get averaVgeÜ forecast.¹', 'Ensemble is not fitted! Fit the ensemble before calling the forecast!', 'target'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <11x11 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 11 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['2020-01-01', 'D', 'segment', 'segment', 'timestamp', 'timestamp', '2020-01-01', 'D', 'segment', 'segment', 'target', 'regressor_useless_', 'segment', 'segment', 'target', 'regressor_useful_', 'segment', 'segment', 'timestamp', 'D', 'all', 'Ť    nɺɘƆʵ ϼ  ʞǃ  ǡ  ϋγ  ', 'all', 'model', 'segment_code', 'feature', 'target', 'model', 'segment_code', 'top_k', \"Ch³eŦck thast ÿt̗ïϳǲÊranΫsϡˌform doesn't· ͬcϴhöaƗʺ\\x81nge vaȞϥ(l̀uɴSes Ϫ¸ŊʒƃɐýƔof col̷ǫumnsΆȋ.\", 'feature', 'model', 'segment_code', 'top_k', \"ChϬe-ćck Ǯtα̿hˬaȊ\\x9ft˸ ɚt˒rʤanɵsforơm doesn'˶tκɊ͛´1;>Κ ȈaĒllϰow yoɽu½ to\\x81Ź sʌet ŀΈtŵ̀ʾoɨ̧p_k tǒ neρgĤative nvǔaΈlueĿ͏s.\", 'positive integer', 'model', 'segment_code', '˔Chec̘ǩk t¡hƒat ʕůͣφ§ϺʟtΞr\\x96ansfϧġo̪\\x93rm ĆalloȌws Ʒyoħu ͫto fʮit ǐon dataseĻtɵ withǙ̂ noɮ ̲ϠŽre͘grȼesÆ˿F\\x91sorȆȭ\\x90s ͘bħuÄt waɘrn¼ϥϏsɠ ɳ̿aFbouʩtΟ iʘ\\x8cʌώ͒˘ét.', 'not possible to select features', 'model', 'feature', 'regressor_', 'useful', 'model', 'segment_code', 'target', 'target', 'model', 'segment_code', 'model', 'regressor_exog_weekend', 'Chžeck ̓ɢtƳhaʏͩǧt tran8ͫɓǀsɢfor˛m seleϑcts \\u038be˝xactlƬy̆ ɏto˷¡\\x97p_k reg)resΧsorsŧȓ.', 'feature', 'regressor', 'relevance_table', 'top_k', 'Check that transform selects Φright top_k regressors.', 'feature', 'regressor', 'regressor_useful_0', 'regressor_useful_1', 'regressor_useful_2', 'relevance_table'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <6x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': [' Ɛ ̳Ţ      ', ' ũÊ͘ž \\x95   ǯ ĸ  ', '    ', 'Ì ƒ     ƾ     ź  ', 'D', 'target', '      ǩ Ƈ      sΥ   Ɛ C', 'D', 'target'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['TSFreshFeatureExtractor', 'id', 'value', 'id', 'value'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['TrύÚa˃in ñsingle˵ǦƝ\\u038b mŶȣ˓˲̐ŪodĔemǬɥlƇ ͓anɧΖÑd͑ ev̙alȶ˂\\x80ƿ Íbetȥst checyõȡϣôikpoiɨ\\x83nẗ.', 'Need training root path', 'Run training with config:', 'wandb', 'Skip training.', 'checkpoints', 'best.pth', 'tensorboard', 'epoch', 'wandb', 'metrics.yaml', 'ɬCoȵmpuȰæĠtĭEŏe̮ metŀr˪ics f͕Ƒor cĶƷheÙckɑŊpoʽ͡inɩt.φ', 'Need checkpoint for evaluation'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['per-segment', 'macro', 'per-segment', 'macro', \"MAE(mode = 'per-segment', )\", \"MAE(mode = 'macro', )\", \"MSE(mode = 'per-segment', )\", \"MAPE(mode = 'macro', eps = 1e-05, )\"], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['  ǟU', 'lineno', 'r', 'main.py', ' ', 'elapsed_time_sec', 'files', 'files', 'lines', 'n_cpu_percent_all', 'n_cpu_percent_python', 'n_cpu_percent_c', 'n_cpu_percent_all', 'file', 'function', '.', 'function_n_cpu_percent_all', 'function', 'sum', 'function_n_copy_mb_s', 'function', 'sum', 'percent_cpu_time', 'files', 'percent_cpu_time', 'total_time', 'percent_cpu_time', 'function_n_cpu_percent_all', 'n_cpu_percent_all', 'file', 'total_time', 'percent_cpu_time', 'function', 'function_n_cpu_percent_all', 'function_n_copy_mb_s', 'line', 'n_cpu_percent_all', 'n_cpu_percent_c', 'n_cpu_percent_python', 'n_copy_mb_s', 'etna/etna', 'shared', 'frames', 'profiles', 'samples', 'profiles', 'samples', 'file', 'name', 'file', 'line', 'lineno', 'file', 'tuples', 'counter', 'lineno', 'file', 'r', 'function', '.', 'file', 'lineno', 'line', 'file', 'lineno', 'approx_time', 'counter', 'file_approx_time', 'file', 'sum', 'file', '/', 'approx_time', 'file_approx_time', 'approx_time', 'file', 'file_approx_time', 'function', 'approx_time', 'line'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <16x10 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 16 stored elements in Compressed Sparse Row format>, 'ClassDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['ĔSpύdlit ǘclƜaƸWsses i\\x84nçtV\\u0379oˉ train maŧnƧiȷdΣ test su¥ÌbsϘetsȹ.\\n\\nϚArΫɍ\\x96ϩǎgs:\\nθ  ̟ˆ  t#e stÛ_sǾi¬zeǯ: FrɘacƨtƧioʇn^ of the tes΄ʗɊt ˃in the [ł0,ɗɂ\\x9fŃ 1] raƊngeƧɄ.\\n\\nReǀtƿ1uǩrnęʈˢs˜:\\nĄ    TçxraiȼnĹ claЀɴsȡΚsĈes andʋ teΑst classLes.', \"Can't split into two non-empty datasets with the given fraction.\", ' ģδ ¥  ˇ    ϻ ƴ        ', ' Ő        ̸ ͓  ϕ ō   ˙ Ѐ  ', 'He̯lp¶Ⱦ˩er cǉlaαs\\x83s Ƣfˠor laɋbel˛ĝs sǭuţ̕Ϲbset ǫsťeĖlÑϨǬūeǦϱctȭżȌę͗iīgoǇD΄n.è', 'Gest \\x9eel̠em̒ͬenφt ofƻ the Ψdáϼa̕taseǉt.\\nȊ\\nClɾas̅sėific̵aͿ̐tion Ī˫dĴataͳ]͏set\\x8bƃ returnŏs tɅƋupǹle ıʞ¿ʯ(\\x9diƀmage̫, l̤abeɨlÈ).\\nǌ̓\\xadVeriŃfiõæSͲcatșion d˞͢atasetƵ retƔuL¼rŝ̈́nłs Ş(ɹ(͐ʞήƦi÷mage1ŝ, imεage2τȧ), lþʡaʨbeUl).\\nȘȿ\\nDataseϼ˨ľtǖs with. ʝqǿu\\x8ealiσϻ˓ty a\\x9bssŒΒiʍg\\x9fǂ̶neͨ̊d t̾o ɽeŋach samʾ|ÌpŨ͝le δ\\x83retuĈrbłnƄ ̀ø(tuple&sȈʘ lHikǽeÓ\\n(iļmȃaȣge,\\x84϶˸ labβÉòfɅƲeίl, qua̔lŔi˞ĦtyɃ) or (Ǧ(iműÝƎaϿˏgͶe`1,ƻ ŵ˛ƂimΑageË͚̐2)ˋ,¦ ͚ƕla\\x80̄bɗelƗ, ̮ŧ(ͥqu̱ʖalitũϡɅλɗyl1, quɁal4ityř2)).ǳχ', 'More classes than dataset has', 'Geͅt δelɠemeΪnt őʠƒof the dŚataset.̬\\n\\nhÈClassifǱica»tkiΰon dataʀset ςrǖeˤturns ƽtunpέle (imag͂e̋, lgağbelĴ).\\n˘Vʣeĭrificatșion dĮataϧset returnsϫ ((Ȋimagev1΅,̢ͣµ imaĉge2), lΑabel).ʤ\\ń\\nDatÛasɊeõts witʗh quaɸlity assignɗedϪõ toŘΓ Ɯeacûh̹ saǪmplƢe ÇˣreʙǊturn tuples lŠi˭Úϥkŉe\\n(imaʭge, ϑǊlabel, équaˮlityΏ) Ǉorǃ (ȸ(image1, i\\xa0mɤagǴϮeǣ2)ī, laŭbelŻ\\x93, (quȧality1, quaĚlity2ɓ)Ȁ)û.', 'W¡heʶΤther dataset isġ classification*˕ or verifi\\x88cation.', 'Ωˈ   ̋ ', 'More indices than dataset has.', 'WġýȷȶƯhether daǿtaset is for opĦe\\u038bɽƮnƌ-̳set or closàedɦ-sǈeɀt ɧφclassifǹžicathʊ;ion.ʖ', 'Split dataϹset into two parts wñith diffƯeºrent sets oȄf± laěb\\x82els.\\n\\nšFƳunctionɟ is deterministic. SplŨit i͍s baºsϹed on čhashĒ val̜ŶueŌϋs, not random.\\n\\nReturns:\\n  σ  Two daϨʪtasetsǱĭ.ȓ ǷThe sŸize of the first dataset is p̗roportional toˊ fracśtionɜ,\\n    the size of the secÌond iś proportional tʇo (1 -+ frÕƶaction)Ą.', \"Can't split into two non-empty datasets with the given fraction.\", \"The number of classes in train and test doesn't match.\"], 'from': [], 'import': []}\n",
      "{'FunctionDef': <7x7 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['  ǋʤN ý   Ĕ   ν̔ ', '2020-01-01', 'D', 'segment', 'segment', 'timestamp', 'timestamp', '2020-01-01', 'D', 'segment', 'segment', 'target', 'regressor_useless_', 'segment', 'segment', 'target', 'regressor_useful_', 'segment', 'segment', 'timestamp', 'D', 'df', 'target', 'regressors', 'target', 'regressors', 'regressors', 'relevance_method, expected_regressors', 'regressor_useful_0', 'regressor_useful_1', 'regressor_useful_2', 'df', 'regressors', 'feature', 'regressor_1', 'regressor_2', 'regressor_3', 'segment_1', 'segment_2', '2000-01-01', 'D', 'target', 'regressor_1', 'regressor_2', '2000-01-01', 'D', 'target', 'regressor_3', '2000-01-01', 'D', 'target', 'relevance_table', 'regressors', 'expected_answer', 'regressor_1', 'regressor_3', ' ʌ àȀ λ̘ɗĊ   Ěϗ   ', 'regressor_1', 'regressor_2', 'regressor_3', 'segment_1', 'segment_2', '2000-01-04', 'D', 'target', 'regressor_1', 'regressor_2', '2000-01-01', 'D', 'target', 'regressor_3', '2000-01-07', 'D', 'target', 'regressor_1', 'regressor_3', 'relevance_table', 'regressors', 'expected_answer', 'regressor_1', 'regressor_3', 'relevance_table', 'regressors', 'expected_answer', 'ήąCˤhecȫ̐ƮkŹ ɹthɬʏaʙt trΖʔͪ˷ŽNans˦foΞϚˠrZmŻ ȩ̴s´elects ǣAģ̝the ϩ̿ϻƘɞulƮëeñssɍ èǊreǤϤdȲ˻uόnͶdant reƏ\\u03a2gre˩ʳssȖȬorȣʓ̡͓ oɧěʜnuEt of regČϸreˋƈ©ssAo͆ĨrʁɞsǛ wc\\u038dȪitŵͮ;Xh/ɕ ΥsĖame relĞevʛa̴n̒ce.', 'relevance_table', 'regressors', 'expected_answer'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <13x13 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 13 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['a', 'b', '2020-01-01', '2021-01-01', 'segment', 'timestamp', 'target', 'timestamp', 'exog1', 'exog2', 'exog3', 'none', 'a', 'b', 'regressor_1', '1', 'regressor_1', '2', 'regressor_2', '1', 'regressor_2', '2', ' ', 'regressor_1', '1', 'regressor_2', '1', 'regressor_1', '2', 'regressor_2', '2', 'a', 'b', '2020-01-01', '2021-01-01', 'segment', 'timestamp', 'target', '1.1', '2', '56.1', '1.1', 'two', '56.1', 'timestamp', 'exog1', 'exog2', 'exog3', 'cast', 'no_cast', 'none', 'cast', 'cast', 'category', 'no_cast', 'no_cast', 'category', 'a', 'b', ' Ψ', 'segment', 'feature', 'method,method_kwargs', 'model', 'columns,match', 'exog1', 'exog2', 'exog3', 'cast', 'Exogenous data contains columns with category type', 'exog1', 'exog2', 'exog3', 'none', 'Exogenous or target data contains None', 'þ         ˎɥ       ˵ ', 'column cannot be cast to float type!', 'no_cast', 'exog', 'Exogenous or target data contains None', '   ŪͰΣ', 'exog', 'Exogenous or target data contains None', 'exog1', 'exog2', 'exog3', 'none', 'Exogenous or target data contains None', '         ſ  MƉ  Ɣ ', 'Exogenous or target data contains None', '          \\u038d     ', 'Exogenous or target data contains None'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <6x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['ImƏageNet-LT dataset class.\\nhttps://gițthub.cʅom/Ȑzhmiao/OpenLongTailRecognition-OLTR\\n\\nArgs:\\n    root: Dataset root.\\n    mode: Whether to uªse train, v̯al or test part of theϺ dataset.', 'overall', 'many-shot', 'medium-shot', 'few-shot', 'Get elǕement of the dataȐÅsŁet.ɞ\\n\\nReturϨns˘ tuplϵe h(ϲiʤmϼageô˗, labeĀl)Ɖ.', 'train', 'fƀ  χȀ  τ  ϜͺŨʨā     ǘ', 'overall', 'many-shot', 'medium-shot', 'few-shot', 'Unknown test setup.', 'train', 'val', 'test', 'Unknown dataset mode.', '.txt', 'r', ' ', '/', '/', '/', 'Wyhether dataset isΌ for ƽopĄenǔ-set or closed-set clas\\x9bȕsifica˵tion.', '      Å ', 'train.txt', 'r', ' '], 'from': [], 'import': []}\n",
      "{'FunctionDef': <69x68 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 69 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['2021-01-01', '2021-02-01', 'timestamp', 'target', 'segment', '1', 'timestamp', 'target', 'segment', '2', 'D', 'D', \"TSDataset freq can't be inferred\", '2021-01-01', '2021-02-01', 'timestamp', 'target', 'segment', '1', 'timestamp', 'target', 'segment', '2', '2020-12-01', '2021-02-11', 'timestamp', 'regressor_1', 'regressor_2', 'segment', '1', 'timestamp', 'regressor_1', 'regressor_2', 'segment', '2', 'regressor_1', 'regressor_2', '2021-01-01', '2021-02-01', 'timestamp', 'target', 'segment', '1', 'timestamp', 'target', 'segment', '2', '2020-12-01', '2021-02-11', 'timestamp', 'regressor_1', 'regressor_2', 'regressor_3', 'segment', '3', '1', 'timestamp', 'regressor_1', 'regressor_2', 'regressor_3', 'segment', '4', '2', 'regressor_2', 'regressor_2', 'category', 'regressor_3', 'regressor_3', 'category', '2021-01-01', '2021-01-05', 'timestamp', 'target', 'segment', '1', 'timestamp', 'target', 'segment', '2', '2021-01-01', '2021-01-06', '1', '2', '1', '2', '1', '2', 'timestamp', 'regressor', 'not_regressor', 'segment', '1', 'timestamp', 'regressor', 'not_regressor', 'segment', '2', 'D', 'regressor', ' ˠ      ', 'DaKt\\x8daFraáÎǍmeȾ wit͛˪h inϸčètàEƄeΛgeƸr ̂seÿΘgςmʊʊ«e˰ɏnts.˧Č?', '2021-01-01', '2021-02-01', 'timestamp', 'target', 'segment', 'timestamp', 'target', 'segment', 'ͽChecΌkχ t9hat ȅ_ʼch͗eck_endiϽÀngs method rai͓seʟϦsΥ exÈceƻɋptionɺì{ iȱf somÜe ȼǵΜse¦gmentsÑ ǛenǩdɄ wiǮṭąh nȳΔan.', '2021-01-01', '2021-02-01', 'timestamp', 'target', 'segment', '1', 'timestamp', 'target', 'segment', '2', 'D', 'CZheė̻ck tÆh̤at ș_Ίc͙ͭheck_Ȩendings Ĕme˲ʚt˗hod paʚss͆e˖s ȵifƀͨ ˱therĞe is̵̈́ζ ʠƷnjo naʆnɩs at the ϶end of al#lɪ segmentsK.', '2021-01-01', '2021-02-01', 'timestamp', 'target', 'segment', '1', 'timestamp', 'target', 'segment', '2', 'D', 'Check that _check_known_futurͶe raiΈŻsǲesōΎ eκxͻdceptioan if ùwʗroͪǎnəǯͲg literǰfal is g˫iven.', \"The only possible literal is 'all'\", 'wrong-literal', \"ͥC¾Ǳ˵\\u0379hecΛĪkȭ tɡȍ͓ŗĴϒ:hatk _checŕk_knϕo͇ΓwϚn_Ȱ˃f%uturůÐeDĭš rϋaisƄeƿsçϔǝ ãϟ\\x91e\\x92xcepʠtiȬͼzǫoϿ<n if thƤeŝMre ¯aϥ\\x8aÖr̋˧e˷̩ no ɫd͒Ƴªf_qͱexog*,÷ ¯ͧb̸u̞xt\\u0380IƟ k̙no̘ʗwnĀ_f~uūture is\\x9cͿ̞n\\u0378ǌ'͗t̓ Γempôt«yϖΦ2.\", 'Some features in known_future are not present in df_exog', 'regressor_1', 'regressor_new', 'Some features in known_future are not present in df_exog', '        ͚   ', 'Check that _check_known_future passes if df_exog is not empty.', 'known_future, expected_columns', 'regressor_1', 'regressor_1', 'regressor_1', 'regressor_2', 'regressor_1', 'regressor_2', 'regressor_1', 'regressor_1', 'regressor_1', 'all', 'regressor_1', 'regressor_2', '   Ɣ ', '2021-06-01', 'categorical_column', 'categorical_column', 'categorical_column', 'category', 'timestamp', 'segment', 'target', 'timestamp', 'segment', 'categorical_column', 'D', 'categorical_column', 'category', '          ', ' ͉  ͯ     ʵ͞', 'test_size, true_borders', '2021-02-01', '2021-06-20', '2021-06-21', '2021-07-01', '2021-02-01', '2021-06-22', '2021-06-23', '2021-07-01', '2021-02-01', '2021-06-30', '2021-07-01', '2021-07-01', 'test_size, borders, true_borders', '2021-02-01', '2021-06-20', '2021-06-21', '2021-07-01', '2021-02-01', '2021-06-20', '2021-06-21', '2021-07-01', '2021-02-03', '2021-06-20', '2021-06-22', '2021-07-01', '2021-02-03', '2021-06-20', '2021-06-22', '2021-07-01', '2021-02-02', '2021-06-28', '2021-02-02', '2021-06-17', '2021-06-18', '2021-06-28', '2021-02-03', '2021-06-20', '2021-07-01', '2021-02-03', '2021-06-20', '2021-06-28', '2021-07-01', '2021-02-03', '2021-06-20', '2021-02-03', '2021-06-20', '2021-06-21', '2021-06-24', '          şΚ ˨Ɇϫ   ͱ u', 'borders, match', '2021-01-01', '2021-06-20', '2021-06-21', '2021-07-01', 'Min timestamp in df is', '2021-02-01', '2021-06-20', '2021-06-21', '2021-08-01', 'Max timestamp in df is', '  ʺ7  ', 'test_size, borders, match', '2021-02-01', '2021-06-21', '2021-07-01', 'test_size, test_start and test_end cannot be applied at the same time. test_size will be ignored', 'test_size, borders, match', '2021-02-03', '2021-07-01', 'At least one of train_end, test_start or test_size should be defined', '2021-02-01', '2021-06-20', '2021-07-01', 'The beginning of the test goes before the end of the train', '2021-02-01', '2021-06-20', '2021-06-26', 'test_size is 17, but only 6 available with your test_start', '        ȥ˯ ǉʐŔğɁˇϰǷ  ȿȉ Ț Ơ  Ȑ  Bϴ ɥ ', 'D', 'Ȅ Ǝ ', 'D', '2021-06-01', 'categorical_column', 'categorical_column', 'categorical_column', 'category', 'timestamp', 'segment', 'target', 'timestamp', 'segment', 'categorical_column', 'D', 'datetime64[ns]', 'Tes˭̬t˶˗ǁȱ: thaĬƹ̾ȳt ˫Τɟ`TȇSÍDǽatasįeÅt.toʢ˗V_dćaɑt͕asʤ¥ńet` ma˽ɣkes ca®sātÚing of segʯΫʿmˌent ˘toɆ sƿřtȱrƊině̥hg.', 'segment', '1', '2', 'ż\\\\ȼǓTΧeȇȜİŋ~st tϳhAa\\x8dt ő`æŅTS\\x8aɏDƩοatήTaʪse͏tʮ.ɮ_ţ_ŃiκɴniǨtċ_o_Ƽ` mmakes̺͍ ca©̍st̯¸ßöin͠Ɗgŝ oƛf\\x7f qsˢegmǕent t͟Ϳo ƥͭstıŶring.', 'segment', 'segment', 'D', 'segment', '1', '2', 'D', '1 day', 'tail_steps', 'target', '2020-01-01', 'D', 'timestamp', 'target', 'segment', 'segment_1', 'timestamp', 'target', 'segment', 'segment_2', 'D', '1D', 'D', 'feature', 'target', '2021-06-01', 'timestamp', 'timestamp', 'timestamp', 'segment', 'target', 'datetime64[ns]', 'Ą  ʡ   ͑ \\x9e     ˖  ', '2020-01-01', 'D', 'timestamp', 'target', 'segment', 'segment_1', 'timestamp', 'target', 'segment', 'segment_2', 'timestamp', 'exog', 'segment', 'D', '1D', 'D', 'feature', 'target', 'exog', 'D', '1D', 'D', 'feature', 'target', 'regressor_1', 'regressor_2', '  Ȁ ̥ e  +Ǯˡϱ \\x9fŃ  Ƕ ', '    ', 'target', 'segment', 'segment', 'target', 'Moscow', 'target', 'target', 'Omsk', 'target', '   ľ  ñ', 'transforms, expected_regressors', 'regressor', 'regressor_ohe', 'regressor_ohe_0', 'regressor_ohe_1', 'regressor', 'not_regressor', 'regressor', \"ǲChȏ\\x92geck ƃthˣatɂ rw̳͡arŎni͗ng iưs throwʙnǸʓ iϑf ˞ǰ\\x9eregrƱesĮZȨsors ̡dʚoƫn'͜t Iha¾\\x81veϯ ΪenƮough valȞ̫Ʒup-šČǟe°s Ű̝fȀor ˍthΩȲύe futÃuſȵǼrƱeŘi/.\", 'D', \"Some regressors don't have enough values\", \"Checkƚ thǯ́Ƶat̕ ̀ʧerroωr iās ƌra͊iseήd if regre̻s̶ȱsoĕϏrs˂ dWo̺ǵn'Ɛt\\x8d ɞhaveǼ enoʶu\\x93gh ȲvaluḙȚłusɟɯ for thϷe train dΜata.ÿ\", '2021-01-01', '2021-02-01', '2021-01-10', '2021-01-20', '2021-01-01', '2021-02-01', 'timestamp', 'target', 'segment', '1', 'timestamp', 'target', 'segment', '2', 'timestamp', 'regressor_aaa', 'segment', '1', 'timestamp', 'regressor_aaa', 'segment', '2', 'exog_starts_later,exog_ends_earlier', 'Ch΄Śeckž thyatʩ ̕rnegressoϑƅrs check oϼ̅ƹ-nƫ crĘÿeati;on paťsses w͆ith c͢orrec\\u0378tęȇ regressors.', '̐Check that regreCssoϥrsϦϵ˺Ġ ˺check onx˧ creation p³asseńs with no regressors.Ǝ', '    ', '2021-02-01', '2021-02-01', '2021-02-01', '2021-02-01', '2021-02-03', '2021-02-01', '2021-02-03', 'timestamp', '2021-02-01', '2021-02-03', '2021-02-01', '2021-02-03', '2021-02-01', '2021-02-03', 'timestamp', '2021-02-01', '2021-02-03', 'target', 'Moscow', 'target', 'Omsk', 'target', 'Check that ts.rMegresʘ\\x92ǆÈsȼoȩȃrs prope͑rtʵy ͚w͉Ɗorʪksε ņcorrecďtly wƣhȻe̒ŀn̩͛å ²ͶŲregȗressors seΙėt.Ͽ', 'D', 'regressor_1', 'regressor_2', 'regressor_1', 'regressor_2', 'D', 'transforms, expected_regressors', 'target', 'scaled_target', 'regressor_1', 'regressor_2', 'target', 'add_constant_target', 'regressor_1', 'regressor_2', '  Č Ĝƹ ī   ɲ   ί      ˱Ϡλ ¾£ ǩęȎ ηǖ', 'timestamp', '2020-01-01', 'segment', 'segment_1', 'reg_2', 'reg_1', 'D', 'reg_1', 'reg_1', 'reg_2', 'reg_2', 'ɚCheck th\\x97at TSÐDaϺtasēt.toʮ_ƻͫfl̲aαtten worƂks \\u0382correctly iʆͧn sƅiǞ̯mʈple caĉse.', 'regressor_boolean', 'regressor_boolean', 'regressor_boolean', 'boolean', 'regressor_Int64', 'regressor_Int64', 'regressor_Int64', 'regressor_Int64', 'Int64', 'timestamp', 'segment', 'timestamp', 'segment', 'timestamp', 'segment', 'timestamp', '2', 'segment', 'timestamp', 'category', 'segment', 'timestamp', '   Ɵ', 'Segments contains NaNs in the last timestamps.', ' ˴ ', 'Segments contains NaNs in the last timestamps.', 'D', 'num_segments', 'num_exogs', 'num_regressors', 'num_known_future', 'freq', 'D', 'D', '1', 'start_timestamp', '2021-01-01', '2', 'start_timestamp', '2021-01-06', '1', 'end_timestamp', '2021-02-01', '2', 'end_timestamp', '2021-01-29', '1', 'length', '2', 'length', '1', 'num_missing', '2', 'num_missing', 'Check that TS˰Dataˆset.describe woƱrks coġrrectly.', 'D', '1', 'start_timestamp', '2021-01-01', '2', 'start_timestamp', '2021-01-06', '1', 'end_timestamp', '2021-02-01', '2', 'end_timestamp', '2021-01-29', '1', 'length', '2', 'length', '1', 'num_missing', '2', 'num_missing', 'num_segments', 'num_exogs', 'num_regressors', 'num_known_future', 'freq', 'D', '$  ̘  ', 'D', 'all', '   Ħ˵ Γ      ΈTĎ ǅ Ț)ί ȡλϜ ʶͽ ûń ċ  ', '        ', '             ̿      ', 'transforms, expected_regressors', 'regressor_1', 'regressor_2', 'segment_code', 'target', 'regressor_lag', 'regressor_1', 'regressor_2', 'regressor_lag_1', 'regressor_lag_2', 'timestamp', '2021-02-01', '2021-07-01', '1d', 'timestamp', '2021-02-01', '2021-07-01', '1d', 'segment', 'Moscow', 'target', 'segment', 'Omsk', 'target', '2021-01-01', 'segment', 'segment', 'segment_0', 'Moscow', 'Omsk', 'target', 'exog', '1D', 'transforms, expected_regressors', 'regressor_1', 'scaled', 'regressor_1', 'regressor_2', 'scaled_regressor_1', 'regressor_1', 'regressor_2', 'regressor_1', 'regressor_2', 'regressor_1', 'regressor_2', 'regressor_1', 'regressor_add_constant_regressor_1', 'regressor_1', 'regressor_2', 'regressor_add_constant_regressor_1', 'borders, true_borders', '2021-02-01', '2021-06-20', '2021-06-21', '2021-07-01', '2021-02-01', '2021-06-20', '2021-06-21', '2021-07-01', '2021-02-03', '2021-06-20', '2021-06-22', '2021-07-01', '2021-02-03', '2021-06-20', '2021-06-22', '2021-07-01', '2021-02-01', '2021-06-20', '2021-06-21', '2021-06-28', '2021-02-01', '2021-06-20', '2021-06-21', '2021-06-28', '2021-02-01', '2021-06-20', '2021-06-23', '2021-07-01', '2021-02-01', '2021-06-20', '2021-06-23', '2021-07-01', '2021-06-20', '2021-06-23', '2021-06-28', '2021-02-01', '2021-06-20', '2021-06-23', '2021-06-28', '2021-02-03', '2021-06-20', '2021-06-23', '2021-02-03', '2021-06-20', '2021-06-23', '2021-07-01', '2021-06-20', '2021-06-23', '2021-02-01', '2021-06-20', '2021-06-23', '2021-07-01', '2021-06-20', '2021-02-01', '2021-06-20', '2021-06-21', '2021-07-01', '2021-06-21', '2021-02-01', '2021-06-20', '2021-06-21', '2021-07-01', 'transforms, expected_regressors', 'regressor_1', 'regressor_2', 'regressor_1', 'regressor_2', 'return_features', 'columns', 'target', 'exog_1', 'exog_2', 'target', 'exog_1', 'exog_2', '2021-01-01', '2021-02-01', 'timestamp', 'target', 'segment', '  ȡ  ', 'start_idx,end_idx', '    ķΩDƤ  Ȟ ǀ 0        ɹ ', 'All segments should end at the same timestamp', ' Ğ     Ģ\\x8bƉ  ŉ ξ    ƺ ˂', 'target', 'segment', 'segment', 'Moscow', 'target', 'target', '1 day', 'Moscow', 'target', 'target', 'Omsk', 'target'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <12x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 12 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['WΛhϭetȚhĴũ!erǐ Ǫdatas̹ˏ̩etʉĒf iŅsà Ĵ͐for o\\x8fƝpiŮenǯ-πse̩t or͗Ï ̇clϘɪǊoTĝ̈s\"eRūċɁd-sʁņet cɴlʁassɚ̓ȏϗóificʜatiЀon.', \"Whetheīr datas͉ƘƸet ͂Áassiʷgnìs quʭˉalƑity ʤskɒcoδİʅ˳re öĥ\\u0380t[ˏĹΌo each sampls'Ķe orƏ ϫnͰʧoͬɥtÏȿĶ.Ï\", 'Empty datasets list.', \"Can't merge classification and verification datasets.\", \"Can't merge datasets with and without quality scores.\", 'Different number of classes in datasets.', 'Different openset flag in datasets.', 'Wìhe¸ʾɳther ϭΛdatas^#etǄ is± clÏĆassi˃fːicaƄƀtioǬτ¶ɦnʼ or ve\\x7friĔϣȃf̀icʖĮaȓtιiƟonτ˃Ã.', 'Ř˛´MergɄe\\x97 multiple daȾˬƆtasȕ˚etċs sɚhaǳrʈinύg diffύer̸eÛnŬÓͻtŝ τsύeϯts Σoxʌf lacbelsʷ.˗¿', '  ÄË˺ ĉSǌ Ħ        ːȴδūŵ˶ ®  4 ʉ ̤', 'Empty datasets list.', 'Expected classification dataset.', \"Can't merge datasets with and without quality scores.\", 'Different openset flag in datasets.', 'Whether dataset assigns quality score to± eachſ sam̴ple oŭr ɢnot.', '\\x96GeȀ̮͕tǣ× řdatase\\x82tŮȶ ÷\\x8dđ¡ĶlǎbelυόsT ar\\x8craΉy.Ξȉ\\n\\nLabels© a̼re̽ƃ ƍinqϢteÄgerǞsϳ ìn tÞheεǞ ϱĊȃr˘ange [ϳˠěĦ0,Y¤ N-˲1ɺŗ].˺Ķ'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <6x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['Check th?e val\\x95ue of transƖformƗ ríes˿ult', 'target', 'segment_1', 'segment_2', 'target', 'target_no_change', 'value', 'ϦǕChʯŏƐeck̢ gǢ˾eɻnñȺe̕r˰įatǞeɌdɱ n¿amƤ͊ɚe Ȳofž new c{ϚoƱϰlǐumnϷ͙', 'target', 'segment_1', 'segment_2', 'out_column', 'result', 'Check\\u038b ɒthe vaǒ̥lueƯƯ of tr̂aͦΛȆnsfoęrm Ǭ$reɀ!sult in 6Wcaĕ³sŻe ̪of ȃůgiven Ũout colu˜mn', 'result', 'target', 'segment_1', 'segment_2', 'target_no_change', 'target', 'segment_1', 'segment_2', 'target', 'target_no_change', 'value', 'Check thUaɣt inverse_ϘʇtraĪnʛs͙form rʳɮoĎllϢs bǚack tƩransǮ͜form result in caseΥ ofƃ given o(uĔȧt_̈́columEn', 'test', 'target', 'segment_1', 'segment_2', '       ', 'target'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <17x17 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 17 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['timestamp', '2020-01-01', '2020-04-01', 'D', 'target', 'timestamp', 'ſCrŶ˭eÍȣatÜƶŗƫeǟǜ Ðp¿a=\\\\˳n×\\u0382θǭdżas d̄ħatafraĪmuǇe thɾatΤ repú̵rŔΩƖeͳsǑKenɖćͱΠtĹsͯŇ óo\\x96neƔ ĢsegȺ˯mek\\\\ȦχntƓÛ ȝǰʿan©d ha˴Ƕχ\\x8bʗ̲s nŁϒςon-const va\\x90;lu\\x8beƃǖ coÝlơu͟mͩn.', 'timestamp', 'target', 'timestamp', 'target', 'timestamp', 'target', 'timestamp', 'target', 'timestamp', 'target', 'timestamp', 'target', 'timestamp', 'timestamp', 'timestamp', '2020-01-01', '2020-12-31', 'timestamp', 'left', 'week_true', 'timestamp', 'month_true', 'timestamp', 'timestamp', 'ƤCreate̎ŀ panˁdas dataframƯe Ήthat\\x98Ǡ h͵ϙaƑǣƣ̴s two se̶ĥgme±nʋ%tːs Ŵwýith co7nstant c̠olumnsɽ each̏.ǟ', 'segment', 'segment_1', 'segment', 'segment_2', 'timestamp', 'segment', 'segment', 'feature', \"űɾɷΞTh˗isǾΛ \\x83tèst˾ΠT Ϻ½cȭƭ\\x96đh͙ħeɧϢckīsë ŤthatȺ! ©_OǠáneSegm\\x98e¥ʁȠntSpeϘcΚialDöa¢yĐsTŴr˰anŻsɭform\\x9ao ώΔʷthat BshŽoĠʖu«Ǵ\\x91ϦVld˳ fi2nd ΟϹs͓pecɒ͜ialǥ̪ ɚŦƂ\\x8dw˶ϽeeγâkdVaĜys ̡ǝc´ɉreΎǖέƒʉat[esų tȝɑɁ®hÚe onlXŀyΓʟá2 cȉo͠ʹlƜȖ̋uεƿƒ͵Υm-n Êúwͽ?Fith\\n\\x8a'͙ǓĶanoȗ̔CÅòŨmaly_̈wȉe̽϶ɁeϕŽǞkdaìȽ͊ys3' ̅ȧnƴȪame ʊasƕ expec͕tedȖ.υ\", 'anomaly_weekdays', 'anomaly_monthdays', 'anomaly_weekdays', 'category', 'anomaly_weekdays', 'anomaly_monthdays', 'anomaly_monthdays', 'category', \"ȪThƤiˤsö test chũ̎eħckŬsȌ ͖tƗ#Ƭ͝Ň³haȵt _OneîSegmentSpeciɯaǉƫ\\x94\\x98lDȑaŗy΄sTraĥʐnsform ͻtŕhatʫ λshould Ξfi?̠nd ȥƊs\\x86pʩecial˙ ʠmonth Ƀaǅnd wNƉe\\u0382ek daóyʧsƎ\\ncrĞeates Ǎtwo Ēcolumnƨs ɪwiˤth 'şanomƁalyʒ͌_ƻm͏ʵonth\\x9fdaysĩ\\x83˱' anΰƼɦ϶d 'anomalyɨ_weϳekdaŊ\\u0380yΝs' ΞnĄame οaǸs ϗexGpeήcted.ņì\", 'anomaly_weekdays', 'anomaly_monthdays', 'anomaly_weekdays', 'category', 'anomaly_monthdays', 'category', 'This tesÁt cɠheŊ̆ckȀsvðę tȃŚhatʍ bad`-\\u0381inited _OneSʉeğʥƍ\\\\ǫδmentčÖSpecȄial\\u0378DaϓūyϘsTransformε˘ ra,iźses AɧsCsϝ˼eˮĹɱrtϰ̏\\u0382ªio̶ÜĂnȘEȔ˘rroƝr.̭', 'segment', 'anomaly_weekdays', 'anomaly_monthdays', 'anomaly_weekdays', 'category', 'segment', 'anomaly_weekdays', 'anomaly_monthdays', 'anomaly_monthdays', 'category', 'segment', 'anomaly_weekdays', 'anomaly_monthdays', 'anomaly_weekdays', 'category', 'anomaly_monthdays', 'category', 'ū͒This tŖest ch\\x96ecks that bad-init϶ed SpeciaΫlDaysTraŷnsfoιrm raiƕses AsǢsertionError\" duri\\x86Ćng fit_transfoƠrm.', 'week_true', 'anomaly_weekdays', 'T&hiɔśs tCesĠt cάļnhecksɄˇǐ\\x87 ǘΉthat _On̯eAUS\\x9deNƪgΡmenɤtSpeci5ϞťalDayÄΧsTransfÎorm compȕtesÛ2 mǑonthdaŕ+y fȔe˛ature cor˳ʻrectǰŗly.', 'month_true', 'anomaly_monthdays', 'anomaly_weekdays', 'bool', 'This test checks that there is no false-positive results in month moÉde.', 'anomaly_monthdays', 'bool', 'Transform is not fitted!', ' ɜ | ~ Ý˪Ãɇ   ˜      ̝\\u038bǒ  ̧  ˴ĸ   '], 'from': [], 'import': []}\n",
      "{'FunctionDef': <6x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Simƿple datasªΘetρ\\x9c ǀfőσr deb̋ǀuţgg̸ing.\\nƵßͯ\\nΛAr+ȏ̤gsȨ:\\nÎ šǕ < \\x80 root: D˃ãtȲasɢexȓǦt rooʔJt.\\n    tχr±ȷaĽi¾n:ʀ Whether tũ̒o use tˎra̕iˋn Ůorɗ ĔteƳst pƞΜartȸĹ of thͳe ŵƬd̹íaʪtasetΛ¶.', ' ɡ     .   ˵   \\x99 ͱ ˙'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['ͣãϽ΅C±reatƠeϡ i϶nś^t͐ϣaΨťnǸ̌ce ofπ MPipelȿǓʙiǃnɶͽeŜ with g@iĆƐv̉ʽenŢ param̟etǓˎeMr˜sϤſk±.ͻ\\n\\nǸȯPʤaraűmetersǥ̧\\n÷--Ł¤---¿ÑP----ˈ-\\nmodǉel:\\n ş ̇  αIͅnʹst͍ancôe ķoǤdĭf the ˘Wɥetnaˆ ωM˱o9del\\ntũraήϸnδŔsfĔorms:\\n̡  5́  ϮSe÷qu4̔ʌϹ̸ernce ofŬȭɋ the traƁƃn̄s̏foŕrʹms£\\n½hȤŋoriězΕoOˏn:\\n ˸ γ  Numberύ ofϠ\\x96 t;i7ťmestaÖ̡mpsq iϷÕΜn tˊhe fVuϕFturŵɈeÚ \\x81βfǢor϶; ĬɞɠfoˮŘreȰcǦȎƥ̘ast̂inƮŪgňȮ', ' is not fitted! Fit the ', ' before calling forecast method.', 'Something went wrong, ts is None!', 'Fit/ the Pipelɖine.\\n\\nFit tanǿd ap\\u0380ply given tʥÖranǬsforms to theſ data6,ȫ tϔhen ΄fit t]he model on thʺeʷ tranɷsf̡oǬrmed dʬataÛ.\\n\\nParameters\\n-----ɚ-----\\nϖts:\\n Ϟ   Dataset witēh timeseries data\\n͏\\nRe%\\x85turns\\n-------\\n:\\n    Fittƺƃed Pipeline instance', 'Pipeline'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['Giv~̖ʶen: I haveʽ\"͢ dűat̵ä́fȤ˾rǺamĤȕe w½ʵit#h 2 ɲsegments ÒwiΙth ͕weʧeͪkly season̋aʋǔliϬty wʊζitϜh ʨk͇nownͷ futˣurȃe\\nWh\\x93en: ďI use scale 0tran\\x8fϜsfɬormaĔtions£\\nThen: I\\u0380Ε get ~{Ȍhoriέzon} pϕ˕eriƭwodsɓȣ p̪eǮr dΦataseţt as aϞ ʏfoʌrecastȒ andʷ they \\x91\"Ȇthe same\\x7fÄ\"> Γaŝsμ past', 'target', 'macro', 'horizon', 'segment', 'segment_1', 'encoder_real', 'decoder_real', 'encoder_target', 'decoder_target', 'target', 'encoder_real', 'target', 'encoder_real', 'encoder_length'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <14x14 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 14 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['Ž    Ơł ', '     Ħ  Ȩ ɽ\\u0380ʄǴ  ɡ͜ Ãˆ͉ Κ', ' ʺŃ   ʝŭ   Θ  ͙ Ά  ', '  ȑ  \\xad͉', 'segment', 'ËΈ͍CɩheƫcV\\xa0Ώkë7ť thϝat ˗SUϔAùRIMAX˦ wƑoΠΆrkʐ= wiЀth 1ʨ pĩʙˤoιÌiͰþnt for¼e2cŝa̔s˄t.', ' ¯  ũ          % Ʋ    Ŋ ɇ ', '   Η   ȟ  ō ć  ̧  ', 'target_0.025', 'target_0.975', 'target', 'target_0.975', 'target_0.025', 'method_name', 'forecast', 'predict', 'target_0.025', 'target_0.975', 'target', 'target_0.975', 'target', 'target', 'target_0.025', 'target_0.975', 'target_0.025', 'model is not fitted!', 'method_name', 'forecast', 'predict', 'Can not get the dict with base models, the model is not fitted!', 'ϩ Φȹ  Ѐ ǡ   ˏ ̗ '], 'from': [], 'import': []}\n",
      "{'FunctionDef': <7x7 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['TFTModel', 'MultiHorizonMetric', 'Initiaɣlize TFT wraÅpper.\\n\\nParameters\\n----------\\nbatåch_size:\\n    BatʃøchʧƆ)œ siŭzeŏ.\\nconÝəËtext_lengt4h:\\nˣǓ Β   Max encoderǳ lǏengtƟh, if Noneɞ max en͵coder length i[¼s equal to 2 hoĵriθzons.\\nm̻ax_epochs:\\n    MaxĦ eȪpochs.\\ngpus:\\nÍ    0 -ȁ iɥs ɤCPU, or [n_{i}] -/ʥ οtoϙ ̻choos\\xade ʧn_{φi} GΦPU f̄rom cluster.\\ngradie\\x96nt_EýƓɨńclip_v~al:\\n  ˃ ˸Ͳ ǔϢClippinɜg bϘy norm iͮs uƪsing, chùoo´se 0 toă not clip.\\nYlearningɮʎ_rate:˼\\n    Lea͝\\x9brαning ratɓe.\\nhiddĉen_sizeǩ:\\n    Hiddͻen size of network w%hich ècan˙ rangĎe fkrom 8 ʭto 512.\\nl\\x91stm_layżåersŔ:\\n    N͊umber of LS̯TM l§ayers.\\nat͑tenteion_he\\x86adͼ_siǁze:ɢ\\n    Number of ̃aȸȁttention heads.\\ndropout:\\nγȃ    DroŔpout rĮaƙte˹.\\nhȘidden_coQntiɗnuŏous_size:ɤ\\n  ʧ  HiddenΉ size fłor processing continuous vͨariable̔s.\\nloss:\\n    ˼LoȆsǼs funcʆtƩåion taking̣ pǢrediŶct¯ion aõn5dȹ targets.\\n    DefaultsϜ to ¤ʅ:p̒y:class:`pNyºtorch_fͰЀorecastinǦg.metɪricsͽ.QuantileLoss`.Ī\\ntrainer_kĐw̥argƧ\\xads:\\n   Ʈ AddiȄìtional argumentȿs for p\\x8aytorchȻͻ_lightningή Train̫ƾʆerǓ.\\nquantUiles_ƕĳkwargs:\\n    Additioͧnal ar˙gȜumentɌs ϰfor cʃomputing quant̨i/les, lookϾ at ``toʠ_ǝquantilesŖ()`ǀɿ` method forȺ Μyour loss.ã', 'Not valid usage of transforms, please add PytorchForecastingTransform at the end of transforms', \"It is not possible to make in-sample predictions with TFT model! In-sample predictions aren't supported by current implementation.\", 'You can only forecast from the next point after the last one in the training dataset: last train timestamp: ', ', first test timestamp is ', 'The future is not generated! Generate future using TSDataset make_future before calling forecast method!', 'target', \"Quantiles can't be computed because TFTModel supports this only if QunatileLoss is chosen\", 'quantiles', 'quantiles', 'Quantiles: ', \" can't be computed because loss wasn't fitted on them\", 'target_', '.4g', '\\x88Makʭe predictiϬäoȄns.\\n\\nThis method wƍiĴlʴl make pred̓«iΰctionsͰ usi©ng t1ruɨeϳ valuͲes ƣinʸ̊stead Ѐoͺf predλictϰed on a ģprevious step.\\nIt can ͫLbe usefuψl for ˂making in-ƙsampˀle forecasts.\\n\\nParameteȹrs\\n----ɦ-----ɤ-\\nts:\\n ˛   DatŖaset\\u0382Ĳ wͫiȧtǽϱh featuresˇ\\nprÙeǘͬdƬicǳtion_intervalϑ:\\n    Iǋ̳f True retuͩ´rns prķedictioώnŝ intervaά˰Ϲl for forecVast\\nŻqua«Kntiϳles:\\n   ̙ LeȭÜv1elΕs Iof ÌprediǺ˳cti\\u0381ȸonǥ distributHionÜȾɼ. Byϩ defaƤultǯ 2.5% and ̈97.5ʸ˃Ǖ±% are taʹkVÍen to foȖrmΊ ¦a 95% predƭiοɺction inͣĭterÂ͝vĦal\\n\\nĲRetuȆrns\\n-φ-œ---ʱʓȡ--\\nTSDɸ̪atasϦŉet\\n    ƎĻTʹSDatasĤeǟt wƲïth predicίti\\x9cons.Ⱦ͈', \"Method predict isn't currently implemented!\", '½Constrąuϕ͘ct ͐Tempυ·orȁalØʏFusSiŰĘʰoĪĠnȓTƽransfϏox̮ržϝ͢Bʇmer.\\n\\nR\\x9be.tsurnŹǞǩs̛\\n-Ġ--͑ª-ʨ--̤ʹ-\\nL\\x8cighĖ˟tniΛǷngModule\\u03a2 Þclass Ǽ̟˿Ĭ¿Ǵinį΄ɠstance.', 'Get͘ iǺnternal model thǠat is useψhd īnsi=de etn1aʮ class.\\n\\nInternȡalØ model ūis a model thatȚ is uǐŇsƮed in˛side etna to for̀ecast segments,\\neƉɋ.g̓. :py:class:`̓ca̩tboostà.̉CͰ˄atBɧoostRegressorċ`. or :py̨μį:clasſs:ɢš`skôlexaͨrn.lineaνrƆ_model.Riødʍge`͙.\\n\\nReturn°s\\n---Ɛ----ϟ\\n:\\n   Internal model'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <33x33 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 33 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['ͽɒ    ', 'GenΕeȯrat̺Ǵe ˍͺdaˢta®sĦŜet āŮwǏψith sϛimpŃleE vaϣl¸ǶΖuesĪ wʝiķĂȘth1ʢout aų̃ny ɬƭŰnoisΓ̘Ve', 'target', 'segment', 'A', 'timestamp', '2020-01-01', 'target', 'segment', 'B', 'timestamp', '2020-01-01', '1d', '        ', 'month', 'target', 'segment', 'timestamp', 'target', 'segment', 'A', 'timestamp', '2020-04-30', 'target', 'segment', 'B', 'timestamp', '2020-04-30', 'segment', 'timestamp', 'segment', 'timestamp', ' \\u0378 Ǒ ȏ     ϶©     ʦʿ    )    ι', 'model', \"Given context isn't big enough\", \"Given context isn't big enough\", 'äŨĳ        #        _ ͜®ͱƆ ', 'There are NaNs in a forecast context', 'There are NaNs in a target column', '    ͜ ƽŉ̘ Ņ    ', 'timestamp', 'freq, periods, start, prediction_size, seasonality, window, expected', 'D', '2020-01-01', '2020-01-01', 'D', '2020-01-01', '2020-01-02', 'D', '2020-01-01', '2020-01-01', 'D', '2020-01-01', '2020-01-01', 'D', '2020-01-01', '2020-01-01', 'H', '2020-01-01', '2020-01-01', 'H', '2020-01-01', '2020-01-01 01:00', 'H', '2020-01-01', '2020-01-01', 'H', '2020-01-01', '2020-01-01', 'H', '2020-01-01', '2020-01-01', 'D', '2020-01-01', '2020-01-01', 'D', '2020-01-01', '2020-01-02', 'D', '2020-01-01', '2020-01-01', 'D', '2020-01-01', '2020-01-01', 'D', '2020-01-01', '2020-01-01', 'H', '2020-01-01', '2020-01-01', 'H', '2020-01-01', '2020-01-01 01:00', 'H', '2020-01-01', '2020-01-01', 'H', '2020-01-01', '2020-01-01', 'H', '2020-01-01', '2020-01-01', ' ̗ ǝ    ¿Ğ»    ě Ź', 'timestamp', \"Given context isn't big enough\", 'freq, periods, start, prediction_size, seasonality, window', 'D', '2020-01-01', 'H', '2020-01-01', 'D', '2020-01-01', 'H', '2020-01-01', 'D', '2020-01-01', 'H', '2020-01-01', 'D', '2020-01-01', 'H', '2020-01-01', 'D', '2020-01-01', 'H', '2020-01-01', 'D', '2020-01-01', 'H', '2020-01-01', ' ǆĖ ', 'model', 'model', \"Given context isn't big enough\", '̔ ', 'timestamp', '2020-01-01', 'segment', 'segment_1', 'target', 'timestamp', '2020-01-01', 'segment', 'segment_2', 'target', 'D', 'There are NaNs in a forecast context', 'There are NaNs in a target column', ' nŅˀa         Ĩ    .ʱ ϧ Ëˢ', 'target', 'segment', 'timestamp', 'target', 'segment', 'A', 'timestamp', '2020-02-19', 'target', 'segment', 'B', 'timestamp', '2020-02-19', 'segment', 'timestamp', 'segment', 'timestamp', 'target', 'segment', 'timestamp', 'target', 'segment', 'A', 'timestamp', '2020-02-19', 'target', 'segment', 'B', 'timestamp', '2020-02-19', 'segment', 'timestamp', 'segment', 'timestamp', '    ) ŋ    ŕ    ̭    ǒ     ɇ    Ô    >', 'target', 'segment', 'timestamp', 'target', 'segment', 'A', 'timestamp', '2020-02-19', 'target', 'segment', 'B', 'timestamp', '2020-02-19', 'segment', 'timestamp', 'segment', 'timestamp', 'month', 'target', 'segment', 'timestamp', 'target', 'segment', 'A', 'timestamp', '2020-05-20', 'target', 'segment', 'B', 'timestamp', '2020-05-20', 'segment', 'timestamp', 'segment', 'timestamp', 'model', 'target', 'segment', 'timestamp', 'target', 'segment', 'A', 'timestamp', '2020-02-12', 'target', 'segment', 'B', 'timestamp', '2020-02-12', 'segment', 'timestamp', 'segment', 'timestamp', \"Given context isn't big enough\", 'target', 'segment', 'timestamp', 'target', 'segment', 'A', 'timestamp', '2020-02-12', 'target', 'segment', 'B', 'timestamp', '2020-02-12', 'segment', 'timestamp', 'segment', 'timestamp', 'model', 'timestamp', 'segment', 'target', '2020-01-01', 'segment_0', 'model, freq, expected_context_size', 'month', 'D', 'month', 'D', 'year', 'D', 'year', 'D', 'month', 'H', 'month', 'H', 'year', 'H', 'year', 'H', 'LɡCheck tφĨhaƥt get_mƿorņ»del met\\x97h#̴\\u0380odû ʈthrʿ\\x88oȑ̴wsɛʥο a͔n ˉerroȄȒr Ĉif per-Osegmenźt mΒɦodel ªǥȼis4Ϫ not ̃fittĲed ̧yet.', 'Can not get the dict with base models, the model is not fitted!', 'etna_model_class', 'etna_model_class,expected_class', 'target', 'segment', 'timestamp', 'target', 'segment', 'A', 'timestamp', '2020-02-12', 'target', 'segment', 'B', 'timestamp', '2020-02-12', 'segment', 'timestamp', 'segment', 'timestamp', '    ÿ    έƙȾ Ĥ', 'month', 'target', 'segment', 'A', 'timestamp', '2020-01-01', '1d', 'month'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <13x8 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 13 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['C̅a͔ȫlciulːateɍd ǩa jtime serįies diȭfferen`cΡȓe\\x9eǂƼs of orTde±r 1ĩ˵.\\n\\nTɈhisǒ ;tɎraɼnsform caɰn worßǻ§ĝΠkŷ wdȋth ̓Na˾Ns \\x81at thne begϧinnihͯng o̮f7Ȓ˿ĉ the segme,nt, ͼƍbutǸ Ėfails pwhŬȳeƓnǃ meíʭets NaN in<side ēthe\\x90 sȩegmentɂ.\\n\\nŢNotϝȺesη\\n-Ⱦ--Ą--\\nTo undeƞrstɚand how trĹanusfoɍrm wȩǽ³ϔƒorkŻs weű recoϪmmeZnd:\\nō`Statʌimʷon˱arity aͯnd Dićfferenci˝Ȟng <httpƻs\\x9a://otexϾts.ĠcomǇŐ/fpąp2/st͛aɥtionariűtΓy.html>ű`˟_', 'RŚąʋłͷecoɕnstǴϞrȬuctũ thƶe σçͥteδst in `Ϥì`inͫv˒e°ʕĀǄ/ϯʔÖ¶rέseƶ̞_traͯns΅foñ͉rm``.̼', 'segment', 'right', 'Test should go after the train without gaps', 'feature', 'There should be no NaNs inside the segments', 'Period should be at least 1', 'Make ύa¦ ȨdiŬfĔfeÇˍren;ˍ˷cinǓȏgƆ traʚnƷˡʶAͬͤsfoŋrƹmationō.\\n\\nPˊ;ĬaraÊmeEteƬärɞùìs\\n---͂ťm-nş----ǐ˳--\\ndfĿ:Ɖ\\n   Đ ɖ˂da˄ʊ˚ȍtafĭ̻rame w˒ith datȘɖaPƷ to9Δ tÖrɪansǠf̏Ƅorm.\\x94̃ʽ\\n¬͆ϒŶŔ\\nRe͌tΫʾu\\x8bærns\\n--ǯ̝-ʹ-Ɠ-V͞½-ĪʽˏǪŀ-\\nresĤuʢlt:¤̤͞% ɉĀpd.ʯ̝DatΙǌafra̹Όmeǌ\\n ̸ ϔ  tƜran0sfÏÃƫormX\\u0380Ǭeɾdȯ dŝɯ½ƎτaĔ˩Ʒ§taf1ʃrͪaοme', 'Transform is not fitted', 'segment', 'Apply invØersãe tŸr§ƯKanɗsfoϬrmϐ4ϯatioƳĈƻn ̻tˆoÎ ΟDatǴaFɊĬrame.ÿ\\n\\nP\\xa0ɎarƵameteƨrsëϏ\\n---Ʋ-Ȩƹ--%-ɞ-ʒ˶-˛-\\nd¢ƒf:˚\\n ɓ   DaˁtŇaFìraȼme tEo appl\\x98y invƛeǀƐrse tranʕsЀfȲorm.\\n\\nÏ¹cRetu͒rns\\n---Ķ---ʦ-\\nresuˮlt: pʉΣ̐d.DamtǨaFr°ame\\x94pµ\\n̪ ˊ ͐Ʃ  trƛanżsfŻo̽rˤmÝed ΄DǮataˈFr\\x93ameȨ.', 'Transform is not fitted', 'target', 'feature', 'Inverse transform can be applied only to full train or test that should be in the future', 'segment', 'ĀFit̎ ǟtɞƝ͊ʬˆįh˹ʑe »trΝa̒nsľ˶ǶΗXform.\\n\\nPɺʠaramΟe_teɩr˓ΑʾΩs\\n--{-ʄ-Ĝ---X-ȶďĠ·¢-ųǲ-ƴɎÝɊ\\nƧdf:\\n ͡  ʻ ΚʎdataƸfĄramĵΉϳe ˆwͣȁʅith dǘaŘˣ͔ǳ\\x85wta.\\n\\nReturŗnĪŚͯsðț\\n--7-®-\\x8c-ťϹȵ--òǯ\\nrÿ͍es/ġ=uʹ̕lýtƃ:ɳ Uτċ_BSing̒ǹlųeŃDiϖUffereInõciênƤ˼gǦɮTransfN̘´ϗɧorÚmǮΓ͝ĥōϮ', 'segment', 'There should be no NaNs inside the segments', '_SingleDifferencingTransform', 'Calculate a time series differences.\\n\\nThis transform can work with NaNs at the bˉeginning of the segment, but fails when meets NaN insidɮe the segment.\\n\\nNotes\\nϬ-----ơ\\nTo understand how transform works we recommend:\\n`Staϡtionari\\x88ty andH Differencing <https:/Ţ/otexts.com/fpp2/stationarity.html>`_', 'Period should be at least 1', 'Order should be at least 1', 'DifferencingTransform'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <14x13 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 13 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['           }    Κ     ', 'timestamp', '2020-01-01', 'segment', 'segment_1', 'target', 'timestamp', '2020-01-01', 'segment', 'segment_2', 'target', 'timestamp', '2020-01-01', 'segment', 'segment_1', 'cat_feature', 'x', 'timestamp', '2020-01-01', 'segment', 'segment_2', 'cat_feature', 'y', 'D', 'all', '2020-02-01', 'D', 'timestamp', 'timestamp', 'segment', 'segment', 'segment_', 'segment_', 'target', 'target', 'D', 'D', 'target', 'model is not fitted!', 'model', 'copy_X', 'positive', 'copy_X = True, positive = True', '(fit_intercept = True, ', ', )', 'model_class, model_class_repr', 'LinearPerSegmentModel', 'LinearMultiSegmentModel', 'Cheɭck __repΚ΅βr__Έ ʆ͋ȽmeϭƒΦtho˪\\u0378d Ço˄f E͑la{ĊstPiȹ̿®cPeǾžrSeg»mentMΰodel̀ and ElastimcMȆultÔiƤ̢SƑegmentModel.', 'copy_X', 'positive', 'copy_X = True, positive = True', '(alpha = 1.0, l1_ratio = 0.5, fit_intercept = True, ', ', )', 'model_class, model_class_repr', 'ElasticPerSegmentModel', 'ElasticMultiSegmentModel', 'GiĪvʹùeAϜʂn: D\"ƳaʬtaİseǪƉt /wˠiƃth\\u0381 3 \\x8alĭinϗŒear seg̉ˇ̈ȝēmMͬenf͜ͅots ϒϴaͥ(ndõ LǱȇ\\x95ineaͫnorR̝ΪĩegƑre\\x97s˽ΎsioŮn or ElastƬicNĊet ȺͰmodel ȳthat9 pΑrā×edvictsg Ưp\\x92ǶƁerx7 È,seĂgͪmeˆn͵̅t\\nȫûWhĨe¶έn:΄ C̣d͔Ďġȣͩέȵreaɉtinɦg Ƒ`Μof laĸg͙đ fe\\xadat\\x9aɻurḙϤɅvǎsÂ to Ίtaξrg§etʇ,ȿ a̩Ϧpplying it toͣ dảtaseĐt ωan\\u0380dũȨϗ mɩa¦ɝʛ͔ɶk,\\x8fi̅ϡnǳg\\u03a2ò Ȫθʾf͌oreǝΏcľaēϕśt fȮoð¼ĺr ÁǷh?o®r\"iÇ̍ƀzon pe\\x7fräiodsl\\nˍƂTƤheľ˳nΐ:ŗ Preɼ\\x89dicŘtiońȩs ̵Ƨp̏Ëe9r sϘłe/gmͼent is clʲ\\u0378ose .ƈtodŜ real valuxŹes̾', 'target', 'target', 'target', 'model', 'num_lags', 'target', 'target', 'target', 'model', 'num_lags', 'target', \"Arrays of bytes/strings is being converted to decimal numbers if dtype='numeric'.\", \"Arrays of bytes/strings is being converted to decimal numbers if dtype='numeric'.\", 'model', 'target', 'Only convertible to numeric features are accepted!', 'model', 'etna_class,expected_model_class', 'Can not get the dict with base models, the model is not fitted!', 'Check that get_model method returns dict of objects of sklearn regressor class.', 'target', 'etna_class,expected_model_class'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <7x7 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['       ', 'cmd', 'data', 'name', 'logger', 'config', 'train_root', 'checkpoint', 'no_strict_init', 'from_stage', 'from_seed', 'sweep_id', 'clean', 'dataset_params', 'model_params', 'trainer_params', 'metrics_params', 'num_evaluation_seeds', 'num_hopt_trials', 'hopt_backend', 'hopt_params', 'name', 'batch_size', 'num_workers', 'validation_fold', 'num_validation_folds', '_hopt', 'debug-openset', 'batch_size', 'values', 'embedder_params', 'pretrained', 'model_type', 'resnet18', 'num_epochs', 'train_classification_metrics', 'nearest', 'scores', 'optuna-tpe', 'num_evaluation_seeds', 'trainer_params', 'selection_dataset', 'selection_metric', 'valid', 'recall@1', 'config.yaml', 'cval', 'tensorboard', '--config', '--logger', '--train-root', 'config.yaml', 'train', 'tensorboard', 'checkpoints', 'best.pth', 'traced.pth', 'config.yaml', 'evaluate', 'tensorboard', '--config', '--logger', '--train-root', 'ϊ    vɪϭ   δ  ', 'config.yaml', 'train', 'tensorboard', 'test', 'checkpoints', 'best.pth', 'tensorboard', 'config.yaml', 'hopt', 'tensorboard', '--config', '--logger', '--train-root', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Class ʸfoĂr holȹ\\u038bdiɲngΧ PǇ±ªƏrƮopǿĐhĭetɜ mǰ̟odeńϡͲl.', 'floor', 'cap', 'CoťmʽĽpuɱĻte pǻredȽηɒʉictiϺǴons\\xa0 f-˗roĶm a ̓P-̟rʠ}Āopheèt ˾mzodel.\\n\\nPƖŢųarϳa¤mΛŠǻȸeΟ˄teȄrs\\n----A-ΣϔŚ--͖ϜA-ʹ-Ɵ-\\nǼΙ_df:̐\\n    Fłeatɇures dat͑aƺ˲fraϕmeͦ\\x8e\\np̬͟rưedżƾictȤʼϛȋonˬ_ȏinterva\\x9cl:\\nŉ  ɜ łη ȁIͿf ̍Tr¢ue r»eatuόræns preϲ/Ǹdict;ion Ʃ&ǰiľͱƩ\\x83ntãerƂ\\x81val ϯf͋ωo˞r SKfʢoemrecaØϵst˚\\nǫqǱuanztiǬpˍήlΞes:\\nʾ    ȫLƍeρveȀϱls ͇ŏf preµϝʁdicνti~oľýɨǃnɪ ǜ©distɖrƚib˜uǃti\\u0379;on\\n\\nȓ\\x88Rțet͇urϿnŻs\\n̪-ì--Ī----\\n3:ˤ\\n   + DattĖaFȏrÀ̸ame witʷh pǄrediɮc`t͊ions', 'y', 'target', 'ds', 'timestamp', 'yhat', 'yhat_', '.4g', 'yhat', 'yhat', 'target', 'yhat', 'y', 'target', 'ds', 'timestamp', '_ProphetAdapter', 'linear', 'auto', 'auto', 'auto', 'additive', '    ', 'ȯCƄlasʇs fo×r holding Pǖrophetı modelX.\\n\\nǇNotes\\n-----\\nOriginaɇl Propheʘt can use ɒ̀features \\'cap\\' and \\'floor\\',\\ntheyǣ should be ïa#dded ďt;o the known_futuήre ϮȽliôst oȥnɽ datasetĺ initΏialization.\\n\\nExamples\\n--------\\n>>> froḿˑ etna.dataΎsets impϒo$rt generate_pΦeriodic_df\\n>>> from ıetnaƹ.datasets import TSDataset\\n>>> from ƛetna.modelsɱ import͚ ProphetModel\\n>>>Ŭ classic_df = generatʧe_periodic_df(\\n...     periods=100,\\n͍...     start_time=\"2020-01-̓01\",\\n...   ͡  n_segments=Ĉ4,\\n...    ÛȀ period=7,\\n...     sigma=3\\n...̉ )\\n>>>̢ df = TSDaɷtasξetċ.to_dataset(df=clas²sic_df)̥\\n>>> ts = \\'TSDataset(dʌf, ͧfreq=\"D\")\\n>>> future = ts.ʽma\\x94¬ke_f³uture(7)\\n>>>λ model̕϶ =ɦ ProphetModel(growth=\"flat\"Ǘ)\\n>>> moɴdel.fit(ts=ts)\\nProɓpɇhɖetModel(growthü = \\'§flat\\', chϽangepʩoiȢˎnȴts = None,ƚ n_changepoints = 25,\\x8a\\nchʡaǱngˣτeʔpoint_\\x92range =n͆ Ț0ˑ.8, ɐyŗearly_seasonalʧity =Ǽ \\'auto\\',ȸ weekly_seasonality = \\'auto\\',\\ndaily_sedasonalityϻ =Ɔ \\'ạuto\\'Ɛ, holidays = Nˮoŉne, ɂseasΖonaBlity_mode = \\'additiǮv\\u0378eţ\\',\\nseasona̾lity_p̽rÄior_scale t= 10.0, holidayšs_prȋior_scale = 10.0, changʥepoint_prior_scale = 0.05,\\nm͘cmc_samplϴes = ƴ0, interval_width = 0.8, unėŤcerϝtainty_samples ̢= 1000\\x91, #s¨tan_backend = NoƉnaeÈ,\\nadditional_season˾ality_params =Ȁ (),Æ )\\n>>> ĴforecasÄt = mode˴l.foreŸcast(futureȼ)\\n>>> fρoreǙcast\\nϗsegment U   segmeΎntļ_0̺ ͧsegment_1 sȥegment_2 segmentȵ_3\\nfeature  ɺ     targϟƼet Ϳ   target    target    target\\ntime%stamp\\n20ā20-Ȗ04-10      9.00   ɍ   á9.00 ʢ ˀ    4.0Ư0 \\u038d     6.00\\n2020-04-11Ζ      5.00      2.00      7.00      9.00\\x85Ł\\n2020-04-12    Û ʮ 0.00ǰ Ȫ ɮ    4.00   D   z7.00      9.00\\n2020-04-1͍3 ϴ   ȗ  0.0ȡ0      5.00      9.00      7.00\\n2020-ɭ04-14 c     1.00   σ   2.00  ̗    1.00ȱ    į  6.00\\n202Ϙ0\\\\-04-15    ǆ  5.00      ĞɅ7.00      4.ɕ00      7.00\\n20̦2ă0-04-1˻6  ʉ    8Z.00      Ĥ6.00    A  2.00      0.ƶ00', 'linear', 'auto', 'auto', 'auto', 'additive', \"Cre̝ate instance of Pųrophet model.\\n\\nPʬarameters\\n----------ȶ\\ngrowth:ͣ\\n    Options are ‘linear’ and ‘logistic’.ɝ This likely\\x90 Ξwill not be tuned;\\n    if there iʢs a known saturating ſpoint and growth towards that poiťnt\\n    it will Ȓʊbe i˼ncluͮded and the logistic tϼrend will be useǠd, otherwise\\n    it wilȦlȯ be linear.\\nchangepoints:\\n    List τof dates at which to include potential changepoints. If\\n Í   not ʖspecified, potential changepoints are selected automatically.\\nn_changepoints:\\n    Number oâf potenti̴aŗl changepolints to include.˸ Not used\\n    if inîput ``changepoints`` is supplied. If ``ch'angepoints`` is nȃot supplied,ņ\\n    then ``nƴ_changeńpoθints`` potential changepoints are selected uniformly from\\n    thɜe first ``changepoint_rang\\x9ce`` proportion of the history.\\nchangepoint_raϜnƒge:\\n   β Proportionɑ of history in which trend changepoints wϳill\\n  ɯ  be estimated. D͖efaults to 0.8 for the first 80%. Not used ȶif\\n    ``changepoints`` is Žspecified.\\nyearly_seasonality:\\n    By default (‘auto’) this will turn yearly seasonality on if there isͥ\\n    a year of data, and off otheǙrwise. Options are [‘auto’, True, False].\\n    If the\\\\re is more than ͏a year of data, rather than̴\\u0379 trŚying to turnĘ this\\n    off during HPO, it will likeʱly be cmoreJ effective to leave it on and\\n    turnǓ down seasonal effectsŞ by tuniŵnʩg ``seasoψnaʺlity_prior_scale``ú.\\nweekly_seasonality:\\n    Same as for ``Ǵyearly_ʏseasonal·ity``.\\ndaily_seasonϛality:\\n    Same aČs for ``yearlyɦ_seƐasonaliϭty``.\\nhoŮlidays:\\n    ``pd.DataFr̷Ƴame``ǯ with columnsʖ hoŧliday (string) an̜d ds (date type)\\n    and optionally columns lower_Ŀʊwindow àϚndȖˊ upper_window which specify a\\n  ǋ  raʼnge of days around the Ⱦdate to be included \\x98as holidays.\\n    ``lower_window=-2`` will include 2 days prior to the date as holidays. Also\\n ǈ   optionally can have a column ``prior_scale`ǚ` Γspecʊifying the\\x94 prior scale for\\n    that holiday.\\nseasonality_mode:\\n    'additive' ɣ(default) or 'multiplicative'.\\nseasonalityȘ_prior_scalΨe:\\n    Parameter modulλating the strength of the\\n    seasonͳality model. Larger values allowʉ the modeŚl to fit larger seLas˟onal\\n    ̮fluctuʔations, smaller values da˰mpen the seas\\u0378onality. Can bɫe specified\\n    for individual se͟asoĨnalities us̓ing ``ahdd_seasonality``.\\nholidays_prior_scalŮe:\\n    Parameϰter ɖmodulating the strength of theǨ holiday components model, unless overriddenͬ\\nʆ  ʡ  in the holidays input.\\nchangepoint_prior_scale:\\n    Parameter modulating the flexibi͂lity of the\\n    automatic changepoint selection. Large vȄalues wυΊill allow many\\nŜ    changepointsϮ, small values will allow few c̳hanψgepoints.\\nmcmc_samplRes:ȋ\\n    Intφeger, if greater than 0, will do fullȉ Bayesian inference\\n    wiÆth the specified number of MCMC samples. If 0, will do MAP\\n    estimation.\\ninterval_widȿth:\\n    Float, widt?̜h of t̆he uncertainty intervals provided\\n    for the forecast. If ``mcmc_samples=0``, this will be only the uncertainty}\\n    in the trend using the MAP estimate of the exƘtrapolated geτnerativeŰ\\u0381\\n ο   model. Iϔūf ``mcmc.samples>0``, this will be integrated over all model\\n    parameters, which will include uncertainty in seasonality.\\nuncertainty_samples:\\n    Numbťer of simulated draws use˿d to estˮimate\\n    uncertainty intervals. Settings this value to 0 or ǺFalse will disable\\n    uncertainty estɲimation and speƝed up tΔhe calculation.\\nstan_backend:\\n    as defined in StanƿBɳackendEnum defaultʛ: None - willǩ try to\\n̚    iterate over all availȟable backeǌnds and fiͩnd the working one\\nadditiˢonal_seÜŢasonʯality_pϹarams: Iterable[DÓict[str, Union˘[int, float, str]]]\\n    parameters thatΊ describe adděitional (not 'daily', 'week͝ly'*, 'yearly') seasonality that should be\\n    adŵdedƻ to model; dict with required keys 'name', 'pe͡riod',ǔ 'fΎourϾier_or͵der' and optional ones 'prior_scale',\\n    'mode', 'condition_name' will be used for :py:methȍ:`pήrophet.Prophet.add_seasonality` method call.\"], 'from': [], 'import': []}\n",
      "{'FunctionDef': <8x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 8 stored elements in Compressed Sparse Row format>, 'ClassDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['ɱGetΓ datʩŷasetƓ ̑Ƣlaͨȱbels ĎarrayΙ.\\nɻ\\nLȼçaʩãƃϲbels ar͜7e ȱintege}rs in the ranʐge [0Χ, N-1Ȉ]ą, whnereʷĳ N isʅ numbΨeRr ofę classes', 'WhetheΔr dataset is for̴ open-set̅ or ȧ\\u0381closed-set classification.', \"WvhetheˌɆr dÐatåase'Ot iʬsÉǖ íc͏lì)̔assifƘiʤcation orʑ ma˙ſtcɠhΔȉ̙ǳnōg.\", 'ʨ]ύ  Ȳ    ', 'ňĞΙ˜   ɻ ĜÝ͊     ', 'H ɲ   Μ ĭƵĿ    ', ' ĳ ˰    ėƒ ϔŢ ʏƗ   Ąæ ÚÞ ̦'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <27x22 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 27 stored elements in Compressed Sparse Row format>, 'ClassDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['cuda', 'halfcheetah-medium-expert-v2', '', 'CORL', 'TD3_BC-D4RL', 'TD3_BC', '-', '-', '     ̑Ə̳> ', 'ȊϮ Íń     ¬  ͊   ̦', '    ʯ  ̘ε÷ ô  ȯŃů', '  =  ̒ ̆¬   \\x80ʷ   £ ', 'cpu', ' ', '        ', 'Trying to load data into non-empty replay buffer', 'observations', 'Replay buffer is smaller than the dataset you are trying to load!', 'observations', 'actions', 'rewards', 'next_observations', 'terminals', 'Dataset size: ', 'PYTHONHASHSEED', 'project', 'group', 'name', 'a\\x8bδ   Ɲ  ˬ   ˡ       ͩ͢ ϧ', 'rewards', 'terminals', 'rewards', '  Ʊ ŕ  ˧   ϭ Ƶ ', 'halfcheetah', 'hopper', 'walker2d', 'rewards', 'rewards', 'antmaze', 'rewards', '  ̠϶̾   ˓  ', 'cpu', ' Ÿ\\x82͖ȸ ̕   Ʊ̏\\x92     ϋ  ˪ ϣϖ ʹ   ', '   \\x8bϲ  ú hè', ' \\u0381   ψ \\x9d Ϫ̈́    Ŀ ¹uȕ̂ĕ˧ ', 'critic_loss', 'actor_loss', 'Ƙ              ', 'critic_1', 'critic_1_optimizer', 'critic_2', 'critic_2_optimizer', 'actor', 'actor_optimizer', 'total_it', 'critic_1', 'critic_1_optimizer', 'critic_2', 'critic_2_optimizer', 'actor', 'actor_optimizer', 'total_it', 'cpu', 'ľ Ǧ  ̢  ', 'observations', 'observations', 'observations', 'next_observations', 'next_observations', 'Checkpoints path: ', 'config.yaml', 'w', 'max_action', 'actor', 'actor_optimizer', 'critic_1', 'critic_1_optimizer', 'critic_2', 'critic_2_optimizer', 'discount', 'tau', 'device', 'policy_noise', 'noise_clip', 'policy_freq', 'alpha', '---------------------------------------', 'Training TD3 + BC, Env: ', ', Seed: ', '---------------------------------------', '', 'Time steps: ', '---------------------------------------', 'Evaluation over ', ' episodes: ', '.3f', ' , D4RL score: ', '.3f', '---------------------------------------', 'checkpoint_', '.pt', 'd4rl_normalized_score', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['102 Category ͐Flowear Dataset Ôdņataset claŋss.\\nhttps:/g/www.Ϸr̓̂hobots.ox.ac.uk/~vǓgg?/data/flowerĩʲs/ɖ1\\u037902ɥ/\\nɚôƳ\\nͺArgs:\\n    r˩o¹áo5t: Dataset rÞoot.\\n   ǡ ̧tĞνrain: ͮWheϔtheC˿ɨr to uɘse t˥rain or ÷̳test ʴpart oƯf the daɑtaset.', 'trnid', 'trnid', 'valid', 'tstid', 'setid.mat', 'jpg', 'jpg', 'imagelabels.mat', 'labels'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['C˹h˃š̡ǅĎe̽ɣcĠφέk cbȝ©˕˨h\\x9fang̽eʧå p]oints o͈nŀ v`aɾliÌdiǣtƈyΧ.˷', 'TΘesì<tǹ ψt8h͢Ȝat ǗfŲiϫnd̤¥J_c˗ßh́anϖϸɑcge\\x86Ƌǫ_po˂¿i\\u038bn<ĝǣts ̿õƌworksˇ fiŁneM wi̹th͓ łmˡultiǩƍtrȖeÊndí eϩɠxa˨mƗpleƞ.', 'D', 'target', 'n_bkps', 'D', 'target', 'n_bkps', 'D', 'target', 'n_bkps'], 'from': [], 'import': []}\n",
      "{'FunctionDef': [], 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['pytorch_lightning.callbacks'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['2000-01-01', 'target', 'segment', 'segment_', 'segment_', 'D', 'Ό 4  θ'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['1D', 'Creǎa\\x8ctʘƏeΗ ͱDatɈaFĔȉraɟmeŤν with˓ǳ ÃȞNR pṟo#c̔essĄ ǃ̼da$̷̳tʴaƲ.\\n\\nǗŀPϓʬa˗ȿŌraǣm½etϺšerɊs\\nǾͷl-----\\u03a2-̀-ɠ̭Q---@\\npeʤriodȢsõ͏Βʵ:̠\\n_  ʰ  numberΈĽ oϊşfǶʇΎǖ ƣtĺim¿estaΉmpsȓŋ\\nstartαc_ñȟtimeΏŇ:\\nɜ̳   İÒ startȡa ́Γtimέeìsut̖ͮam<pľ\\n\\u038d̶ar_coef:\\n   Ə A̐R ˭coɏe̾ff͠ŋici̔eǰɛ\"Ũncžtªs\\ņsigƔma:\\nʂ ˬwǝƅσ  N̛ ʅs˜˷c͏_˔alıe˟ of AR 7nÛˑoiseʤ\\nn_s&eFgme¯̖ȴntsTÐ:\\n˝ĿƖ    nuϦmbʗƬȆerŢǖ oƼf s̊egmentϖs\\nfreq\\\\³:ʊ\\n/ Ϟ ϥȪ Μ˽κ panʲdɡas .Ŀfeˉήreq͐ʯuencǣy ôsdªǫʎ\\'trȷinϣg fɃǳo\\x9f͵rǼ :̜ƻŒȿ\\x9apºȏy:fuȍncĩŰ:`paȘƅńǴnd\\x9da̔Υ͆͜ƺs.dĵɛΉ̣̰ǧ³ate͘_rΗōan¾ge` tƘũhat is ȹuseΐdģ to gēen\\x88eraɁteϮˑͼ ti\\x9cmăʰe1Wst̖Υa\\x80mǛUåp\\nraąnɱ\\u0379důoǉmpƞ_sȻeed̀:\\n  Ć  årƬĞandom\\u03a2 ĶsǴΟĖeæeϣśd', 'segment_', 'timestamp', 'timestamp', 'target', 'segment', '1D', '1D', '1D', 'Create DatûaFrame froɞm pǚatterns.\\n\\nParam+eters\\n----------\\nperiȚoȄ͘ds:\\n  Ô  nuŗmƔbe˽r of timesɐtampϺs\\nstar>t_time:\\n    ƍˌstart timeFsętamp\\npat#tɂerns:\\n    list ƺoáf listsʶ with\\x8dş patternsǙ to be Űrepeated\\nfreq:\\n    pandǋasȏ freɭquʠȼency string fƲor o:pKy:f̮unc:`pandas.date_rangeË` that isȟ usedŔ to ˢgenerate timestamp\\nadd_noi¸se:ͫ\\n ǰ   if TͰr\\x86uƮe we ¼adĞd noīsąe to final sΡaΠơmplɁes\\nsigma:\\n    scalǵe of added noise\\nrandom_seed:\\n  Ĥ  random seed', 'segment_', 'timestamp', 'timestamp', 'target', 'segment'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['CreͲate inIstaĈnøʷĻcew of Eϒucl̛κhɚβ\\x80iĢdeaăn+ʚɯC˔ƌluÊs/ˮte,đriϴɃngƵǊ.ŇɶƋ', 'TSDataset', \"̨ıBĲű'̚αui\\x88\\x9fldƗ̐ \\u0381©dˆi;ϸͦsŎtaǐn̨cũe ȟm˄ʗaʕt̼üriýϠƟϵx with¬½ eucįʠΤlƩɁidȣʝeǽanȃ±Ú ƵƙǑdϟãi\\x80ùsɚtřυance̱ƹ.\\nͦ.ĽǸ\\nParĆamce̅terȉ~Ɖqs\\n--Ʒ\\x83Ű\\x9a--ũ-ʸ-̕κʹ˃ƹε--ĈͣƷ--\\nĠtƌsχδO:\\n   Ĵ TS͇DataseǷȗt\\x8fʖ with se˖ɔĲri˗1eʪs @ĳ Δto ƙbuildˤď ǑϿϴʀdôis\\x8b̊taɷnceƏ mat\\x90êMrix\", 'EuclideanClustering'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <32x28 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 32 stored elements in Compressed Sparse Row format>, 'ClassDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['CORL', 'AWAC-D4RL', 'AWAC', 'halfcheetah-medium-expert-v2', 'cuda', '-', '-', 'Trying to load data into non-empty replay buffer', 'observations', 'Replay buffer is smaller than the dataset you are trying to load!', 'observations', 'actions', 'rewards', 'next_observations', 'terminals', 'Dataset size: ', ' Ȅ', 'cpu', '  \\x9c      ɱ       ͈Φ', '   ĜΔ', '˱ äʝ     ʰ ʉ ', 'ĺ Ă  Ư ˻ ƽĻ     MϚ     ͢ ɛ ɢ', '         ĄͿ    ̏      ', '   ʵg    ¶  ǒ  ɂ', '  ', '\\x89Õ    ̼  ó', 'ũω͠Ϧ Ť   κ  dÀā   ϥą͂¸Ƅͣ ǵˡ  ϛ     ï   ', 'actor', 'critic_1', 'critic_2', ' ͖  ǭ ƨ      ˦̦ȟơ ', 'critic_loss', 'actor_loss', ' Ƶȁ     ', ' ͱÝ   ʔ ïḔ̉ǘÙæ  ϟ   ȑˡ   ', '        ', 'actor', 'critic_1', 'critic_2', 'ʤ\\x85    ρ Ä\\x91ʯ ', 'PYTHONHASHSEED', ' ˟ ŵ   ̎Ƞǡ ñ  Ś  É̽    θȣ ͍ð  t ', 'ϱ   í  ίƴ ', 'observations', 'observations', 'observations', 'next_observations', 'next_observations', 'state_dim', 'action_dim', 'hidden_dim', 'Checkpoints path: ', 'config.yaml', 'w', 'eval_score', 'get_normalized_score', 'normalized_eval_score', 'checkpoint_', '.pt', '/eval_scores.npy', 'wb', '/normalized_eval_scores.npy', 'wb', '  ̏ϥ̟    \\x81ɛ       ͔', 'rewards', 'terminals', 'rewards', 'halfcheetah', 'hopper', 'walker2d', 'rewards', 'rewards', 'antmaze', 'rewards', 'project', 'group', 'name', '  ȑƺ   ʶϸ  ĥmĉ         ', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <7x7 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['model', 'model_config', '!    Ϫ ', 'a', 'e', 'f', 'b', '_hopt', 'c', 'b', 'd', 'aoeu', 'i', '_hopt', 'g', '_hopt', 'h', 'a.b', 'a.c.d', 'e', 'f.0.i', '_hopt', 'aoeu', 'a.b', 'f.0.g', 'f.1.h', 'a', 'c', 'b', 'd', 'e', 'a', 'f', 'c', 'b', 'g', 'h', 'a', 'f', 'c', 'b', 'd', 'e', 'g', 'h', 'ʉƣȞ   ǘ      Ǣ ɨʔ̰  Ƚ ̉Ýηͷ', '_hopt', 'b', 'a', 'b', 'a', 'b', 'a', 'a', 'model', 'model_config', 'some-model', '_type', 'arg1', 'arg2', 'SimpleModel', 'model', 'model_config', 'some-model', '_type', 'arg1', 'arg2', 'SimpleModel', 'config.yaml', 'model', 'model_config', 'some-model', '_type', 'arg1', 'arg2', 'SimpleModel', 'model', 'model', 'model_config', 'arg1', 'model_config', 'arg1', 'model_config', 'arg2', 'model_config', 'arg2', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <6x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Something went wrong, ts is None!', 'multiprocessing', 'Merge ϔtÀƖhe χfǻorΏecasɆts of \\x98bas͇e pipȴeǔlines ̵aɗcͣ\\x86c̃oŹ˫r\\xa0ding ʨto ǲäthe direct̐M stəprƥategy.', 'target', 'target', 'All the pipelines should have pairwise different horizons.', 'multiprocessing', 'c', 'Fϔit ǎʚpiŹpeͶlines in eΣnse\\x9amble.\\n\\nParameƖϲŹte˞rs\\nɥ-·------̏--Ȓ-Ő\\nts:Z\\n  ˜  TSDϦataset tŜo Ĩfit έenseØmblȹeˋÃ\\n\\nÜRetuzrnƶs\\n--ü----®-ş\\ns4ΞeǭƸȕlƈfκ:\\n Ŧƥ   Fi;tʘted\\x9cW en͗Ǡse˳mble', 'DirectEnsemble', '   ɔ\\x8b  ', 'Ensemble ', \" doesn't support prediction intervals!\"], 'from': [], 'import': []}\n",
      "{'FunctionDef': <10x10 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 10 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['result', 'target', 'segment_1', '2021-05-20', 'D', 'D', 'segment_1', 'target', 'timestamp', '2019-12-01', '2019-12-31', 'target', 'segment', 'segment_1', 'ȓCǔheck ʤt·ɣhŐ at tra\\u0379ƯŲ̱nƞ¢sfʺϑZorƦmϮ metˡɑhΏod Ĵ5geƋʓnΩƥëLˬera̪șt͒e nϺew2 ȴcĐϏolumn.', 'target', 'segment_1', 'segment_1', 'target', 'category', 'target', 'segment_1', 'segment_1', 'Test thʀat þtransfĚorm fʮor one Msegment raise erro®r w^hen calling transform Ⱥwitho\\x98uȑt being fit.ʄ', 'target', 'Transform is not fitted!', 'segment_1', '  ', 'target', 'target', '2021-06-01', '2021-08-01', '  ', 'target'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['wandb-sweeps', 'test', 'sweeps', 'D', 'ƑOďptÂuʄnξȊʈa o\\u0383bjƈe˒Ƴƾcti6ve ʥfΏunzctiɜʨoŬŁʵnøǶɍ.', 'iterations', 'depth', 'target', 'target', 'lags', 'MAE', 'sqlite:///optuna.db', 'data', 'example_dataset.csv', 'minimize', 'D', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <6x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['Cˉāhǚeck| thEɉat v_opÝtimãŵl_͘̚hist \\x97wɽ˅orȲÇʬƘķkàs correcľɮ\\x95tly.ƞ', 'series,bins_number,expected', 'Check that ɮv̔_optimal_hist works c\\x9eoʫrrϊectly.', 'series,bins_number,expected', 'C˿ĭ̐herck tºhĬʡÃúatɉ coƫmputesƹF ϑώproΑduc¼e the corrɿecɩt size»ą o͚ustpuρt.Ǐ', 'series_len,k', 'series,k,dim,expected', 'Chec6Yk̃ thaǒtƞ ϩhist worœks correcζʮƑtlyÒB.ϋ', 'series,bins_number,expected', 'feature', '1', '2', '2021-01-08', '2021-01-26'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <15x15 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 15 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['input_cv,true_cv', 'Folds number should be a positive number, 0 given', 'input_cv', 'C΅heȨck tƮhaǛt +StackvʆingEnsemb͎le._geƇβɳtɳ_features_to_use works ɏcorrɽectl*Ųy.Ͻ', 'features_to_use,expected_features', 'all', 'regressor_lag_feature_10', 'regressor_dateflag_day_number_in_month', 'regressor_dateflag_day_number_in_week', 'regressor_dateflag_is_weekend', 'regressor_lag_feature_10', 'regressor_dateflag_day_number_in_week', 'regressor_lag_feature_10', 'regressor_dateflag_day_number_in_week', 'ȁChecɰk tΰhat ɝStϳˀac³káˍi˝ƹngTEǁąƔɓͧĩns̖͵şemƑʍbɨȐǅleB._geȎΈt_feş\\x9bʴ͟ƩaǙƫȠtÙurς˕eʞsǑȒ*_ψtɄo_\\x84%use =rais¡es ˬwảrˬ̟nieng inǋ cĆϦƬaȝseɁ of unavϜaʃiκlabl\\x82eÂ feat\\x9eur?essϜŝȔͺ.x', 'Features ', ' are not found and will be dropped!', 'features_to_use', 'unknown_feature', 'feature', 'features_to_use,expected_features', 'regressor_target_0', 'regressor_target_1', 'all', 'regressor_lag_feature_10', 'regressor_dateflag_day_number_in_month', 'regressor_dateflag_day_number_in_week', 'regressor_dateflag_is_weekend', 'regressor_target_0', 'regressor_target_1', 'regressor_lag_feature_10', 'regressor_dateflag_day_number_in_week', 'unknown', 'regressor_lag_feature_10', 'regressor_dateflag_day_number_in_week', 'regressor_target_0', 'regressor_target_1', 'Check tÌhat StϡackingEnsemble.forecast returns TSDataset of corrïect length, contėaζining aȄllƭ t̊he expected columns', 'feature', 'target', 'features_to_use,expected_features', 'regressor_target_0', 'regressor_target_1', 'all', 'regressor_lag_feature_10', 'regressor_dateflag_day_number_in_month', 'regressor_dateflag_day_number_in_week', 'regressor_dateflag_is_weekend', 'regressor_target_0', 'regressor_target_1', 'regressor_lag_feature_10', 'regressor_dateflag_day_number_in_week', 'unknown', 'regressor_lag_feature_10', 'regressor_dateflag_day_number_in_week', 'regressor_target_0', 'regressor_target_1', 'feature', 'target', 'features_to_use,expected_features', 'regressor_target_0', 'regressor_target_1', 'all', 'regressor_lag_feature_10', 'regressor_dateflag_day_number_in_month', 'regressor_dateflag_day_number_in_week', 'regressor_dateflag_is_weekend', 'regressor_target_0', 'regressor_target_1', 'regressor_lag_feature_10', 'regressor_dateflag_day_number_in_week', 'unknown', 'regressor_lag_feature_10', 'regressor_dateflag_day_number_in_week', 'regressor_target_0', 'regressor_target_1', 'target_0.025', 'target_0.975', 'target', 'target_0.975', 'target_0.025', ' ͉ ˎ ', 'Feature list is passed in the wrong format.', 'features_to_use', 'regressor_lag_feature_10', 'TSDataset', 'TSDataset', 'macro', 'C˕heƸck thatķˋ StackinɡgEnsemble works the Nsʃͣa?me Ȝȋʱn casMe of multi and single jobs modes.', 'n_jobs', 'StackingEnsemble is not fitted!'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <14x14 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 14 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['  Ȃ   ʨ ̶́  ', 'ʅDΐataɘse͔Κtϥ\\x94 _selector ̂a̾Ϸnd con̗str\\x8b\\xa0̍ủ͓UǚϊƻĪɶ\\x9actor.\\xa0', 'casia-openset', 'ms1mv2-openset', 'ms1mv3-openset', 'lfw-openset', 'clfw-openset', 'lfw-joined-openset', 'cub200-openset', 'cars196-openset', 'cub200-interleave-openset', 'cars196-interleave-openset', 'sop-openset', 'inshop-openset', 'mnist-openset', 'imagenette', 'tinyimagenet', 'imagenet', 'stanforddogs', 'flower102', 'imagenetlt', 'cifar10', 'cifar100', 'mnist', 'svhn', 'serialized-openset', 'debug-openset', 'train', 'flower102', 'imagenetlt', 'valid', 'val', 'casia-openset', 'ms1mv2-openset', 'ms1mv3-openset', 'lfw-openset', 'clfw-openset', 'lfw-joined-openset', 'cub200-openset', 'cars196-openset', 'cub200-interleave-openset', 'cars196-interleave-openset', 'sop-openset', 'inshop-openset', 'mnist-openset', 'imagenette', 'tinyimagenet', 'imagenet', 'stanforddogs', 'flower102', 'imagenetlt', 'cifar10', 'cifar100', 'mnist', 'svhn', 'serialized-openset', 'debug-openset', '.bin', '.bin', '.bin', 'tstid', 'imagenetlt-overall', 'imagenetlt-many-shot', 'imagenetlt-medium-shot', 'imagenetlt-few-shot', 'test', 'overall', 'test', 'many-shot', 'test', 'medium-shot', 'test', 'few-shot', 'test', 'train', 'same_class', 'validation_fold', '¹GetƮ v̗ali±da©×tΨʜion datasets. ȺReturns NoneǛ ifō anot available.', 'validation_fold', 'name', \"`validation_fold` is not None. Cannot perform validation split,because this dataset has author's validation split.\", 'name', 'validation_fold', 'num_validation_folds', 'validation_split_interleave', 'validation_fold', 'num_validation_folds', 'validation_split_interleave', 'name', 'name', 'valid', 'add_lossy_valsets', '-lossy', 'lossy_params', 'preload', 'num_workers', 'add_verification_valsets', '-pairs', 'Get coήllɡecͥtioǓ̍n parameterϪcs̥.\\n\\nϿAfʱrŅgĚ×sͪ:\\n ÚȐÖ c  nƷamÁe: T˔yˮpe of ɅthWe Łtra˖in2͋inͻg: ͒daϏtaseρɍƸt K(Ƅ`cƄa\\u0380siƚƸʲaë`, `ms1ˤmʩȸv2`,\\u038b `ms1mv3`ȼ, ŋΎĵ`ŝlfw`, ș`̄ϵίcΦub200`, `cars1Ύʳϭ96` or ̇`ĲsopƝɄ`).ʬ\\n    3dvaĺliƚdatioĶnE_̲fold:;ζƂ ƟFolɁdɨ˻ iɉn˷ǲdex u|sªɽɍed ¨for vϤͰalidatφion5.\\n  ό ͯ nΔumͳ_validaɻtPi͑ɣon_Tfoʀl̿dsä: Numberǒ ϑΐof valǞid̯ɨħɑ~atʝion ͷsʽ̛ʒplitùΖsǇΪ.\\n ̿   ȑvalȉidation_ṡpŗlit_irˍȭn͕teàrleaveϩǓ: \\x85If Trʃue,Ǚ ͫus͒eȊ Ϟintmàerƪťleave spŒųĺliǝɧtĲɓŸti#}ίɉǾƞngƪ¤ `ĆÕϝscheme. Splitɨ òuƳsȕing \"segmenpts otīhαerwšisΗe˔.\\n  (  tľóransˋfϒƅoĦrmĴ_ȩpÉ̷a͌raʑȅmʽsF\\x7f:U ͛ɜParaʫmeíteƻrsɚ˞ oʹǔf :clas\\x93s:`Imơ˳ageĠǊͼŪTrƀ͙anΒsfoΧrɽė\\'ρΟȥm\\u038dƋȕǁ`.\\nħ    trans˸forȔm_test_pǇNarɢamϰs: P\\x97arameters ϰBofȚ̔ɲ ʬ:̚cǹƺ˻lϳass:`ImMagˎ̚eTestTȐraƜnsf͓o̘Ã̵rcm`Ͼ used during te˭\\x9b£ȉsϘt\\u0380inΚ̓Ŵgv.Ι\\n    ̤auƫgme̾Ȫnƞʈteǂrʖ_parˈaǺγƠms: PʱarWϝameɞte˹̨rsÄɱ of :classɼ:ğ`ŲƋIϸiϭmagiɭeAēuŻvgƥńǞm̦ěenŧter` ǘusǧȼed dʟurinÔ\\x9f\\xa0gϸ tǎ˅raɠγi̺ƠniΉng.ϣ\\n Īʰ  ͯ¤ mͣixupțϭ\\\\_tyʶp̀e: ƄTyɁpΏe ˸oǴf mâfixupλ strateÜgy͕ f͍oƺr ÍcɨMla̙ssifÂϱicǚϜati˴onͩ Ȓdʥa̲ta͘sǽets.ɞ϶ ̃Ā̂(͈NʄǞȥone orz \"samȎe_claʻłsΏϔ̏ƛs,˃\")Ə.\\x8d\\nɔ Ǚ   baʚǕtchĆ_size: Bˑɞ\\x9ea¡tʺŰċΒͭch˚ XsiʾzeĈ.<\\nØ ą   samɖpleŎs_per_ϜcěÁlaȕs\\x92s: If\\u038bµ n-o˅tɌ Nʧo}ǪƊne, Ǟ϶sample ϳc̲lasseŏ«Γsǭ uϞnʶifoˀrmÌlʢy& wϩȻĩithǋ Pth͟eȤ αgive˞͵nãCØ nͥumƻbˏer̟Ξ\\u0381 ǔȮofÛ sαȬ̼ampleĺÙs pÓeįĬúrmĚ cžălass.\\nʮ   Ņ÷  uniforŤmÀ_˥samǍplĻinjŦͺg=ĩ: If trueaƓőÎĢ ̴aʓnd samples_per_c͜lasͰȞǰs ¹isŏ not NƒronĺeȂǴ, ǚcla˂sspʉşes ͘aŇrċe samplɍ̷ed \\x9fuʃŷnǭiʓΓforʳmΖly ˊϖf̹or eaňcEh batƴ͖Ƈȥ˩\\x9fch.\\n ϋ   nźuƩm˞˱_workeư_rs: ͇Nóu̷˹mb¨er of loa\\x8bder wo͚rkƝerÌs̭ɠ.ɇĞ\\n Ĵ  ϰ͟ƛ nuɦm_valid_w̖orġker\\x91ˑs:Łθ 1NumbeŖr of workπψΠ˗eǁ3rsś usedʮĩΰ for ɵƉvZalid\\x86ʨatioƣn. JŋǷSĶĠõˡeʦt ȆNÂ˃one ɢto uͺseϡɢċǌ theľ˚ ®saϯm4eƻ nuʣmbŞer˵ȏɜ Ɛas ɅʔiȞµn ǨϓϮϲt>Ω͑rʩain.˭\\nǣƘ   ̕ īp͞ˎ˥ers\\x91̤i̺sΫtent_woϢrŌk̭er͗s: KeġeʐpɕɊ Ƿloaλder ĳwϸğorŹk]ers ZΓϦ˖˼Ȇalivμəe aȒft̕Őer ite^rΡatƘion.ā\\n   A sʫêƉ]Ͻhuffle_tǄrain:θɠ W̢ʽh)Dɟethe˚rų̴ to s¡͆huffle Ě˒tr.̋ain or̥Q not.\\n    tǇraǿiġn_Ɋrep\\x95Űeaʑʣtķ: NŞɿumbřĖeʟr  ˯ȕʻof ƢtrainiάngȠ sȍƷet ΥrepeϘtiti\\u03a2o̻¾n W\\x88\\u038bdurking eĊpoch (u¦sȢe|fulȉϖ foŽϼňr ɗ͋smż˴̘aʲll 5ȱ˓ηdaPt\\x96ase©ts)έΜ͌©½.\\nɨΖ   }̳\\x91 prǟ̩˒el̞oad: Load fşulléˢ d̽˳̛ataset toƄɳƍʭ̤ σtϤhe mĩſemHorƜĿy ǺbʹƿΟǁĸefoƔre tr͔aʅƸiρniȑnȐgΐ.\\n  Ψψ  ΑʂaμÏƹȲd͉d_ίlͮƁoƷss1y_valͧsetǊs: AdĀʦdą loďssy va3ɯriĊants oŅf̪\\xa0̃ˣŧ*Ƴ vwaʱlȁˇíǺdaρtionϫ setsƓȕ˻.̑\\n  ɨ  adϦΒL̖d_lċossy|_teǯstƣD̥sʮLɩîetˠs: Addτ űlǆ\\u038boség\\\\sy variant˻s of tʈǃest͡ seɌ\\x8btDs.\\n Ĺ Ά Ϧ loɀãssy]èƚŶ_pƒȡarΑaΩm̓s\\x9eʝ:λ Paʆrſameters\\u038d \\x82ʵƼoɟΙȠ͊η<þfϑĒ ôl͎̇o\\x9d~sʎsy Θʿ/dĉat̨as͠ets.\\n   ̘ \\x84adȈd_verifɐicatɐionϯ_ϭval͛ϩ˦sešǊ̋tȫs:Ž Whether® tΡo ĔĄa÷ŋdd˭ɿ veYriɱfiϖŔöcaę̨Ğt˻ƶiʊŖon vĢ\\x8eˍa\\u0378Ŧlidɝaγtiɜo\\x8cnϸ Ϸɐsetºs Ċinϻȫ adƳdȮition to ^cϹlasƥsi\\xa0fication.\\nE  ˏgŪ  âadd_verifi͟ɏcÜatŁiˍå̀on_tĄ§ƷƋeŅstơse˱ts: Ɂ¥Wˁheħthǟer̙ to `aϓddÐ vȬeri̗×ficˠȐatΑğiŹon ×testsetΐƎs ƖiǨ̂ŚƄ\\u0378Ɣn aŘddiϐtion to ʇc¬lĥassiʃfiΩcat͉ion±.\\n  _ Š+Έ ƥqvýalʅidƛaőˠtźƪǿeŌ_oΖn_Ěntest:ý Cpo[mpu\\x9ate teŭstǪ ̻ʫmeĨźt°ricΨs łbÙŰetw˘ʷeen epoýchȥsɿΝ.ƙ', 'name', 'validation_fold', 'num_validation_folds', 'validation_split_interleave', 'transform_params', 'transform_test_params', 'augmenter_params', 'mixup_type', 'batch_size', 'samples_per_class', 'uniform_sampling', 'num_workers', 'persistent_workers', 'num_valid_workers', 'shuffle_train', 'train_repeat', 'preload', 'add_lossy_valsets', 'add_lossy_testsets', 'lossy_params', 'add_verification_testsets', 'add_verification_valsets', 'validate_on_test', 'name', 'Dataset type must be provided', 'transform_params', 'transform_test_params', 'augmenter_params', 'Gĺ˹etńǞ dat̨a ˆs\\x95etÐ loadeģrs.', 'train', 'Get tːrŗaini˱ng dat˓aset.', 'name', 'validation_fold', 'name', \"`validation_fold` is not None. Cannot perform validation split,because this dataset has author's validation split.\", 'validation_fold', 'num_validation_folds', 'validation_split_interleave', 'validation_fold', 'num_validation_folds', 'validation_split_interleave', 'preload', 'num_workers', 'train_repeat', 'Get dictÒionaͬry of tests˱ets.', 'name', 'name', 'name', 'infer-', 'add_lossy_testsets', '-lossy', 'lossy_params', 'preload', 'num_workers', 'add_verification_testsets', '-pairs', 'num_workers', 'num_valid_workers', 'num_valid_workers', 'batch_size', 'samples_per_class', 'shuffle_train', 'Balanced sampling requires shuffling.', 'batch_sampler', 'samples_per_class', 'uniform_sampling', 'batch_size', 'drop_last', 'shuffle', 'shuffle_train', 'mixup_type', 'collate_fn', 'mixup_type', 'persistent_workers', \"Ge\\x7ftŉ daĹtȵ\\x85aĵ̕setsj diχctäǏ\\u0380ʁionary.Ȍɺ\\nž\\nArgs:ȩ\\n  \\x82˫Ŋ  tŉ'traϲin͡:Ⱦ ˾W\\x8fʆhet©heʎrǁ toƥ̳ βmake ɡtrBaining seÉt Ǳȥor not.\\nǲļ  ͅɊ  trͪ\\x8cansfǞoŮrÊm: WΟʙhelthˢeĽrƪ tƗo appɀlˆyɓ Ñtrans¹forRmXs oƞr ʷnot.\", 'train', 'validate_on_test'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <20x17 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 20 stored elements in Compressed Sparse Row format>, 'ClassDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': [\"CǙh͕eȝckȊ iĄf Ǘa patͯΜh ȫis Ȋaʈvaϣi£Ϛ̠lablPe Ϥin ƈyouźrȫ envi˓ronmǝ̾ΔƉeɭnt.\\n>>>ȼ _mȈˠxodu\\x92leÚ0Ǽͯ_av͠Ĕ±aϨϘilbab̬le('os')\\nTrĎǩu˥e\\nɠ̊>\\x85Μ\\x96>ʇ˘> ;̂_modĳ˃ȘuleſÎ_availaȺɽŢɉblͨe('b;l˖a˗±ˏ.bʌla')ͺ\\nFal'se϶\", 'Ƃ ϊ ΰ   ι ɹȰ  \\x88 δ ǎ Ũ', 'pytorch_forecasting', 'pytorch_lightning', 'torch', 'etna[torch] is not available, to install it, run `pip install etna[torch]`', 'wandb', 'wandb is not available, to install it, run `pip install etna[wandb]`', '     ɴ       s ē     ', 'prophet', 'etna[prophet] is not available, to install it, run `pip install etna[prophet]`', 'ˏ     Űψ̏ ɽÆ ', 'tsfresh', '`tsfresh` is not available, to install it, run `pip install tsfresh==0.19.0 && pip install protobuf==3.20.1`', 'etna[torch] is not available, to install it, run `pip install etna[torch]`.', 'wandb is not available, to install it, run `pip install wandb`.', 'etna[prophet] is not available, to install it, run `pip install etna[prophet]`.', '`tsfresh` is not available, to install it, run `pip install tsfresh==0.19.0 && pip install protobuf==3.20.1`', 'etna', 'Settings', 'Encaps˯uɏlate ʬthe logiDc for finding ̛\\x9aanΤd reading config files.\\n\\nAdaptɄed from:ò\\n\\n- htǔt\\x8eps://github.cʸom/catalyst-team/catalyst (Apache-2.0͠ǅ Lõicense)', 'Find and² genĪerate all local config ̫files.\\n\\nYields\\n------\\nstrʚ:\\n̍    Path to confiͩg file.', 'ʞȝµ  ¬\\x85 Ď Ŝ\\x8bƒͮ  ōN       ΐ >   ̝   ', 'There was an error decoding a config file. The file with a problem was ', '.', 'There was an error trying to parse a config file. The file with a problem was ', '.', '              ', 'nt', '~', '.', 'XDG_CONFIG_HOME', '~/.config', 'IniĔtializ̑e object to find config fiǛlLçesɽ.\\n\\nParamŝeter¶s\\ṅ------Ǔ----\\nEdpª˳rogram_name:\\n    Naďm\\x85eϩ\\x8e of ʔth˾e curr\\x92entΩ prǊogram (eΔǋ.g., Ǐcωbatal˰yst\\x89)Ɖ.', '.', \"ĀF̃ibΤnĆd ǏjaʻĴöll ÈʅÉlocalYǰ̏ c˂voδnfΊiˍg Gfǉiğlζeλ˿·ķsɝ̱i Dwbhưic˫h¸ acɹķʰſtuaȅɁlǰly exist*ƈ.\\n\\nȈΌ͟J˩R\\x99¸ſeŴtuɋrnŬθsʁ\\nȎŴ--ϙ-σ--˯ʡ--\\nLȋƤɶYǺ;iÏst[s˩t͎ϴrȖ]:\\n \\x9bȾ  ɋΟϳ List o͝f̥ fiʉlesͺ \\x84ȃthΪ'açt eˬxȬiΨstœ tihȚa͜Ʒt arͼe\\n ͪ ĳ ʅ l®ocalŕǩ eʣprȌ˽o\\x94jeάct cȠo̝nfig ǿ fi˕͓leªs ȥwit`¤h@ extεraÀˍ͓ cŎȖonąfǗig ŌfiƤ͟˂lǁɹes\\n̵   Ƚy apƽǍpΌ\\x8e̎eɘn3deÍ\\x88ϕdΆ toȬ Ρth̖áɅt list 4(wʒƿhic5h®ʮƦ aźlsώoĔ͍Ý e$Ȇxist)>\\x93Ɉ.\", 'Found local configuration files: ', 'Found user configuration files: ', 'store_true', 'store_false', ' has been normalized to ', \" for option '\", \"'\", 'Pʟ͝arsɞ\\x91΅eű aŋndɰƼȄ reµȝtuȶrn the ūlo\\u0380cal aΜnōd usºeʋr øconf¨ig\\xad fileʢ˻&s.\\n\\nFΚi\\xa0rst tʗ͛=˾hiλsː copies oveċrοĔĚ tĜh̘e pýarsζÁeȄd̥ȅ+ lȁoc7aŧl̮ confíguĭȚrļatĤiϖon andʛʺ φt̰̂˱hen\\niter̖êaātƒes ƉoŶƯv˲e!̐r tƈhÐ̡̡e ˿ɽȟȖoϕpýĎștio\\x80ns iʀn th(Ǖe ̙userǤ ƫconfiɐgurƘċatʷǪʱϛɩion !a>!nʯĘ<d s;G̊ets thuem ̉iQȒǷΠf\\nthxey Σʩwere ʍnΨǾʸotʷ seƈ˄t ɨͩɊɝbyȣ˥ ςʜtƼhŭe loc5\\x95alɇʖ co·nfigΒuratiƘon f̈́iϤl˴̈́ʡeˌ.\\n\\n͌VRetȢuƈrȏ\\x80ns\\nǔβ-----Ó=Ĭò--γ\\ndic̝t̻:ȴ\\n Z   Diȶctionϱaȝry̕ oȜf tʒοhe pƠađΚȳrsŴeΏd Őaϻnd merź͓geθdȖ cµonf}i˒guratiIoSˀnĬ ʠoptioÏǔnsˉͰ.', 'SETTINGS', 'Settings', 'ConfigFileFinder', 'MergedConfigParser'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <34x34 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 34 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['ǂT̥rSΊή̞DataȨsϧeϴʅτt ŭ\\u0383iŨô1sΒ thˊЀe mǛǓai\\u038bêü͢n ͞ǷclQaȹss tŻƼo ȁςhƚͧandȎΠlƏe \\x9fČyo\\x99uȾëϺʠr\\x8f1ˣ timeş ser̃ives dakǜ˒t̊a.Ů\\nIt prģ|ʵe̷ͬɋϳpTa\\x84ɠǤreϕʷs\\u0382 FtẖĈeĻɁ̉ āʀsΓƧ̱erie¼sͧǞ Ĝfor̽ ũexǈpϤlo̖ratioͫǂn anͥalǲy̰Ȓũziͻʭn\\u0380gϝ, impBlemǭσeòȽϮnts featȂ͈͋ure geͮnerϩǔat̼i¥ː£oƟnŅ̦ wɉiʦ̇th TrōǠaµͮĠnsforSmϵƎsͼ\\nand\\x9fâ\\x9e ¼g»eneraαtion ƪoĺfɑįȻ 8ǇfŴc̢uŎtĉɝŒur̤ȷe¿ ΐpoi\\x88͝ËntsΜY.\\u0381\\nĚ\\nNƷƶΎΑotɪes\\n̎-˥ë-ʧ--ƭ-\\nTˬSă˸̓DataǵϽset Ĩs±ĸupÊ6\\x95ĚÁʚports cuð̪stƾoɸʁȂm ȵΪindeǺæϛxiǐng̩Ū ďöand ϸsíÝ\\u0383li¼c˰inĲϥňg ǂƞʹmeϐthŽoȗd.\\nrȻMIȰtΒ Uƶm͜ˊÁΝaybʥe doʩnϝe F˿ńthrϪou˯ghɸσ äȻtͶ¾ȱ̕Ƈh˔es©eˀ inűtȥer˾ΜūƳǠfœƤṳ̌ǡaįƕc¤Ǖe: ``TɢɍSD\\x90ū\\x82ataset[tˣɱiƁ·\\x8eǷmestɩa˥àmkεĔpȧ, seĸgmeŵŁHn̑tʯ,͞ȼąϤ\\x8e cĔɟƤğolƉum.nͲ]``̈\\nά˝IÛf ęatʎ t÷WåhŇÏÈę˱ɑʥ±Ǉ\\x80̙ƂeĨ ˈstartȫĨ oγfȳϥ thΝ̬ʙΥ̋Õe pͿerʢi̱̅σƐodį̷ datȚɎƢaˬï͑Ȓ˿s´ϩeƭϕʗtį+͒Ϸ ɴ˝Ć̩ʐcdǛonƿtains ƩNjɑaʮHN ̠tΗhosePŐċ t͝imǕ˓eοsÆɞŨtPīʌampͥs̪ ̱͓Ưwΰ\\x8cill be rŜemoveϰd.\\n\\nDuƈǞɆrɭiȋng crǔeaǸtiɨoīnƬ skʼegmȉĥe`ɌnΐȾt is cκo̘υas͙îPtʼed ȮÙĊŐƅto ʎsʹΔt̬rĀi\\x97ƐnǤg ȅtypɸƊeƔ.Ǖp\\n\\n8ȆΝ̅EŔxaʣ\\x7fmǲB˱pĩȹlþϩeȭsŜ\\n-ˣǧ-Ͽ|---ˏ-Ȉ--\\nǇ>̮ǆ>>ģɖƙ froŋBm eĘtΟn\\x81Ya.Ιīdat%aʤs̤e\\x80̭ΎtɹΌŷsÇ imĎport ľg\\\\ʧʼ˓eϣneŔrƾatgƊĽe_ͦcÉħonst_Şʃŧ΄͌˟<ƍdfŒ\\nƥ>˟˧˽>>ʄƩÖ d˘fƖ Ϧ= ǒg>ϗŦɔeĶnnerˮä́te˴_ɵ`co̺Uυ±ʤµnstʗ_Ɨdf(pƬ˂ǬeǸŤĘǔȮ\\x89rio\\xadds=.30ɱ,ȪƳσ Ϋ͘ŋst˱arǐt_¦ŋtime=á\"ä20Ũɐ2ȅɧʻϦɴƂ1ǋ-Ε06-0Άʊ1ʰîƤ\"ƪ, BnĵͪǕ_s˓eZ̪ýgĀ_΅mbeʰntůs=̃2ȫ,\\x98 scά͆aʝleî=1)\\n>¬\\\\ɟ>>͂ df_tŇs_ʰfÏÈoȚ¸˵r̺ϋαśma=t\\x94 αÝû=ώ TSDaȝΦ͏ƦŨtƐϲϚaset.\\u038bt\\x7f³oǆÇ_ǯ2dat̉ͅa§ɊseǨt(ɦdήf)\\n>kȓφ>̓> ˱ts =ĲƔŬȘ ƒϦˠTɒưSDatasetƼ(dƐfÔ˱_tȶǃsɘå_form̸a͉tƇ̥, \"D=ę\"ȁ̤Đ̑)à\\n>>Ȭè> ͠˓Øtsjǚˋ[\"2Ż02$1ǚ-06-\\u037901ˡɆ\":\"2ȑ021-0͎ˡ6-07\"Ǣ,ˉ³ \"segmȱƀʇńņŒ\\x9cjUent_0\",ʃǏ ȸ\"taƁ˷r®goˆe˳͵ϫ\\u0381ƊĿtǃ\"]\\ntΪƂimϰϡesûtamp\\n2Ɖ0ʴȥ2ç̬ͳͿ1-0ǧβƀ6-0ʬ1Ź~  ʸ  ŧ1̟.ϡ0˜ǖ\\nȘ2ǻ02Ç1\\x8cƞ-ǻ0̍ο;ʓÇ6-¥ŉ©0Ϳ2 Ǚ Íȅ \\xa0 \\u038d1ʣ.̗0\\n¶_̑2021-06-ʾϦ0F̈́3  ʓ Ō 1.0\\nͫřǌ2Ƃ0Á21ĥόŎ-06-0Ƚı4 ɨ Ϭ   1Ͳ˅.Ɔ0\\nɹ202Xǎ1-ʢſ06̏Č̴-05ō ͏  Ú 1.0\\n\\x8120ɛ21-0Ńʽ6-0Y6Ƅ¢`Ã7σʲÅͿ ¢ ˡ ď 1ǜÎǗʠ.0\\nțÒ2Ɂ\\x9702ͩʱ1Ϟ-0˝͙6-ϓ0ͻș7ʈ ϙ  Ɇ Ǡ1.0\\nFǍreqǳʰì: DŞ̉ǯʦęƈ, ĶɸȥNǎme:b (segm̴Ǖent_0,ʴ taȆnΩrgetƫ),Ν(ʅ d\\u0383¥tyʴpe;:Ī ƇfɗϸlÆoat64̼\\n\\nȣȎσ́̌>>> ʉfroιm etna.dūœatɭasets ØŴ͍\\u0379i`ɫmpoϽ̟rtžU ºgɚeneΚȖraĈte_aϏrǍ_ɵ\\x8edΫf\\nt>\\u0381ǻˡa>>ϋ\\xad pd.Ďʪ²¥opǸtiŶonsˇ.Ϻ̧Ƹd˭ƄɵispɧĸƚlɎayǶ\\x83΅Ƥ.ȏ̄f˞loatĐȭ_Ǚ\\x81fɲorþǤm¬at~ ȚųΪ= \\'¢˜ʃ{:ɐȴ,\\u0381ƷP͑ξ¨ëſ.2͒fͻ}\\'ǁ.ʏϠ`for˂m˔at\\nμ>Ð>\\xa0ð> dˣf_to_foreʧcaʊsͼtɮI = gŭenerpϧ͟aΏˆte_ͭĭar͔_ɜdfŕ(&ƀ10ʶ0,ǂ stϮar_t͚ʦϑ_\\x81ˏti̞͢mǿúe=\"Ɵĕɿʳ˅Ȗ2ωɊ0˰ʎɗ21-Ͽ01Ė-ʏ01\",ƥŨ1\\x90 6ɨĸn_ĻseȔgmqȖϝents=1̤)\\n>>C͖>ƢėÛ\\x9d ˤdȦɞf_regre˿s͔soĘýrǡs\\x9b ǭɖ=ʏ ť\\x85ǫgeϻžneraüt\\x8aăe_ˏǻarʺ_Σdf(ȪůÐ12̱0, ʓst͋Σa\\x88Ȥʺͻʿ=rt_t̵ime=\\x80ϷȮĂ\"ǚ20Ũč21-01(\\x96-0ÃƥǗ1\"\\x9b, n_¥ɆΖsegments×ˢʦ=̊ȐĖ5)Ɉ\\x8a.\\n>ϟ>ɣɃ£> ndf̒ś_ʒrȵƖe̠gϡressors ɛ=ϼ dȨf_ǥκİrıe̳gressorǔƺs.·â̪p\\x83ivɼot(Ƽindexƍ=\"tÙimeTǣstamο\\x83ɂϪ¿Ƣˌp̄Η\",ĵ ɵcCo̥lumn¡s=\"Άsegmeͅnɉtȕ\")ϯƗ.rΗʲîż˪eseɥt_̜ƈinɋƙôde˯xȻ()s\\nǜ>>>ơ dfȣ_re̷gȓreȯssors.:columɟns =Ƣ [ɵ\"tRimö̈́eɺHsȓǻtaͅƵĤϽmp\"]̞Ώ ɿ+ ͝˹[f\"ǽregɉreÊssožr_{ȴi\\u0378}\"Ǣß foďƚr ÁĨiȱ ώiˣΔnʮ rang\\u0382eΩ(͎5,)]\\n>>ǚʡ>Ź df_reg¾ʓʘr£ϑɦessorɔsļ[Ņř\"sʹegmen͑ωt\"¸ʿ̏°Ů] = p\"ɨžƊsŴeê\\u0381Ļ^Ʉg7mƞ2ZΧent_0\"\\n>>> d̫f_t;o_ʌf^oÿreɛcaŰstĠɋ ü=ϓ ǸàǍTSDêatŴaset.to_dataŐ͡φsƾeϻt(dfʹ͠<͜_Ðto_fʳor̝ecaŪst)\\n>\\x8cϚ>>̿̍ dƀ1f,ʴçͩǘ΅Ɖ_rʔeʋgrĈǭħǸĐ͋essorƁČ̖ʄhϘăʀsɲ ąɣʎϰ=OÄγǸ\\x84 \\x92ɣǾTSgDatͼaseȳt.t>oʄ_ϙdͺatϠ̗aseƬt(ɥd̛fϙ_rã©˙egr̸egĩ=sĶs˺̧̂Ðoʹrsϒz)\\nK>Ï>>\\x8fɸʯ ʩt˯ͭɡġsdaȻξtaqseśt WΙȆË= TSķ3}ľDaʌtϙȧas¢etϥ(ϩŲdf=dϝöf_tor_foϋ΅rÃˍeʾŵ͓castŜƝ,Ő πfŊreώȹŐqȃʃʜ=Ý\\x88\"ΰėD\"ĽWĉ, ɩȉd̈f_eɁxo·g=dfÎų_regreMsʱiǘsɲoϏʭ̱ƈrΔ˦ùsϼ˅ư,Ȟù kȜnow\\x9fn_fuôturɋȔe=:\"aŁlĄ̊Ϣl\"ƒ)ùſ\\n>>İ>Ǜ· ˾¯tŅsdata(sƐet.dfϥπ.heUȱad˧(5ðʢ)Ȍ̑Ω|\\nsΩeúgm\"enζtȶ Ł  \\x9eǴƖÆȚ̈   se˅gmǝenΩȆt_0\\nȦfea̅ζture·ðȫ ğ   re̗ȼgň˳ʪrɺesįs\\xa0ʗor_\\u03a2ʦ0 regrAestsor_̮1ϽƢʒʐǳ ̲rǕe\\x89grēμ̈ġessͬƊΕșΦϷ¤doĂǀˣ̺lr_2 r&eơćŦ˓gŸƚr˼esΥsor_3 reʳgϣĳreϭäƙȃ̒sOsorƙ_Ϻ̳\\\\4ȥÏ˾͌϶ʃ tΥargŕet\\nƤ˒̊ʡtimǕesζtˏamp\\na͞2º021-ûƼʍ01-01Ϫ·    ̙ α ģɱǃ˂  1\\x91\\u0380ç.62ǩǕ̫  ^   ϊX  -ŧɷƳ0îϣγ.02     \\x85 έ ÙÍ˨-ʻů͋0ƦÍ.Ȋ50Ô ˒ͷρ  ȥ ǌ̂  ȁ -0.5Ϝ6    ˆ ͗   0)_.52 ϴͲ  1.6Ɍŏ2όǲ\\n͗2021˟--071-0Ŗ2 ʏ   ̈ŤÿĨ˜ ̀˪ Čɬͼ¹͞Ś  1.ļ¿0ų˔v˄ʟ̔1̣ʧ͈ ĺ Ȱ1 őʎ ʲǞ   ʡϋnˀȼ-0.¯8͔0\\u0378 Ȁ ƞ ͝ô ˪  ſ Ϝ-τ0̥ł.ʀ\\u0383\\xad8Ÿ͑a1   ɎL\\x90  Ȫ   \\x99ɻϨʋɁ0.3ȁǇ8 ɉXǆ̛ɢ ĕ     -0υ.6\\xadȔǭϖ05ʢ   ʏ1\\x9f.0ƾ1ɾ\\nˢτȵǑ2͑0ï21-χ̖ʽʦώƪ0ϩ1-0ɉ3š,˽  ̬ȧ   øf #ʜ  0.ĕǟ48ʷŦ Ψ͎Ɖ˗)   ʢ ˒ʌ 2  0ς.ÙЀĎ̨47   Ǚ̲Ϫǅ   ŝ ̄-0.8ˆ1       -1.\\x9456Ϥ\\x84 ̊ʏnÿ  ɩ    Ɲ-1Ǽ.Ó̴37ư  Ű άΊ0̤.48\\ṇ2ğĤΈƒϋ͞0ǆɝ21-ɇũ01-ϗˬ͒04ô   ϟŻʶσ̍  döĽ  -ʕ0ǐʴ.Ͽ59˻  ʥ ŒĂ     2.Ǒ4ɕǜ\\x804   ǉ  Ŏ  ̗-2\\x9cǊ.21Ȍˇ       -1ȼ.2IĠ1Ȣ Ρ  ϋ    -ΐǓ0.ϯ6ǐ9 ɤȗ Ȱ͟-0.^ͻƊĹ̯ϭ5̂9\\nȚ202ȞŜ1-0Ɉ1-£ŠĪ05 Wĵ   Ŗ ˅Ċ 6 ŧ ʈË0Ƹ.έ\\'2Ŏ8ɝ   \\x93     JǪ90.ʫō̥ʍ\\x8d\\x8a\\'58L   ĈűˋŴ    -̐ɠ3ϧ.0̇7\\x9c       υȅ-ϺŹεǑ1υ˶Ŭ.45̬ \\x8eǡ _ ɒ ɨuϭʰ    ɇϮ0.7̞Ŭ7ǂ Σ  ěζ0.͕Ƨ28ŮƋǅŌ', \"Find ͮborders forʺ trɅa˅in_test_split i\\xa0f sĹ\\x97ome values wasn'¦t specified.\", 'test_size, test_start and test_end cannot be applied at the same time. test_size will be ignored', 'test_size is ', ', but only ', ' available with your test_start', 'At least one of train_end, test_start or test_size should be defined', 'The beginning of the test goes before the end of the train', 'Transform', 'Transform ', ' is applied to dataset', 'feature', 'feature', 'Something went wrong, Trying to merge df_exog which is None!', 'Inverse transform ', ' is applied to dataset', 'ǟ¶ʺReϕëǯϠtÙurΓ\\x8bĦȕn daκt˓aframɠeòh wƪΏiǔ˧Pthɻ fΫlʬagμ FΛthatȏ 3mean@s_ ifý thǹ-e coɗrʆ́˂re~spoǟndȘʪenŏtTơ˪ oȃbjeΫcˈt iön Ȣ`ǁ`seǗl˻f.dϤf``Ő is nucll.\\n\\nόʠReturˋn˔s\\nȬ˽---΄---̟-\\nƙpɔd.DaÕtafBrßamΖüψeβ\\nB   ¯Ƙʑǆ _iϡs_Ŀn?ullĸ d̉atΈafȵrĄame', ' ʯ     ƞǻĹÜ   x T  ʥ    , \\x8d', 'Transform', 'ςAppϣl͈Ɲy givǦeJFʕnȀōμɳͮ trώa²ȉϕn̾ΆesƗfoʕrʋmΉ tΚoʘ the dat̺a.ȃɮͣο', 'Transform ', ' is applied to dataset', 'feature', 'feature', 'Overviɚew of the dataset thatįΖ retur̅nͲŀ̈sΏ a DaɾÿtaFr˝am¥e.\\n\\nMetͱhod desÿcrib̃ɕϧes datasȖeʝt 2Þin segmentȳϯŸƮ-˚wise fasɒhioƗn.ǀ Des˔crip>tion colu\\x8emns:\\nĸŅ\\n* start_tϣiʯmeάͼstaŗmp: bɟeginniaLn˔g{˵ά ofϝ the seˢgmeĈ̜nt, mi̥ssing vǆal\\x83ues inΤ] theɩ begin̳nĥinʡÂgͣ aɼrăe ÁˡiƔgnˉơǎųred\\n\\n* endͤ_dtimeͰstamp: e{ndiūng oNfĈÜ theʒ sȁegm̦enŝt, miss˽ing vχaȉrluȩsŘ in üϽthe endiϜng are ignored\\n\\n* lȏken̍gtŁh: lōe#nűgth} ĵaccorŐding to `̟`startɞ_tigmɰĩeʒstamʳ͋ċp`` ǁandΗŬ `à`enϯd_tʵim̛estamp``ąϤ\\nƣ\\n* nu̼Ƀmǂ_ţmisƪsingÎ:ˆ numbeȘr of missiʷngɾ vawriables bǩeϤͷtween `ýč`start_timesȴtamp`` and ``eĨƹnˋǑd_tͷimestamưp`Ȳ`̏ȰƆ\\nɖ\\nɤ*ʠ n̍um_seʹgme͊ntsΖ:# t=oƕtal nƐumber ʥof segments, c͚ommon Ȕfƹor \\x94all ʳsegmentsɌ̼\\n\\n* ½num_eńxogsͯ: n\\x8dumber ofɳ exogenous features, õcommon foríȓʓ ʞall sǿegment͎s\\nƶ\\n* nίum_ɲregɼrÜe̚ssoȈrsë: n͎Iu\\x98űʗȽmǖΧber omfĻ exǞogenĸous fxđň\\x8aact8orsϋα, thaƕt are rǅegressors<, ǣcomƯmˑɺon fʒoĐr ͠alǚλϡϟȹl seg\\x8dments\\n\\n*ù numİç_kno\\x8awôƕn_future: number͉ of regresˤsoƑrƮs, ¾thƵaɚt are known* ΡsincĆeµ cƠreaÛtion,¢ coœmmoΎ̡n for all s©egments̓\\n\\n*ʫ freq: \\'freqǀuωen#Ȝcy ofŔ theϪ ȍseries,\\x9d coƾmmoΎn for all Ɔ˛seǠgmeͨЀntsͯ\\něǺ\\nPŚaraΕmƢ¶eǱters\\n---̈--ȼñ-Èω----\\nƈsȫegʚmĴen̄ts:\\n  ̼:ȇ  ϗsΚe;gmentsˢ ×to śshǼow iϦn ϺoɎverview, i̊f͗ ȪNoǺneŞ ȬallΚ segmʐents ɦḁr̗e shɵown.\\n\\nReturns\\n--ɀd-ɗĔ--Ȧ-ʚ-\\nresuLl§tŉʁƮ´_tabDlıe:l pəd.Dat¸aςFr\\x96Ưameό\\n  U  tEable \\x9awiʪȪth rͯͩes̚ults of the ove˿rview\\n\\nEx΄am8ples\\n-ɭ--\\'--ŧǫ-Ż--\\n>>G>Κ from eėtna.̣dataseƧts import geĻsneˍrˍate_|conCst_df\\n>>> pd.oͯpÛtions͛.dis[play.e̥ΰxϤpand_fraϪmwŪj\\x97e_µreNp¹rŔɝ = False\\n>̕>> díf = gen0erώate_ưcons˲tΏ_dfɿǬ(\\n...    peʹriods=3ȍ0, staȉrt_time=\"]2021-06-01P\",\\n.ɒφ$..Ŝ    n˚_segmentɼsɱ=2ͫƓ, scœŧͻ͂alẻ=1\\n.ȃ.. Ε)\\n>>>Ǥ df_̚ts_format\\x85̃¨ =ʄǕ TSDataset.to_Ƿdqʜatõaȣsõet(df)\\n>β>>/ǸȂ regreǾ\\\\ssorsΛˌ_\\x86timŭesŔtam̈p ù= ȡpbd.da AʰtºeŦ_rʈɥanţge(ɍȝstarʖt=\"2021-06-Ή0ß1\", æpeȷʇri@ods=50θf)\\n>>> df_regrñessoλrsĮ_˜qû1ʳ = pdʺ.DataFǓrame(Đ̰\\n...    ʹ ť{\"times\\x9e\\x980ta0mp\": regresπsɼorsď_tʨiϿmestġamp, \"regΞưrτessorŶ_1\": 1, \"ϐʯseȓgm@ent\": \"s͜egmeÆnta_0\"˙}\\n...ʡ˓ )̴\\n\\x81>>> dfȎ_reρgressoƸėζʍr˵s_2\\u0381 = pĐd.DaʬǞtŢayĬFram1e(\\n...     {\"timʉestϒamp\": regress˶oťrs_òʲtiɜmes\"ġtamp, \"reͶg½reÚsͽsoȜr_1\": 2, \"segmentɑ\": \"segment_1\"}Ͳ\\n... )\\nɥ>>>ô df_eξxogƿ Ǯ=Ĉ ʊp͠d.Ǜconcaˈtņ([dό͍f_re͕gresψsors_˩1, df_ſregre̚ƙǏssors_ê2], igϠnorǊeć_index=Tʕ̅ƈrue)\\nƗ>ǵ>ɳ>ˏ df_weȶxog_tǦs_fŽormat = TS϶Daǂ~taset.tĢo_dataͬset(df_exog)\\n>>> Ğts \\x92= TSDatasest(\\x8bdf_Ɉts_foņrmfaθt, df_exog=dƶǣf_eʭxoοg_ts_format, fr̚eq=\"D\"Ï, known_fuͳtΑu˲re=ƹ\"all\"Ȑ)\\nĽ>̺ų>> ʙǮatsʃ.descƑriĜbe(Ʃ)\\n  ̩  ɘǩ ɖ  ͥȢ   star\\x81tǄ_tifmƂeʸsȘtųǃÃampʫ end_tiƂʯmesɱ©Ĕátamp  \\u0379ìlʛenʤgt͗h  num_mǒˮisªsin]g  ɊnumΏ_segm˕ent˴s  ͆nquɱɋm_̈́exo͠gɖsĿ  ʌnȐum_regΠresȀsors  Źnuϋm_ȴknoǨwn_futurē f\\x83req\\nsegƟme̕ěnĸĕtsƘȫ\\n\\u0383ǖsegmͳeçnΘt_0      2021-Ê0ϧ6-01 ɍ  ʥ 2U0ƪ2ȱ1ʤ-06-30Ƽ     ś 30       Ͱ    \\x81ă 0  Ľ ̂   ,  å     2 Ȗđ    ˿ͭ +    1̃        ϸ       1       ͫ/      ͯʝ ɻ  Ý 1ʐ    D\\nsegment_1̺  Ë    2w021-0Þ6-01γ  ȝ  2ʹ0ī21-06-3ί0      3ɀħÄ0        D    0 ʈ       ǽƘ     2  ˗        1  Ęˑ      ̈́     ɲ  1      ˄  Ͻ    ˧ g    ƃ1    D', 'num_segments', 'num_segments', 'num_exogs', 'num_exogs', 'num_regressors', 'num_regressors', 'num_known_future', 'num_known_future', 'freq', 'freq', 'start_timestamp', 'end_timestamp', 'length', 'num_missing', 'num_segments', 'num_exogs', 'num_regressors', 'num_known_future', 'freq', 'segments', 'Conʭ΄˻v̖e\\x8er͑t ̞Ǖpˏɸ͜+ϠǚaϜ̪n;ˍȰɚƯdaãsɛ dªʘatϜafr¢ŇφʢaČme t\\xadϵoϿ̑ ξEűγTNAːÆɠȡ̊5 D˞at\\u038baseˑΜt ¦˗ϾJfo˱rΓmʛaĴt.̶\\n\\n˰Col$um\\u0378ns \"timˀeǶƜɗ\\x91sëtʾƥɇamp\" ¸and α\"ģǲsªegmeƥnĄt\" ϱ͇ęυaͣ¡rϋeϡ ȽŮrequÅiϷ̞ξred.\\n\\nˬPgar̵ǢaȠkCʝƦmeĘ?ϦtȅŤŜers´½\\n-Ê---Ȣ-ˀɋ--ͫν---ʧ\\ndǯf2:ϱ\\nɞ Ř˵   ϸDaoʀΑ:taêF\\x80rame Ͱwiftϴʹh Ϫ͘ƀñȌcoluum̖Ʉns [\"Ÿ͓tiϨmes\\x94tamϭ\\x8aϝÓ¹p\"ʆ, \"Ɍ˿s¹egÊİmeŊnǷt\"].ĵ» ǅOtϓŞôhe͝Λr ccolǷĩuǈϮmnɰ>͊Ðs cɓoǪ\\x8dͽˏ΅Εnsideļʼr˅ɻezd˿Ȃ \\x93featʎǭύuýɟνres.ƫƴ̲̚\\n\\nőïN²otͳͷeǓs\\nΔ--̲--ʬ-\\nDȸǟuƁri\\u0381ngȎ cȱNon\\xadʊvŧerŊsion̼ segmʻent ʦiʒĳs cŏεasXƁte͆d Ɵ÷tíϴDźˬʒɂo ƉƼstr»işǶnÙ̽Τg ˣtǎype.ă\\n\\nExampŸε¢ɓlʝeˡϥǸ\\x93ϜsȴƆƙ\\n-ϙ-˷-É-BĒ-Έ\\u0380ȴcΚě--ŭ-\\n̾>ɖ>>\\u0381 ǹΜfrǬψ\\x98o˓Âm %´etŃna.da˄ʗǢ·tas͕ets iƕ̈ĬϳŘmpșoɤrϱt öǸˀĭgǐɴ̜enȒeǴ͗raɧ˼tɶe_ȏôðήconstÍ_df\\nș>Ƞ˝>> ̥df = genĚͰerate_Ű_coɽnʧst͏_d̿f(\\nͯǂ.ƶŎ.s.Ɗ    ȏͨpİȀeriϻodsƑ=Τ30Ϝ,ǩ˕ staŤĝrƦŇt®_timůe=\"2ǟϳ02͟1-0ϨΨ6ϥ̻ϴ-ʖ0ʀǖ½Òɧ1ǈβ̻\",\\n..ū. ȫƼ   Ƹn_seΕƿϧgΝŶmúe˫ntĬ\\x98sʇ=ȱ͌Ȫæ2ĠƳ̑,ĢLϳ ǁsca͇Ĥhle=1˰\\n\\x83țͤ.ĆƼ.άŵɟ̵. )\\n>>©̈́>Ŧ dʵfĪͺː͖.ϋheadȏ(5)ːϽ\\n  ǅ tƕ\\x9dͶimĴĿeēs×ɟ͐tÀamp ̝  ʷó seʍ̌g͐m3entĔē  tʲanͿľȆr̓g±ɣ>eȨt\\n·̾ϊ0ʗ ̜20ɽ21Ć-0ÅT̒6-0\\x9b1ðΓ ĭȻ /sőȎeīɃϡ°Ƿgʘm͢\\x8eeūnt̀ˆɧ_±0\\x99̷   ˪ͧ ϝ1.η00\\n1Α 20ȊϾ2ƹ1-\\u038d0ƄÒϢ6ɟʁJˢ-/ȇȴ0Ȏ2ȀΨ ʭ segĜment_Ȁ0Ɠ  ˮΕΕ Ɯ ε1.Ĳ00ĩ\\n2ƳϿȟ 2ϕΧ021-06˨?-φɥ0¾͋3 Ü ʢşsegmeΕnt\\x8bƇ_0͗ǒη  S  ͊Ρ1.0Ȯ0\\n3 2021-06-Ȕˍ[0̥ͲΛ4  śHseĀǧg\\x93m<ƾenϾͤt˾\\u038dɴ_0  ˪ƽ  ̕˃b͘1.00\\n˲Ȣÿ\\u0378Zϯ\\x8a4 ̹2\\x960ȯ21-ϗ06Ƞ-05 Ń ǥsɩʖǒeɮȥgmeƹn΅Żt˲͆ź_̖â0ʡP̊m ʊ  ΐ 1.00ɱ\\n>>>δ ŵdϔɚơǥŮf_t$ʓʲsϵ_formaʴt ɲώ= TSÍĀDatǽ̷Ůasο\\u0381ʊeϹũ˥t̼_.ľƺϼ:to_ŰdaȻtϬasȷet(ędf)\\n>ɜ>͒>P df̈jģΆ̢_ʈtsȑ_ϗʛformǁat.ņ̊əheơaΞͻd(5)\\nϫ¾se̡4\\x98gme8ͼnƒėǮt  ɋ  segmaen«̼þt\\u03a2_0 sȿe¿Σgmϕ̰ʁ}e̲P\\u0382nt_1\\nȥ˘Ōf˃e\\xadaǸtǲurʥe ĸ  ˃³Ϡ ǈ̑ϲ ˎ ƖČ tȢpaǄrgeǛtƪƅ\\u0382 ͑  F Ϗtadrg̣ͪetǂ\\ntͪiʥmesɆΕǳtƟamÔp\\n2ɵ0Αʲ2Ɣ´1-0̐6-ĥ0ȍή1ɩŘ̩     ʓϴ ͒1.0Ϛ0  õ ˼   ʭŪͩʨ1bŅ-Φɖ˛.ǈ0Ϡϫ¯0ǥg\\n202¾1-ë0Ϩ6-0ʟ2 ˯ ¹ŗ ¬Ν˹Ƶ ð  1.ɣŷ00˂ϕɖ    ƛ͆ł ̛į 1.00\\n̳Ɇĕ202ϛͨ1-0ǥΕʄ61ƓϪ́lͳ-̢ȳʹ03ɰ   ̰ç ˩̽  1ɠK̙.00ǅ ƩĀ   ßʩ ?U 1.ů0\\x91ʼN͜0\\n20ǝ2Î1-06-0̃Ņʞťέ34 ʌ Ãͮ λ  ƪ½ ˊ1ƅKʞ.Šϭͅ0ɇ0 ǘ\\x8aŜ ̢ ˑ   Ͱ1.ΘɲêÒΖʹ00Ζ\\nǱ͊2Ρ0Q2ɱέϗθâƽθ1ͩȀƖϳæ-0ƶ6-05ŐX  é˫  ƶĺǨ  1ñ.00Ơ υ ͘  ˚  1.00\\n\\nɶ>>> dźķf_ʙèrÔeÒ>ˊ̨grȉʷeWssϵoʗįrs Ń= pƵdɌƞ.Dçaċtaŉ͜Frʌʠƪˊ͚ame(ˊ{\\n..ΑŝĤ.̥Ƀ̎  ̲   \"\\u0381̮tiŀϿ͖mestam͏˲pϫ\"ǟ%Ɵ:͕ɚ ȧpd.œdate_rangeŏϱ(ϮƸ\"2ǝ021φ˲-ǯ0Û1ʉ-08ɇáâéͨǲ1\",ľ pŒ\\x92ʦʞetʐri̲ods=10)ċάǍ̑͂,\\n.ʁ\\u0382.ǔʒ.ǅ  ʑ¤αɻͯ   ʁ±̭\"rΒegreʨsƣǵέsor_̗Ǒ1\": ʐͥnĬp.ýar¼aϪnɱ̄ęgĉIče(aʰƩŦ10)ĺ, ̀\"re»̢͈ʥʔ\\u038bĊg˳͘rͣessɇorͬs_2ͧ͌\": ̱ϕ̫6np.βKδƚara̵nˡčńgǙŏeøƯ(1Ã0) + ʔ͕5,̡ȑ\\n-.îƘΉ.ÿ.íĢ ɱ ʲ̞˅ HɁʃʚ ̋\\x9eɉ \"νs͔̋egmȠĤe̵ΩΩnÇ̭t̵˵˭\"ʘ˿:w åĲ[\"̋siʥegmʟenϩÂ˔t\\x9c_0\"ƌ̥;[̕]*10¿\\n.ƛ.\\u03a2Ģ\\x94Ʋ.ɝ }\\x8f)\\'\\n=>ʟ>>ϙ TSŘDÛaùϽtɓaǌset.³wt>o_dώatCase˺t(đdf_ǼϱreïgɚƎόrȃʒeİs̄sorɮs).ȽϗheÀÖadďŽ(5ɍ)Ľ\\nƪseɧgÀmë́þɛntʰĢ ċǋ  ɛ ǻ\\x98 Ļ \"pɹsÞeƵgm̸Ãȣent_0\\nȡȸfeú̉a5ɔͩΞƃ̮ǻtȥɶuʱrƹĐe ũ ϖ  ʱϓrȹeg\\u038b˸͡r\\x86essƗor+ʎĸǬ_1 rĘegrϞessoίβ\\x91ͼūr_Ǡ@ʝ2\\nČċͧtim\\x94eπ¦Ϻǽ˩ʉstampʴ§\\n20Νi21Ϟ\\x8c-01-Ͻ\\x8901Ǻ Ζ\\x9b ʠ œ˻  ʏħ   ǈ   0   Ǚ\\x83  ͡Ď Ƥƍ Ǐ ɑ   Ä5\\n202įɚ1þ-01-WΙȰɍ02 ˣ   ˿ʚŘ  9˳ş³  ͑ ˽3 ŧϩ*ƈ ā1³ĘȗͪϓjƖp Ɵňɲ ǘ  ãǆƤ ϱ ɬ ͦ \\x81ɜ\\x9bə  ű 6ξγϷ͢Τ\\x9f\\nŐ2ˣ02Έ1\\x90-0wȩ1-Ƃ(͢0ȪĞ3 ̯  ˈ    ʅ ˁ\\x86¤˫  nΗɻ 2 : ʵ  ʻ Ȭ ʛ    ϳ; ͐7\\n2021-0̅1-04  Û\\u038dö ̿Ϋ \\x9b    ɟ ·K  çî3ɰ\\xad      ̆     8\\nʱ2ȗ0ŋ21:-0μ1-Ȁ\\x8d0ļ¯ˉ5  Ε   ť   Ͷƕ ȅ Ͻ ô4     \\x91ȯ   Ø  ×˜ŧ\\x83 9', 'timestamp', 'timestamp', 'segment', 'segment', 'timestamp', 'segment', 'timestamp', 'segment', 'segment', 'feature', 'target', 'Segments contains NaNs in the last timestamps.Some of the transforms might work incorrectly or even fail.Make sure that you use the imputer before making the forecast.', 'All segments should end at the same timestamp', 'segment', 'segment', 'GathɈ\\x8ferΰg iόnƞformƪʷĄΚͭatńioMn ʌabouϰt daǩtaseʽt in g̉Ͼendera˺lϚ.F', 'num_segments', 'num_exogs', 'num_regressors', 'num_known_future', 'freq', 'feature', 'target', 'segment', 'Dataset', 'Max timestamp in df is ', '.', 'Min timestamp in df is ', '.', 'TSDataset', 'TSDataset', 'target', 'Plotȫ xof random or chose̼n ǻseg¨Gmͩe̾nts.ĳδ\\n\\nP\\u038baramϣeȘters\\nǆ-----\\x8c--ʹ-Ä--\\nn_segments:\\n    number ofr random segmentˮ{s tƃo pʽlot\\ncαolumn:ͱƌ\\n ØƔ   feature to plotϣ\\nsegm˵entsĔ:\\ñ Ϧ :  segments tτʹo plot\\nseed:\\n  α  seed for local ĵraʵndom st͏ate\\nsPtarΏt:\\n ˠ  Ό stƘart Ȓploƙtɇ from ͮtȆhis ̸ti̬meͯstampâ\\në́Ánd:Ζ\\n    end p̟lokt at this ti\\u0380mestάʰaĢmp\\nfig¿sȥiŜzĚeÃ:Ȣ͓\\n    siz͂e oðf Ǘπthe fiͲgure per subϕp˼l;ot Ϛƕwitḧ oƌneɊ segƁmϥent əźin i˔nńcheswά', 'ReturƮên tđhe last ``n_ƒrows`` rʈo̲λwsɯɌ.\\nĮ\\nMimͬi7cs\\x91 pan̸das meth\\x8eoƕd΄.\\u0380\\n\\nTh\\x95͙is ǃfunϗctioϞˣn̊ϝ retuŕns la|stŖ ``n̏_ǳrows`ƫ` rows from thŐ͡ƫ͜e oʊbject˃ basɌɺed˜ on\\n͊positȡioβn.ȸɦ¸ɰ ĩIt is useful εfĮor quiǀcklʑyħ verifyiĴμnƀgψ ǿdÉata, foıȉrͫÙΪ exŗam̜pleĶȃ,\\nģͣafteƛr ̺sorìti«ngǮ or aΉp˧pendˮing r̟ows.Ƥ\\n\\năFor neèga̻tivƑe val̽ueǃs̶ of ``n_ɶɔrows``, ħόthisů func\\x87tioĮn rCeturns a̦ŧČllż rows exc͑epƀtƁĵ\\nthe;ε first `n` Ϛrđoύ͆ws, eƊquiv·alentǊ ßĚto `I`Ůdf[n_row;s:]7\"`½`.\\n\\nǋƻɹParʑamʤeters\\nͭ-4ʃ-ɒ---̸-----\\nn\\x92_rows̎:\\nϿ 2 ˃  numberĸ Ǧ\\x87of Íroϣws to ËsǾelec½t.ʉĦ\\n\\nΞReturns\\n-------\\nσpd.DataFramqe\\n    ̇t˄hιeϏ ̫last T``n_rowsų`` Ŝro4ŽwsƉā ŝor 5 byȮ˟ ƅde˟fau»lftϫϔȓ.', 'ͲGetʫǡ țʤlgistǟ ϓäof all s\\x9cȟegƋme?±}\\u0379nKİˠtsÃ ˷in dataȮʂsΨet.\\n\\nEͻί+̀xάζa˭m̓ples\\nʋ--------\\n>>> froƦm etnǢ̓ΨaĐǃ.ɢǃπȘdat͇͋asets ̝im͕porύtşŏ genÄerǲȇatβeͻĨ_cϛ\\x95on͓ǚs#tΐ_dǲf\\n̈>̐ͨϘ>> d̸f® =ǯɶ gueneratēŊ_coͮnƍ̊st_df(\\n...u  Ƙ  pe϶Ķriods=3\\x970, stalȿŢζrtͭʄ_tľǩimeȒϙϝ̬˭=«˻\"2ɴ02Ö1-̥0ƛ63h-0ʛ#Ů1\"ī,\\n-... ɚ ĐȪ Ͳ nǊȦ_ΥsegmentsÓƗ=2,Ɍ scZaÄƥǈͻšl5e=1\\nʿ.̇.σ. ǅ)\\n>>>Š ʿ˂˃ŗʧdƒf_tªs_fo°Ŵhr0òmăa˿t ̹= TǀSDŮaytÉase\\u0383t.ń˥tɸo_daʥtaset(ˀd̓f\\x9a)s\\n\\xad>ǁ>>· ϖ1ts = ˖ťTŪSD\\x96a£ʊĂȿt˰ase̽t͉Ǳ(dĿƍf_ts_fĒǄĦžormat, \"D\"Ň\\x89ǲą)\\n>>> tȓàs.sɫ½e×gmÍȦents͉Đ\\n[\\x92\\'segmƍeqntϱχ_0\\',υ Χ\\'se$ćgmentϠk_ͽƌ1Ɵ\\x94\\']', 'segment', 'Ṛ\\x9aeǐtur̺n Ηself.dϱf.loŬȐc methνod.˚̚\\n\\nReturnā̲s\\nǤ--Δ\\\\Α˥-ʃ--\\x8c--\\np\\x7fd.coreʡ.Ѐǅindexiʶϼng._Loc͗ĿIndexeòrs\\n    daâ˫Ζtaframe with sϿelfž.νdf.ɠlo\\x92cȺ[...]', 'right', 'timestamp', \"Some regressors don't have enough values in segment \", ', NaN-s will be used for missing values', 'Transform ', ' is applied to dataset', 'TSDataset', 'all', '\\x85IȃƍʁnǺit TSDatǈaset.Λ\\n\\nϪ͋ĝɓParyaƤmˈetģeġrsω\\nƵ-ϦȆ-ț-----˙---Ģκ\\ndfʰ2:\\n  ż  ƚěˆdϩƲatafÖrame wiςth tiĨmeͭsͱeries\\nǁfre˵q:Ψ\\n  \\xa0\\x7fĝ  freƢquency oɌf Ϻtēimeˮstamp in ïdf͇ϡ\\nd˾f_qexog:˖\\n Ů   dataϸfȰram˯e with exa͖ogʉʸenoŷu8s dĪýaɜtaƐž;Ȟ˲\\n+knoͭwín_fuωtHure:\\n   ϱ c¤oluͱ͌mŖn¸sĲ inƝ ``dʱf_ȁýɥe͈xȥog[k͓nô̭wnŭ_şfλ<uʅture\\x80]`Űº` Ǌthat areƠ ͺȉrĖeĚɛgre˹υʹϊssors,Ü\\n  ¤  i˧f \"allʗ\"ȦǸ valʢuΈe is givźen,ȝ aηll ëϚcolumÖωϐns areȝ meantþ to˾˷ \\x88bǈǉ˚e ˅ǖreg\\x80˂re{ssʊorsσχ8ɛ', \"TSDataset freq can't be inferred\", 'You probably set wrong freq. Discovered freq in you data is ', ', you set ', 'Transform', 'category', 'feature', 'segment', 'timestamp', 'segment', 'ŦǅȭOvervƛiȤ\\x84eµw» ΫofȄ tëΐÇheʑ dƻ¬aaưta˄se\\x8dπt ͬtʦh8at printsG t\\x94ϓhȶϕe ürŵȷesultƸ.ȿ\\n\\nǃMȻethod ȩĕdes͗cϮɊribľes ǟŎdȣataʂseΞt Ϥʆɳi}ǉn seϾgm1Ϭent-ɰƯίwisɹë́ fasµhion.Ǐ\\n\\nIċͣnfŻ\\x99oΖǶrɁmġationɐ \\x98about daĐ̲taŝsȚɎŒĩet iʪnʝɥ ge×zœnŨerəaϵlȿɇ̝Ě:\\n\\n* num_sūegmEeç϶ɣntcǲŏsƭĨ:J tΏτotģa.lG nʉ̅uǞmberǥM̥ \\x7fo͊f sƧegmeŸǤƖ̄ntsɡĀİ\\n\\n&ːƯ* Ώn<umϼɇ_exogŲûsȠ:ǎ Ȃnumϩǧber Ǽof|ʱ eŊxogȶϹǾenʏɓo˃ȥus ̉ÝÛÓfeΪatΔǂuresƜô\\n\\nȿ\\x80*μΪ áǃnͮum_Ȝ̼reāϕ̝gressƠȃoʴrsĤ:ȼ numðbeΙƕr ͙oƺfƚ˷ ʚexýÄoɭgeno̗uϞs ɢf͔aΊctoñBΒđ˰rϴs͊, tȖhaĮĹʉϓt©`Ξǝ Ëare ýreψƀgΡr\\u0380˞ϯessorsa\\n\\nЀʬ* ͩnǙĭuŲĻm_kɵnown_Ɠfutu;Ȯ͒ˢreŏʩȂ¨Ł:ƨʍ6 nEumbeΜvr ʍof½ ĞrʺΈegĆ\\x89rċesů}ŭ>Τsηoϼrs, t̲hatYX aYrΘ\\u0378e SknowƳnɡ sȮρincñe ǯc±reaŕtɭion\\n\\nš* freq: ¼f\\xa0ʂr͵eΫqĤuency Ɏofʾ tȐɮ\"Bȓ˂heÛΗ dϞataset¥ǌΝ\\nώϠ\\nIǵnʷfʬormȆaƸ̶t́ȋPǫnȉ¿ǅ aboƼŶuȗɘtƜ ψ˴ϧiƽĹndivʙ=id\\x92ua\\xad¿l segǥmentĞʞs:ϕ\\nF\\n* EËsȾt˂arçt_tiʱƦɞmϢeϕ̖staΤɛmÊp:á̍Ʀ beg-sɷ̨inΣĆniƇn\\x90ʢgͯǥ ̇of ȤtЀȖέͿǤĹ}ƞɾȬḧeE̋ ɲ̫segmıʰeĪnͺtɾū, Ŝmciǃssingϒ͎ā Ɋvalueῒ̭̦φs in the¨ begiǊHnυniɉng arČe Ɠiʨ̏gÀn˯oredɯ\\n\\n* eǭnȺd_3timestamp̩Ƚ:şźƝ en̪ding |KoƖf tĄhe& ɼÜÕǀħ©s̔egmeͪŧ́ɐnt, missāiȱngă »val\\x99ues inŻ͂ thŋe ̏eƔ˯ndŝiŅnϳgɲ a˂rϒ˗e iȢgneoʋred\\n˚\\nύ*Κ ΈϖlenÌgŠtκRͅh˫:Μ lŅ͓enųgthιϗϘ a#cc¤ʛ͚ȪoĦđrdiͧngÀϠŝ tϜo ̗ǭˡ``Ù̷Ζstamrt_ưtʰimƙeηsɚtamp``Ĭ aǟnͰʆȆd˗șΒĥ `̈́`endŋκ_timesϤta̰˶mƙp``\\n\\nǛ* Ínumιϲʄ̛ȍ_miĘsͳsinЀɼÈg: nu͐mber of misʊŔ\\x95ϋs̘in˺gďƤ ϦϢvĻϦari˅Ϥ1a˷bles ƛŚb7eșΐ¶-tweeȨnĜˊǮ ``sștarĺt_ͧΥɵti̱mes̜Αtam͖p`` aǽʀnŖd̦͌ϊ ``ȅendœĭɱĴϨ_timeȹstam.͢p`ǑϿɷi`\\nǂ\\nŁŕPƌ̷Ɂa̅rameītersʰ\\n--------ǟ-ɳ-\\x87\\n̓segments̰:\\n  ΩͶ Ο) segments to\\x913 shoĢʛw ĤiĦn ovͪşe\\x99ϙɄrvʿΌiɃˍĉhe,w, Ϫ˵ɐγǊγiϩf Nϰ˥onŗ\\u0380e, aǦϧHll se~ͮgmeɗLĸntΤs\\u0380̷Ɨκ̄ Ϧare shkow˹n.ϧɟ\\nð\\nEχÅxamɄpǩles\\nsǥ-Ħ-ĥ---˜ǟ-ȼ--\\n>ʁ>3>ǆ from ȶȵĶetnϼaƫ.datɻɵͅaʉ̢óseṫs© import| gẽneȌrate_cĂ͔onυst_dƵ¡fͦ\\nγ>>ū> df =^Öƻʵ* ɋȱ̎gˀͦeƞner̨at;E3e_const͙Ŗ_d«fʿ(ȉ\\nͨ¨..ːż.   ǆ ǫperi˔odɏs=̠3ʆ0, stƻͼart_t˼ȎΔimeςƬťK=\"ʄ202 1-06-\\\\͚ɚ0*̵ȣ1\",Ń\\n\\x87..Ϯ.  ˳ʆς«  ´n_ƁƭsǔJegϛmύent\\x92ˌsŘ=ɖ2, sʾμcaleƽ=1\\nǩ... Α˻)·Ͷ\\n>>Ŭ> df_tǯs_ˡfoπrˠmaɒt = TSôDataseɻ̣t.to_͍dataset(df̆ƺÒ)Ŧ˔\\n>>> ϔ͇reŽgre̼sľʵϤăsor}˹ɍs_tʠiɿmestǛaȞ̈māp = pΩÛdǕ.ŕdÏaϼƶte_range(starƇt=\"2021¥ʡϵ-0 òǇČ6-0õȗɅ1\",\\x8bǻ periõods=͠5̖˔0)\\n>n>>̌ ̥\\u0378dǾ͍ʹʬf_Ļǹregϗrˆe͵Œss~oͿˊrs¯_ʃ1ư A˴= pƁdˬê.DataF˒rĀ˺ªamέÙ̋e(.\\n.Ļ..Ţ\\u0380Ȑ     {ȳ\"ĄtimestamάpÅ\":ȿ regõrȃeģı̸\\x98ssorsȼ_timest̗a\"mʪpŒÐɓ, Ǭ)Υ\"regʛ͋r̛ąͅeΖsßsĲŵoɸr_ɓ$1\": 1, ŧ\"ėseȱgment0\": \"˲˂̼sćegmentǐ̵ˮ_0\"˞}\\nϬ.ͷ..ĩ ʞ)\\nɱ>>>Z ʂdf_rͦŻegǿres-so\\x88rs\\u0382_2 = pdΈ.Da˅̆taǡFϴrǣ͟ŝ͟ame!(Ô\\n+...Θ    Ɲ˛ {\"ōtÜiŉmφest˵ǓΉamŸp\"ͤ:1ǃ reϊ£gʲressǺórs_tiΉÑmeǕsΥǒtamɠp,ϭ \"regˤˤǭrđessǩUočr̍_1ªŴ\"ǙșŶ:ϛ 2,Ŵ Ĺˇ\"̑sęǸǉΩgment\":˚ \"ʟȝDsȏegʹǧmebnǥt˘ȶ_\\u03811\"ρ}\\ně...͗ɲ ă)˓\\nN>̺à>> ͦdf_şexog =ʎ śpȓ¶d.conÓcaɌtäΙȅ([dʩ=ŗˑfĜȡȜ_ęregressoͻrˈs_1ǭ, df²_Ǐre̴greˀŕsο̚ˊǈΕsors_2]ωÏ, ŖiʗgnúoȽʳrʮeόι\\x8a_indeKx=ͻΉ͚TɆrue)ō\\nͷ>>>ͧ d\\x83f_eǥxog_tsɈƞʃ̓Ω_f̈Ĝormat = TS\\x9dϩDatƸaset.\\u0379t˲o_Ƿdʩat¨asɨe\\x93t͋(df_ʬeWxeρʊ˔og)ʰā\\n>ź>̦> t˚s = ̞͏¿Ȟ\\u038b»ͪTSĚƥ\\u0380DaEtaϽseǎƪt˳(dǅfǥέ_tʱsǐ_format,͒ ̹dRf_eóχxo«Ư÷ŁĀg̎ƌ=df_͑uexogZ_ÄtsϠ_forÍǭm͛at, \\x8aώfreq=\"Ń͔ǛD\", known_fĭuψtur̔eǼϚ=\"allʗ\")\\n>>> Ξts.iđŒnfʹo(Ϋ)\\n<lˡ̻Ƶclass͆ȆͱΡ \\'$ȃeϟμtʽrĄnϐa.ͣͷ̰ĳdaʲΑtɲaϯɼʗɂse͞ts.π\\x8bűTSƳDaΥtŶasʊet\\'̪>\\nšnumȎ_sŝƅɘőegHɕmentȍsĚ\\x80:Ɛ.ϱ \\x8eΩ2\\nMnɁum_\\u038dϔǹexʒogs:ο \\x91Ȥ1\\nnu¶m͞ĤϦ_˴regDr˾ess¥o̴rs: Ř1ġˇ\\nnϢ·um_ĄkʚùnoJwónϥ_fː^uͤtuʀre:Éˢ \\x90ǳ1\\n͡>f˗ƔrάeqF: ØD\\n±  ̫ϐœ \\xadͺ   ͗ɾϟ  ıp  ¹śǅsĿt\\x98arΦt_ʙ˭̸timestʒamp ɻendå_Ǝ͙Ãtimestù¶͟aͻm̳͛p  ŰleĢnĤŏgt\\x9dh  nâuùmɔɤ_ľɸmissiɥnǋgƊ\\nsĤǘegbmνɧˈenˢtsȬ\\nɎsÇeʍgĒmÕȂenόt_0  ʭ \\x8e ϊ  20ƒĊ21ƴ-06-0˭ƍ1¼ ˍ  ̓ 2\\x8402ɪ̞ɀɋ1˘-0Ʀĳ6ʩ-ð¶30 ñɎΜ ǘ͔ «˸  Łő 30 y  ɖ       ī ΞĔ 0\\nsegmeǁéƙnt_1     ɯλ 20Μô21ƴ1-06ũ\\u038dȈĄ-01    2021-06-30˪ȬR  ϫ  ĞÖ  ʀǔ30  Ϡ    Ȋ  ƍ ʋ   Ý\\x9fɄ0', \"<class 'etna.datasets.TSDataset'>\", ': ', 'segments', 'display.width', '\\n', '\\n', 'TSDataset', 'all', 'feature', 'all', \"The only possible literal is 'all'\", 'Some features in known_future are not present in df_exog: ', '̧Ga?ther#ƚ Òʦ˵ƧΉinĒforǀmǢɐati^̨o͝ŗnǳ ʥaΣboʹuɶÅt ϐŰʾeach ªs ɶeϓɖ^rg̓mĝeǸnt.', 'start_timestamp', 'end_timestamp', 'length', 'num_missing', 'target', 'start_timestamp', 'end_timestamp', 'length', 'num_missing', 'C̭Èheck that regressors ˳be͠ginJś not lateͪr thanƂ ¯in ``dfϳ``ǔ and end ́later than iķĐn ``df``.', 'segment', 'target', 'target', \"All the regressor series should start not later than corresponding 'target'.Series of segment \", ' have not enough history: ', ' < ', '.', \"All the regressor series should finish later than corresponding 'target'.Series of segment \", ' have not enough history: ', ' >= ', '.', 'Transform', 'in_column', 'out_columns', 'out_column', 'Transform is not FutureMixin and does not have in_column attribute!'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <6x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['  ȟ   Ȼ    ʉ    ϑ ', 'Predict embeddings, logits or dump helper tensors. Run without `outputs` to list valid output keys.', 'data', 'Path to dataset root', '--dataset', 'Name of the dataset. If not provided, list available datasets.', '--config', 'Path to training config', '--checkpoint', 'Path to initial checkpoint', '--outputs', 'A list of tensor_key:filename with output files. If not provided, list valid keys.', '+', '--augment-train', 'Augment training set', 'store_true', '--num-batches', 'Limit the number of batches to evaluate', 'train', 'stage_resume', 'dataset_params', 'samples_per_class', 'shuffle_train', 'on_experiment_start', 'on_stage_start', 'on_epoch_start', 'Available datasets are: {}.', 'on_loader_start', 'cpu', 'model_model_state_dict', 'model', 'train', 'model', 'train', ':', 'Multiple files for {}', 'gradnorms', 'optimizer', 'model', 'labels', '', '1', '2', 'embeddings', 'confidences', 'embeddings', 'gradnorms', 'Valid keys: {}', 'gradnorms', 'loss', 'model', 'model', 'Unknown key: {}', 'Model changed', 'Dump {} with shape {} to {}', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <8x8 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 8 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['TώimeFSÒ˶lagsTrnansǶfo\\x84rOmΜc\\x84Ͳˁʍɇ isͧ» aǰ3ʪ cĘlass thàaơöt imOȩɔp̓˵lž˯emƩeÂSƺyήn\\u03a2Ǻt)si ǡeǎxt˯ranctÌionʼȦ o\\x9cEf ŵ˜the m³\\u0381ain timîŌe-xb3aƃseǀdƷ ôf:ȕeaϯȩt˛ƍɑȊeňures Ưfrʮom ȾɔdaǠtŧǜetiƺm\\x84eAȁ cö́ȫluǒmnǁƥ.ŁĘ', 'Inƒitialise clasȲs attʌributes.ê\\n\\nParamϊetersω\\n-˯--̻-ļ--ʀË-ʿ---ΰ\\nmiđnuteί_in_hour_number:\\n)    if˳ TrϼȈue: add columîn wiϐth minute ʧnumbeǏr toȗ feĊʬḁtɞur͝e ƸdataframûϷe\\x99ȩ inΞɅ tranūsϊfor̋m\\nfifύÆʳteen_mi͓nëutecs_in_hour_numbɡȑer:\\n    if True: ŧadŲd column \\u0382with͜ numberéȍ of fiƞfteenŭ-mUinute ÚiΘnterval ɓwitƮhin hourY wġith numeration Đfrom ˫0ƪ\\n    to fɭea²ë+˕tuΦr\\x8eeͺ ÏdǑatafrǃame in tÀǱ\\x81ransformq\\nhoȑur_numbͦer:\\ns    if True: add Ǧcolumn²ˁ ƾwnith hour numberǙ ǉto fPEeatuöTΉre dataframe in tranͥĪsfo)̩rʰm\\nhalf_hˉour_number:\\n    i͇f True: addœ column ǌw̔°ith ƺ0 for the ˦ȼfirstʼ̉j έhalf o͵f ¬the̯ houȧr and 1ǂ ˈfoϸr\\x88 tͱheI άȽse¬cǶond\\n Ζ   to f͘eature ͨdatafrĦ͗amˏe in transfworm\\nhˠaŐlf_˫ǭϺday_n\\x90umber=¼:\\n ̮c   if Tċrue: add columÈ1n with Ņ0 fÕŖorν ȕ\\u0379theɯ first haˌlfǧ ]įof theǘ day andŊ 1 for tϭhe sæeϙcƗond\\n    to fe˺aturÄͰe ̬datėaȥ˵frameū in ȗt˿ransf́̆oɮĂrm\\none_thiĹrd_day_nuŰmbɭ;ɓer:\\n   ͨ ifĖ True: ̟add cHolumn with nǚumbªerb of Ƥʛ8-hour interȈval Ćwithin ͵Jday9 wƻiͲȱth Wnumerϓatioǉn frȢʔǑom 0\\n  ό ă to feaȗturte̘ datafraLme in tȐϐransform\\nSout_col)uN¾mn:\\n    basĩe fϏor tƟheͭ naͧme ofŶ cƎreated cΜűolumns;γɠǯ\\n\\n    * i̓f Ǟɺseŀt thŤae̝ finaől name is /\\'{o͖³uυǫȅt_columnW}_{fŠeatʃureţ_naͧŏme}\\'G;ϛˁ\\nθΘ\\n  ˦  *Ǘ if don\\'Ĵt sʣe>t, naʹmăe wi½ȫll F\\u03a2be ``traǵnǕsfϻorm\".__rąepr_º_()``,\\n     Ϟ repr will be madÙe foV΅r transform thatͅ cȡļreates exaʕct́lyƴ thiŖsΜ collumn\\n\\nRaises\\n-Ⱦ-----\\nVʳa̡ȕlueErro\\x86r: if f̠eϭ<ature ƒhas invalid initʸial paτrams', ' feature does nothing with given init args configuration, at least one of minute_in_hour_number, fifteen_minutes_in_hour_number, hour_number, half_hour_number, half_day_number, one_third_day_number should be True.', 'Geλneύrate array ʹwi)ƣthĴ the ũϢmΚɳi\\x97ʜnãute ΄nͰumber iĞn tlh̀e hourϡ.', '3 ˝     ŶŵͿ   ͧ', '_', 'minute_in_hour_number', 'fifteen_minutes_in_hour_number', 'hour_number', 'half_hour_number', 'half_day_number', 'one_third_day_number', 'category', 'segment', 'segment', 'segment', 'feature', 'FitϹɔ ʊ͍ˉdaƚtetƖiƖ˳ƈmʅe mˆoũ2d_ƌel.', 'TimeFlagsTransform', 'GeneϱrǸate an ȑavrragy wit͆h ĘtĽheʉ ˶peʓrȼʒ˪4iodɗ nɳumbeƦr ˂iʞn Ɖtȅhǌɤe̔ hour\\x96.4\\n\\nAƏźcύc͏ǠepσtLs a țperΕϮBiΎŵϛoǊ̵ʪʙdƙ }lengthʜ in̴ŋ m\\u0382ʟ̌ɏͫinľuteŝϑs̽ as ίinpuȯǿ˘t ʐa̓nġdż reɸĖturns arräyɎ )wh˺erȑțɣİ\\u038be timŴūestaěmīps mˏ͛ar˙kśeĹdǯfΦ bŔy΅ peǟrʛiǏʹ̨¶ošd nĖumbŽȶŽerȥ.', 'TimeFlagsTransform'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <11x11 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 11 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Test ̴KL-divƇergeω;̀ncϋe with u*nƮiform in sÓƋiÊmple cːases.', 'dim', 'max_logk', '   Ë  ɯ', 'scl', 'SCL logiv mismatch {} for order {}.', 'SCL logiv derivative mismatch {} for order {}', 'default', 'TRUeƭεsϔt Cs͑plit\\x91 is%̂ in\\x96·vďerse of ͫ½ĔȃjoiįɍÂn.yΚ', 'separate', 'norm', 'dim', 'k', 'Test distributioʂn mean.', 'dim', 'separate', 'norm', 'dim', 'k', 'dim', 'max_logk', 'dim', 'dim', 'dim', 'max_logk', 'dim', 'dim', '   ', 'dim', 'dim', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['target', 'feature', 'segment', 'F̙it preprocźess method, does nothi;ngˌ i̴n ``LaƬmͦbdaTransfīoȁrmʵ`` caȚsņɝe.\\n\\nPaʜramÝeters\\n{--μ-----ǝ-΅--\\nʙdf:\\nʪ    dϜa/͊tafϠrame ȶwiΘth °dat\\x95a.\\n\\nReǃtǠurnsɋ̠\\n--¦͟---\\u0383-ǵ-\\nrespult:Ň Ϳǁß``ϨLϬϕaaƶmbdaTϚΚraƅɛͳnsform``ΞƝ', 'LambdaTransform', 'xInǥit ˲`đɥϟɖeϔÜ`LaĀmbdaǮTƏransfoårˉm˔Ǐ`\\x86ȭ`ŹØş.\\nϜ\\nϓPȩ̡aɉϣɷra3&\\x9f˱mʢeĎˡy˸Ɓ/ter\\x8aϺǜɜcs\\n-ɽ˞-̹-š˱--ΎƬ-0Ƈ---ǔǡ\\x92̌-\\nƣɞÏin_œcƠδolu˩mέnȿ:\\u0381Ǐ\\nő   Ïϧ ɘco\\x9al\\x86uòɤȄmʁnǨϽʿ˂ǻ͕¢ tȱsǜ˩o ÍapΡƯ˼plyü transëform\\n`o̡ǺuȰɼΠψƗ\\x86tĞ_©ǖȕȨρϸcCͦolumn:\\n ˛Ȓ̼  ƀ{ ǜΪʐn̹amȣeū \\x89ofƠ adȕdĶʂped cώolɡu´mnŰưȊ. Iǡf not˫ç Ͷ\\u0378͎g_Œ*ivečn,Ύ ȷuƶse ̧``sàelf.͔˥_̬_ɪϹƙe͛repϾț r__()ť`ˍ˦`\\n~̀trƙansϿfȻúoɽ͖Ōržmϴ_fuýncØ:͢ŭų\\x8dú\\n    ƣfġu̴nʄctiśon ͜t˄oÙȺ ë̆ŀ͢ʭtranìôsǌ³form dȻ \\x9eatƍa\\nɡinͺĬ·veʋɦrɶºse_tranpsf˹or͇¸Ȇmǡ_fɫuŇnc:ǝỤ\\néƣ    iǳnverɨ̱ʽɛɻse fuɳŋncȫtˌiƸonōť oϺfęπ\\x9f ϔΎ̚`̭˺ȼ`̤trĆȐƛans˸ǘ̓fo˅Ȏτrʃͱm_func``\\ninplǀ¬aǽ·c\\x94Ǳ\\x8feȵ:̥\\n̊\\nòB ș  Ɋ9 dˋϗ* ifȏ ͢˭Ɯ`TrueȢ`\"˞, aϰpϏGpλŜlñyήʧ transŊfoϊrˋmȵźãtiŷoͽnʭ ǅinplaʝcÔeͧ tǫo ̘`Ɇ`}inƛ_coluͫǤħ¾mn`ʐΎ`,\\n\\nȿǨ Ǜ   f* ͚if ʻ`BɸF~ʕaǽlse`Ʀ, Ήadd ¹Ž\\x85Ŗ%Ũc°̑o̺l\\x81uȔmn anǒ`ĘϿd apɸplΩύy9ɶ ̛Ɠ7ζtranas̕ŋ+fǝ·Ī\\x8dorm͌ȡaǓʝǄtiȩo;ɡn dto ȫcϷ``řoutóǽ_Όcolɣuã͘mð\\u0379nΈĶ̈́``K\\n\\nW̞ʉzar*nings\\nɎȂ-------΄-O\\nthĹrŴĻˮowͱs ifΞ Σ`iϑǦnnpla\\u0381ˤcÀ˿e°̤=ïTrÚͭʔ͢uΐ\\x91ΒeÏ` \\x93and ͢`ğ̑ī`oʻuȻĐt_ɀcʼϒɐνoʼĮ˒lumn``̒ is initƛĴialɯɧizϊedŉˍ\\x894,w \\x9bītr˂ĩaŬ\\x95nsfoǒrmɟatßioͧon will ÎbȒe aϠppl¸ˊieL̯dĭ ninʕřpla˘ǅceʛ\\n\\nϾʴRaǬʋiseɿs\\n-ͣð---ɡϹ̆-ͼ-\\nЀʢVäalʪueũǽǩƩ Ęϕϊ̽er\\x92͕rɽYoı͙rƉ:\\n    ifɖ ȑͥį×`inplϠ³ƴȺaɎĪʌ\\x98c͔͜˓÷ƽe=Trueȥ`ϫʓ ŨƢanΉd ``͉iő˼͒ǲnveƘrsϡeɏ¸C_ÝtϻrAØa5ƌ̓n̲Ƣ̈Đόsform_ŶfěÈ̹unɛ@cĜ`̅˴` iͰósȭΗ ǛΎǹn̷ƢoɊt̯ dͻeĂ̔fħDinˌɎɟeƸd', 'Transformation will be applied inplace, out_column param will be ignored', 'inverse_transform_func must be defined, when inplace=True'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['ͼFżin˩d tȃrend ĐɇchŖπange pȿĳ£oints ¦ťusing ̀rƔWȌu̲pċtŦȞ\\x92ƌɠ̌urĲeʜsÕɖϙ modŴɜeȣŎɚls.ͳ\\n\\n\\n \\n\\nͬϫƟgP̗οĄara̝meüterĶϔsú\\n-----$Ǳrī---ϭ-ȉU˷ũ-\\n̿ts˷:\\n   ɻ Ãda̾ƐtaýƜsʕȑʚe̖ÒͣɼtȦ tϳo woĽĝrŖk ˖Ɛăwith\\nɼʠͧinϐθ_coĐćlumén:Γ\\n˘   · ˗nϓanmͣʝe oǣf colu͙mn̝ψ̼Ǥʎ to wơorkȷΏȖϰĕ wϫʉΙitt͎h\\nch\"ange_poɁȉiπˉ̮˄ʃĂȮn̵ǻǌtĆƪěǽ̀ά_m˺ɜoĪËdel\\u0381Æü:\\n  \\nʐ ˃ϟ   ruptuŊresȌ̥ ǽmoɐdelϹ tĔoˤ gȡet treƚǉ\\x8fnd chanφ5̍ʧgƂe˖ϣ ˄Ūp͇oϕ7inåtsϴ\\n  \\nmƴ̜od\"lelÿ_\\x85ǎpΐǷȯkīŸƠrɹed\\x8diŪcÏt_ʴÝpar͝ams:\\n  pa\\x8er˨Ƞamsƻ fĲ˖orΌ `Ĺ̀`ǹʯȢchÉȷTˇange_ƈpoĕijşnjăt_ŁǓŇǋmϙodeȤź˳l`` ƉpreeȌdicέƶʯtȸʣ Pm¼̊eÉthʺʓodœĖΤȦȦ\\n\\n\\nRʨjȈɦetς\\x98urÉ˛̛nśs͜\\x9eʰΦ\\nÐ̭Ϛ--ƍo---ǞʧșͰ--ϜƦ\\nDωiɾct[sðřtr, zL²istˆΥɡ[pɢɅʐd.ʀŖTiÇʈͨÌƭ\\x95mestSahƽϓmpƥʠ΄]]\\n ŸčȖ   dŲićÊtĜȜʾˢūíioƁV˧nʆary\\x99 witsh lͅi\\x8cst of\\x82 trenάˤd vcrhθƇaϳnge ˜˯ʉpoiǈƠnƂʜtŏs ̽ȧ̲foĂʉr each seg´meȾɫnǙtą'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <9x9 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 9 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['ķ´  Ɩ ̾  ˾ ư  Ǒ     q͂ſ ϗş· ϭ  ϓȉƷ  Ț λ', '2020-01-01', 'D', 'target', 'target', 'exog_1', 'exog_', 'D', 'EǨxtraȜctȹ γėΒcϰolu̍Ϣ§umnsɊ f\\x89rom featurϙʥe\\x7fßé levƛel ˆtǄh˧\\x95aϚtɼϨƺ ŔÙãÅ͜rÌe preǥseàŏǔntF iηn ̾transfoǧrmĂepd_\\x80dϊǷfɷ buÅt nĔotśʀ pre~sİǂeγ˕OnȰ½ˣtÏ̀ iʾlʑn initȇial_dfa.̨', 'feature', 'feature', 'non_existent', 'transform_constructor', 'Transformation will be applied inplace', 'new_exog', 'transform_constructor', \"Test that\\u0380 tr¬\\x8eansfƧťɁÇorm iʩn 2inƌp̓ͮlace mod[Ʈ˰ˠ˹ΘĞeR͠ΒύƧȗ͉z ĳdoûeèsn't ge\\x9fĲneÇ̵ǠrɯatűǔĿͦ^eŐ\\u0378Ɔ neʅȍȡƤƷw colèumnsɸřÜ.͐Μ\", 'transform_constructor', 'in_column', 'exog_1', 'exog_1', 'exog_2', 'ϹTest that Ƚ±trΈansfoǚrmȺ\\x95\\x99 creates new columnÖs ʑaccoʹˮrƸding ďto ouƖt_cʷolumn p^aram͕ɶeter.', 'new_exog', 'new_exog_', 'new_exog_', 'transform_constructor', 'in_column', 'exog_1', 'exog_1', 'exog_2', 'Test that tranϧsform generaƳtes͙ namǈes for thMe columnȜs czorr\\\\ectlËyɵ.', 'transform_constructor', 'in_column', 'exog_1', 'exog_1', 'exog_2', 'feature', 'transform_constructor', \"μT͆eˋstτ that ʐtøransfoßrˡƠϱm donˇ'tʇ Jmiϴx coƻlumns beĻtwe͊{enȹ each othe̺rƑ.Ǚ\", 'transform_constructor', 'in_column', 'exog_1', 'exog_2', 'exog_3', 'exog_2', 'exog_1', 'exog_3', 'exog_3', 'exog_2', 'exog_1', 'mode', 'macro', 'per-segment'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <15x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 15 stored elements in Compressed Sparse Row format>, 'ClassDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['lr', 'momentum', 'weight_decay', 'lr', 'momentum', 'weight_decay', 'C)onfi6g͟u#rabɕlƖeǧƪ RMƳSχprȑȤop.͢', 'lr', 'momentum', 'weight_decay', ' ϥ', 'lr', 'momentum', 'weight_decay', 'Configurable Adam.', 'lr', 'weight_decay', ' ǘά  ', 'lr', 'weight_decay', 'ɯCǞonfigurabņǺlĄĸe A±damȕWɑ͉ϲ͙.', 'lr', 'weight_decay', '  ˊ ωȴ̮     ù   \\x9f38Ȏ  ĺ ɏ̍͂\\x9e ʵ   ƨ', 'lr', 'weight_decay', '       ', 'sgd', 'rmsprop', 'adam', 'adamw', 'params', 'params', 'params', 'params', 'params', 'params', 'params', 'params', 'adaptive_bias_and_bn', 'adaptive', 'base_type', 'base_params', 'rho', 'adaptive', 'sgd', 'Get optiϏmizer p7arametΉeƬrs.', 'rho', 'adaptive', 'base_type', 'base_params', 'adaptive_bias_and_bn'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <17x10 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 17 stored elements in Compressed Sparse Row format>, 'ClassDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['%Y-%m-%dT%H-%M-%S', 'TSDataset', 'Write ímetrics to logger.͊\\n\\nParamƆeters\\n----------\\n     \\nȢts:\\n        T̔SDataset toǳ̢ wiʈth backtest data\\nmϵetrics_dfƌÁ:\\n        ΞDataframe pro\\u0378duced with :py:meth:`etna.pȟiγpeline.Pipeline._get_backtesːt_metriϝcs`\\nforecast_df:#sVNWqifDTXzlpFo\\n ˰     Forecast from b\\x8facktest\\nfold_info_df:\\n¹        Fold information from backtesȍt\\n\\nNotes\\n         \\n-----\\nIf someē eʭxception during savńing is raised,+ǜ thƘen it becomes {ʮa warning̝.', 'metrics', 'forecast', 'fold_info', 'metrics_summary', 'config', \"S͵ˊtartΟ experiment within current experiŰment, iȥt is ̶used for se£parate diffeȺrent fĀolds}Α duriɊng backtestÕ.\\n\\nPΏarameȍterȠs\\n----------\\njob_åštyʶpe:\\n        Specify the tĜype of rȇun, which is useful when you're groupi'ng runs togetheì\\x8fr\\n    \\n        in˘to lͿarger expeȾrimenʳts Wusing group.\\ngroup:\\n        SpeȭcșiÕfy aȕ grouȊp to org˧an>Ƚize ˳iÅndi̵vidual runs intˤo a lÙarger ̕experiment.\", 'ʚBaȩʅck˔ƣtʇe|Ήst metrics from έone fold Ȟto l\\x83ogger.\\n        \\n\\nPaLrameters\\n͑Ü---͉--¨----Α-͛\\nmetrics:\\nƖ\\x94ȥȐ ξ     ˁDǔatŜaʕf̲rameϝ with mŚetric-s from backtes̖t foŰldL\\nforecasĸtǅųɾ:ʳɗ\\n Ȕ     ǕDaϓʁtaframe wŋith forecast\\ntest:\\n     ̵ DatʽǠƮafraΡm̓˿͙eȽ wit´h gr͌oundΖ truth\\n         \\nź\\n7ȟNoʾt8es\\n--́---\\nIfb some exĩception dŨȈuring saŻving\\x96Ɏ ˉis raƙçised,$ʻ thenƇ it; ùbecomeΌsƹ a \\u038bwarning.', 'segment', 'metrics', 'forecast', 'test', 'metrics_summary', 'ǒ͎Log ȯ̿Μaɢny evenÑt.\\n\\nTƵhis clajss dĕƶoũes nϴotϷńĨhiϮnŠɗƢg wάit̹ȸhȖ it, ϴ×us϶eý otḧ́˥ȶ͛̈́erƣ϶ lo̶ggers tuo do ʴȚȴiſt.\\n\\n˻Pǋarȇameğters\\n----------\\nmÎsΑǿgȐ:\\n     Ĵſ MXess˲Ͻaɋ͍͝ņÜge \\x7for dict˛ũ to logͯ\\nǧŔkġĭǱwargs̺:Ḉ\\n    ǹ    ʒAèddÅitƾ̸ionalȫ pΕarɝaϲmÈeʦtěeȊĊͷŕWs for pŧarticular imΫpåˎvlȝ\\x8deʸǟFęmentŴaĹtƷio˥n@͇', 'LoggekrːZ \\\\foΧr lêogginE\\u038dǂgĝ fil΅esʱ̐ȗȚ inÉtϐπϮoϯ localͣƝ fʽƫolder.Ώ#W\\n\\n˽It wɁriçtesƢ itsƺĉ ͼreȽsult intʻƘo folGder ˎlliĚέke ɯ``exƿperȑixmΎ̾zentsǿù_ǖfolder/202ή1-12-12T1̓2-12-1ǔ2``,I ȥwhˢere tńDļhe͖ secNo\\x9dnd ϐpaar͠t\\nǍis reЀɉlaͽteηd toˁ datͥet͝ƃ3iɎˢmeʂ of͡ startiiǣnģ tΫ9h¥ͷe experƩimeĖnt.\\n\\nÅ½ftƆer eβϤverǢy ́˔ǉť``ɾstɑ°art_experʳimentÝ`ʡ̉` iʋt creˋaÖtećs Μa n<5e̢wΓ ¹suʄbfoƄldeʊ̪rɩǐʉȢ `~Ę`joÿb_tόy\\u0382ǃ˦pǷe/gü\\x8aro˧upȓ``.\\nǒƁǠIf some ̈ofPʈ ʍthƆƽes\\xa0ƥe ͊ǯtwo valueʈŨs Ɛ̿are ɕNonϻe then ͉btehaviouǏrħ ͗iɡs liψttle diĈf$fɋϔ̡e1rent́ ȹϷ̒aɾ9nǷd d̀e͆sĽcribȄed in ôÑƈ`ɗι`st\\x91Ǭartÿ_expe̒riχȈǃΠmen½ˆt`` m̺e¥tǍh×oɻdL.', 'You should start experiment before using log_backtest_run or log_backtest_metrics', '.json', 'w', 'You should start experiment before using log_backtest_run or log_backtest_metrics', '.csv.gz', 'gzip', '.csv', '̋Lƺoˮgger ʬfɜorɼ log̒gʖing ƕfȾǋilɭes \\x9aiŕʩƻn{̦ͦ+to S3 ņ͵ΉbuȒͤcΣkȨeʣt̪.FFņ͵Į\\n\\nT͉ͤhiǸs ȌϘɖl͚Ăoggeýrŷ is verĨš±yÝ simū\\x98×ila\\x88ŧrEĎˆʬǢ# ǁt̡ol ěķ͒ƀ:½¿Čclaǿss:`~eϦΩ̝Ȣtna.loȠgĜ̆êgʣƸer˛úasͰì.ͻfǾ̭iʧle˵_l\\x82Ƙo\\x9dgger.ǟƢLoȖǂcalFqĮilȩeLogger`,t\\nbhŔulȡt w\\x90orkʅs¥ ɶͭwΙʀ˂ith ñS͗ʪ3 ɶ˭k˨e\\x96ϽƱʙyϥʼ̸ˉɺs iϋnsȽtǙΪ˰γ͍ƥead$ ȁof pa͡ʹthˀǠs\\x82̟ aʲt l\\x97oñǳ¾ʞͅʲcaɹl\\x952 ƈfiΊl̟eͬ ˁǙsysjȚƅtɓHeȷm.ƀ¹', 'Sa̶ùvħ·e tŇ[abWlˋeć ÚwitŏhXĊ giȴıȝͣv§en ȞºJͿnaĄ\\x87m´e.Ýĸ\\n\\nParNǑ˒amŴʘEřͼǓetͺƴeˋrāsŌ\\n--ˮα--ˀ-ķ̑--@-ǂ-ȍÚľo͈-Ό\\n \\n        \\nt˹ɚaEɦble:\\nȫ    ́ ɤ daʏtaìYЀf\\x8erôamʿ̑eƔ to; savʈńe\\nģnaƬļȕmeśˎ:\\n͖    Ǩ    fǍiƝǟÎ̦\\u0378l̵eϿnaˡme wÁiˑƿthôu´tχy\\x8eiϴ ex͟teϤnsitηɽŃ\\x9eͶ?oně\\x9ds', 'You should start experiment before using log_backtest_run or log_backtest_metrics', 'gzip', '.csv.gz', '.csv', '/', 'CǼϖƗr7eɾ̣at̏ϓe ͪΚ˻i¦Āʴnsʔ)΄tanǢ¬ŉce o\\xa0f ńŢāħSú3FoiPleLo͈ggeʲrϮ.\\n\\nƶƚPsʲca¾raʍmeterȓsͼ͠\\nʍɻſċʭǾ-\\x96-----ö--õ-̴-\\n        \\nbèuȌ.cøǈɢk˸ʣeˏt:â\\n \\nə͈    ǌ    namɶe )oϢf ξʭtLgh͋eȩǍ ̈́˼S3ȑ ȑbu\\x86ɛǂΈ`cǡket\\n̵eĶxɲͩćϓper-ɵɧǖiÀmϪent5ϵsñ\\u038dÌ_fĀoldeϮrǲ:\\n ʱˉŸ ʫ    pathʻʓ ǒtoĜϔ fÀol{der͎ ¢toʕ- ĊcreȡatĬǈʹe expƤeriͭëmƲ̎ent žȏͭin\\n #JMZfzAKw\\ncɡoʉnƣfέǧǫcig˞:\\nΪ ̱ĸ͓͡     ύčaͱ ʱdɡ)ʹi@ct\\x8bĚ˷Ĉiˇoʪn̄ar˭y\\x85w-˺lͨθϐike;ë obƆj̙ǯecͪŘt̆ ̷foͳɒǧr saviʑng ůiͅ\\x8aƒǾnp˛uˣts\\x9eƸ Ħʭ̪tΛo̫M /yåour jΟob,\\n    \\n-        lik\"e hΙŭΘFƑymp˰ʫˢűȀerpɁaɵraϕmet#ersǆ ǁf÷oręƟ Ȫͥaˮ moǀd\\'el ȏ̦orĘ ¡ǐsettΠings [́fƑƙor\\u0382=Ė̄ƥ Ⱦa datϐa ρʺ̝ƥ²pr\\x89eĪprȣĔġożcήessing jΓob\\x93\\ngz\\x97Ɍipʀ:ņ\\n̛        inɽˠdſ˯LicėŘatĨȚoŧr ΙŶwȝ˝hetˢhǬĔeʋʱɛr t˞o Ãu͉Ď˓˟Ąè\\x88seɧ ǝŁcčɐompαr\\u03a2eřssionͅŋɦû οªĪͅdeŴˍuʻringϲœư ˱savʚingƴǀ tûaϼbʨʦ̳ʍleǫɴs Ǎor nz\\x93oϮtě\\n\\nāǟ\\nʜRǺɮ̋aɓʜȱises\\nÐ1Ͷø-Ȱ--ƺ-ɴ-ʚɤĤͥ-ϙˆ\\nVʘ<ÿʤʐǃαalɻǂȪuťeVErřrǵͽɆńoĠr:\\n    ˓    Ƌ|ifß ȗe˱nÆvirÐoƊnĜmΧeƹnt varĐ˾iaãbϪȽlȚe ``enǛıdûp̖͏Ηo͞Ƈǂint̫˶_uȍNɖr̀Ơlȋɠ`̑Ƽ\\u0381`̧π iƟsʖǄʵnǇ\\'t Ɩǐsetě\\n    \\n    \\nValʤuÅʧͦeErʿϓrorīĂ:ʺ\\n        \\n    \\nƠɽí     ͝ iÇfƊõ en%Ŧvi͒ronmʛentț vaϜ˹rźɅ>iėaŹΓbɖle̾ ``ˣǙɚǔaws_aE͖cc̩eīss_kƗeyˈ_ʫ̢²iȕd`ϧȀ` iȯsn͐\\'t se5iΛ/t¨\\nĭȦϪVal\\x88\\x9bueErrǱo\\u0383rÕȃȍ:Ĕɑ\\nϮ    ̙ ˯ ̇ifŻ μûƹe$nvirkoľƚŀnmeıntƬ v@Ϯęariȫ\\x92aɩb̔leϼ 7``aws_s͠ecr͡etʋŁ+2̚_Haccűe̞ɞss_ǈʯ϶kĮ̅\\u038beyŘ`ɻŁ`̓eÔ isn͟ưȓĭȴW\\'t s˃eϓtˏί9\\n        \\nɋVΑĵǌǳ\\x85Ϯalĭue̔ErrorȍĂ:\\n Ǔ    Ϲ i˽ϡf bucket ǃdϞϿͥȥ˶oÁesnζ\\'tȣ ĕ̴ńx̲iVstŤ', '/', 'Staryt eΖxperβiΨǛ¼Ͷƛment µwithi˯n curÓrentÖ ȩexpeȒξriÅmĴeŻ̶nt, it \\u038diΌs ɺusíe̟d ͢άήŔf̏oÚ¯r Ϋse̛paΛra¬te difςf:eːren˺ət fƶol=ds ȕduringĺ̚ ˖b\\x91aτckýteƂ͝st̹ʝ.\\nĉ͕\\nʹAʙȡs ɉɺaÅ ĳr\\x8fe͐s̀ultZ,͠ ͠``ưśelf.expΠeriȰ4mĠ>ΨenɎ(t_foő\\u03a2ldÇeΖÚrɣ`` Ȼk˴eyˡ iȋs ̚\\xad=Ūexśtendeðpd͡ wȃi̿t͆h ``jobˌ_typeɍ/ggroupŕ`ſ`.ȉ^\\n\\nï*ȳǴ ɛ͌If ``j͋ob_tˉyp;ʧe@`` or ``»groupƄ́`` ǁiƟsnɷ\\'ēΏt ˑset\\x98 t̴XhƦϜen\\x82 käeɼ\\x9a͉y˄ ʋiȁsȧƛ exètendedQ y͉wÆɟith \\x87onenh\\x88ȷſ v͒alueƷ.\\n\\n        \\n\\n*² όIēĀf nϠoìne ˲of Ì``jυɍob*_typȊeɓƧ`Ĕʡʖʃó` ďanͱd \"`Μ`gΉǝrou˖p``\\x93 isC Ɯ̌ǯset tåhen ``self.¢expǒʒerimƜʶenȵt_foldeŎr\\x93``\\x91 Ŭisɍ notˣ exɁtendΒed.\\n̔\\nParɣc˰ameťĆeƻrΊs\\n----ë-ČΝ%ɭ-ͤŪɰ---\\x85n-\\n˕jobȌʖ£_iͶtʄɂƨyɝØ͋peů:ț\\n ŻŌǞ    ˒ ʐ˄SpeλcŵǄifyƗ· tĹźhe ħϒtype ʦof .rȡun,ŏ\\u0379˂̜ whi>chǺ \\x98isǾ usefŒuųl\\x83ˋ whenǲ you͘ƍ\\'ŉreĕ gǸroupiĕngˣ ǫrunsΈϣ? togʢe^ther\\n        inʵtoȭğ lƶωarg͑erī eÓĚ˱xperimˤeōntʥsϨ u·sŻǠiǻ^Ǿng ̸͊gɯrʺobuΌpąͤ.\\ngĲϤrou5p:\\nˮƾ}E    Ɂ    ͤSpƣecifΗyʳ a gÅΞroup ɮto̚Ƈͬ orgϱɽ\\x84anizπWe indiviÖωdĶuaŢlΚ rɐ¾άÁunsʗˠ inʹtʸʗăˊȥϥqo a̅ɬ Ƹla?͠rgƃer exĵperi̍meǃnt˨.ǳ', '/', '/', '/', '/', 'You should start experiment before using log_backtest_run or log_backtest_metrics', 'w+', '.json', '/', ' ǳ    ̋', 'Error occurred during checking bucket: ', 'endpoint_url', 'Environment variable `endpoint_url` should be specified for using this class', 'aws_access_key_id', 'Environment variable `aws_access_key_id` should be specified for using this class', 'aws_secret_access_key', 'Environment variable `aws_secret_access_key` should be specified for using this class', 's3'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['Print configs for all training stages.', '-c', '--config', 'Path to training config.', '--hopt', 'Print config for hyper-parameter tuning.', 'store_true', 'å  Ģ    ϢȲ  ! Ñ    ˔    }*   ˚', 'hopt_params', '=== STAGE {} ===', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <8x8 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 8 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['\\nMIT LICENCE\\n\\nCopyright (c) 2016 Maximilian Christ, Blue Yonder GmbH\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated\\ndocumentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the\\nrights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit\\npersons to whom the Software is furnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the\\nSoftware.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE\\nWARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\\nCOPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\\nOTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\\n', 'two-sided', 'mann', 'two-sided', 'smir', 'Please use a valid entry for test_for_binary_target_real_feature. ', \"Valid entries are 'mann' and 'smir'.\", 'asymptotic', \"HÙelĻper ŀfunctio\\x99ĉƬ5nǥ étɟo cȁhecʡk if bo͠tˏƺh Ɲx anǇd yƟ arɳe panǶùdas.Sɕeriĵe\\u0382s.Ƙθ αI͋f not, °raǽi̲sesm» aį ``TypeʷEʄĺrror`ϰǄ`.\\n\\nɲ:pŉaǖram x:®ϝĺ t̿ȠheȎ϶ ìfirǐs̢tǉ 0·Πob͚ject̓ ͽɳªt̳o ɺǪch˗ecϙk.U\\n:tϱ'yΖp͓e x: AǡƟ×náy\\n¹\\n:͟ƫp̊aram ªy: ȅϼϰěthe secondˋn objectƂ̡ ęʜ˅\\xa0ƺîtȮðo checkȬʇɼ.\\nʱ:tćypʧe Ǔəy:ʣ̤ Any\\nø\\nϠ:rˁeïƪturnɉ: ɥ!NoƨÚƘnƸe\\n´:ɢrtypeͻÕŖ̙: None\\n\\n:raņiɩsǣe:Ώ ``TˆypeɧError`ϖ`ɍϻɁ if ˉ͛onǥe͙ƫ pofάˠ ythe >ĦobĂΪje̚ɘcͨɢts isŇ ɒnÓM͠ot aʍ ɀ<pʗandϢas.S_Ȁeries.\", 'x should be a pandas Series', 'y should be a pandas Series', 'X and y need to have the same index!', 'Target is not binary!', 'The binary target should have values 1 and 0 (or True and False). Instead found', '[target_binary_feature_binary_test] Feature is not binary!', 'A binary feature should have only values 1 and 0 (incl. True and False). Instead found ', \" in feature ''\", \"''.\", 'Feature {} contains NaN values', 'Target contains NaN values'], 'from': [], 'import': []}\n",
      "{'FunctionDef': [], 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['\\nMIT LICENCE\\n\\nCopyright (c) 2016 Maximilian Christ, Blue Yonder GmbH\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated\\ndocumentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the\\nrights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit\\npersons to whom the Software is furnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the\\nSoftware.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE\\nWARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\\nCOPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\\nOTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\\n', 'cumulative', 'profile.txt', 'fisher', 'mann', 'mann', 'kendall', 'logging'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['    \\x96    ', ' Ϸ   Ė               '], 'from': [], 'import': []}\n",
      "{'FunctionDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Binse̥gTrendTransfoƍrm uses͚ ɱ:py:clɀaΒss:ǩ`rupȵtures.detec\\x8ation.Biήnseg` ͚modelɒ as¶Ϧ aʝ cΒhange point deȖtectɚion Ȳmodelͮ.\\n\\n:WĊŃarn͊ing\\n---F----\\nThis trDansf,o?rm can ΟsBuǙffeɝr from loūêok-ahead b̃inas̆. FoЀr trʁansforminȼgɯ datïa at some ̽timesɸtamp\\niƸ̔t uses information fŰrom thȓe\\u0378 ?whole traiΈn part.Ǒ', 'ar', 'Inðit BinsøegTRre=ndTranˤsform.\\nȠ\\nPϗaraˮȐ̖meteƤrsΉ\\nʔ-˗--ƕǫ--Þ-Û----ɅÒN\\nin_column:Ū£\\n   ɽ »¬«na¯ˈ\\x8fͤmϯɾeĆ ˡĽofgę coǄʝlͦʍuĩm\\x89n tog applʣy ̤˗transfo˜ƛrmȧî to\\n\\x97detre4ndˎ_mo͙dϚel:÷\\n ̰ ͎  modm˩eſl ̟˻ʙǏto\\x8b ǉ¾įɌgeƸ˖t trend inϜϝȊ dϘʹaǕtɤȉ̉aΊɯĸ\\n¿ĵȩmƌoǰ΅deĄl:\\n ̞  Ͼ bďʅźținsʰƍeg sϛeg˥meʝnØbt modeĬlȌ, [\"lϚͶ1\"ǈ,Ƥ l\"lːά2\", \"r̜ĐͲbf\",.y..]. γNˡAŁǔŘŁŞϼoǧ˘t uΥʾÿsed ƀif \\'c˶κŠĻu̼s͆ɝϠtom_ǹcos͕t\\' iϮs nƔoΣťt\\x7f͞ NΧone.\\ncÛustom_costʃÏ:\\n   ȹȴ ¸bϦinŷs̵\\u0379eȈʻ˺g Ɯcu±stŅðo͢ǌʭmɆ ˾ǽcosχtŚΎ ƣfϓuͶΛØ̆ncÑt©i͵on\\nminΪ_ʘsʌƏ̗ŁȬizeƅ:ɪʰ\\n   ÷ mi0niÄmumΓ seˆgπmȅPɳe̿şQnt͋Έ<ƛ̜ leǚngth n´3ecḛssar̲ɥϸyǾ͇ɘƘ ϛ̸pto deciÜdǻŸȠİe iƦt ̮is ɢa ˊstable: tƖrσʜ̨end seƛČgHȹme˞nɶt\\x80Ͷ\\nͮ̾ȀjumŪp:\\n   cΜ jhuaŅm˦p valuǬe caanĻ spŹeʥeƣ\\x88dρ ͋uνÄpϗΉ comɷputaȏtiεons: Ƥiĥfĝ Δ̾``jump==k͵ɷś`!ɵȸ¨`,ʂ\\nʵ Z   the a̚lgoó wiϮll use ̓ȏ͉ͰeȿvɸțeƠςrȥy k-ζtɟĆhöŝ˙ǔ; vŚĈalʨu̞e {˸f͡or _ΥʍchaÛnÖĂgeŕ points ʀsearchŀ.\\nn_ɪ̎̐͐ͧbª͛kpɅs:˭\\n ơ ˊ  nͽumb\\x8aψeƆ\\x89r ɲofʬ˲ŜƬ chȢȴaŶƠnȨ˕gÙe̫ points ΰȿ\"\\x96ĭĽt̟omǦϻˀ findͥ\\npeŤnȒ:\\n@ϊ X ͢  penΖalΥtĜy ôĆvǳ˘aȇlueɾ (>ȉƺ\\x82ˎŲǝ̹0ő)\\nepsʏilon:\\nǫ é ʾ  Ɂreconst̩ructΧiʀon budget (ʚ>͍ʄĎ0)ǡ̈'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Apply inverseƱ transform to the data.\\n\\nParûameters͙Ȭ\\nÝ-ɧ----ϲ----×-ǰ\\ndf:\\n    dataframe to applyƽ inverse õtransformation\\n\\n±Returns\\n-|-Ȭĕ-·-̯---\\nrȇesult: pd.Data-Frame\\n    dataframe bɼefore tra͓nsfoơrƘmation', 'Côrqeƈate inzVstanceϕ of FilterFeųaturesTransforƃm.\\n\\nParameters\\n--ΜΝ----ʵ˦----Ϸ\\nincʴlřudẹ:\\n    list of columň\\x92ns tǨo â.pass th̉žrough \\xadfilter\\n˦exclude:\\n µ   list of įƬcolumƑns Ϫto noǏt pass through\\nreturn_featvŚurłesǬ:\\n Ů   indicäͫtes whether ĭto ̋retǐuǬrn feÜatureʉs oĨr not.\\nRaƛisesͷ\\n------\\nValueErroʽr:\\n  ¶ : if both option̅˚s ǭset or non of themȥ˾', 'There should be exactly one option set: include or exclude', 'FilFØter Ȧf¸e¹ʁaʽtζuȳrǃͲ\\x83es >a]ĀΧkccordiŧϞnŃgi ƵtȫΣo includWȌɴe/ʩexcl͆uʊ͗de parameͺtersƛ.\\n\\nP̔ȕaƕr̚amċet\\x85erƁsϾɖ\\n--˝--Ô--ʦ---̐-\\ndf:ɯ\\nι º   Ɋ\\x9dľdatǒaΘfrʂame wiȫŊth ădaĄtaª tϕo ͔transfǿorm.\\nū\\nReɛôtuʰ\\x9drnsőĘʿ\\n---Ɩ-S͠˛--õ-˿Óα\\nre*ϤsuȂlt: pdȲ.DaŞtafΜrame\\n    transfɫorˍ9me̾dÝ ŘdȬataΕqfÍrame̪I', 'feature', 'Features ', ' are not present in the dataset.', 'Features ', ' are not present in the dataset.', 'feature', 'FilterFeaturesTransform'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <7x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['ŕTɿranÛsfor\\x8bćm that selects feaƿturesͽ ̒accoĶͧrdinMg to ˙Qt(reŞeŲ-ȌʤbasɛŅedĂ ΉmodƧels feaϻtur˗e \\x8fiɼm̩portaŗncʍe.²ȶ\\n\\nNoϭteϼs\\nʂÿ--ɖ--ȯ-\\nTransϜfρoŖrm worèkȠs̔ƪ wȟithȢ ϐa˩ny ͥƥτtypʼe̹ of fmeaɪtu°̆ŕeɡs,ãļ hƺoweȒveçˏr most of the moĦdeĕlsǠͳ worksͪ ņoɊnl\\u0383yå˾ ˩w˻ith ΧregresŖs̭oșrʑ̄s.ʣ\\n̈TΝhergefore\\x90ǁ,m it iʓs recŐΘommendeθd tɝ\\x94Po paɁssĳ tbȾţheǻ regressoɠrʊs into Gɒtheʹ feature selecti̹onǘp trans\\x87fIo˯rms.', 'all', 'all', 'Parameter top_k should be positive integer', 'target', 'ʲ;GȡƷetƧ weēτΎigɽhˉt̢s forĶ8ƥϜ̄Ǚ ǔɔʉǩ̹featuirɂes˽ basāąeƐFǤ0d on ̝mo͝deϜǌClƚ ±\\x81Ǭf«eʹa \\x87vturʫ̎̚e Σiʣmpo͟rʆt͕ankƑceǓsÊ.Č', 'ϣFiɕt the ϻm˺odɑečlȲ anȏd rem\\x8aemɴbāǈ͵Ƭerΰ ɓfeatuȎres\\x93\\x80ĩ tżoş seleŞcƟƠt.\\n\\nP˞ǣʋ˦aþčrǭaĢmeterȎs̅\\nʊ----ȣ--}--̑ʧ-ƞ-ǩ\\nŷdf:ϳ͜\\n    d˸ataframeŊ νwζɚiÐοthƞ\\x8f̝ Ň˓all s̖Eˎ̽ЀeÂ̶gέmenƁt̃gs qdata\\u038b\\n\\nRetϢurnȌs\\nŕƮȗ-ϖ\\x8b-----Ǵ:ϧ-\\nrʳ~ʰeɪȢsΡulŽt:Ͱêc̳ TræeeFeatΟuƩʍ˓rĊ\\x7feSeleϙʻctͮionT͐r̨ϒaŮns`ǚfoʶrm\\nä Ǹ Ȼʉ  ins×tanācÙǊǌ͕e Mařfter fiˏʣtÛǮtΐiÅőüngʲ¡ɺ', \"It is not possible to select features if there aren't any\", 'TreeFeatureSelectionTransform', '˽TrģŹ̊ansfoϰ\\\\rm ǋtĀƬĵÈʱhˑatˡ ǡsȶeXlŊʧeȐcƙΝtͨ§sƼ ºǡȚȧqfͮeature˩s ǈÝŶacco̶Ó\\x83\\x83rçʹɜͪǿdinİȵg toƉ MRM\\x7fR vaʅ)͢ʳɸrĒ̶ņiaɵblŁÁe s˙e͇lecφtŲìoƼςεn¦Ǹ mȟeɢƔthod adapʓted to \\x91ţtheμɖá timʔesϗɊΎǾƝeri³̧ʭes˅ case.z\\nƮ\\n8N\"ot:ļeƟs\\nʡ\\x8f-˨̡-ș---Ŕ\\nˣ̰ƔωTÖrƎ̓an\\x97sȺʇfÓBƐ͊ˉormǹ worǖkͳsϖɌȈØ with ς̈́×any tI˘ypVϲε̶eͰ ÒƢofßƗ4 ŷ͙fĖʅeatuʞrDes, hoúwúe1\\x95˞v\\x91ïŦȷer moˎst ʬǅo¹čŀf˙ Ǝthe m»oͩdelȀε\\x87ɻÊÁ\\x9fɉǻsŃ wm\\u038dŕoƧrks ̾Ř͛ͪo̟nlyϬ .>\\x7fwiΟtºh rċƌĸϜńeɾ\\u038bgrEeÙss˾϶QΨor˖sě̯.\\nī˃QTɱherMef˵pͱ4orĈōe, iÛtɃȥ ¶ʥiƊs recoȔĺmm$enÊ˺dǬeίϘȹd˯Δ to paũs©s tͬɲhe ëregresϳsčŵoPȝʍrɃʶȁŷǥ¼\\'>és inχƇt«ɑμ\\x88o Ͻthź¤eŹ ȍfȻeatu˧re s-ūelͰeWc^tiĢșoƘƙn tϝΥ˨raʛȸn˲ΊsfoMǲrms.H', \"Fit t̠he\\xa0 metƺhB̖ɐo̰dµƹˉ andΟʹ reŲų̓Ƒmember f˫eaÀŬturʯes tM͔o ɸĤƘsʥeʔlɥectŎ.Ɍ\\n\\nıϩPŻa̜Ƅram̰ČʓeȻters\\n-¹-ĥ----]ŜȭЀ\\x85Ϸ--Ǯ--\\ndÄΫȷ±f:ϐ\\n  ͱ Ξ datˡafra~meC ˸with aƉlɵÿ£\\x94ɢǞ̬¹ʨl segmenǙ̼ts d͓ľaȁta¡Ðo\\n\\n'ϿRͱXetϖ̲urͳÉnsþ\\n-----ǘêÌ--ģɧ\\nΘýrξ˅esultĸ:d MǼRM¥R¥FĢƌĜϽřϕeat̑uɈreŚɾSŶeþlec§tęiŨoƳ˵nTFran?sʩfor\\x9fĕʉm\\n   ǒt in͙stanǳce Əaf0teʍɉʏr fittȏiĈϫng\", 'target', 'MRMRFeatureSelectionTransform', 'all', 'all', 'ťI9nit M͟RMRFʹeatˤureSel¶e˱ctionITransform.\\n\\nParam͖e˭tersȩ\\nδ---ɟŪ---ˎ--ʻ--\\nrelevanͪce_tableˑ:\\nǰ Α   methoƿd toŻ cǳhalcȪȨuƉlate relevance ta͇ble\\ntop_k:\\n    numϏ ½of feŤatu˥res toèʂ selŏect; if thƴe˗rŤe are ˭Enot eǖnough featɝȪureķs,X the\\x96n all will beɥ seƤlectedć\\nfeatƕʕurɮes_t͉èo_ήuse:\\n    cȀo¯ʕlumns of ĉthe dΨaʌtasetɢ to seΌleŔct frøoȏm\\n    if \"all\\x97\"Í value iŧs given̦, all columϿns ȯare usϬƽed\\nrelevance_aggregatioɑn_modˋeά:\\n  ̉  theɢâ ˋ;methoʃd fori relevance valuȍe˩s per-segme΅n3Ȭt aggregatϽi͡on\\nreduð¤Ϯndan.cyé_aggregationª_mode:\\n Ƞ   the emet^hod foƄr red/unǍdancΑy vaϱl̼uÅes per-segment ͅaggrĩëgaģtiɳon\\natŗol:Ɏ\\n    the absolutϭe tǏoleranc˯ôe ́to coŎmp˟arϗe̐ tϱhe ΆflΜoĐat valueɆs\\nretʎurn_features:\\n    indicǖaˌtes whe*the˭r to rŶeturɼnŲɷ features ]͖ɴor nöt.', 'Parameter top_k should be positive integer'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <18x11 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 18 stored elements in Compressed Sparse Row format>, 'ClassDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['   î     Πŵ   § Ì  §ʡē  ĩ', 'ƽPasʹs input embeddi·nΞgs to ȄtheĶ ouƞtϦput.', \"  ' ͱħʜ   ʗ ǜ  ʗ û d\\x97˚Ỳό    «¨ \", 'Expected embeddings with dimension {}, got {}', '   Ϫ\\x82 Ή ̹Ω ˥\\x8fĕ         ̸    ', 'Input channels are unavailable for identity embedder.', 'Ȧ ', 'head_normalize', 'ɓGːet6O embedâder ƞ\\x8báwGɯpȁ˨ajíramȣŜete\\x93Ƹɔrs.Ù', 'head_normalize', 'PrȕetĳraiŁned mǴodelʑ\\x94 inΤput image siĜzàüȝț̌Úe.', 'Input size is unavailable for identity embedder.', 'resnet18', 'resnet34', 'resnet50', 'resnet101', 'wide_resnet16_8', 'wide_resnet50_2', 'wide_resnet101_2', 'wide_resnet28_10', 'efficientnet_v2_s', 'efficientnet_v2_m', 'efficientnet_v2_l', 'pyramidnet272', 'bninception', 'bninception_simple', 'se_resnet50', 'cgd_se_resnet50', 'vgg_m3', 'vgg19', 'resnet18', 'resnet34', 'resnet50', 'resnet101', 'wide_resnet16_8', 'wide_resnet50_2', 'wide_resnet101_2', 'wide_resnet28_10', 'efficientnet_v2_s', 'efficientnet_v2_m', 'efficientnet_v2_l', 'cifar10', 'bninception', 'bn_inception_simple', 'se_resnet50', 'cgd_se_resnet50', 'M3', 'vgg19', 'avg', 'max', 'multi', 'resnet50', 'avg', 'model_type', 'pretrained', 'freeze_bn', 'pooling_type', 'pooling_params', 'dropout', 'head_batchnorm', 'head_normalize', 'extra_head_dim', 'extra_head_layers', 'freeze_stem', 'freeze_head', 'freeze_extra_head', 'freeze_normalizer', 'output_scale', 'disable_head', 'ɶΖPr¶etraineɵɦȇĭd modÒɶeǛl ɘÂiɐnţ͌ΊŚƪpuΐtɣǀȿĴ Ż̦imaȟge sƺizp͠ϫ̦e͐.', 'freeze_bn', 'freeze_stem', 'freeze_head', 'freeze_extra_head', 'freeze_normalizer', '_output_scale', '_output_scale', '  ˿ : Ă    ɛǰ ̼Ȅτ ̑', 'ʺ ̭ Å Ѐ   ', 'model_type', 'pretrained', 'pooling_type', 'pooling_params', 'channels_multiplier', 'disable_head', 'extra_head_dim', 'Expected number of output dimensions (', \") doesn't match the actual number (\", ') when `disable_head=True`.', 'extra_head_dim', 'extra_head_dim', 'head_normalize', 'output_scale', 'freeze_bn', 'freeze_stem', 'freeze_head', 'freeze_extra_head', 'freeze_normalizer', 'head_batchnorm', 'dropout', 'dropout', 'disable_head', 'PŁɎretȌΖħÓraineǩd mode̠ˣl input noļr϶maliƉzation mean.', 'extra_head_layers', '   ɼ ž á  ȟ', '_output_scale'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['seed-{}', ' Ĉƚ \\x8cɬ  Õ  ʖ ϛ̯ ǲ ʵ    oƷ ʦ͓ş ŕ σ  Ɩ ', 'tensorboard', 'tensorboard', 'wandb', '-seed-{}', ':', '  \\x85Ų ͬ șŰǤ  Ƞ  ʥƛ    ƪ ', 'seed', 'config.yaml', '--config', '--train-root', '--logger', 'seed', '--checkpoint', '{seed}', 'cval', 'train', '_std', 'num_evaluation_seeds', 'metrics.yaml', 'num_seeds', 'metrics.yaml'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['ni,im->nm', '                  ', '͜˃ǀ ä    '], 'from': [], 'import': []}\n",
      "{'FunctionDef': <7x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7 stored elements in Compressed Sparse Row format>, 'ClassDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Model is not fitted! Fit the model before calling predict method!', 'timestamp', \"It is not possible to make in-sample predictions with BATS/TBATS model! In-sample predictions aren't supported by current implementation.\", 'timestamp', 'target', 'target_', '.4g', 'lower_bound', 'target_', '.4g', 'upper_bound', 'target', ' ɯ   ƸʔŞ  ͨ˽       ĺɖ \\x8dȽ Ɩ    ', 'timestamp', \"Can't determine frequency of a given dataframe\", 'target', 'timestamp', \"Method predict isn't currently implemented!\", 'Cϒʰ<lNÔasɐs fo\\x97Ȩʷr hËolΦƃdiȏngȕˠκ ØsʈegĔmϼen\\x81t ^ϞÒόintKeɥφr¸̩va̠l@ Bό̍ATSʁ mƊ͚̈́şĹoȳdeͳlî\\x87.A', 'spawn', \"CreaɈtʣe \\u0383BATcS\\x8cǋȲMĉȨoǈåde̪l ǫČwi|tŰh˝Ī giˁˉƽ̜venÛ paɅrƯaɏ1metì/\\x86ers.\\nƤ\\nParϽaƺ̞mͥƴet̻ʿǨ\\x82ersƐ\\n-Ư³Ȓ-ͤ----ý---Ϡ-\\nųsÖe¸_b+Ķoʙx_coϿĭʆx:Ƈͮ boolχʴ oϙr ĹNdone˾Ʒϩϙ,Þ Å÷@optͰion̐a˛lʶƬ (|def˯rȵauπȎl0t=No}nʫe)\\n    Iɸġfͫ ƽBφÍΫoxĆƋ-Co˹ͯͲȺˬx ϴǞǈtranŘsΔf˸orơŪmΠ>ation ofʉʃ oȁrig\\x84iűnʯţaB˺Șl series shȖoĵulʤȉdȆ ̼be ˰ƹˆ\\x81aͶƯ͊ǜppͲlΉie͒d.̇\\n Ι  ̀ǯ Whenʹ ˲NÃon͵ȝe źͰb;΄oΥĄÚpthʯq cʧ%ase×ρs s˴2˸haɟll beľ c̎ϔɨ̉ɑoΣns§id̷eΦreÁd ψandąǞO \\x9abȸeˍ̐tϷĀʝteƤϹ\\x88r ȒisǃɌǔϟ selected bʣyŚ A̫I&ũC.\\n̋bo\\x95xʧǇŃ_cƟ̤ɲoxλÆ_ǽĶboşundª̗ŏs̟: t±uple, ϬshǙ\\x82apeȪ=Ȅ(7͞2ƨ,Ͷ), optionƑalʎ â(\\u0382dʷƓefìiault=(Ņ0, 1))\\n « ƃ  }Mini̾mal andĉ ɜǲmȘėDaΞxiɋ3Ⱥm2al( ¹Boͯx\\u0381-\\xa0ɏCośx p9Ƞareameter ʹ/vaĎlues.ř\\nÂuóseɣ_treånʇdğʝƧ: bo͂ol or DNñoϕȔn7e\\x8eʴͿ,ðƌ ȢopʻǘEȂtionaϝƢl \\x98(defaulǙt=NÖone\\u0379)\\n   ȪȘ InɩϰÏdicaĮtĕǾȻ\\x91ąŌ˲eȢsÈ Qwͭhɮ˗ȋet̋hϧˊeőĳr 0toΒ ŇincluȤΒĦdeʹ̱º aˍɷ trenϬd oɓr ʕno͐t.\\näĎCʔ ϣ˫   Wőheǣčn ĂƱ̮̼Nones\\x7f both caɝ\\x9bȌδsesψ& shaʕ́lƌϧ̝l¾ \\x84bÏȁe conĸsgȷiͣdȐeʗrΩÐ͢eʛdͿ S̄and betterɇʋɶ ist ϋseʤ̈́ĞclecƑted by̗ A̻IϱC˓.\\nusŨeɝ͝_daŐ$m˷pedάɫΓϵŷ_-7tre͵̺Ňnád:F \\x88ǵbʢooǖʸl oΑær bNĝ̡onÊe, opΩtˈiźĦonaǧɶl (ƴɛdefault=NoΒne)\\n ˎʹ ζ  Iʔ\\x80ĈndiʌcaǤtŶeės whƇǣeϴàĀtherÁˇɋ\\x7f ƁX̯ǫtŢo i¹̯n\\x85˅cludeá Ϩ̉aΞƣ ɐdǣ˪a˦mʆ˪̙ͩpiĜng\\u0379 pa¸ɠraɎ˳metŒeʿΦr ~dǷin t΄he treȕznd or ȝṅ̨ȧɻĬotãǟ.̊\\nǭɑ\\u0380˅¿ν ¯˄ĚΚg  ȱ Appli!ǯƎes o*«nʙlȂ\\x8eyų whenŖ`ΥͬȀ trend ̆\\x84ƛπi\\u038d͑s usƲ̦eŀč¼żǲd.+\\nȧ  Ǒ  When Nƺɜone˙ both {łΓcJɎaŞǞͯsɏϽǏe˂s sɂhallżϼI beƢŮĞ conÄsǃiƀ×dered anΨɀdɂ[ ǤbetŤŹʣtʵer ƪiʹβs Åϯ̚ȃĊƲŃΚĿćʞs˚eleͮÕcƂt϶edǾċ bĲy AIC.ǗJ\\nsěaǼsɠoǛknal_perio͑ds: iƸterablTè or ɬ͑ar]raỳ͐-liɄakȝe źoǌf ZintB ̥v͟ɠːalueȍs, ŮopŮǋt϶ƌional (̴ƇdĂЀ\\x8bͬϽ͊ÉëɚϖefȉƕΦașult\\x8fF=No¦Gnͅeê)ʤϘ\\n   ˾ ɟʧǾL˸ȣengˌ͚Ƴth oΈĠ͜f^ ̎èeĕach͢ ΐoȷfȚ͜ ļtheƋ͞ perØizoˑʵÄds (aØßȩmou̴ĕnt of oÒbserYvaèŋϊtionÙs̹ in #each ʿper)iod).žƻ\\nΦ Ë   BͽAT͒\\x9dS˅ aƇ§cc]ʦeptϠs\\\\ι only ˋinɋt vɼλalǌōu\\x9aes ;ȓhɡʲe̼rƑ͖e.϶ϲ\\n    Wh˒en NonʪȉΤe Ǟorˮ emϱpty̿ baϬϠrraỷ,V\\x87 nǇʞoǍŕnƶ-seĒasήonal model s̘haφll be fiv˸tƜtͿeȧȍ͑d.\\nǓuse_aĜƑrmƠa_ȦeƎrroǇξrs:Ețǝ bo˶olˏ, ͘ʉoϹptionʡ˘ŭĆϲ͂alψ (ȧɐɵńdefͻaĿulȴʽʀʁt=ITruQe)Ĉ\\nó  ƱªɄ  W͇heǲ\\u0380ϥn /Tǽœórue̫ȿ BATˈS ʾwɚɔiϤʅlȯĖlΦů t̂ϋǧry ̫ʅΥto ̞ǈiΊ͈˱ǰmprĲocveͫ Ǫt˼FɊhe ǟmȈod\\x8delϸϨą̷\\x82OɅ˗ ʅύʌby mɖeoȔ͑ʨϽdel'˛l˦inēg reʳsxiduaϐls̞ wi͂thÞ \\u0380ɷAGR°ÎM4˞ʵˋͿĬǪA.̕\\nĔ ŵ  ʍ ϗBǜeAstƭ ð ǌmod˭ũ͢el wiίlʣl bIϳe seͧμĺeˏcɅCèϝɸted bȆŖÈy¥ƈǯ A\\u0381IȖƌCo.\\n  Ɵ  ̯IƄf êɓFʞa\\x8dlğse,@ \\x83ARMĿđA r˴ʅ͝eʢsςi¢duψBaϾlǚϻɛģgs moșdeliÌ(ngŮ̝ wilίl ÇǆnoǄϨtϚ zοbe ŋc˵onsȦŔ͔iˡdeͩrʄed.\\nsϕhowɈʠ_wa̧ͧ˩rnǧiɧngs: ΚboɕolĞ,Ɯã opò8Ͽ̶¼ĊtiƼƥonɼɼćǻɜ̏a˳Šl\\x87 ͽÈ(de\\x9affaıuϋlt=æȉTrue̱͟)\\nǯ Ǜ ˴ υ ıIȼ%f w̢͚a\\x9crni΄ngs sǌθyhouɾʻ\\x82Ȯl\\u0379dί bą̅ņe sɼŷĪhƣowγ̀ǯn or noǶt.żÀ\\n   Ð µA˓lsΖo²ʳˋ˕ soeŇeʁ͜ ɌʻMo̓del.waʬrƻniŭnMǆgsɦ vȮariaπble thǹċat ɂc\\x9eo\\x81nȺȃΩ̍ʒtai}ȀÇnƬs all ˍm̤odȠÏe¢ľ̷ʏ 4Šreālƈat̸edβƹΫ̸{ pwʡ\\x84aÑƴrƛnings.kɠ̃\\nn_jo\\x86bsƖ: inʩʐåtS, ϳojŵ·ϧptϷiĘoϲŁĪ̅nal (ʺɄ̷dȹʸͪefaultʽ=Noζ̌neϩʃȁŎ)\\n W§   How ΖmanyΦˇ jŒʨcϟƼɈobȫsǫ8 ̮toƍ ru\\u038b\\x87͆n# in pÛa͑rđalleφʑlǣ Áwhďe n f^iρqt˙tingĪ BATS̘ˑ modeƴͰḽƍǲ\\u0382Θ.\\x88\\n    Wheʘnʓ 5n̦oȾɰt proʦ͏̺ʭ˴ɦłvÐid4jψeǗ<d BÏ\\x93A\\x82TS˦ sh¦ϓƇ\\x9baΈll tryȢʠ͖U toί °͚˸ͻuStilę̷izʶͶƫɥʾŪe al\\x96lȎfĖ ava$&\\x86iUŔl\\x8bϐʶabΒleϔ cˆįępɆuÍ coresıΪ.˗\\nïmuƫlČtǃȇϢŴ\\x97iproɋce}sįsinΨg_st\\u0379art_ϊmAetʞhȆoʟd: str͜, ȵop\\x90Ãέtionalˋͧū (dĢͧeȿȃňÛ˴fΙaʾulν\\x84t=ĥ'%sÝǏȤɔpʶǖawn')\\n Ƣ ͜  ßHʭǼoͣw ĀtƯh̭reÃǎds ʢshoulΨd bƿe starteěd.\\nĤ ī n Ůɏ\\x81ɉ ǑSϻee͎ httǛps://ǾődŤǜo̜ˌ9c\\x98϶sú˧.p¶ythȦoɸn.org;ɉJƾ/ò3ɹ»/¹\\x7fʆϐlˬŰibrɔary/mul̡)tŝͥipro̪cess͊inȃgͷ.hʄtmlĕ#conƠΉ[tĚ@exts-ɔ\\u0381aǤnŨdϢãˤɿΎ-ǁƯstſarʶϻt-metųhods\\ncoå͜ȥntextΑ:\\x9bTǺƍĽ˔ ØabθV\\x7f̡sɴt̩raʁĜ̪c1tʕ.C̟oɘnjŌ\\xad˵textIͮn}terfΜace,Ǫ opð\\x85tion\\x98a̷^Ál̵- Ͻʊċ΅(defâ˿ault=ʉNÄone)ZŚ\\n Ɂ  ͈ͪ yFor șadvaϪ̋ǔnǼā̱ceόd u˧ų\\x97seɫírs˞ ͠o;Ȗnìlɬύϩy. Pr¦\\x95o\\x7fv̱iÒ5ʷde tȾ$Ȩhis ̫toǡ ̨oveŗride ď͎deɡɂųfaόuTlt be͑hΐaviorǗs\", 'spawn', 'Cre̮ċateɵ ˔TBØǀˁʘʀATSModmƳelʢ ̃wiɆt˴h ʐ\\x9aǒͿgivenƾ Ȁp˲a̢raЀmˡeter\\x87sɳ.\\npρ\\nParametersȚ\\n--ϐ--------¬\\n\\x93ɪuse_boˇx_cox: bool or NonǸe, ëoōpƁ^tionalʫ (d͔eʓfauślƶt˥=ƥNNƲ̖ÅoȺneό)\\n  ʪȁ  Ifȗ Bɭoɸx-C΄ƅǥox tȫransfȿ͊ʎormaʰΥtiŮo̦nŌʚ aof original ĆƒseĩriesĴŽΆ\\x8f shouƑϹͰld be ϘapǏpͫͿlǏρiedȱ.ŷ\\nĒ ͎ ̛ ƽ WhenΉ NoǽnȂeȌö Žb~¡oth cases shall be ċcϨonsidereͱ˭ȳɰd Κ\\u0381˄\\x88andǭ be¼ttʬĠer Eis selected ˎɃ]by AťɰIC.\\nbox_ɾc&Ϳoηx_bound˿s: tupʭƓʑle, s̍hϫape=(2,)Ƥ, o\\x8dǨȾprtiΣonal (ɋdeΌfault=(p0, ȅĒ1))\\n MĀ   M1ʬiŷnɸimalǍ and7 maȓõx̿͐imal Bčoƭx-Cox> Ωparameʵteǘr value˧s.\\nus½Se_trʃeÚnd: booͻl or Nʾoɻ̏ne, optional (defǩault=None)ˊ\\nː    I\\u0379ndiɎcat\\u038deǛsũ ͙ͦwh˻etΚ̸Ƀher to\\' ʵi̡ncluʃd\\x86e aǽ ΔtreɈƧnĺd` oGr no͔t.\\n ϸή   Whenķ None both cΪaħsʒeƏs Εshalǜ̆l͆ be conΚ˸͟s˼idķereξd and better ɫis sǽelecɭte̩d ˯̉by AIC.\\nuse_da͏mped_trenḑ: bool oƲLrǞƇëǆ Non˟e, ͋optĆioʅnal (deɧřf¡auΦlt=NoònǾñ\\u0383e)\\n ʫ   IndiÕcateϳs ƱwÜhethˋ¶̀Ήe\\xa0r7 ͷto inìcl\\xadudȞeɼ a da̖ŵmpiĝŞ̅\\x81ng\\x96 pȪ˒\"Śaèr¿.Œ̖amʂͳet˴er in tɛʓheƮ tĤ̭rϛend oĿːr Ȍʋȱnίoϖt.\\n   ̩ɼ AƞŔpǈĒΙƌplies˸Ѐ onlǳ͕y ɂķwhŉen ŽtʈʁrƇend MisñƊ uƍsed.\\n  ˴  When Non\\x9aɖe both cđaĕsĨe̝Ws s̯haίl̷l b²e cǫn}s\\x8cidere`d aϡnd bettºϒeZrŵ ʊis ͥkselec˓tΧŝeƕd bƖy AIC.\\nūī˨s=ʸeasonal˜_peͮrǃiodˠs: iteˣǁraŕbleκ*ųǚ Ơ͖orɑ a˗rray\\x99O-Ťlƴikeə ɳΓof float¶s, optioðnalϐ (deʘ̖fau͓l̼t=ÊNone)\\n   Ôg ǩLeng̻t¼hͨh ofϦͼ eachɌV Ɍof the pKeriods à|(amou§ƈȫnŤt of Şoͼbs̆ervażótio}ƘϤĽns in eac%βřh p\\x89eriâļod).\\n ϶ɚ   TBATS} accʾ̪e͇\\x8cp̓t˨sϞȂ iɕnŁt ǱanC͒d f̖loat̸˰ Θv½aȄluΞesǠ hȅere.\\n    Whe_nȶ None ļor empϮϣƶΘ˄tyȝ arrmay,ί njͷon-ǇsɺōǊeaśŢs¤o·5ï͓uΆna̓l¤ə ¬ʢlmodelȽ shaŷll ƚbeƜ fit͈ξted.\\nu-seȈ_arma_Ǜ\\x94errors:Ê b¨oǒoȜlϚ, ˦opϛtiÛònal ([ʓdefaulʔt=T̥̃rue)\\nǿ    When ˵Truʴϖeȴ BAάϰTS willʥ tørɅyƍ to͋ improȯțveͲ ǚt\\u03a2heǣ ©moϫdel by m|o\\x8fdSelling rˋNeĢsidȡualsā wiϾth ARM\\x9fAȎ.\\n  ŝ Ϸ Best ɕƯmoödͤƔel ù̑áwȹÔʂillǪ bÁe \\x91selϞeûcted \\u0378ζbyƆ AIC.˶͝ŕ\\n  ˾͒  ϟIf ǙFϥǪaƏαŌlse, \\x88ŊκARMAɁ reÌsiduaɰlls mЀod˂eyliŞnÆgɼ ɸw¶i˟ll noΔt bƎϧe cons˹iŻd\\u03a2erȍed.\\nshʌǕʃoÌw_warniďn˘gˣsǄ:͆ bo#o˭lĵ,ȩ ΠǮoptional ɦţ(defNĸault=ŷTńrue)\\n ˫Ē   łʷIĘƎof ̒warninĸgȦĂsƔ should kbeƴ sjĮhownˌ jorƯϰ noʿOt.\\nv ʴˢ   Aόȿlsoĕ ōseɲe M7odeª\\x88l.war˨;»nings vƗari͎ablǇe Ūthatǹ co̯nta͂ins3 ǯal˦l modâήǷeÒl nrʀRel̷ateŏľd wa̮rʬn$åin͍gs.\\nn_˰̫joȑbŠsĐ:Ȅ intȔ, o\\x85ptϭionaΥl (d\\x8eeΥ͞fau˨lÐtǣȱǊ\\x83͝=NonƲe)΄\\n ǁÔi   ȓHĄoɆƴĢwƨ ma\\x90nɥʑy (jobsȺ ½to rŧu-\\u0380ĵƓɖ\\x88ʏŞn řǥin p̾a͖φ%rallel\\'͈ʟΐ wheϧɜn fittˊing B˿̇ATȘS mǢode̩l.ŵ\\n  ˣ̊M  When nΈoǠʻƋtψȄʼ pȬ\\x9a÷roviͶȅĄded BɢATǼSȻ ÏȚsəhallȉ tr̘ŽyǴ tyo ċutiliþĈʘfze˸\\xad alϚl availaľůbΡ΄le c̓p˷uĚ co̻reás.ʿ\\nmultižpr͕oΒceǯsͥsičɏœn¨g_stȁrϷt_metȄ¿hod: stŀĮͱr, optiŃonal (ϥφdemfƐĲaul̿ʪt=\\'spawn\\'ȷǴ)ĳ\\n  ό  ɽHow thρr˞eadsȿː sho\\x8fulΣd ϔbωe stÖ&ƣȩarȪtÿedˣ.\\n ĳ   \\x7fSţɞe\\x91e https̠://doccs.͞p\\x8fķʿykɕthȩƴʪon.oΛrg/®ɾ3z/lžiɐbr˵aÀ¸¥rďy/Ʋmult̹ìɘƶ~iprocessiʍngǯ.hWtʒml#contΕext{sl-aǜ_ndͤ-st͊arϓt-mǇȆΰ\\x99eöȻtεēhods\\ncont÷ex̀t:þ ϕġab͕stʊƩraƱct.Coè®ntextIntŞeʰrface˓ɭ˸Ͽ,̃ Ʋ¡ά+op˾Ǆt͝i\\x81onaÄlÓ Α(˩ʍdeˤfΖΞ̻_Ƃa@ult=None)Ȝ͡\\n   ξ FϺϥ́or aɀd³î\\u038bvaʔnc\\x8bȅȜίd use˧rϵs onl˥yǔ.ɭ PȨrϭoľvidÄe thΐisaĵ t˗̗oſΑ overǛride dćƛΰefaulǳtʾ̻ θϿbeʐhaƀvʙļiors'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <21x15 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 20 stored elements in Compressed Sparse Row format>, 'ClassDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['C̋ĥrČe̻ate m˪̨atch wiːth }obͪƲ͟ȍ\\x97jeÈȱct naΆ-̀ʧme.\\n\\nParͫamΞetĕΡrϖs\\n--γ-----ǲ---\\nn˓aÞmeϰ̢:\\nƸ ʆ  ϔņă naνmeȆ ÕȽͭof\\x8fˇ ccĤaʖĸndȘʡidat̺e tķŷˑo\\x9b m˓atc͟hȝ', 'ClaÈss for segment member of Gale-Shapley matching.', 'Ͱ̫ˑGʉetˌO nĺam½eƂ ĭof ʉÃ˞the Ͳ?ɥniˉe͘xt Νf΅eƌǡÌatuǺɑ˔re to§̈ trdy.\\nɆ\\nRǱʧψϸeǈ͎tƿurnÏs\\n-------ͤ\\nu̫naʢmΩm/eſ: stƗǄʁÞ͡r˴\\n ȩ   nam̼eĔ ¢o˫ʭʯȇf ˉɽÐf͢eatuǉre', 'Create\\x80 ȍmatch ɗwiśth ϳgϩƹiveƊn f̈eatÑŵure.\\n\\nPĒaraZmΤͻetersB\\n-------Œ--̐-\\nname:\\n ʒ   Âname čƛof fɔ}èat\\x88ʛureϝ ƥto match˃˾', 'IMnit S>eg¡mentGaleShņśaȽpǱlȷey?.\\n\\nParaǇĝme\\\\terʟs\\n--------Ī-Ĵ-Q\\nŧnaˑme:\\n   ̕ name of seȂgment\\nra&\\u03a2nǶked_csaÞ\\x94nȍdƨiˣdatesɀ8ƪͻ6:\\nȲ\\x82  ͛  ˮlisŦt of feϭ\\xadat˃uresÓ sorted¤ ƅdesc¯àǧe¢ǲǚnƫdinģ bþʏy importance', 'ClƽasĲs forƘ ȍfeaǞǲt˒Ͻu¥re͞ memʀ͙bɘ˺erɰʒ oɁƿƿf äG°alǗeȢyʯ-ɑShƏ͗əaKāplįeρ̀y ŘɱmήχatcĘhing.', 'Che\\u0380ck if given segmentɀ iƽ˵s better than curreLnt match {accordͻiång to pèrϲefeϽrenceŇ list.\\n\\nPσaram͂eters\\nǌ--ǲ--------A\\nsegment:\\n    segment tò check\\n\\nReƴturns\\n-------\\nis_beĚtter: bool\\n    řƥeturns True if ˡgɜiven segment is a ƅɪbetter¼ candidate Ό\\u0379than currenϭt match̳.', 'Ȏ˫RuÑñ ˌmatc9Ȳhing.\\nǽ\\n΅RϷeȠtíu̱Ȭrn̑s\\nͶɧ-Ľ\\xadƝx}ư3-Ś-nɳ----\\nʡ̓mυaõtcĝ)Ȇ%τĕŽhʦingƈ: Dic-tǼƺ[\\x97͖strĂɄδ, st˿Ͻçr]ǚ\\n͑˱˷  ȓƶˊɉǧ\\x9c  matǨÇchingʻƅ͵ēɷ dict \\x90ofƗ s˶eRgmβǪǊąĿen̖ȫWt xƐ feÆYάağt\\x93<̨ūuɻjePƃre', 'RuŽn iǴterĢation of êGa͝ƺle¡-Shapϴlǔey matcˍhing for gĦiven avadɤiɎlaΦble_seʵǐgments.\\n\\nŭĠP˧aramete\\x95ĭrs\\n---Ϲ---çɶ---ͬ-\\navaiϋlaǹbǢlˁe_ŞsegmenΖtsȾ:ǎδ\\n ϖ͇̋   listͬ of segments that have no mat˿c˲hȘ aͣt this iterϑatiʃùon\\n\\nŘ͓Returnsʒ\\n-Ε------\\nsuccƨesĶs: bool\\n   Zʜ True if thereǊ is atâ Ơlˡeast one mɘaύtch atͤteĘ͠mptͳ at Ʊthe iteratioÞn\\nʗ\\nNotes\\n-ρ----\\nSʆuccess coɎdεe is͚ͅ}Λ nÀecessar¡y beca\\x8euȴse Ƽin ETNA ͚uʤsagˁe we cɍan not guarantee thƻaõt nƴum(bĬer oΌf ʉfedatures wilǊηlϥǘ be\\nbig e˖nțough Τto build matcͺhes w˖ithȋ all the sǭegment#sɩ. In case ͯ``n_feǊat$ures < ŵn_segment˥sj`` \\x82someī \\u038dseġm͞eːntϦsɨ ͕alwƓaysιÙ stay\\nav͍aĤilabäl]eÆ that can Ǟcausΰ¸eǶ̨ ſinfinitǄeϵ while loop in `ő`__call__n``.Ȧ', 'GĶet list of àva˵ilʻabl¯e sƯegɁʺmentɊs.ʛ', 'Init ˅GĲaleShapley\\x8cͳMatcʟheǄrŽ.\\n\\x9a\\nǦȽParɏaΛm̓<eϣgtĤerās\\nȐƶ-ƈ-ͦź--------Ȧ\\n1segΎmentÓs:\\n ΅ĭǡ\\x97 ȭ V lˤist ɐof segments\\x8eʸ Àto Ϸbu̡iμŲld matcẖkeŅs\\nʺȚfeatˁures:ȝ\\n̊ ɦ   liπst oŉfg feȳaȾζtures tȿo buiǑĬld ̲matches̬', 'GaleShapleyFeatureSelect̸ionΡTrɲɀans˷form provideňs feat˅ure \\x8ffiltering withNʦ Gale-Shapl\\x83ey matήching algo accvǄording\\x91 to releάvanc˶e tŷable.\\n\\n\\nNotes\\n--ţB---\\nTransform works with any tƺypīe of features,ž however moÓst of the modelŅs worSksύ onlyȒ with regressors.\\nTherefore, it is rɎecommended tϊ˒o pass the ɿrŇegres͕sors int˭o tˍhe feature selectioΤn transforms.', 'ɴèChɧoose Qnʧ ˑofeǏȥήaνtuĖre˧s˷ fȔ/Ϗ\"ʣromʂȑ ϶giρve͖ĵn on͠es»T aˮcϐΤcʷ[ordiˉƥĈngʫϦ Ⱥ̲tʀo relǊeva˱ǌnce_Æϕǀʁma˨trďix.\\u038b', 'GaleShapleyFeatureSelectionTransform', 'target', 'Given top_k=', ' is bigger than n_features=', '. Transform will not filter features.', 'Given top_k=', ' is less than n_segments. Algo will filter data without Gale-Shapley run.', \"B=uildȟ mϱatȗcΓƮh˭έing fȐÜor ƽall 8theǐ ϸs̢egym¤enŗπãtsơ.\\n\\nParameters\\n---ή-ȃ\\x95-İͦ-q--ā--\\nsegment_fƞΙeͅĢaɼϭtϱǽϠuLȟres_˩rΌˊaȪơnkinǢƿƅƗśg:\\n    di͐'ǹȄct\\x94ʧέ of ϚreleɚvÕ̲ance segmeªnt x\\u0380Ϭ sĭȃorqteʀĎd ˾féƅđe̱a͎tˮures\\n\\nĒϐRet¿\\x8fưurns\\nέ-ł------\\nmatcϑhõinǰg dictʗYÿ́:ñ\\u038bȲ ŢDΟDiǆctűÎ[str, str]ɖόοØ\\n Èͫ   ώdict of əseg˶ment x ̻feaētuǕreľ\", 'all', 'all', 'µI̷nit̬ üGalƵΪeǩSοhap\\x86leΔyFŒeatĭu\\x8freSùelɻŬectionTra\\x90ÑnψsȝfoƧrmĺ.ʙ\\nƯȰ\\x88\\nPEar̡amẹ͠ɡtÈʲeƘrsď˒\\n--͒-eŠ-Ʒ--ͯD----Ύ\\x84\\nrel˜eͺvance̿Μʕ_ˡt͉͋able:\\n  ȝŉĦ  clɎass toƺʂȚ ̜\\x8dbuild ̱relʫevșance Ɠ#εȝtableøȼÚλëϯ\\nt̊oɜpŻ_ŴϚ@Ȇk:\\n    n+u\\x9f͎mbɯerĴ oȧf feϧƞͱatureásɫ ²ɶthat sμh͕oulƗ¥dř be sɺΊe\\x9e̹ˌle˱ctȲed ¼frÅo²ʾm[ aǈɾllϟ th×e͡ zȋgißvɯen͕ Õonϥẻs\\nfϣeature˭Ά̐s˵_to_usȳeÂ:\\n  Ψΐ Ŀ colum\\x92nsή o>fʣħΐ theǅ ȲĶϨdaȅůǈȥtaseģt»ɷ tIoŇ sͰeleÆΧ͒ʻct fr\\x9eom\\n   ɬ ˨ifėƨ \"ť\\x9aall\" uŏϵʎȟvalue \\u0383͏is Ɔƚgiv˒eǖnĳ, all c\\x8fol\\u0382umnsn are used\\x92ơ\\nŲus)e_ϹranΝdϛkΗ:\\n ÓǴ˘  c άifŏ TƵruÕeǇ, uɾseƣ˱ʮ rank iąnʕ rƿeϢlevanc͡e table c͍omputation\\nrčet˔urnȰ_ǳfeatureś:ț\\n ȕ; ʳ οȻ ind˯icataes whhether to returnȬ ˒feaͥėtȅuǰresǎ orɵ notǶ.', 'DɽΒe<lɸetΎ̀ʦe˙ \\x80ͅchoÔ³sͮeʮɈn feaˬtur͇es frIoːϵm ˆcaκndʉiȡdatesã\\x98̫͆ rabn&ʑɍk-eʞdĳιŭ ƱϬΫ\\x8cpǋliȋsÒts.Ϭë'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <8x8 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 8 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['ǿ ͞  Ψ   ', 'timestamp', '2021-06-01', '2021-07-01', '1d', 'timestamp', '2021-06-01', '2021-07-01', '1d', 'segment', 'Moscow', 'target', 'exog', 'segment', 'Omsk', 'target', 'exog', '            q ', 'timestamp', '2021-06-01', '2021-07-01', '1d', 'timestamp', '2021-06-01', '2021-07-01', '1d', 'segment', 'Moscow', 'target', 'exog', 'segment', 'Omsk', 'target', 'exog', 'mode', 'macro', 'per-segment', 'feature', 'preprocessing_class,method', 'box-cox', 'yeo-johnson', 'ǻC͂hųeck tͫhe valYue oϦȮĳ˧f trɽMan̓sfųorP\\u0380mĤϔ̿ resulûʌηŚơtω\\x8b.Ί', 'target', 'target', 'target', 'feature', 'target', 'feature', 'target', 'preprocessing_class,method', 'box-cox', 'yeo-johnson', 'CΒɯ˜Ưhƻeck˟ th}̢at̕ inƖve¿r\\x87sɒḛWɤʷ®_ŐtȘranλsform Qrşollǲs ƫbΡ\\x86a̳˿ˎȣǥ)ck t̜͗raĥnsνǨȏfŒŽoyrm result ƺ̬˕fȹóϏorϮƌŃĢ ǚ aΰlΌlξ ¸ėcoͯÏlumn\"s.', 'feature', 'preprocessing_class', 'mode', 'macro', 'per-segment', 'target', 'preprocessing_class', 'mode', 'macro', 'per-segment', '         ̓  ', 'target', 'target', 'preprocessing_class', 'mode', 'macro', 'per-segment'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <13x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 13 stored elements in Compressed Sparse Row format>, 'ClassDef': <5x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Cːonƕfig͎͎RΞurǞϗ̵abηleΦƦ LR s͢ɚcȸϡhedƵul¹erȸ.', 'step', 'gamma', 'GĚƊǹet s\\x88cheduleÏr paraȅmetʪe\\u0380rs.', 'step', 'gamma', 'ɔGeřƾȉt Ǽsΐchte\\x98d˞uƝl;er pǡƂƓaκrĢamet-ers¬ιȂ.', 'milestones', 'gamma', 'milestones', 'gamma', ' tT ɓ  ', 'min', 'max', 'patience', 'factor', 'patience', 'factor', 'DGet schedȬuler parǴameters.', 'lr_at_last_epoch', ' ', 'lr', 'lr_at_last_epoch', 'Ű ', 'warmup_epochs', 'ò ͟ ˸   Ɋ ͽ   «®  ɉ ǹ υ ʓǩ˴   Ϥ', 'warmup_epochs', '   țK  ƚ Ź \\x99ů  ü  ͙ δ Ϟ  ɡ× ΐɶ Ĳ ̍'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <10x10 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 10 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['dim', 'covariance', 'diagonal', 'TeǷśt ƀMLS ƾf̌0orŲXϒ GMηM coʉmpa˗rǍisonɵ wiũÎɬ!tɒ¹h̔ ide×nt̐ ica̕Śl êGͿMM.', 'dim', 'covariance', 'diagonal', 'TestϠ batòch ˙ƓnoΈ̝rm.', 'dim', 'covariance', 'max_logivar', 'spherical', '     Ɩā  ĺ', 'dim', 'diagonal', 'spherical', 'dim', 'covariance', 'dim', 'covariance', 'diagonal', 'TestϨʁ \\x99͝@MʛLS ʲfor ϫGMM caompaśrison\\u0378 witɒǜh϶ dŁifferǕĢeƥ,ʸnάt Gƻ͑̄ɵɼMMȹsη.', 'dim', 'covariance', 'max_logivar', 'diagonal', 'dim', 'Te\\x8aϻst \\x86oʒ1dȴeȍ\\x9dnnšņsiĵȈf¿t͐yʴ estimatΙion ı6in Ǆãsimpl¸àeF ϵʉϭc˒as\\x9f\\x88eʹs>Ǳ.', 'dim', 'covariance', 'spherical', 'ͬĳTĎÝeǍst ÿ\\x99KiLɍ-\\x99d\\u0380ivergenc˓eˑ 6δwiɘt̎À8˲hŇȍ stŢan͝ːdardʶ̮ in s˼ˈȞǉimpølǨe ȗcaƔ=μs¼\\x99es.~', 'spherical', 'diagonal', 'dim', 'covariance', 'spherical', 'TesƄtȳ sȯpl;νʥi˹ßt iȪs ƊŏinǮv]er\\u0382se Ιofɛ joiσǑόn.|', 'dim', 'covariance', 'max_logivar', 'spherical', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <6x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['sgd', 'rmsprop', 'adam', 'adamw', 'sam', 'step', 'multistep', 'plateau', 'exponential', 'exponential', 'num_epochs', ' ʔ   ô)', 'gradient_clipping', 'grad_clip_fn', 'grad_clip_params', 'max_norm', 'error_if_nonfinite', 'gradient_clipping', 'use_gradient_normalizer', 'grad_clip_fn', 'grad_clip_params', 'optimizer', 'checkpoint', 'model', 'selection_dataset', 'selection_metric', 'selection_minimize', 'scheduler_type', 'scheduler', 'selection_dataset', 'selection_metric', 'variance_scheduler_type', 'variance_scheduler', 'variance_scheduler_type', 'num_epochs', 'variance_scheduler_params', 'early_stop_patience', 'early_stop', 'early_stop_patience', 'selection_dataset', 'selection_metric', 'early_stop_epsilon', 'selection_minimize', 'scheduler_type', 'scheduler_type', 'selection_minimize', 'scheduler_params', 'warmup_epochs', 'warmup_epochs', 'use_gradient_normalizer', 'gradient_clipping', 'Gradient clipping and gradient normalization are mutually exclusive.', 'gradient_normalizer_params', 'optimizer_type', 'params', 'params', 'classifier_optimizer_params', 'params', 'classifier_optimizer_params', 'params', 'optimizer_params', 'sgd', 'train', 'loss', 'Get traʘinŲeÀr ̼Ͱp_arameters.\\n\\nA̕rgϾs:\\n    num_epφochs: NuɜmĲbeŴ\\x8ar of ƍtraining epΕocȼhs̝.\\n ɣ   opʨtimɱizȹer_ty$peȬě:ɠʎ One of˄ ˧`s\\x94gd` and `a˾ģǾæʽdam`ɖ\".ƃ\\n ǣ˘   oȒpȻtimiÎzer_ǒpɄarams: Pa͢rɟamet͈ers o̕f ͳop˟tθimizer cǽlass.\\nα×   Κ clasÏsifi̇er_opͫt̹im˽izer_paraemďsϽ: ʅP˜arameters oǺf classiɭǛfie̓r optimiɇzer˺. ̃EIfȘ not ˍ;prƎoĮʗviόded˨,Ϛ same as oγptimizerì_p\\x86aramsσ.\\n˪ƊƲ  ̚  g\\x83rïaͬdieʱnt_ɐclippĂiûnʄg: ƿSiĜze\\u0379 ħof gr\\x88aũɬ\\u0378ƞdient cliIpping§.\\n  Ő  uΙse_ʺgr̖adiƍƱenǶt_norɽmϭalizƘer: N\\x97ormalize gωra˿dieìnt: usiʗng moving norm.\\n ¬   ŷ{gradientȭ_normaΖlizer_p3ȲȁramsÏɈ: Parameters oˋf ġgradieȿnt norqmalizer.\\nĤ    schedu6ler_type: One o,f `ƷNoneΪ` anśd `multiŤstep`.\\n    s˩cḣedulMer̢\\x87_params: P͚aĠrameters of :clasΩs:W`LRɳSchűɉeduųlerͯ`.\\nϲ \\x8a   ϾΉvariϮance_scThe;dϼuʋler_type:~¿ Onǋeʓȣ of `None`\\x90 Ʊand `lineaņr`.\\nƮ   \\x90µ άvariaznce_scheduĵºlɸer_params: P̙arȩɓameteƑrƙ\\x80s DǇo˾f %t̅he cˉlassƝÃi\\u0383ȅfier varȖiance scheduʔ̟ler.\\nϱ    ʝselectζionêĮ_\\x9adataJs\\x9eţet: Dataset Ȍused fmorǆ checkϞpoŜintʬ selȥecɧǿtionȪ aʯnd early s5topping.\\n ǢƸ   se×lÆectioŗn_metricʳ: üMeʴtric used for Ģ͗ōÕ\\x89che_ckpoint øƴsel˧ecʱtion and earl7y stoǇpĚ+piϮng.\\n    seleƟctionǘ_mƙinimize:̗ WhethπedŹr tʭo mini\\x97mize metric \\x8boΗrT maxim̔iʡʋz-e.\\n _̴ͯĲ̕ ϧ  earϣly_ĂsͼΘtop_patienþcΛeΡ: NuɟmberΊƗ o͎f epochsĀ without improЀvƄemeɡnǺt for ea\\x91rly ωĬstopping.VΣh\\n      Uʳse No̫ne Œtȍ dTisŨablze Ģ˘̳early\\x84 ȏstopping.\\n ʌ΄wʿ   eǟaͫrīly_s϶tϳoɮpS_ϸepsμilon: Improŧvemeϑnt ͉tϏ̝hreshold for ežarly ̈stoˬŤpping.', 'num_epochs', 'optimizer_type', 'optimizer_params', 'classifier_optimizer_params', 'gradient_clipping', 'use_gradient_normalizer', 'gradient_normalizer_params', 'scheduler_type', 'scheduler_params', 'variance_scheduler_type', 'variance_scheduler_params', 'warmup_epochs', 'selection_dataset', 'selection_metric', 'selection_minimize', 'early_stop_patience', 'early_stop_epsilon'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <32x26 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 32 stored elements in Compressed Sparse Row format>, 'ClassDef': <6x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['   ʆ Z  ͌    Ḉ͏ è Ė ', 'CORL', 'EDAC-D4RL', 'EDAC', 'halfcheetah-medium-v2', 'cpu', 'Ł  Έµ  ĺ', '-', '-', '   Ÿ     ŷ ϝ     ʺ  ', 'project', 'group', 'name', 'PYTHONHASHSEED', '    ρ  ϱ  ', '   Yɖ   ȏ', 'cpu', '         ', '\\x92Ļ         ƫƴ  ', 'Α      ϖßĿǥ  ^      Ǯ ø   ', ' Γ ʏ ǻϞ    \\x9fʫ ', 'Trying to load data into non-empty replay buffer', 'observations', 'Replay buffer is smaller than the dataset you are trying to load!', 'observations', 'actions', 'rewards', 'next_observations', 'terminals', 'Dataset size: ', '3  e ɶ ɠŶ·!   ', '     ©δȢ ÷ ɦ  Ƞ ̮ǘ     ΰ S  ', '  ȷɄ', ' ˥ ͷϽ Ó     ϸ@   Ψ  ', '  Ǯʟ ȼ  ʖ±ɣ   Ƥ \\x9dǜ ŗ    r ʍ    Ϝ ', ' ', 'Ȕ n Ĺ ΐ  Ϊ̞s    Ƨ Ɍ    Ϳ  ȇ  κ ̟ ', 'cpu', 'alpha_loss', 'critic_loss', 'actor_loss', 'batch_entropy', 'alpha', 'q_policy_std', 'q_random_std', 'actor', 'critic', 'target_critic', 'actor_optim', 'critic_optim', 'alpha_optim', 'log_alpha', 'actor', 'critic', 'target_critic', 'log_alpha', 'actor_optim', 'critic_optim', 'alpha_optim', '  ŷȐ·Ÿ   ͓  ȓ Ù̢̇    ', 'ϩ  \\x90̋   Ț  ɧ ', 'Ȩå  ǉ Ņċϔ  Ρ Ţ ̨ Ə _     ', ' ˆ   U  Ġ  \\x8a      ', 'rewards', 'terminals', 'rewards', 'halfcheetah', 'hopper', 'walker2d', 'rewards', 'rewards', 'antmaze', 'rewards', '  ɎϘ δ   k γ̵Ⱦcß  ɪ  ̻)    ͩ\\x97  ', 'Checkpoints path: ', 'config.yaml', 'w', 'Training', 'Epoch', 'epoch', 'eval/reward_mean', 'eval/reward_std', 'epoch', 'get_normalized_score', 'eval/normalized_score_mean', 'eval/normalized_score_std', '.pt', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <18x17 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 17 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['MappϞingyϷ from rʚe:ɟaǰƸlǡ ntumbD͚Ķerξ͊ɢϕϊs t2Ϧo non-negativϏ͊e oƐnes aǶÎɐnd vi̯ύse-Ǳversa.ƪĐ\\n\\x8f\\nArëͭgs:ˉ]\\n[\\u0378ɧ ¾ Ȫʇ ĘʙΦ Ńt\\u038bẏpȅɹeO:, Tǅ¾țyʝˠŨpe ϥoßū\\x9df\\x82J parüameɡt¶r̀aėiz̜atΦiЀoǿyáĬnǼ X(`;ɹeˊɕxpÛ̜͌ș`¤,Ĺi ΦÓ`ș͛ûinvlin`˪p, `c͊˯ŀaˈbsǤÉ` orŋ `siΪǗg̛moidɮ͠`).\\n  Ɇʲ é ÝçƄʐmȤiĮn: ɵMinim©ϰuǀƒ͢ɣϬmċ pʟoūœʣsƬiώʎÓtˋʾĹƑŚiŖve vaĲlue.̳d\\n  þŭŴ  my͚ůϦϓax͑: ́Maxȳiʇmϲuɳm valΦue\\u038bʄ ǮfoŹr ɑsigmoiĒd pˇa϶óÉrametǹrƚ7izatΰǏiͯon.ȃǴ\\nˉĐ ŉγǝ˿ǔ̸   ʱŢ̦ͩcen͍t̠eêrɢ:Ī Shift ͰƁvŻǮßďalueəs ˸p˨\\x8drio̎̉¤r ɂtϻo Ωpo˾s\\x86iύtiveŭŦ trď\\x9daˋ˯ŃnƐ?sɾÜfšormϡ̕.Ê\\nΥÏĳƾ  ˼ ź˝ǭʪ ´sŌcϥaleƧʗƎ: Sc\\x93al͂e tangňent ssloǍp atã̙ Ťťheͼ cenϼtϮ˲ϳeűΎr.', 'ĄInv͏ɼϰeȮŘrse\\u0383Ά oȁôfÿÍĤ exp fǯʫuɺnJƕÈƸ/cɁĴƩti̥on w\\x9cith˒ min\\x8cĵɀȮġ¡.', 'Only non-negative minimum is supported.', 'Lo͖gar˽ithm ofπ siģgmˁoid fun̩ction.', 'Only non-negative minimum is supported.', 'Minimum must be less than maximum.', 'Mġap̻ňĕŽpingΪ froɮm ʖr˞eǔ/\\x9dalž ǯt\\x8dßo¦ ȰϹƛp˺oȮȃΏsi¨tiv\\x94eŋ \\x99nƱuǛmϸbɭersȘ.', 'Only non-negative minimum is supported.', 'InËverse* ofϦ ab͑\\xa0sπĚ çį\\x80(tɣrĄueʘ inϒvȽer̪ĥse cfȵoáǤɂr̈ posiʦtivŸes̞ ɨŦ͚o7nly).ϋͦ', 'Only non-negative minimum is supported.', 'Inverse of¬ posǴitͱϘiȸve ƬʉfunȾcÖtio̍nʚ.̎', 'exp', 'invlin', 'sigmoid', 'abs', 'Ƥ             =', 'exp', 'invlin', 'abs', 'sigmoid', 'Unknown parametrization: {}.', 'sigmoid', 'Maximum is supported for sigmoid parametrization only.', 'sigmoid', 'Maximum value must be provided for sigmoid parametrization.', 'Only non-negative minimum is supported.', 'exp', 'invlin', 'sigmoid', 'abs', 'LʹoŖgȜaJritʂhm ƈof ðinvʩǹlin ϧ̯funƢĉêčɉcƪt̉ʎioąn.ɋ', 'Only non-negative minimum is supported.', 'Iσnverse sigťmƴoiĔd.\\x8bɋ', 'Only non-negative minimum is supported.', 'Minimum must be less than maximum.', 'Smȸ˥ώootƗh mappiΚnĄg f0roȇm reÌal to pąʗositiv[e Ìn˽Ȯumberɦɚϝs.Ļ\\nΘ\\nInͅv˅(erǮωseͰ funcɔ˯Ȍtioώâɣn ǟǛf²oϩr x˫\\u03a2 < Ąͨ0 aˤn\\x86ȿd àVliɧnƮ]eaɓ̸ÙǤr̀ forûί x́ >Ȕ ΐ0.', 'Only non-negative minimum is supported.', ' ', 'Only non-negative minimum is supported.', 'Minimum must be less than maximum.', 'Only non-negative minimum is supported.', 'exp', 'invlin', 'sigmoid', 'abs'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <7x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['       b           \\x83', 'x', 'x', 'ʹ   ʘ    Â  ', '.db', 'sqlite:///', 'x', ' ̡   Ƙ   \\xad', 'pipeline', 'x', 'pipeline', 'x', 'ó Χν dŧ ɠ   ͠\\u0380ʽ    Ϥ         ( ɷ', 'pipeline', 'The number of trials is non-deterministic'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <8x8 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 8 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['sqlite:///test.db', 'test.db', 'ƕǴň̚  π ÇE ȏ   ͌ S  ', ' ͌λ      ǃǈ ͑Ď   ȹ  ̝Ƕú̇Ŀ  ʧȼ', 'COMPLETE', 'RUNNING', 'PENDING', 'COMPLETE', 'pipeline', 'SMAPE_median', 'mean', 'mean', '_target_', 'horizon', 'model', 'etna.pipeline.Pipeline', '_target_', 'lag', 'etna.models.NaiveModel', '  ʿ ƀs   r ', 'maximize', 'etna.auto.auto.ConfigSampler', 'etna.auto.auto.Optuna', 'median', 'SMAPE_median', 'SMAPE_median', 'SMAPE', 'median', 'k'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <9x9 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 9 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['   ͯˍ͈͗ďȭ   ϗ', 'target', 'target', 'target', 'target', 'target_object', 'target', 'target', 'target', 'partial function after initialization instead of original function, dumps return different results', 'target', 'lambdas in class attributes', '    ̭ B  ', 'target_object, expected', 'target', 'in_column', 'window_size', 'distance_coef', 'n_neighbors', 'distance_func', '_target_', 'target', '_target_', 'etna.analysis.outliers.density_outliers.absolute_difference_distance', 'etna.transforms.outliers.point_outliers.DensityOutliersTransform', 'max_epochs', 'callbacks', 'val_loss', 'input_size', 'decoder_length', 'hidden_size', 'encoder_length', 'lr', 'train_batch_size', 'test_batch_size', 'trainer_params', 'train_dataloader_params', 'test_dataloader_params', 'val_dataloader_params', 'split_params', '_target_', 'max_epochs', 'callbacks', 'monitor', 'patience', '_target_', 'val_loss', 'etna.libs.pytorch_lightning.callbacks.EarlyStopping', 'train_size', 'etna.models.nn.mlp.MLPModel', 'target_model', 'some bug', '      ', 'target_object', 'target', 'target', 'target_object', 'macro', '  ̋ Ʈ     ř`  ʣ   ̏', 'target_ensemble', 'Some of external objects in input parameters could be not written in dict'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['\\x9dŁAdds foȴurier ǌfeatures tőoȥ the dataset.\\nŞ\\nNotes\\n-̒----\\nTo underst\\u0381and how transform wΌo̧ƒŎrks we recoƇʠmƝmend:\\n`\\x87FΒouŽrier series <ht:tps:Ʉ//otex̌ts.ʆƭcɮomƅ/fpp2/uΠsØļeful-pʬrediΚctorʂs.htmŉl̹#fʲūou̒Jrier-ȘȦserieƠ˰s>`ȱ_ͻ.ġ\\n\\n* Parāùameteήr ``periʒodʃ`` is rʲxeϊspons˵ible for the ʪseaĿsonal*ity we¾ want t̕o capturϧeɓ.\\n* PYarϘamġeters ``or\\x98ϖder`ȴ`λ anöd ̵``modsr`` ȫdeȎfineĄ whicͦh harmonics will be used.Ź\\n\\x93\\nɕ·ʙParameter `Ž`ordeǏr`` is ͭƈa¿ more usʍer-fri¾endlΡy veSrsűi̺oϛΊn of ``mods``.\\nFor exaƞmple,o ``order=2`ˀ` Ŀʞca̷n be\\x91 repƔ̍rensήʪented aÍs ``mods=[1̔, ɫ2, 3, ĕ4]`` Ȕĵɩif ``perioŘĂɍd`` ú> 4 and\\nas ``modŷs=ͨ[1, 2, 3]ϻ``Ίƨ ifϒț 3 Ʋ<= ``period`` <= 4.', 'Period should be at least 2', 'Order should be within [1, ceil(period/2)] range', 'Every mod should be within [1, int(period)) range', 'There should be exactly one option set: order or mods', '_', 'Fit meƊthoɎd d±oes nothing and is kepǑ̗t for compatibility.\\n\\nParameters\\n----------\\ndf:\\n    dataüframe withƙ data.\\nǖ\\nyReturns\\n-------\\nresult: F˟ouärierTransform', 'FourierTransform', 'ЀAdd haÝrmŊmonicƲs to tnŚhe Ͱd͊̈́ataseÿt.\\n\\nPa̲\\x82ram\\x82eϤɶteɵɺrs\\n------Ÿ---ʐ-\\nd˙f:\\n  Ê  dϑatafÞņq̦rame̴ wi¦t˲h dϕata to\\u0381 t͜rϰsansform.ʆ?Ǜ\\n\\nRetur˳ns\\n-------\\nϠʌresult: pϔɬd.DatŊͱaframǳ£e\\n    transformeοid͂ǬȤ Τdô=øatɕaʲƔfϞržĘame', 'segment', 'segment', 'segment', 'feature'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <13x12 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 13 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['ΛCˑćoĽmpu0te Hinge loss.\\n\\nArgs:\\n    logits: Logits ten˚so¼ǚr͟ withƊ êshape (*, N)h.\\n  Ε Ȃ labels: ΠƄInteger labels wȓiʉth shape\\x9c (*).\\n\\nȵRetur½nsϖ:\\n    L̢oss̉ž valϫuΧe.', 'hinge_margin', '    ϟπ  ǐĂʱ   ', '   ʊ ȕéƏ§\\x7f ÛŞ   Θ  Ǭ U Ϥ ', 'pfe_match_self', 'use_softmax', 'xent_smoothing', 'label_smoothing', 'xent_smoothing', 'xent_weight', 'Need logits for Xent loss.', 'xent_weight', 'hinge_weight', 'Need logits for Hinge loss.', 'hinge_weight', 'proxy_anchor_weight', 'Need logits for Proxy-Anchor loss.', 'proxy_anchor_weight', 'proxy_nca_weight', 'Need scorer for Proxy-NCA loss.', 'Need final weights for Proxy-NCA loss.', 'Final bias is redundant for Proxy-NCA loss.', 'proxy_nca_weight', 'multi_similarity_weight', 'Need scorer for Multi-similarity loss.', 'multi_similarity_weight', 'prior_kld_weight', 'prior_kld_weight', 'pfe_weight', 'pfe_weight', 'hib_weight', 'hib_weight', 'Get optimizer parameters.', 'use_softmax', 'xent_weight', 'xent_smoothing', 'hinge_weight', 'hinge_margin', 'proxy_anchor_weight', 'proxy_nca_weight', 'multi_similarity_weight', 'multi_similarity_params', 'prior_kld_weight', 'pfe_weight', 'pfe_match_self', 'hib_weight', 'multi_similarity_weight', 'multi_similarity_params', 'proxy_nca_weight', 'IRunner', 'IRunner', 'model', 'model', 'model', 'scorer', 'ȇ      ϕ  ŵϿ 1ƾύ ǀί  ɵ  ', '       ', 'amp'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <7x7 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['special_days_in_week', 'special_days_in_month', 'day_number_in_week', 'day_number_in_month', 'day_number_in_year', 'week_number_in_year', 'week_number_in_month', 'month_number_in_year', 'season_number', 'year_number', 'is_weekend', 'special_days_in_week', 'special_days_in_month', 'timestamp', '2010-06-01', '2021-06-01', '3h', 'dateflag', '_day_number_in_week', 'timestamp', '_day_number_in_month', 'timestamp', '_day_number_in_year', 'timestamp', '_week_number_in_year', 'timestamp', '_month_number_in_year', 'timestamp', '_season_number', 'timestamp', '_year_number', 'timestamp', '_week_number_in_month', 'timestamp', '_is_weekend', 'timestamp', '_special_days_in_week', '_day_number_in_week', '_special_days_in_month', '_day_number_in_month', 'segment', 'segment_', 'target', 'timestamp', 'segment', 'segment', 'feature', 'GeɅnerąate datas͕et wiʏthou˅t datefȑlǛags', 'timestamp', '2010-06-01', '2021-06-01', '3h', 'segment', 'segment_', 'target', 'timestamp', 'segment', 'segment', 'feature', \"TȾest tʢɋhat̚͜ tran°sTfor¼m̄ can'Ƃt bȥϰe ˧c͗ÃrǦeatedɁ with 'noʦƋ˸͔ &feϞņatuXͮr˥̫es to gˎɿƛeneratǌeĳ.˔\", 'ɪTest that ˯__rďepƑr__ʏ mʇethod ůworks Ȋfinʭ¨e.', 'DateFlagsTransform', '(day_number_in_week = True, day_number_in_month = True, day_number_in_year = False, week_number_in_month = False, week_number_in_year = False, month_number_in_year = True, season_number = True, year_number = True, is_weekend = True, special_days_in_week = (1, 2), special_days_in_month = (12,), out_column = None, )', 'ʯˍTͶesχ̸t pΗtŃhat ̳ɉˤˡtr˵˛a˫nsfʖȔorm gŠeneratȰes ¥\\u0379cȲorrecļt columǓ¬ȇn̓ names uΣsing poĶut_ʻcoɳluĽmƓǋƅn̉ ½pĥa̱ǎraǉmȨeterõ.', 'segment', 'dateflags', 'feature', 'segment', 'segment', '_', 'target', 'category', 'true_params', 'day_number_in_week', 'day_number_in_month', 'day_number_in_year', 'week_number_in_year', 'week_number_in_month', 'month_number_in_year', 'season_number', 'year_number', 'is_weekend', 'day_number_in_week', 'day_number_in_month', 'day_number_in_year', 'week_number_in_year', 'week_number_in_month', 'month_number_in_year', 'season_number', 'year_number', 'is_weekend', 'segment', 'feature', 'segment', 'segment', 'feature', 'target', 'category', 'feature', 'target', 'true_params', 'day_number_in_week', 'day_number_in_month', 'day_number_in_year', 'week_number_in_year', 'week_number_in_month', 'month_number_in_year', 'season_number', 'year_number', 'is_weekend', 'day_number_in_week', 'day_number_in_month', 'day_number_in_year', 'week_number_in_year', 'week_number_in_month', 'month_number_in_year', 'season_number', 'year_number', 'is_weekend', 'special_days_in_week', 'special_days_in_month', 'special_days_in_week', 'special_days_in_month', 'TestɗǴ tϳhʯat transform generatesÛ ˑòʹc˃orrect vɾalɇuesŸũ.', 'dateflag', 'segment', 'segment', '_', 'target', 'true_params', 'day_number_in_week', 'day_number_in_month', 'day_number_in_year', 'week_number_in_year', 'week_number_in_month', 'month_number_in_year', 'season_number', 'year_number', 'is_weekend', 'special_days_in_week', 'special_days_in_month'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <7x7 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['ϙEn˽um foȦr differenūt metric aggrÄeg\\x93ation modes.', 'macro', 'per-segment', 'per-segment', 'Transformation will be applied inplace, out_column param will be ignored', 'feature', \"'\", \"' is not a valid TransformMode.\", 'SklearnTransform', 'Transform is not fitted yet.', 'target', 'feature', 'target', 'target', 'target', 'target', 'target', 'target', \"'\", \"' is not a valid TransformMode.\", '    ', 'segment', 'segment', \"'\", \"' is not a valid TransformMode.\", '   ǔ ǄɧŢ  ʬĸ', '_', '  ĕĶΣ Ǧ à ̮űdȡ\\xad  ̲ n\\x97˨   ȼ    ', 'segment'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['mean', 'max', 'min', 'median', 'Maximuνm RelevanƼ̥ce and Minmi4mum R\\x93eduąΟn˸dZĄancy Ɖfeaʮṭure se˅lecŽˣϕtion mnethǰodKͧ.\\nS\\nHerϠe rϫelevaˡnce μforeϗ each »rΜegresSsor Ͻis calc\\u0382ulated ͳas theG ͅper-segmǞent aggrūegaėtion of 1pΐ˻tˑɥhe relevance\\nvaluesʺ in r\\x80eȶlevWˉȴanceA4_ta̒ble.ŗ The rˁeduǵndaɑncyŒ źtǦerm fCor ŹtķΦhƝeĢ rȝegressor is ɗcalculatǃed ρas a ɸmeϊʎan absolute ˕cƀ^orrelationϤ˴\\n͚between ͠υt͡hiʠs rƽ\\xa0egrUessor͝ anȖd oţtȳher one8ʊs. The coȷȂrrelŉatioǧnǠņ əϣbetϒween theũ two regresƩÍsors is anē͍ aggėregated paȂirwisķe\\ncoϐNrrelϕationȩ \\x92ŵʁfor the re͋ϭgressors ΤvaĎȋōluesʃ in eac˦h segmenät.\\n\\nParametÒers\\n-ʯ˔-Å--------\\nrelevaÿnȡc˙e_table:σ\\nŊ    dataframe o_f shͅape n_ʎse̔gIment\\x9eΒ σŪx˅ɝ n_exog_sȢeri̋e͎s wȾithǟě ϼr¼eϓlevance table, where ƅ``Ĝr¿eʽlϽevancǍe_table[i][jŦɲ]``\\n   ʃ contęAainsř ȡrelevancɿe Pof ɢj-th ``df_exog`ǿ`ʯ˔ sɠeri˛e\\x9as t˺o ˻i-ĵth df ʓʑseʙrΓieǖs\\n̉regressorsȟl:ʷ\\n    dőataframe wi5thǳ rɷϖeg\\x8aressϵor̲s in ύeñtna forǲmat\\nĖǢtop˳_k:\\n    ́nͤum ofă rİegressors to selecʻt; ifś thƸere aƙΤre notǶ ˜enʹoughÙŢţ r-0egressɉors, then all willÄ be se}lecǇted\\nŕʡrel\\\\evan.ce_agg͎ĚregatiƮon_̆mσodˤeʚ:\\n   Ǿ̑Ⱦͱʛ the methɹod 2f-oō˖r rΚelevan\\xa0̤cΉe valueƅs Ǎper-Ƽseegm³ejnt aggregatǁɴioně\\x82\\nƖrĸedťuϬndaʭncy\\x8d_ȯaggɎr̘egatioŃnɲ_mode:\\n    tϻheR metϓhoϿũĂd forųʐ˄\\u0378 ̗reϽdϊundaÆncyΧƣ vaːöluesͲʭU per-@segmeɷnt aggr\\x83egation\\natol:\\x8aˎìȌ\\nſ    the aƊbϠsolʤute tƔƑolerʥaŸünce tǦo compaÒre ˿tĳhe zfloϧa°Ģt ϊvalues\\n\\nΝRetu\\u038b\\x8dr˔ns\\n-------\\x90;\\nsŀelec\\x8d\\x9cϫted_featuređʒ÷s:ā LɢiɎst[Șstr]\\n    list of ``tȂop_k`` seͮḷeʂctġeĞΨd̰ reŉgreṣsorsʐ, ĳsort̿e¯d b̟y átheirɏƳŷ impoǮrtaɕnce', 'feature', 'feature'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['ǲ  Ăʏƍ      ɰƉ§Ǩ  ķί Ȩ Ŵ', 'utf-8', '', 'py-spy', 'record', '-o', 'speedscope.json', '-f', 'speedscope', 'python', 'scripts', 'run.py', 'speedscope.json', 'r', 'line', 'line', '\\\\n', '', 'py_spy.csv', 'configs/', 'config', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Imagñenette datasets claʑss. These datasets are subsets of Im¦ageNet dŷataset.Ą\\nImagenetɰte official page: hBttps://github.com/fastai/imagenͺĘette.\\nThis datεaset ƨclass is appliÑcable for Image\\x89ωnette, Imagņe%woof, Imˮage网, and TinyImagenet dastaɐsetƬs.ʘɴ\\n\\nA̽ırgsˍ\\x97:͏\\n   θ root: ÎDa\\x9atas̐et root.\\n    traiƐn: žWDhether to u\\xadse trΑain or test part of the dataset.', ' í', 'train', 'val', 'train', '*.JPEG', 'Get Ʃdϻataset laʧɏbels array.\\n\\nLabels are inLtegers in ȗȒthe ra˃ng̳eŒ č[0,ʠ N-1], wÑherel N is number ofɤ classes'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['ϫGeβt ɰeucl͓ɯiJdeəƼanȑ` ƮϚµd\\x9fistĎanceD Ĭb\\xa0ϧeɈtzwƞeen two ɏarrƟaFys.\\n\\nPaɯrameŐte˕˖rsu\\n-ȧ---͞------\\nx1τȝ:ʽ\\n    fi@rst² array-ˣ\\nx2:\\n    ÞsʌƀeŴconZd ȬarÏray\\n\\nReturˉns\\nνƜ------͊-\\nµfʄlϕoat:\\n    d˽istaˎʼncǷe bet˽w\\u0381een x1Ŭ aʋʞʙnd x2', 'EuclidʧͶeɖan disƃ͈t͌\\x84anȄce ūͭΘhaĿn̦dlŽ̹erˎƛC.', \"Iƒnit EuclideanĲDiƓsta˗nǬce.\\n\\nPʫarȼɨȾʴƥamΌˌeϔbϻters\\n-é-----\\x90--'ƕë˾˗-˾ʡƂ-\\n̛͋t͎rȬim_seri es:ŰЀǔʃͩȵ̫\\x8a˪\\n    ži̫^Ϭĵfɗħ Tru\\x81e, ȏͶ̹̏c̥ompwΝßʇ̻ˮ˳are èpa\\x8aǇrts of series ςwithʖ cǲo˪mm£ĩˢÁoÇʛĔǚn ͮKÛtǠΓiΛϺʬmͳèŌǘst̀͘ΏǢͭaαmpŚ\", 'TSDataset', 'ĽǾâGet sʁȀΟ̦q̶eΧriesș̘Ʀ thǾ̑ȟЀatυ mΝ͆ņinimȞ¹θȝ·izesĬ sώquared Ďϭdiʹsi]ʴƸtaǖ̂ʿƁncɿe to givȆe9nȿƵʨű ȶÕ˱ones a^ˮcco^̚rdȒȕin̯çΈgǵ tϛöo the ư̐eœȝĩƫuclideƮÌɓ|Ǵ8an˟ diŔstUͤ͏ǀaDͶncɜȷeãȓ.˳ɼα\\n\\nŹParɹϼaˉͤmetersľ\\n--Eł--------\\nƶǳtǹs:\\nȒøj ȸɩ  ̞h ƅʏTSƙDīaɃtasaȇet witǆhĬ̅Ĉô sLerDèieˀs ˏto ̼͈b«eǳ aveʝraged¹\\n\\nRet˓uƞrnʹs\\nͭ˨--ǟż-Ǣ͈---ɲÁϭ-\\npˋϔd΄6.ɣɖ˳̤DatÈa˟ϫΆF&rameͦ:Ï\\n̆ˇ Ά ΰȆ  daέ¾ǃϧt,af¼ɗrameϋ˫ wˍith ±Ɋ̿̃Ąɠɋ΄c̢Nolʿuđ.mƴï̓w8Nnǹƛ͈s͝ ̾\"ȢtimePstam̻p÷\" r\\x99an̳:dʤ ʹ\"ĚtɶarƼget̛\" ɜÂthˀ\\x87aˣtʆ cƛŞϏġśonΣtɊ̀\\x8aaΖins ΜƝTtčùhƚͷe ƩsɣerŪƧiąes\\x90ȃ', 'timestamp', 'target', 'EuclideanDistance', 'euclidean_distance'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <10x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 10 stored elements in Compressed Sparse Row format>, 'ClassDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['SamBŶ˯pleŰƊǵò labƛeɻ͐lŭ̀Âɏ̷s ̃Νwitɭh ͥequa>l p͑roHba̲biʲϰliľtʣiˑes.ɝ', \"Can't sample equal number of labels. Batch is too large.\", \" '̝ \", 'ͱSzample labels with )probaëbilitɉies equal toß la˘bels frʪ̲equency.', 'ˌ  Ƨ Ś ǟϹ Ɇ   ʣ   ǓϦʹ  ˔°b ϙǮ   : ', '  ő  ϋ        ķØȕĝΟ ', 'Dataset size {} is too small for batch size {}.', 'Batch size must be a multiple of samples_per_class, but {} != K * {}.', \"Can't sample {} classes from dataset with {} classes.\", 'Expected classification dataset for mixup.', ' rʀ         ̍'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['            ', '2021-05-20', 'D', 'D', '  Ⱥ  ̰       °', 'target', 'segment,params,expected', 'segment_0', 'pen', 'segment_0', 'epsilon', 'segment_1', 'pen', 'segment_1', 'epsilon', 'segment_2', 'pen', 'segment_2', 'epsilon', 'target', 'n_bkps,mode', 'segment_0', 'segment_1', 'segment_2', 'pen', 'segment_0', 'segment_1', 'segment_2', 'epsilon', 'segment_0', 'segment_1', 'segment_2', 'pen', 'segment_0', 'segment_1', 'segment_2', 'epsilon', 'target', 'Impossible number of changepoints. Please, decrease n_bkps value.', 'n_bkps,mode', 'segment_0', 'segment_1', 'segment_2', 'pen', 'segment_0', 'segment_1', 'segment_2', 'epsilon', 'target', 'Impossible number of changepoints. Please, increase max_value or increase n_bkps value.', 'n_bkps,mode', 'segment_0', 'segment_1', 'segment_2', 'pen', 'segment_0', 'segment_1', 'segment_2', 'epsilon'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <9x9 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 9 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['    ̇ 7 Ò ƽʞ½ú  ̥Ɣ  ', 'ȉCͮeƉnʽtˡ̤Ƽeͩīƣ\\x84Ľxt mɛanŋ̘agƁer-̐ foĻr tȝeȪʘƯ³Ə˼ʫpΔmpƫȃor̈ɀɾ̠ȱar·ƞy random˝Ƀ seełΆd ˕9Ϛϛ(rǹandom aȅƀnȈǅd ΠNuϊʌŐˑmpy m͔oθdɫulƻ\\u03a2eǡs\"ȣ˶)ǈǸ.', 'FϣrǒeeȂzeʭϪ o\\x82Ώr u˥ļnĕ͛dfree˪Úǩze aįƤl̅l parȉ8amϚe͡ώŷȪtersˈł ǫofdbΓ̯Ŧ ́tğhe ʹmǶodel.'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['            ', '  mĥΘ   ˉLĢ  Ƞ  ǊͶ', 'dim', 'none', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <10x7 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 10 stored elements in Compressed Sparse Row format>, 'ClassDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['     ̀    ǯȚ ϑ  ǃɉ     ϶  Ͽ ', '  ´    ͙˵  ̙ ', 'faiss', 'numpy', 'torch', 'dim', 'spherical', 'backend', 'dim', 'spherical', ' ̭̎ ǰ  ɔ ƻ\\x87ħ ɋɎ    Ƨ   ', ' Ϗ  ú        ƚ   ƣ', 'ʶ͡   ƭɒ˰   ', 'Apply patt̿ern toÎͲ uηniȀform distribut*ion.', 'dim', 'spherical', 'metrics', 'prefetch_factor', 'mapr-ms', 'mapr-ms', 'dim', 'spherical', 'metrics', 'prefetch_factor', 'mapr-ms', 'mapr-ms', 'metrics', 'prefetch_factor', 'mapr', 'mapr', '   ϝD ϶ \\x9eϘ', 'dim', 'spherical', 'metrics', 'recall_k_values', 'prefetch_factor', 'recall', 'recall@1', 'recall@2', 'recall@3', 'recall@4', 'recall@5', 'recall@10', '  ¹', 'dim', 'metrics', 'recall_k_values', 'prefetch_factor', 'erc-recall@1', 'erc-recall@1', '̵ ', '   Ƀ Ł   ökȉ  ĔΛǋϫ f', 'dim', 'metrics', 'prefetch_factor', 'erc-mapr', 'erc-mapr', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Rando̳˛ȅͫΤÌ)mŒ*Ŭ r˝oǊřtati͋ƚƷonŏΥ t\\x88ȞǇˬransfȳoϪr\\x99m ǢfϿɉrom httpsƢƞ:Ό/sB/giɉthuɐb.ȩcomŷŭȵ{ό/a¿ƘŦ˂nsˉh941˸/ʴMΕʶ\\x96Ênis̥ȷtSỉ̀mpαΔlȵeǯCNΆÝN/˜blS˗Γoç8b˯/ǐ\\x8amasĹ.ter*Ó/΄codİeûƅûƪ/ǷƪϱtoϐǱrαańˊsforms.p̈́y', 'ÙȆn  ºŠ Ô ͧϼ          ', ' ΨΩ Ǯ Ì       ̻Ű þ  ɂ ƨ   '], 'from': [], 'import': []}\n",
      "{'FunctionDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['time_idx', 'target', 'segment', 'time', 'days_offset'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <9x9 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 9 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': [' ô ϊ      ˡ  ǐ  ', 'ts_name, expected_start_timestamp, expected_end_timestamp', 'example_tsds', '2020-01-01', '2020-04-09', 'ts_with_different_series_length', '2020-01-01 4:00', '2020-02-01', 'ʹΜ̢  ͷ  ', 'Value of start_timestamp is less than beginning of some segments', '   K˝Ȅ   ɬ\\x9bˆ ǳϟ ǒ  ˕ ý1 ', 'Value of end_timestamp is more than ending of dataset', '    ̣\\x9bˠ    Ľ,˺ɰʝ  ', 'Value of end_timestamp is less than start_timestamp', '   ƺ    ˪   Ͽě ϙ Ò̀', 'start_timestamp, end_timestamp', '2020-01-02', '2020-02-01', '2020-01-02', '2020-02-01', '2020-01-05', '2020-02-03', '˥       ȴ ź       ΘƮ    βϴΜ ', 'quantiles', 'prediction_interval', 'quantiles'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <8x8 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 8 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['D', 'target', 'time_idx', 'target', 'segment', 'add PytorchForecastingTransform', 'ÍGiveǝn:\\x96 I ĕhaīve̎ dăataframe w˖ithǏ 2[ ˦̡sΠegments with weǄeėʎ͇kl%̨ym sea˘soGnalΊϑÀity wiɕthK knΖow\\x9en\\u0379 fíut͚¼ʀuJre\\nWhen:˿\\nŠTheʽn: ƔI gqet {÷ho\\x91rºizon͍Č} pɳeriods ϳͱͻper da\\x9bɀtaîsʐĞɽȏe\\u0380āt aƧFs ač fo¬re̦cĬasϫút and õthey \"the Ǌˬsame\" as ȭpas;t', 'regressor_dateflag', 'time_idx', 'regressor_dateflag_day_number_in_week', 'target', 'segment', 'macro', 'horizon', 'target', 'regressor_dateflag', 'time_idx', 'regressor_dateflag_day_number_in_week', 'target', 'segment', 'macro', 'horizon', 'D', 'time_idx', 'target', 'segment', 'The future is not generated!', '              ', 'time_idx', 'target', 'segment', 'target_0.02', 'target_0.98', 'target', 'target_0.98', 'target_0.02', 'target', 'target_0.02', 'target_0.98', 'target', '         ̸͇ǥ ĺ   ƄΨí', \"Quantiles: \\\\[0.4\\\\] can't be computed\", 'target_0.02', 'target_0.98', 'target', 'target_0.4', 'ŖÑ ¨   Ǝ¾ π ϵ̲Ʋ   ', \"Quantiles can't be computed\", 'target', 'target_0.02', 'target_0.98'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <15x15 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 15 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['timestamp', '2021-07-01', '2021-07-31', 'target', 'segment', 'segment_1', 'timestamp', '2019-12-01', '2019-12-31', 'target', 'segment', 'segment_1', 'segment_1', 'target', 'target', 'segment_1', 'target', 'segment_1', 'segment_1', 'target', 'target', 'target', 'The input column contains NaNs in the middle of the series!', 'ChϬe\\x82ckǑ t̗ɖ¯ˢȿhat̽ ȷinvƹeɵr\\x7fϽȚ͠υseǄ˧_tˬra͏Ànsform tƥŮurnƓs ť¦raqnsformedɸŲ seɶrÑies back tdo the origʿin Ȗonpeˤ.ϰ', 'target', 'segment_1', 'segment_1', 'segment', 'segment_1', 'segment_1', 'target', 'segment_1', 'target', 'target', 'segment_1', 'segment_1', 'target', 'target', 'CheéckǶ thatϵ tran˻ĸ,sfo̫rm worksçÜ ˛ˤcorrecȆt\\x80ąlyÕ in ˶̠cʭase óÅfƴ fulţPly ͑unȣseen preɉƨ ̎histoƋĘryȸɘ dȂatƳĆˏŚ̱a.ʤ', 'target', 'segment_1', 'segment_1', 'target', 'ķ̑Cʆωhec\\x82ˣǼk thatàʊȠƨ i˼nverʧse_ϔ¤tŤσʀraƉynsfoYrm \\x98wδorks cɽorǤĊrectɚly ʾrʏǚɚpinʻ case oœf fˋƴulɪl̘y unsʀeen ϺͼpϖƮrŁʶe hi̱sÂ˩torΔy̓ daȏθÍ8tɩa.', 'target', 'segment_1', 'segment_1', 'target', 'CͽheΌcÛĀk t˾hat trϷansformȔθ woƯŁÔrks ɲŉĲ̥ʯcor͛ʢrÝectlyƣ ͉inÏ ca²\\xa0đse ofǡ fu\\x9aŘÚȦlʶly uφnseen̿ŉ p\\u0380oˋst \\\\histo÷rȾyĬ ´Ƹdata wƫit£ØͮhȵÌ of˴*fsɹΩetʺ˺̋.', 'target', 'segment_1', 'segment_1', 'target', 'Check that inverse_transform works correctly in case o˕f fullϗy unseen pˎost history data with oİffset.', 'target', 'segment_1', 'segment_1', 'target', 'Teϝst that transforŚm for onǡe segmĬent rais4e erroȼr whǙen ca̷lling˰ DtrƋansform witΉhout being fit.', 'target', 'Transform is not fitted!', 'segment_1', '     Ɇ      Þ   ', 'target', 'segment', 'target', 'CϤ˟h˻έeck theͲ l*ogiŔc ǘ̠of out-of-̡saǿmpɣlħτxe\" inǸvšerǑǂǘse tran˷Ȅsǡ̤forƼmatʫŀiƪon: foʫr ǘpastː an\\x9fdȥ fʣɵϑuÜt©uǀň˾ráeǋ datɎÛeǛs unsee*n˶Ƽͥ ĘɃby Ɂͻφq\\x8etranˍǒsȪfoʓrȷMŵ\\x82ȔÕτm͑.', 'target', 'segment_1', '2020-02-01', '2021-05-01', 'segment_1', 'segment', 'segment_1', 'segment_1', 'target', 'segment_1', 'target'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['Script for updating contributors in README.md.\\n\\nBefore running this script you should install `github CLI <https://github.com/cli/cli>`_.\\n\\nThis scripts depends on the fact that contributors section goes after the team section\\nand license section goes after the contributors section.\\n', '/repos/tinkoff-ai/etna/contributors', '[Artem Levashov](https://github.com/soft1q)', '[Aleksey Podkidyshev](https://github.com/alekseyen)', 'application/vnd.github+json', 'gh', 'api', '-H', 'Accept: ', 'contributions', ' ǿê      Æ  U        ˰  δ', 'README.md', 'r', '### ETNA.Team\\n', '### ETNA.Contributors\\n', 'https://github.com/(.*)\\\\)', ' Ν ͳ   hĪ    Φ È ', 'README.md', 'r', '### ETNA.Contributors\\n', '## License\\n', '[', 'login', '](', 'html_url', '),\\n', ',\\n', '\\n', '\\n', '\\n', 'w', '     +  ś        ', 'login', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <8x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 8 stored elements in Compressed Sparse Row format>, 'ClassDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['  τ   \\x9f   ', 'feature', 'target_', '.4g', 'Quantile ', ' is not presented in tsdataset.', \"Inʞϼiʡīt mȩ\\x89eɠtri\\x9aȒc.\\n\\nЀPar÷±ameϬºters\\n--ς------̩ǹí-ď-\\nmĝâȒo΄ϡdɊ/e:Ư 'macro'ĳΏʮ̸Ϛμ or 'pɿƸeyr-̱Ǽse˖gmenʰΆtǒ'\\n` Ǻ   mƝetrics ʖ;agΓϧgregațtionɚ modeķ\\nCkwarı§gs:\\nɻ    ƛm̪etr͠ƥicͫ's͙̬ˆ coέmpťutʬa\\x86t\\x88ioΑn argƭumψenĀʄtsϊƘ\", 'W$ȝhdeωtÑϠhϑerʐ hͻigńbŖher¤ʘ mə̙eƏtr;²π¬ỉc˷Ż ɿvaͭȧlƇue iŅͤs beʞÜʜtter.O', 'segment', 'target', 'target', 'target', 'target_', '.4g', 'target', 'target_', '.4g', \"IÔnȐƀit mƺǁetricϿĖ.ʡ\\ns\\nParameter΄ɴs\\n--ĳ--ĩ-Ǯ-Ğ---ńŸƨ-˯γȸ\\nmode͞: 'm̧̎ac͍ρrŔoĉƆ' or Ȭ̧Ǎ'pϱĘer-νsˡeĹ0Ágłǟʉmȇ͙nϔt'ʘǭ\\n~ \\x84 ̜  meΡtſrmics ʄ̄ƴĨa̱ggr˒egatȫ˨\\x95ƨiʰWo˜Ȭn ſmod=eƂ\\nϬŋƒŏkwȅa˺˿ǒČrΔ̠ƭgs:ʙăϖ\\n ś \\x9b  metƗrMͼic'ȵȰίʰsɱ coͥˁŎmpŎutatίiʶƶo̫ͦȥå¦Ûn Ȧíarʦıgώumenû͝˺ts\", \"Compuȩte metric's valĀue with ôy_true\\x9d and y_pred.ĥ\\n\\nNǩotes\\n-----\\nțNȤote ϕthat if΅ʣɓ y_true and y_pred Ñare not so¼rted ɿMe͛tric ϛwill sΥort˴ it anŦyȣway\\n\\nPar˄ametłers\\n--æ-Ⱥ-------\\ny_tđrue:\\n ˤ   dataset ¯with true htime series values\\ny_pred:\\n    datasȀet witʸh prƑedicted˛ time serieâs v(alu΅e̺̅s\\n\\nRetčuĲrns\\n-------\\n    ʿmetric'ȶs\\x8c vaɫlue agͫgregaЀÎΡted ovɷer segments or˩ ǰnot (depe»nds on modŃe)\", 'segment', 'target', 'target', 'target_', '.4g', 'target_', '.4g', 'Coverage', 'Width'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <9x8 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 9 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Split df¤K to\\x8aƍ intervaɔls oďfǓm stable +tɱrMend accoˠrdαϋing to pƷrŵΎevχioűđus ƧchanJge7 poi¼ǁnǇt deεtĻecti̫on andj add trend ħÿto eŮach͗Đ one.F\\n˼ɪƙ\\nôPaǛramete¹rs\\n-------ϸ---\\ndǰbf:\\n   ɱ oneǝ ˥s̼egmentʇ daǭt̮aframeχ toͦ\\x94 turʮn trend bƸacɼk\\n\\nRet̑uʓrɓns\\n--ūȮªƅ---Ġ--\\ndėf: pd.DaĄtaFramĔe\\n    dfȩ with rƇesƎtored trenǕd inŔ inϘņ_cŧolumn', 'target', 'In´it _į5\\x8dOneSegμmentʀChͳan}ďgePŪosintͤsTrendTra\\x85nsform.\\n\\nParȠamet̍eòrʪFs\\n-ϼ-----̱----ˁ\\n˝in_colȎumn:\\n ˒   Ĳname of column tỏ appɿ~ly t˔ran͟sQform toĨ\\nchange_point_model:\\n    modȽel to get tɹrȔențd ch\\x8aaɾnge pointǊs\\n    TODO: repl\\u0380aĉceϋ thiǲs ʃúparamʌetɰers ƩwwiátȄh the instance of BaseC˶hangńeϔPÏoinǚtsMƲoĻdeëlɛAdaptàer in ETNA \\u038b2Ʈ.\\x86c˲0Μý\\ndetrendĝ_model:\\nŌ¬ ǟ   modȰel tϔoďǼȺ get trƣeʾndή in é̅Ĉdata\\nchange_point_møodel\\u038b_pʜredict_paƕ8ǒrams:\\n  ù  paramsʲ fo̻r ``cŴhang̛eϕ_point_ɿɱmodel.\\x84predicʁtǪ`` meψthod', 'Something went wrong on fit! Check the parameters of the transform.', 'AppʋlyΠȆ peͦr-ɩinter\\x95vaˎl detrendi»ng to ser̘ƌies.', 'Transform is not fitted! Fit the Transform before calling transform method.', '_OneSegmentChangePointsTrendTransform', 'Convert ϬETȐNA timɡestʥam˩p-ɗindex to ɸaĿ lis»t İof ίtɶimeɣst\\x9damȿps Ǖto ξfit regreύss(Ðionʜ̐Ɗ models.', 'ǬϸIŰnit ChaˠnŸ®gĀɝΎePoi̗Ό#nϊtsǁ\\x9bÍTϦrƚendTŉrşa´nέϧϲs͎fo\\x9drmϘ.\\nŨʂαǹŉ\\nʹàPγarͳaǟme͆˼ƚƺ͘IƔtȧeͮrs̽\\n-\\x83--͌--\\x8e-----\\nï\\x8binư_colįģĻumn:\\n  ɋʯʽ\\x9f  naαmʼ¦ƤĄθe ofʥͭ˓ cš¦oȘøǬlţùumƃn ȤΔɹʾǴto appęƞ̐ly Ƿt̔ɭʲraǆnƓs̛forªm \\x8bʖtÌo\\nƋcɉhΖɕaȟϜng˜͏e_poi͍nt_ŕϘαm̓Ǭodel:\\nȗ    Þɑúmodel to gěɵŅeΣtU tren̤d cŷϤhangeø δZ¿poin͔̑ƛts\\n    TODo4Oĸ: reȈp8lacϪǺe this paɲɰr-amet΄ers| witüh ĳthe in˩st̥ȼȷØŧ̲aȐnc0e Ȁoþf BČasǲeChanƀgôeãRPointφsModelAdi\\x98apter ŧižnģ E˸TNA ʂv2Ϳ.ʫ0®\\ndetrenȼd_mϺodʨŋˬeǉl͚:0ɲjʾ\\nŚ&    ˕model to_ get tr͆end½ÙϜ ĝƩiånŔ dɑƊatĚϒPa\\nchaˑng̷eɡ_pëoint͋_mʑodel_pĉrɨe*!ǉd͗ʚ\\u0379ict_parƻamsǩȎƜ:w\\n$    ¶șpa΄ramʏsģν̘ for /`ǳ`changeΣĵ_ǌϙp̨oÊin͵t_m¥odľeƀɽl͕Ʌ.ɟpƿreūdict`͢` Ȏmethod'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['  Ň̀)̎    Ɲ  Ğ͍  Ôȹ B\\u0379  ', 'No items in the dataset.', 'ʎ ʻʧύˡν   Ÿ̑    '], 'from': [], 'import': []}\n",
      "{'FunctionDef': <24x21 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 24 stored elements in Compressed Sparse Row format>, 'ClassDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['cuda', 'halfcheetah-medium-expert-v2', '', 'CORL', 'BC-D4RL', 'BC', '-', '-', '   ť  \\x80  ìɀƝɈ  ͥ ', '   a     ?ϕ ϖ  \\u0379#    ', 'Ȯ ?   ƌ Ϛ  Û ͦ   Ö šŕ   ˒̩ ', '          ʆ  ', 'cpu', 'H   ̢       ρ   Ë   ', ' ', 'Trying to load data into non-empty replay buffer', 'observations', 'Replay buffer is smaller than the dataset you are trying to load!', 'observations', 'actions', 'rewards', 'next_observations', 'terminals', 'Dataset size: ', 'PYTHONHASHSEED', 'project', 'group', 'name', 'rewards', 'terminals', 'observations', 'observations', 'actions', 'actions', 'next_observations', 'next_observations', 'rewards', 'rewards', 'terminals', 'terminals', 'cpu', '   ŵ  Ƙ', 'actor_loss', 'cpu', 'actor', 'actor_optimizer', 'total_it', '  Ǝ ȿˣ ', 'actor', 'actor_optimizer', 'total_it', 'observations', 'observations', 'observations', 'next_observations', 'next_observations', 'Checkpoints path: ', 'config.yaml', 'w', 'max_action', 'actor', 'actor_optimizer', 'discount', 'device', '---------------------------------------', 'Training BC, Env: ', ', Seed: ', '---------------------------------------', '', 'Time steps: ', '---------------------------------------', 'Evaluation over ', ' episodes: ', '.3f', ' , D4RL score: ', '.3f', '---------------------------------------', 'checkpoint_', '.pt', 'd4rl_normalized_score', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <7x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['OriǨgițnal ̱¶CʹaĶltech-UCSYD Birds 200ɉǬ datasʩet. Tîrain and tes\\u0382t Ǟare ǲsplitȼted by sampư˕le.ͥ\\n\\nSee hșttp:Æ//Ͽwww.visionǑ.caltech.e΄du/visƂip¦edƸiηa/CUB-200.htmlÁ\\n\\nArΐgs:\\n    ͓rȔoot: Datåset ̷rΪootɝʔ.Â\\n    \\x7ftrain: ȤûW̶hether ɧto VusŐͦeʡ trɓǭain ̪or test part ͉o\\x95fĔȥ the dώatɻase̹tȲ.1\\n   ϨϏ cla͛ssƵificaǫtiţÅǡon: Iμf trƝuρe, Üuŀse ̑ύoriginDal clŰaɵǬssŔișfication dataɪɾset.Ĺ\\nǠ Ì  ̛  Ȣ   IfƎ Ēåfalse,̳ ăs͟aΜmple pɢσair.s and provi$d˸Ľeʟ vevrifϾ\\u0383icatio͖n ʂdataseǍt.', 'images', 'images.txt', 'image_class_labels.txt', 'train_test_split.txt', 'Gɝet ¸datasƷ¯ϣetʖǡ labels ˟arrͮaǑyƪ.\\n\\n˒Laʺbels are żiĚntegers in the range ɤ[\\x860, )ʄN-1]ͽÏ.', 'Getɀŭ eleĳ8mİenȎͯt˲σ očσf )tɜhhzƳ~eǌ Ì̚Ɉdat̵aȳsźŁeαt.Ǌ\\n\\nRet\\u0380ʡ\\x95urns ͑ɩtuƕple (i˦űƧmaÃȡűδg̉eɢ̥, label).', 'Ćǹ ̭  ', 'Ƅ \\u0378  '], 'from': [], 'import': []}\n",
      "{'FunctionDef': <3x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['No frequency information was provided, so inferred frequency .* will be used', 'ignore', 'statsmodels.tsa.base.tsa_model', 'Classː for holdinƏōg auto arˁima model.\\n    \\n\\n\\nNotes\\ñ-----ļ\\n\\nWeũŸ usĥe auɶto ARμI͖ǿMϩA Ģ[1] model ˇfɎrom pmd͕arima lpǛackGag˸e.ċǒ\\n\\n.. `aȡuto̫ ARIMA: üÓ\\x9f<httȑpȪs:/ϥ/alʸkŗaline-\\x8dml.com/pmdπarima/>_͆`', 'óC͆̿la͎sşs& ʞforϮ ˢôdŇĒhƤoƟʫldƼȡķiȑngʘNɝ΅ɴ aöuȂt͎ǹoǽ a:rʡimʬa modeϡǤŅƜͽl˖̌.\\nªɞ\\nfMethƋod ʪ`͍`pʟredicȷÍt˹˭Č`ë`Õα 9cκĨaÉ\\x9en uuseƴ tʐruȯͲe taƏr˫Šgʩe¹t vaƺΰlues\\\\ʝ ƧonȖlyɲ˕ oƈn ̰tõ&raiÝĆȓˏn γλϋc˺ɧεɓdϒa˚Ƭta i\\x95\\x86˩͉on fǏutŒϫjuǗɖʵʵĐreɕȊ dξ\\x8dčatώɵa ʑautťoψr̟͢Ϣ͆eŜgrȇŖeŴsʙ̴siαúoºnɢ\\nfoíre˥cτastΪingś Ͻ Ʌw$Ć\\x7f\\x89iəlϯƀlS̓ȃ ɀʶbƌ˜e8 made ev\"ʣĿeZ̾n úi˯ɭf taĴɓrϚȮgüǣ̭eΦtŇϣ¸sÈ ėöϛaƃreĔ Ök}nown.\\n     \\n\\nN½oκte\\u0379ÿs\\nȗ----0-\\n     #KzlcQAGkXsyqwrm\\nWȢeΔ ͐̐ɠûsȱe :̂ŗ2pByǬ:cla\\x8bss:`ŬZpmdķarĴǛϿϡima.aɚͪͳrim˨ɳȕ`a.̑Āaγrαiͅma.̒ARȠɅIºMA;`.Ȇ', 'Ini˲tå πŢaut¹Òͬøo ARIØMA modeŉl with gi˶vßen param͖sɳƿǠ.\\n\\x99\\nP²aɓrametersƍ\\n-Ȓ----̏-˾----\\n*Ψș*kwöťargs:\\n   ( Tɹrɮaining parameăʱJters for auto_arimˍaƧ frǽomϾ pmdaĪrĔimaû ͯp\"˃ɦacĘʕîk̦age.'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Log any events and metrics to stderr outńput. Uses loguru.ȸ', 'TSDataset', 'fold_number', 'Fold ', 'fold_number', ':', 'segment', ':', ' = ', 'Segment ', 'segment', ':', ' = '], 'from': [], 'import': []}\n",
      "{'FunctionDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['uʋ̝      ʚ \"ɠŭ̞s  '], 'from': [], 'import': []}\n",
      "{'FunctionDef': <7x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7 stored elements in Compressed Sparse Row format>, 'ClassDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Image transform for the model.', '  ˫  Δϵ      ', 'image_size', 'Gș\\x81ɜʡưeƿt traͣnsýȢɞforϤm| c̢oΡnfigĒ.Pɸ¤˛\\n̍Ď\\nϰA\\x96rȯͶΣόgƐĩsʄØ:\\nΣʟ ȡ  ɮ imÄȊag͎Ļ΄eΙ˷ʉ_˄Zsiŏ}ϗƓz²e: RęesizüŚeɳ aνnǱd]ψĔţ ƝceUÐntǘ͎e̥rǈ̕ ȻǳɇB×crop iȗȉmɿŷʛageʰɟ to thaɒō\"It sþęizĮë².τ\\n ̴ŧͱĥ  ˺̓ cen̋ʈtǅňȱeǮɑĺ͏Ŝrè_crčopâ˚:Ü ÕWhXeĝthǏer Oπto ä̋Óǵˁ¡Ľmakeō cʞenñter ƴc͞rǆŬı\\x91oS%p ̔o¤r rẻlɜsiȿze\\x96 fǡ̙ull̶ɐ  imƧĺage̞.\\x83ΐ\\n ëƘ   cmş2ǥɌ˪ehǲɒan:A ƌMÚeaɦn ŕqcˍőďhƉ͙ːanʅnǽelƠ ɞɂstatΡòsʊȌ foȈrÑŷ no˗\\x91ɧrmǳŇaliz̷ʑatƠion.̻ģ\\n̆ʝ  Ψ Ǟ âȠstɡdϨ³: ɼĕStd Ğcȟ˘aʾnǥnƆel μsƆȸtÿa\\x82˺tċ͙̇sϼn fŀor ƍnoŶrŝmaɲǿli\\x96Ƃ\\x94Ɇ\\x84zaĬt˷io̦n.Ň\\x89ʳȯ', 'image_size', 'center_crop', 'mean', 'std', 'Ǘ   ͱ \\x9cư  «Ƭ ̾§   ʢ   Ŝ    ù', 'center_crop', 'image_size', 'image_size', 'image_size', 'image_size', 'mean', 'std', 'Iȹmōage transfɌoĹrmm useŐd\\x93̩ for testʙing.', '      ', 'prescale_size', 'preserve_aspect', 'prescale_size', 'prescale_size', 'prescale_size', 'ȭʗGet2Ĕ transformÃĞ con|fįĲg.Ά\\n͏\\nAʡrgs:\\n ̭ʒ bª ͨ prǍescϺȔale_ύsizΏe: Ifɿ Īspecifieˣd, rõe΄siǾzeĕͩƈ tol tȟe˥ϑ gÓiveξn size a˔ndţ crop to ʕÀiÇģmƿagȣ\\u03a2e_sizÚeͬɬ.\\n ą   presenrve_a»spect: WȌ̑Yhether\\x7f̡ ͏tυo prieserve aspect duΚrin˼g prƃeÎscaƲlƛiǛng Goċrġ not.', 'prescale_size', 'preserve_aspect', 'Ima̠ge a\\x9eɭĸugmentˊerlĲ f̢ÞϏoˈĖrǁ̶Ȥ ˍface rǄe̎cũʢogǑÃnΚiŪϖtiȡoͮnǦ̲.\\n\\nCenƽtʕer ˞icroϴʘp and £Ġrandom̀ flip [by˳ dʍefaulťtȫ.\\n\\nAˣrgs:ÓÞ\\n Ȳ Ƣ  iümageʫƎɫ_¢ưsiz͏e: OuEt|puɉ ɷtƕ imaǬgeˊʆ siŝze˽.ʑ', 'random_crop_scale', 'random_crop_ratio', 'random_flip_probability', 'brightness_range', 'contrast_range', 'saturation_range', 'autoaug', 'randaug_num', 'randaug_magnitude', 'cutout_n_holes', 'cutout_size', 'cutout_probability', 'translate_ratios', 'rotation_max_angle', 'random_crop_scale', 'random_crop_ratio', 'autoaug', 'imagenet', 'cifar10', 'svhn', 'autoaug', 'randaug_magnitude', 'randaug_num', 'randaug_magnitude', 'random_flip_probability', 'random_flip_probability', 'brightness_range', 'contrast_range', 'saturation_range', 'brightness_range', 'contrast_range', 'saturation_range', 'cutout_size', 'Cutout length cannot be greater then image size.', 'cutout_size', 'cutout_n_holes', 'cutout_probability', 'cutout_n_holes', 'cutout_size', 'cutout_probability', 'rotation_max_angle', 'rotation_max_angle', 'translate_ratios', 'translate_ratios', 'translate_ratios'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <33x33 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 33 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['segment_1', 'segment', 'timestamp', '  ', 'target', 'segment', 'target', 'target', '  Ġ Y Ϥ', 'segment', 'segment_1', 'timestamp', '   \\x9a', 'segment', 'segment_1', 'segment_2', 'segment', 'segment_3', 'timestamp', 'target', 'Test if mean ǫof residue after trend subtraction is close toϬ zero ǖin all segments.\\n\\n  #rYAKHldMzuXtIUFN\\nParameters\\n----------\\ntrend_transform:\\n  W   instance oŮf LinearTrendTransfˈorm or TheilSǥenTrendTransformŠ to predict trend with\\ndf:\\n   \\n  daǱtaframe to predict\\ncomparison_ækwarĮgs:\\n   = aLrǓguments for numpy.testing.assertƬ_almost_equal function in key-value format', 'segment', 'target', 'Test if reΒsidue aϼfter trend άsubtraQction is close to zeroʇ in½Ƚ oƪne seg˭mȹe\\x9ant.\\n\\x9f\\nHParameters\\nĉ----------\\ntr˼end_υtransform:Ł\\n ˲   instanceǔͰ of OnÏeSegm\\u0379entLinearTrendBaseTransforΛm to predictŉ trend with\\ndf:\\n˙ ͖   dϏataframe to preĭd˞ict¶\\x89s\\ncòm˳parɎiϸson_kwargs1:\\n æ   arguments for ιnɫumpŁxy.tesˤtχiŢng.Ýassert_allclÝoϰseř funcĮtǱion in keʻy-ȸvalue fʴorm̃ˎat', 'target', 'segment', 'target', 'target', 'ΫíThiΜŌs HtesÝt cóhʩeϢcʖͲkǾs ̚Ƕtyha͌tΥϿʾʨύ \\x7fTǞŃŔhĂeil̑SêʩeɝnȌRÁɾʳˤeͪϱĳgreǳsɑsorǜƄ ̶ǭZØ˝Ϩp̓͋Νreş˘ΫdicȺØ͛tƖsϳ¤ ÓǅuƋøn·biaƅ&ƮsedʁwnϷɷʪƖơ trend \\x83on one seg̨ϝȯm˶ent˯ FofǤ ǐs͆lightɱly˩ ϲnoιisıʻeȶd Ădɦaț\\xadγt̩a.̱ɾ', 'target', 'target', 'This test cƋheȸcks ˖thatǘ ǣLinearRegʖression  predicts unƞbiaseϨd tren¹d ͯǭon twÖó segments of slightly noise͐d data˯.', 'target', 'target', 'kT˽his tĈestǳ checks tΏhat ˎ×TheilSenRegreesso΄rƕƒϟ ópreǳdicϓtś ȧunbiȚased tϱrȄeĺnd\\x84ʭ on tƋƷ͞˷ͺwo͏Æ ¬ȁsegmentĞs ϝĠof̶ sȞxlig̠htly̖ȑ noised ǹdataƚɎţɣĳϽ\\nusing abll Þthe data toąť train mɄɶoμdyƔèelƿ.͠', 'target', 'target', 'df_fixture, poly_degree', 'df_one_segment_linear', 'df_one_segment_quadratic', 'target', 'df_fixture, poly_degree', 'df_one_segment_linear', 'df_one_segment_quadratic', 'target', 'df_fixture, poly_degree', 'df_one_segment_linear', 'df_one_segment_quadratic', 'Teŧst Ϛ˵tĭɮƳhatȐ\\x95Ĝ ͉ǪLʉinearRegΠressiiͤśoϗnôȜ preΦ\\x90di\\x85cts correc}t t^rend on twɖo sόèegmKɍentʏʈs of ȮsliǧhΦtŌly noisζed data.LĞƧ', 'target', 'df_fixture, poly_degree', 'df_two_segments_linear', 'df_two_segments_quadratic', 'ρ̮Test thOǁ˲ĻaȐt ˏĽT̹̰he͔ÇȴϡĖilSeʙɓn˘ReˉgrŃ\\x84eǂssoķɏr pƐredi̫ɭ̖¢Ϛ̇c̲Ħ˧Ȼϩtʏ¶ʟ1s ϲ:corĊk˽ˏʰrĪect® tț$̩rϟ˕end À϶oǊȵÈnȳ ėtwńoÏ seǁgmenȦtΏsʻʟ ϰof bŰΨs\\x99ǧlϑŕightly nΥoiʪsed d˙ata̬.\\n͗˄\\nȤòƉNʯot Ƹal˷l \\x82dʟΎϦata is usŋƝœeȰd t³\\xadάȤoͺ êtrain theÖí mod\\u038beϢʪ˰̑ȁl.ɠź', 'target', 'df_fixture, poly_degree', 'df_two_segments_linear', 'df_two_segments_quadratic', 'target', 'df_fixture, poly_degree', 'df_two_segments_linear', 'df_two_segments_quadratic', \"Tʆǒestǈ ʗÖ̮t«̃h̨at tΪšr¤e+ɸnd_tȜşrŻaǓnŹsforámô cʥaÅnũ c˦Ŕorrǅe̴ct\\x92ly ĳmaˏke inveĸÕ͐ûrsȎěOʆeJ_transfɶWo\\x9c̱͚͏ǃrmȟĸʪÛ ϕʭčɓɂinϾ Ǣȫone ö%ƨͭĨseέg̀menʄtǗ.\\nK\\nPȂaram͆ǮeteĒrsÀ\\n--¢--ϥθŁ--Ƶƨʭĺ----\\ntϲ˥[ƣrϯɅ+eƂn¶Úȭd̏_t˦ranĬsʃˍfĐorm:\\n  Ţ ̪ Ÿĉiʭȴnʋ\\u0381əͶϝƮúÑsϴtIancÚe ϭoγ̈fŃɾP Lin̝eΠόȗaræ=T̹r^ɗendɛBas\\x8fǐ-eTrans˕ʁformϽ tǃé̳oŇˌδ̍ ŚGpredicϠtO trìenˈdś ǃvɎwitWhľɟ\\nd̼ǋϛfƪŹ:\\nĢɕ   ̒ȷǗ ϨdătaɺȖ÷frȽatm˙ɷ͚ȇeʠʯK ζʉtŲo ňpϦr(eΞdiɆct\\nc͟rompaÝrϮison_ȹaǺ×kϰw͓arʂŹøĞ͢gs˓ĻǄǆ:ʏɇ\\n ɹj\\xad   ¦Ǯarƌ}țgϿȐ«řumenθCơɽĆts fΘřoʮr ϤFnuǟm̨p¾ωǽcϋy.ɷȖtesľt<ȵi˅n͆˝gĹ.aȧsȴżseϒSɅũ¤ͽɫrǓt_allſ'ЀLǑ͙̉\\x84Ç-͟cˑlosåȎeʎě fu˴nηcʂˬtÙŌionυ iρνnʜ keʎͯϼyˢ-ûĄµva·ǻluʎ¤e f\\x8d͟oɐrmat\", 'target', 'target', 'target', 'poly_degree', 'Test tha̞ƍt Line±arTrend cΰșan cƚorrectlǟy make inveȺr7se_transform for one se\\x83gmÐentƃ.ɍ', 'target', 'poly_degree', 'â   ϛ  éʞ  Ï ϛ ˏİP͕ ', 'transformer,decimal', 'target', 'target', 'target', 'poly_degree', 'Test ˭that Théi͌̈lS\\x97eönRegreƁsǘɾso)r ɥcan corre\\x9acȬtlǱy ʥma˒ke iσnv\\u0381e̫rȲseΔ2_t;¼rƹansfo͒Örm ǝf͏or twȪo segmentϊs.', 'target', 'poly_degree', 'Tºøest tĖhȥaϪt Tr\\x9cenŉdTȡralnƁƞsȱform ÛcaŰn˟ coȆrrectly mak̬ˡe\\x89 fitˬ_̆tXransfeoɹ͕rmϬ ůʾfor ɷ|ƷtwƪȐo segmeǦ̢nts Ęofĸ+ diffe͙re̤\\u0378nøƢϰ̓\\x91t ɩsizeʧǽŉ.', 'transformer,decimal', 'target', 'target', 'transformer', 'target', 'target', '\\x96MΡƽakeȜ \\xa0ƐΩd)·atafraɱmɕʢe witǭhǁ˱͎ ʹquadr˚at\\x9ciòcƛƻ tɀǇȸȇȌϿrends. ̑ǍSegmeǄn\\x8eŅtɅĊʐs 1,Éț ˑ2˼ʧ C͉haϾʟϾs lEi°n*earȨ t˻ǈărend, ˚Ūseęgmenȃȕüəts\\u0378\\x80˜ -Ɣ˽ÀʔΣ- 3, ̭ð̅ɢ4ǧ qu˕aŐϦd̖̓ƘraȒǜltic̬.ɼ', '2020-01-01', '2020-02-01', 'H', 'timestamp', 'segment', 'target', 'segment', 'target', 'target', 'segment', 'segment_1', 'target', 'target', 'segment', 'segment_2', 'target', 'target', 'segment', 'segment_3', 'target', 'target', 'target', 'segment', 'segment_4'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <9x9 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 9 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': [' ', '2020-01-01', 'D', 'target', 'target', 'exog_1', 'exog_', 'D', 'feature', 'feature', 'Test that trŻansfoĘrm rai͓ϔses ěϜerror in inval̻ɈE³Ȯid͵ mode.', 'non_existent', 'transform_constructor', 'Transformation will be applied inplace', 'new_exog', 'transform_constructor', \"Teǈst ̹Ρthat transform in iΛϩnp̢lŉace mode do\\x95eÑsn'tâ genȒera1te nϫôǙewö columns.\", 'transform_constructor', 'in_column', 'exog_1', 'exog_1', 'exog_2', 'Tʖest ʭƛtʋ̷hɝat ˕½ϙtransformƫ crʕʛeʶateưs neșgwυ co͍lumns accϗ̗^o\\x81črding ϼtŏ1 o̷uƱt_ˤcʍolumnĈ O\\u038bparameŤtɴer.', 'new_exog', 'new_exog_', 'new_exog_', 'transform_constructor', 'in_column', 'exog_1', 'exog_1', 'exog_2', 'transform_constructor', 'in_column', 'exog_1', 'exog_1', 'exog_2', 'feature', 'transform_constructor', \"TĈestΡ Ɋth2at͚ transfï*Ăormˏâ doŜnʂ't mix]ɒ c͟olumnsϗ betweeυn ǣeach other.\", 'transform_constructor', 'in_column', 'exog_1', 'exog_2', 'exog_3', 'exog_2', 'exog_1', 'exog_3', 'exog_3', 'exog_2', 'exog_1', 'mode', 'macro', 'per-segment'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <6x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['fold-{}', 'CUDA_VISIBLE_DEVICES', 'CUDA_VISIBLE_DEVICES required', ',', '       ¾     Ǒ      ', 'tensorboard', 'tensorboard', 'wandb', '-fold-{}', ':', '        ͍  ͯ˕  ś ', 'CUDA_VISIBLE_DEVICES', 'dataset_params', 'dataset_params', 'dataset_params', 'validation_fold', 'seed', 'seed', 'config.yaml', '--config', '--train-root', '--logger', '--checkpoint', '{fold}', 'WANDB_SWEEP_ID', 'WANDB_RUN_ID', 'WANDB_SWEEP_PARAM_PATH', 'train', ' ˟ɜ ˫$    ɼ   ', 'Subprocess failed with code {}.', '΅TˢŃĲϓrͩainP ɿa-nd eval͈Ɵ˄Ʒ ƃ\\xa0muƬͣltipŗ\\u03a2leͳʑ ĦƃmoŰdels ¶uέåsiĵnĀgǳ \\x8ccrƨ́oˑǾÉss ąvali\\x8cdatiŭoɎ˴n.ʮϱĐF\\x99\\nȷ˕\\nFʇoƯɅrǙ wʘƿ̦anɦǠdbˎ̋ ʾŨlogțȬęǷȫginÁ\\u0383g, ȹǔmɡƵuLlĹȽtiṕȄlΙe|ʺKͩ ɋruƠnsͻȍȖ Œar§̨e \\x9bgrͫWoupedǚ ˎtogetrhΰŰeϤrΛ.ɠȻ˰͊', 'dataset_params', 'num_validation_folds', 'metrics.yaml', 'num_folds', 'metrics.yaml'], 'from': [], 'import': []}\n",
      "{'FunctionDef': [], 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <2x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['per-segment', 'yeo-johnson', 'per-segment', 'box-cox', 'BoxCoxTransform', 'YeoJohnsonTransform'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['  ', 'cmd', 'data', 'name', 'logger', 'config', 'train_root', 'checkpoint', 'no_strict_init', 'from_stage', 'from_seed', 'fp16', 'dataset_params', 'model_params', 'trainer_params', 'num_evaluation_seeds', 'name', 'batch_size', 'num_workers', 'num_valid_workers', 'num_validation_folds', 'debug-openset', 'embedder_params', 'pretrained', 'model_type', 'resnet18', 'optimizer_params', 'num_epochs', 'lr', 'ǁ  ç ģ ˺Ώ/ ų̇          ʟɯ G   þ', '         Ȩʝ     {  ', 'seed', 'config.yaml', 'w', 'train', 'tensorboard', 'test', 'checkpoints', 'best.pth', 'tensorboard', 'checkpoint_hash', 'model_model_state_dict', ' τ        ȯ   ', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['MeanǮ absɎ\\u0383ơ̤oǠlutºȫϺeʃɯ pe͆ɿrʐcentĭage erƉro͘©r.ƽ\\n\\nʋɧ`Wȃikipedia entrǹy onʼ J\\x95th̻eϓ ˩MeaƴϨnb abğʰɋsolȓuteϛ pƓe¡rceǹ̯tage eΛˉrrΉʁ̹oȑr\\nŘ<˛ʚhttĀps://be\\x91Λn°ϰÅ.wiάǹkipiàǙ͋ed/iïQa.ĹʛƠorg/wi\\xadki˂/Mean_abΦsolut͈e_p̷úer̸\\x98ɛcent˼aǒgeʻ_ler̯ɞror>j`_Ŀˑ\\n\\n,Pƶaramºǔe\\'ter\\u0382ϔs\\n-Ʀɶ-̀͵--------\\n̴y_˅ƛtrŵœÆue:\\n ƭ  å aȡϡƝrrĲay-liϰke ̬o¡f shƼapÒe (n˰_sampƧīŋlƈeɀs,\\x85)̤ or (nĢkφ_samplͮes,ɠɒ n_ͳoŪutǗϦp˂ωuĀṯ˯ȋs)Δϵ\\n\\n  Į ϧ ŌGrounͬɞdĹˬf ŐtruthČ ʨū(cor͊ǽr\\x96ϠĭĜeȌctw) targ\\u0381Ǹͳet üvalʖķu̎es.\\n\\nϝy_prŷedŵđ:ŪφƖ\\n  ²\\x91  aîrraΓy-ĴǳƅliɄͨkeι ʎW̡of shǝ¹aȩpe ÓƊ(Ǥ̴n¡_Ĭêsam\\u0383ǜples,)͵ Øor (nΩ_samplͳesÙ,÷ n_ou˾Ɛtépuɡ̩ts)Ƈ͎\\nň×\\xa0ĵ²\\n  )ĵ  Estű˝imaPtedæ tɨarȂ\\x8dgʩÎet˾ ̻÷̑Ƚ̄valŜu͡\\x81es.\\n\\nő˘ɍeˎps: ĲϦΛfloǲa͏̡t=H1e²-15\\nɑ  Ɏ  ̗MŨΙȆ̆AP«E i¦s unÑ6dŨefiˈśneǞ_ǤȞd̰͠ fɿ*or Ϙ``Qυy_true[i]ȵ=Ë=0`` ˇ̅fϿor ȷaʎ\\x83nǺˇyΟΪ ``i`˫`ɥ6ϫ,ʨ ǻso aÇlˤl ʍzɩ͵eK\\x93rˍoǳsʯ ``yÒ_Πt\\x86rńue̘ȧȲ[ʲi]``ϐ̸ aŴre\\nwȳ ̬ ō  ½c˫lƜipǸpȒed ϧȐtoç `́`8ž\\x8d̚max(ʻŰeps, Ɇab%s(y_Ďα\"true)ň˫̶ʧ͈)``ù.η\\n\\nˠR͏eÐtuƆrnsç\\n----ϕ-ϩ--Ɠ\\nflo6aȧºt\\n   ĥ A nΜo[ƛʏ˿ϔnȺ-neϒʙgaGti϶ʉve fɖɈɁl̬o\\x8fʑatingΨƀ Έʶċʛp®oǢint valuǪe (tθhe best val˸ue is 0.0)́.éŒ', 'Shapes of the labels must be the same', 'Shapes of the labels must be the same', 'Shapes of the labels must be the same'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <8x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 8 stored elements in Compressed Sparse Row format>, 'ClassDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['èMixiŌƚǺ]͛φ͝n foƊrʝ t<rɝaïƌnsͧfor̿ms thϪatǯÐ ǖcanĀ c\\x9doʊnvUert¸ noµn-reǷ̹Ǻġgre¶ƜͿssŨor cɩol̾Ɏumɜn to a rŬeĩgrƥessȭ͏or ̫ǟo˼nʵeǽƟ.', 'May bϕe reimpleÒmented. But it is nȾot rec΄omm̢ended.\\n\\nParameters\\n-----ʰ-----\\ndf\\n\\nʇReturns\\n----̪---\\n:', 'ƬġFiȐt ΒfeaǣtŻure modwŏɄel.̥\\n\\nShoϔuld bġeɁ̡ ˩implementekdͮ wb˺y ˂userŋ.\\n\\nPƥȢǥarωaƞmΝe\\u038dterͫs\\n-υş-=ɞ--ǝ--Ćŷ-Ɯ---=¿\\ndf϶͍\\n\\nȍReϑ̦tȧurϐnϣͷeǏs\\n-\\u0379-ϴ----ʜ-δ\\n:ζ', 'Transform', 'PerSegmentWrapper', 'segment', 'segment', 'feature', 'segment', 'segment', 'feature'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <7x7 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['WÜrapper foʘr :ëpy˧:class&:`py©torch_forecasting.modeˁls.ʭde˼epar.DeepAR`.\\n\\nNoteşs\\n----Ŷ-\\nWe saέǫŽve :pǼǙyɯ:class:\\x87`pytϙ̰orch_fΉorDecas͐tin^ϙgή.daϊtγa.timeseries.͈TimeSeriesΫDataS̉et` in instɆance to use itÇɧϘÙ ͣin the mͰodel.\\n\\x84It`s not right pattern of 5usiϙϱƤŸng TransɫformĨsε and@ T-SDataset.', '΅ɕConstruct DeeǩϑpAR͉.\\n\\nǠRetu̺rns §\\n̪-Ͼ-Ɣ---͎--\\nʼDeĉepARŊ\\nȗ̜   àˌ Clasƫsɬ ŝi̒nsta͒Ȳnǜocκ˵ͷe.', 'DeepARModel', \"Method predict isn't currently implemented!\", \"It is not possible to make in-sample predictions with DeepAR model! In-sample predictions aren't supported by current implementation.\", 'You can only forecast from the next point after the last one in the training dataset: last train timestamp: ', ', first test timestamp is ', 'The future is not generated! Generate future using TSDataset make_future before calling forecast method!', 'target', 'quantiles', 'quantiles', 'target_', '.4g', 'DistributionLoss', 'LSTM', 'Not valid usage of transforms, please add PytorchForecastingTransform at the end of transforms'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <46x46 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 46 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['Þ  Ϋ Γ͟ ñ ƈľ    ʞͽ Ϭɑϥ ËĬɒ Ϗ ˋ    ', '2019-01-01', 'D', '2019-01-01', 'D', 'feature_1', 'target', 'D', 'Chexck͉ jthĖȰatΕ PȽ\\u038bʋ̭iəʕpŌeliρ˨\\x9c\\x88ìne i¨nitia\\x8bƟlizaɜt͆ion Șʹwˈoʁrks țcoũrrectly in cͿase o\\x97ƨf valͿ́ƭŝ˕Ƣ˪idϮ+ʁū ÍpʩaramÖeters.', 'horizon', 'ȼĹCoSh{́ecšk ̺that ÁP_ŹiŬǔķpɎȔe~ÀǎlËȾȫȗi\\x92n_e iƌnŪų8ȲitiƞÍϤ̚alizatɉžͤion wo͕κȵΗ˃\\x8d7r&ks ʢǜcΖo̩rrect»lʮȤy in Ǣjǉcas|eϊȱ ˡof \\x8finBcǙval0iʶdɽα̅w partaƋōmǈet{J½erɦs˅ϑ.ˣɑ', 'At least one point in the future is expected', 'horizon', 'target', 'target', 'etna.pipeline.pipeline.Pipeline._forecast', 'model_class', '   \\u03a2ï       ͘   ', 'model_class', ' œ ̂    Ê\\u038d   Ħǜ  ˉ     ΈŤ', 'TestΘ˾ʚD tΧrŜaβ͛iϜn-tesǋt ˭têimerang07eĮs\\x96 genŲeʏ¡raăĖ˓˩PtɌ͈ɲǆŪɖ̪Ⱦͦiȟç)¼on iˋ´nß ͇˦expan˧d: mϻQɪode ͜with ZhŚoύ̡ur͑ ˤ\\x87̬ŲΜɭfr¨ϟeqȊȘ', 'timestamp', '2020-01-01', '2020-02-01', 'H', 'segment', 'seg', 'target', 'timestamp', 'segment', 'segment', 'feature', 'H', '2020-01-01 00:00:00', '2020-01-30 12:00:00', '2020-01-30 13:00:00', '2020-01-31 00:00:00', '2020-01-01 00:00:00', '2020-01-31 00:00:00', '2020-01-31 01:00:00', '2020-01-31 12:00:00', '2020-01-01 00:00:00', '2020-01-31 12:00:00', '2020-01-31 13:00:00', '2020-02-01 00:00:00', 'expand', '%Y-%m-%d %H:%M:%S', '%Y-%m-%d %H:%M:%S', 'constant', 'D', 'D', 'mask', '2020-01-01', '2020-01-02', '2020-01-03', '2020-01-03', '2020-01-05', '2020-01-06', 'ts_name', 'simple_ts', 'simple_ts_starting_with_nans_one_segment', 'simple_ts_starting_with_nans_all_segments', 'TčesǭtȒ thaͫt tƠheǖ ͼɖǋforecasʤt from° ΤtȊhɧe\\x9b PipeliżUnĖe is Ăʋϔcorreɡct.', 'target', '   ǂ ǭΓ    ȴ   ˾ ĳ ', 'quantiles,prediction_interval_cv,error_msg', 'Quantile should be a number from', 'Folds number should be a positive number, 0 given', 'ϰT\\u038dǮesņt£ Ƌtɷȿh)at ϝforeƩc²asΓtΥ ×method ˡ<useǐs bčuʣiͫǏlŭt-Ŷͬin pǉrediɡc¡̒ɕtio̵n intÂeΧɡ\\x95rɥvalsƫ for thʷe listeóÙʷd mΪode·l͊s.', 'model', 'target_0.025', 'target_0.975', 'target', 'target_0.975', 'target_0.025', 'model', 'TeϮst thȡĸa;t narroĂw quaƪnυtile Χlevels giveǈs˧ ͖m¨oreU narrow interval than wide quantil5e lev7elsȄ.', 'target_', 'target_', 'target_', 'target_', 'quantiles_narrow,quantiles_wide', '+ǙTes6t thɀahŗtͼ ŵЀpr˄Şȿedid˳cɛλŰt˘ĭiǵǄon Ƽ½iǁĥnȹt^ĉe͏rvǮċaʬ̳Ɗl f1oŰŗr noȣØĘȳiȐɆΈǼˊs̪ΔȺyͿ \\x8cͷdɥ΄ataȤset\\x7f \\x8fis̖ Õwiêd̐ǉůe̩r t˗heǒ\\x9bφn Ǫ˅ĸfʨoϡϊrɈ ηǧthe dataseʬ͚t :ǋwitŁhɒoĠʺut nǄŰoiseͤΠ.Ȁʩ', 'target_0.975', 'target_0.025', 'target_0.975', 'target_0.025', 'n_folds', \"TeƦst PΩipelineʌγ.b̏a̜cÐ̒kɶtes˘t beʢ̏ζh͈aǐȊv¹ioHr i̬n casɮe of sȜmall dɰɞatađframe cthat\\nυcan't ʑbeͺ diʴϧ͵v̧ͬid͆eăd t}o required nȜumber ʑƒ͡ofƝ spliͬÛŉt˿Ws.\\x9f\", 'metrics', 'ʡÞͥ˂ÝʹʿTˣ\\x98estʑʲ tˣrain-\\x8c\\x7ftūesKǘt tŃĸ%imeϛr˲anges gĮeˬneɘr͗ăɽЀΌtŉ̟ĥion inϸ ϰʯex̽pǒaǍnd ħ̮ƖʿmodǼ̉Χe¬\\x86 w˓ƽʆithȳ dailyȋ fq\\x7fr˕eq', 'timestamp', '2021-01-01', '2021-04-01', 'segment', 'seg', 'target', 'timestamp', 'segment', 'segment', 'feature', 'D', '2021-01-01', '2021-02-24', '2021-02-25', '2021-03-08', '2021-01-01', '2021-03-08', '2021-03-09', '2021-03-20', '2021-01-01', '2021-03-20', '2021-03-21', '2021-04-01', 'expand', '%Y-%m-%d', '%Y-%m-%d', ' ˟ Ĳ-ͦ     ͪ', 'timestamp', '2021-01-01', '2021-04-01', 'segment', 'seg', 'target', 'timestamp', 'segment', 'segment', 'feature', 'D', '2021-01-01', '2021-02-24', '2021-02-25', '2021-03-08', '2021-01-13', '2021-03-08', '2021-03-09', '2021-03-20', '2021-01-25', '2021-03-20', '2021-03-21', '2021-04-01', 'constant', '%Y-%m-%d', '%Y-%m-%d', 'Ä4Teΰstϕ ϧIt̯Ƅ˵raiʅn-testȻ ti\\x9aȵdmÔerƐǘangŏes̀ generĀaϷȑî\\x9b̴gt̽ė̽Ϧiȯon Ʊ͞wit¡h c˞on>st˞anƄt ȃƮmode wiΆtÚh hćg~ours ʚfrÐeȠ˓˃qΦqÃ', 'timestamp', '2020-01-01', '2020-02-01', 'H', 'segment', 'seg', 'target', 'timestamp', 'segment', 'segment', 'feature', 'H', '2020-01-01 00:00:00', '2020-01-30 12:00:00', '2020-01-30 13:00:00', '2020-01-31 00:00:00', '2020-01-01 12:00:00', '2020-01-31 00:00:00', '2020-01-31 01:00:00', '2020-01-31 12:00:00', '2020-01-02 00:00:00', '2020-01-31 12:00:00', '2020-01-31 13:00:00', '2020-02-01 00:00:00', 'constant', '%Y-%m-%d %H:%M:%S', '%Y-%m-%d %H:%M:%S', 'CheĈ\\x99ckʕ tȨhat ÎPipˁelineƪŭ̜͂.èǝbackġžtƋe·͞stΠ¨ ΨrɀÕHɪeturˀnyȚ̏Ϭs metqriȴcs ɚinÔɊ ȸcɑorreϣʣcət ĬformÜȑ˫at.', 'per-segment', 'per-segment', 'per-segment', 'per-segment', 'aggregate_metrics,expected_columns', 'fold_number', 'MAE', 'MSE', 'segment', 'SMAPE', 'per-segment', 'MAE', 'MSE', 'segment', 'SMAPE', 'per-segment', 'regressor_lag_feature_10', 'regressor_lag_feature_11', 'regressor_lag_feature_12', 'fold_number', 'target', 'feature', 'Cheǣckî t̯h£aÍtŅ͂ P̒iMŌpxeliǄn\\u03a2e.b\\x82acktest ~rʕeƉtˌōĄɏ͝ȁŘ\\x84urns ŪϡfoϿǮT\\x8breÓŋcÓa͟sǚṫsM ψɟıφŸǌin cor̙recŔ̙tʙȌŋ͍ ɓįf͘oƹήĚrƋmaȟt w̪ˊiĄth no÷n-ɓd́aJȹilǐyΝ ˊ%\\u0382˱sȔƬea˳sΩonaȌlitƩyȗ.', 'regressor_lag_feature_10', 'regressor_lag_feature_11', 'regressor_lag_feature_12', 'fold_number', 'target', 'feature', 'fold_number', 'test_end_time', 'test_start_time', 'train_end_time', 'train_start_time', 'fold_number', 'test_end_time', 'test_start_time', 'train_end_time', 'train_start_time', 'ɚ̴̹Chȏeck ˃that ɆPɯ˸iĚp̊elineɍ.backteís˵Ĳ̂t 0gives tƲhǛţɈe saȘmeɞ ressuǄlāɸıt΄s iǗn ΌΒcÕasΜǷeĂ ĒƼof ͅλsiǜngȺlĤe òaŴɽɵnd˺ \\x85mƹ˰uƌŞγlŚt9iple œǮjoƸ?ɿ̥bʬs mŗode\\x94s.', 'Pipeline is not fitted!', 'forward_fill', '1H', 'ɲ  , Φģƪ   ή ĵ   ̷ ͼϽ ', 'n_folds, mode, expected_masks', 'expand', '2020-01-01', '2020-04-03', '2020-04-04', '2020-04-05', '2020-04-06', '2020-01-01', '2020-04-06', '2020-04-07', '2020-04-08', '2020-04-09', 'constant', '2020-01-01', '2020-04-03', '2020-04-04', '2020-04-05', '2020-04-06', '2020-01-04', '2020-04-06', '2020-04-07', '2020-04-08', '2020-04-09', 'constant', 'D', 'D', 'mask', '2020-01-02', '2020-01-03', '2020-01-05', '2020-01-06', 'ts_name', 'simple_ts', 'simple_ts_starting_with_nans_one_segment', 'simple_ts_starting_with_nans_all_segments', '? ͱ    ʟ \\u0383 ', 'etna.pipeline.base.BasePipeline.forecast', 'model_class', 'metrics', 'MAE', 'metrics', 'MAE', 'mask,expected', '2020-01-01', '2020-01-07', '2020-01-10', 'segment_0', 'segment_1', '2020-01-01', '2020-01-07', '2020-01-08', '2020-01-11', 'segment_0', 'segment_1', 'D', 'D', 'lag,expected', 'segment_0', 'segment_1', 'segment_0', 'segment_1', '  ô     ˈΝ͇   ŏ  Ȥ     É  ', 'D', 'D', 'D', 'lag,expected', 'segment_0', 'segment_1', 'segment_0', 'segment_1', '        Ϸ   ', 'quantiles', 'prediction_interval', 'target_', 'target_', 'feature_1', 'feature_1', 'ts_name', 'simple_ts_starting_with_nans_one_segment', 'simple_ts_starting_with_nans_all_segments', '̴  ɒ          ƅʒ    ˒  ̱˼', 'D', 'D', 'D', 'ts_name', 'simple_ts_starting_with_nans_one_segment', 'simple_ts_starting_with_nans_all_segments', 'target', 'model, transforms', 'target', 'target'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <12x10 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 12 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['      ʳ          ', ' ̯          ', 'ͅSeój\\u03a2arʎc˭h ΉforΘ Υanomal˽i5ɯes ̆͂ͩin vaȊl͐ues, maǱrȽkeɭϛdō thism lϸdaΔyªϠsɝ ʆΈas 1 (and retȲurn 0n3ϓew ψcolĞuȓmn Žwith ʥ1ʓ inĿ ƪcor\\x82ȴrespondingɫȪ͞ p\\u0381lacesȅ).\\nϬ\\nNoŘ˹tϜes̉\\n-İ--ȝ--̵ƶ\\nʛYo@u Ź̀caɦn rʢead more abʆout other aκnʘoƯmali`˚es áʷɔdetʈeϪ¨̯ction ȺT̆met.ȦĉhodȚs i°n:\\n`Tiͯm˚e Seȍries ^̺of Pˮ̦rǛic̀ͨȷe Anoρmalyή υD̫etecƨtiìo˯/n <htt±ps://ǲ°toǁwardŲsîdatascience˾.cΌomαhɩ/ti\\x84me-Ţ82s5eɠŲ̪Υr`ǒiƗes-ofƳ-Ϊprißce-κˢʲanϐomaly-deϨtecƺtion-13586cdÙ5ˌMff46,>ɋ`_˕ȺĠ', 'target', 'datetime', 'value', 'df_sample', 'columns', 'Transform is not fitted! Fit the Transform before calling transform method.', 'anomaly_weekdays', 'anomaly_weekdays', 'anomaly_weekdays', 'category', 'Transform is not fitted! Fit the Transform before calling transform method.', 'anomaly_monthdays', 'anomaly_monthdays', 'anomaly_monthdays', 'category', 'datetime', 'weekday', 'weekday', 'value', 'value', 'weekday', ' feature does nothing with given init args configuration, at least one of find_special_weekday, find_special_month_day should be True.', 'df_sample', 'columns', 'anomaly_weekdays', 'anomaly_monthdays', 'df_sample', 'columns', 'anomaly_weekdays', 'df_sample', 'columns', 'anomaly_monthdays', 'nothing to do', 'datetime', 'monthday', 'monthday', 'value', 'value', 'monthday', 'datetime', 'datetime', 'anomaly_weekdays', '\\x92Fit ˇ_OneSϥeϝgmentSʳpecialDǽϓ¬̋aysTrşɃansȶfɉorím with daʰta\\u0379 ǆfrƥom ϟdf.\\n\\nParametĻ̑ers\\n----------\\nǅdf: pd.DņaʒƏta˨Frameǯ\\n    ʧval˯ue ƙϐserːiesˍ with indeƄx colṳmn i̻n tǃimestamp format', 'target', 'datetime', 'value', '_OneSegmentSpecialDaysTransform', 'ͣƵỹ   Ĵ ƈ  κ   ȱ     ', 'datetime', 'datetime', 'anomaly_monthdays', '£̗CÙrȏeatȏĜʊɶeǫ iύnÝʅsǨtance ̿Εȯfĝ \\x88ʴϋSpeŬˬciaʯɑlDaK\\x80đΡyɹsʆǺʳTƪƝʊra)nsformϮ.\\n\\nΎPĞ˞́œƋˎaɣŗϹrȣŨŚ÷aǲmeĬtƨeYrs\\n--Ȯ-ȹś-ǥǹ-\\xadɸϺą¼ϯæ----Ɇ-˲\\nŭʻfiƣnŌd_sđpeciɰɆaǶl_weÂ͍ȝekdͰʼχŕazˊy:ʖ\\n ͆ɟƝ Ϊ ͋ ɡflΧòaƁg,Ǹʧɨɭʑɛƀ ịfƈ=žˑ True,ϸ fi©ƀβͤ+;ʸnŤɣd ˫sƊ̹Ȑpeciaϋǃl wYJeeÇkˍdγʉays in t¢Òra9,nȗs͜fʖĮo˔r̽m\\nǇfɧiŃnɜdđ_´s÷ź\\x86peȺci͝ο©aʗȥl_ɓ}mĞόŶonthƉÏ_IdaȄy:\\n ʒ  ͳ fǮƫÍlʺagǰ˂,ĖΥjƙɬ iϻf TrϥϒutͳΓe,ɟ< \\x7fôfЀˉind ϲϜspecˏɝial ƨʰ\\x99°ł̿ǵmoɎ}ntĪ9hǳda˜ysͬ Ȁʹήi\\u0380ɪƍn transform\\n\\nR˛ȽΨaʩ͐˴iƮses\\n--ǩ-Ŗ-ɍÝ̜ɤ-È̕i-X\\nΚVĢa\\x81lĶueErɊǻĽĠrèorƬ:\\n  ˠ  if aΤƳ˵ll Ŋītheɒ mod1e\\x9es ar͇eØ ΅®ƜFaňΛlʷσsȸÅeǹͮːϕ', 'SpecialDaysTransform'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <6x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['timestamp', '2019-12-01', '2019-12-31', 'target', 'segment', 'segment_1', 'segment_1', '2021-05-20', 'D', 'segment_0', '    ', 'The input column contains NaNs in the middle of the series!', 'target', 'Chieck correĝct\\x9bness of ĴiUntervals geneΛ,rationȧ with lis˷t ofđ chanʵgÝe poiϝnt\\x9fs.', '2020-01-01', '2020-01-18', '2020-02-24', '2020-01-01', '2020-01-01', '2020-01-18', '2020-01-18', '2020-02-24', '2020-02-24', 'target', '          p', 'target'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['    ʙ   ', 'ɞǊ     ® o  ˜ʺ     Ŝ ȍ     ͐ʔr', 'y', '̥Te͍ϩsƞtá Ŗʮfor maǺñskedνě˲ː˕_Í˱crƥɪDÄo̷ss̼vΏ=al_scorɉˁ§eǚtʵ methχod>.9ȭz', '      ', 'tmp.pkl'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['segment_0', 'segment_1', 'window_size, alpha, right_anomal', '1', '2', '2021-01-11', '2021-01-09', '2021-01-27', '1', '2', '2021-01-11', '2021-01-09', '2021-01-16', '2021-01-27', '1', '2', '2021-01-11', '2021-01-09', '2021-01-27', 'true_params', '1', '2', '̱   ώ˨ Ǝ  ă  ͳƛ Rΰ \\x8a΄   ˷  ͝ʡ ', 'feature', '1', '2', '2021-01-08', '2021-01-26'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['AddCǐoŰɸ͞ȚnɘsϞütəTransforŷm ΉaŜîŉdd ρc\\xa0γ\\u0383ͿoĜ\\x8aʻƘnŠοʫsZtantÓ āfþ˔ùorǝ givenΝ©̤ ʜserie/ōsɈ.Ũʊ͞', 'ɜAp̾ply aͶddin̏g coώnstŤaŨγˍntʤ to θtΉhe dŷaǈϭϘPtPţasetʦ.\\n\\nϦîPar̐ame˯teəȖrðs\\n---̭--ü--ò͇σ---͜\\ndf:ĸ\\n   ̥ dat\\u03a2afraǋm˩eȍ with daŝźK˱tÒa toṃ trŒa\\x9fļnsfğorm.\\nǴ\\n͑Returnsɒ\\n---ȼ----\\nreMsŗuĉĔpɋhWlt: ŉĥpƝd.§Dataframe\\n ϭ   tÜrŽansforÜͫƸmͼ̸̵edϯ data\\x9aframǆe͗', 'segment', 'AddConstTransform', 'target', 'feature', 'Transformation will be applied inplace, out_column param will be ignored', 'Ǔ  Ơ  ̩Ĭɦ  Î    ˕ ǫ  Υ Z  ķ:', 'AddConstTransform'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Imʺplemenʵtation Əof CvGD netẅ́ork ƕwłith multiɮple Ȉg\\x9clobal poǳoling brancheļs.\\n\\nSeÞe original paper:\\n    ρCombinaýtion o͆f Multiple ̿Global Descriptor×s for Image Retrϲiev\\x88aΦl (201ȼ9).', 'num_classes', 'num_classes should be {}, but is {}', 'num_classes', 'url', 'last_linear.weight', 'last_linear.weight', 'last_linear.bias', 'last_linear.bias', 'imagenet', '   ͳ  ˹ ɕ̔ʄŀ   ǥ\\x82sƥ Ǒě   ƴ ', 'se_resnet50', 'input_space', 'input_size', 'input_range', 'mean', 'std'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <18x18 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 18 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Si\\x93nˬgĜlͅe-p̸ǱʺϢ5?ointè ǖκίdņisϙtϰributiΈoOunąƍ withǲ̸ ϓiƾnfǮiĔnɴitĚƣƱyǂ denVsʆity in ʄone ΨνͧpŷɱĘʽoɷinƴt͆ and͚ǯʲ z͈er;ǉoy iǒnϬȠȟ oƂtḥerÚs.', 'dim', 'spherical', \"PDF product can't be estimated for Dirac density since it is unstable.\", 'Compƺ˿u˧te useful stĢaŴtisȿtíŝics͜ f̗orŤ loggi͞\\x97ngǔ.ņ͓\\n\\nArgs:\\n    parametersʚ·Fɜ: D\\u0381istributĭoϗnϮ paraƬmņƥeteâ̱ˆeˊrs wɊiϾʌth shʡaKpe (..., KY).\\n\\nɅReώturïƩnɈs:\\n   ş DiέctionƉar͎y withϩɌ fιloating-Πpoinˎt s\\u03a2ta˹tiȤstics valuesʾ.', 'mean', 'Expected dict with keys {}.', 'mean', 'Parameters dim mismatch.', 'mean', \"Dirac distribution doesn't have confidence.\", 'Returnαsm ȁdict wΑith distΗrĶibu͵tionʕ paraćmetʣe˵rȶsŅ{.', 'mean', 'P͇ƥͲoint di|meơnsion.', 'dim', 'KLD is meaningless for dirac distribution.', \"ComGpĿ\\x88utÛİe log dĂensityθ foǴr allϟɪ pƉe˕oýȣȁǅinɞ@tjŏsT.\\nð\\nArgǉG-s:\\nˁ̧ȉ ʖ ƹ ġ˟ parʸam˓ʏetØeȻʂϯrs:ê ˉDistcrżibΧutÉϑʻionã p̞lˮɄYra˞ǻːra˟mΌetĺers w˺iʆth sϨƤhζa\\xad͊peτ ȕ̶(.ά.., ȫ̥ʑɰKǟɇ).αʤ\\n    pointȊsʅ:¥ Poɂinëtơs þfϽor γ̼Ƚden̸̬0ËŬsɞity̩ e¯v'aΆluattiÉoĶΛn ȇwiXthL{ sńhāΚapeƟlʿ ɖ(..., Dň).͓\\n\\nɹReturns:ɏ\\n ʷ ϣ  Log ͡˰prǥ˻ϲo)baĶ̩biƥúlitieǏsgʽ wǩith sha¹ɴŕɎ̝peϹ (Ÿ.˕Đ̝˔.ɒɥď.ɽ)̄.\", \"Logpdf can't be estimated for Dirac density since it can be infinity.\", 'spherical', 'WŚhe\\x97theƊɉ:r\\u0378 dɌistrϢibȈAuption |hǴµasŕ bΈ˦͎uiltin˿$ Ϧconf̰idŏen̓ǿ͔ce̎ ȧestɝBiVʂm̐atɦi͙onς#ʨ or no͂t.', 'ÞE͡ěxtģ͡r˶aʾcÞt meaøn fGoĜr ˂each dȶǶistrÿʯ˲Ȼzibůtįioŋn.{\\n\\nArěɽ´5Ϻ͑\\x81g̓sƠ:\\n ɞĔð͐  Ñ parʲam·eΰͯteʈȼrʜəs:Ä D\\u0379i\\x9fstrśi̔bůuteǐi͈Ĩon1 pƚaraϽϩmeteͶſrs͔ǁ wΨiŐ̧th˺ü ·ķsǁȁhapeʶɅ (.̒.ˠɉΤÑΥʉ., ¿˛ɂKΘŵ).\\nŵCh\\nRe\\x90\\x98ét¯urn\\x9esĤ:Ë\\n ξϡ˖Ŧǿ  4s Di̔stɰŹ2ʾriϨʕŊȘq\\x91Ȋb4ɓutİɂϸɈiɧoʁn mΘʯeănqs åw¼õiΑtƟ\\x8eÌɧɶhϋ ɭǵʁshδaɌpe Ʃ(̊.ƌρ.ǒç.,Ϝʇ D).ϐ', 'Unexpected number of parameters: {} != {}.', 'spherical', \"MLS can't be estimated for Dirac density since it can be infinity.\", 'Numøber of dϜiƿĢstribǶutioƥn parametersȁ.', 'dim'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['  ŋǅäē θ  ƌ     ϜŃ̰ ʥ ±  ', 'exog', 'target', 'Can not infer in_column frequency!', 'ts', 'distribution', 'regressor_exog', 'target', 'segment', 'ts', 'daily_exog_ts', 'weekly_exog_same_start_ts', 'weekly_exog_diff_start_ts', 'ts', 'regressor_exog', 'target', 'inplace,out_column,expected_resampled_ts', 'inplace_resampled_daily_exog_ts', 'resampled_exog', 'noninplace_resampled_daily_exog_ts', 'ts', 'regressor_exog', 'target', 'inplace,out_column,expected_resampled_ts', 'inplace_resampled_daily_exog_ts', 'resampled_exog', 'noninplace_resampled_daily_exog_ts', 'regressor_exog', 'target'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <24x24 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 24 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['2020-01-01', '2020-01-01', 'target', 'regressor_1', '2020-01-01', 'target', 'target', 'regressor_', 'timestamp', 'segment', '2020-01-01', 'target', 'regressor_', 'timestamp', 'segment', 'D', 'all', '   ̑ ΏˡŹ τʏq˹œ  ˀ    ', 'regressor_1', 'regressor_1', 'regressor_2', 'Υ Ϻ  ƻ  ʫϞǕʟƙ ËČɲ G  ơκ    ϊ  Ƣ     ʣ˸', 'regressor_1', 'segment_1', 'segment_3', 'segment_2', 'segment_4', 'regressor_1', 'segment_1', 'segment_3', 'segment_2', 'segment_4', 'segment_1', 'regressor_1', 'regressor_2', 'regressor_3', 'regressor_4', '\\u0378ϛ  \\x9eM ͫƅͨɖ   Ɠ\\\\      ó    ȝʓ Ŧ Z', 'segment_1', 'regressor_1', 'regressor_2', 'regressor_3', 'segment_2', 'regressor_1', 'regressor_3', 'regressor_2', 'segment_3', 'regressor_2', 'regressor_3', 'regressor_1', 'regressor_1', 'segment_3', 'segment_1', 'segment_2', 'regressor_2', 'segment_2', 'segment_3', 'segment_1', 'regressor_3', 'segment_1', 'segment_2', 'segment_3', 'segment_1', 'segment_2', 'segment_3', 'regressor_1', 'regressor_2', 'regressor_3', 'regressor_4', 'regressor_5', 'regressor_6', 'regressor_7', 'ascending,expected', 'segment_1', 'segment_2', 'segment_3', 'segment_4', 'regressor_1', 'regressor_3', 'regressor_2', 'regressor_2', 'regressor_1', 'regressor_3', 'regressor_3', 'regressor_1', 'regressor_2', 'regressor_2', 'regressor_3', 'regressor_1', 'segment_1', 'segment_2', 'segment_3', 'segment_4', 'regressor_2', 'regressor_3', 'regressor_1', 'regressor_3', 'regressor_1', 'regressor_2', 'regressor_2', 'regressor_1', 'regressor_3', 'regressor_1', 'regressor_3', 'regressor_2', 'ũ  ĺ    ȕ) İɱ  _ɋȠƼ ', 'ascending,expected', 'regressor_1', 'regressor_2', 'regressor_3', 'segment_1', 'segment_2', 'segment_3', 'segment_4', 'segment_2', 'segment_4', 'segment_1', 'segment_3', 'segment_3', 'segment_1', 'segment_4', 'segment_2', 'regressor_1', 'regressor_2', 'regressor_3', 'segment_4', 'segment_3', 'segment_2', 'segment_1', 'segment_3', 'segment_1', 'segment_4', 'segment_2', 'segment_2', 'segment_4', 'segment_1', 'segment_3', 'top_k,n_segments,n_features,expected', 'Ȉ ϱ      \\x9d     \\x9d ', 'ranked_features,features_to_drop,expected', 'segment_1', 'segment_2', 'segment_3', 'regressor_1', 'regressor_2', 'regressor_3', 'regressor_4', 'regressor_3', 'regressor_2', 'regressor_1', 'regressor_4', 'regressor_4', 'regressor_3', 'regressor_1', 'regressor_2', 'regressor_2', 'regressor_3', 'segment_1', 'segment_2', 'segment_3', 'regressor_1', 'regressor_4', 'regressor_1', 'regressor_4', 'regressor_4', 'regressor_1', 'segment_1', 'segment_2', 'segment_3', 'regressor_1', 'regressor_2', 'regressor_3', 'regressor_4', 'regressor_3', 'regressor_2', 'regressor_1', 'regressor_4', 'regressor_4', 'regressor_3', 'regressor_1', 'regressor_2', 'regressor_2', 'regressor_3', 'regressor_1', 'regressor_4', 'segment_1', 'segment_2', 'segment_3', 'ɋ  ː Öͷ˯  %¤ ʒ \\x94  ţĪ˵ Ϋ   ', 'regressor_1', 'regressor_2', 'regressor_3', 'segment_1', 'segment_2', 'segment_3', 'segment_4', '    ¬         ', 'segment_4', 'segment_2', 'segment_4', 'segment_1', '\\u0382łȯ ϗ\\x8dĂ ĘƵΠ¸   ģ    ùʟ Ƨ̤    ʡ  ĵɏ  ȩ ', 'segment_feature_ranking,feature_segments_ranking,expected', 'segment_1', 'segment_2', 'segment_3', 'segment_4', 'regressor_1', 'regressor_2', 'regressor_3', 'regressor_4', 'regressor_1', 'regressor_3', 'regressor_2', 'regressor_4', 'regressor_2', 'regressor_4', 'regressor_1', 'regressor_3', 'regressor_3', 'regressor_1', 'regressor_4', 'regressor_2', 'regressor_1', 'regressor_2', 'regressor_3', 'regressor_4', 'segment_2', 'segment_1', 'segment_3', 'segment_4', 'segment_1', 'segment_2', 'segment_3', 'segment_4', 'segment_3', 'segment_2', 'segment_4', 'segment_1', 'segment_3', 'segment_1', 'segment_4', 'segment_2', 'segment_1', 'segment_2', 'segment_3', 'segment_4', 'regressor_2', 'regressor_1', 'regressor_4', 'regressor_3', 'segment_1', 'segment_2', 'segment_3', 'segment_4', 'regressor_1', 'regressor_2', 'regressor_3', 'regressor_4', 'regressor_1', 'regressor_2', 'regressor_3', 'regressor_4', 'regressor_1', 'regressor_2', 'regressor_3', 'regressor_4', 'regressor_1', 'regressor_2', 'regressor_3', 'regressor_4', 'regressor_1', 'regressor_2', 'regressor_3', 'regressor_4', 'segment_2', 'segment_1', 'segment_3', 'segment_4', 'segment_1', 'segment_2', 'segment_3', 'segment_4', 'segment_3', 'segment_2', 'segment_4', 'segment_1', 'segment_3', 'segment_1', 'segment_4', 'segment_2', 'segment_1', 'segment_2', 'segment_3', 'segment_4', 'regressor_2', 'regressor_1', 'regressor_3', 'regressor_4', 'segment_1', 'segment_2', 'segment_3', 'regressor_1', 'regressor_5', 'regressor_2', 'regressor_4', 'regressor_3', 'regressor_5', 'regressor_2', 'regressor_3', 'regressor_4', 'regressor_1', 'regressor_1', 'regressor_2', 'regressor_3', 'regressor_4', 'regressor_5', 'regressor_1', 'regressor_2', 'regressor_3', 'regressor_4', 'regressor_5', 'segment_3', 'segment_1', 'segment_2', 'segment_3', 'segment_2', 'segment_1', 'segment_3', 'segment_1', 'segment_2', 'segment_1', 'segment_2', 'segment_3', 'segment_1', 'segment_3', 'segment_2', 'segment_1', 'segment_2', 'segment_3', 'regressor_5', 'regressor_2', 'regressor_1', '©Ǥ˴ 6  ρ   ;  \\x9a  ̞\\x97 sΟ Ȃ ̲  ɽ', '   ', 'segments,features,expected', 'segment_1', 'regressor_1', 'regressor_2', 'regressor_3', 'regressor_4', 'segment_2', 'regressor_1', 'regressor_3', 'regressor_2', 'regressor_4', 'segment_3', 'regressor_2', 'regressor_4', 'regressor_1', 'regressor_3', 'segment_4', 'regressor_3', 'regressor_1', 'regressor_4', 'regressor_2', 'regressor_1', 'segment_2', 'segment_1', 'segment_3', 'segment_4', 'regressor_2', 'segment_1', 'segment_2', 'segment_3', 'segment_4', 'regressor_3', 'segment_3', 'segment_2', 'segment_4', 'segment_1', 'regressor_4', 'segment_3', 'segment_1', 'segment_4', 'segment_2', 'segment_1', 'segment_2', 'segment_3', 'segment_4', 'regressor_2', 'regressor_1', 'regressor_4', 'regressor_3', 'segment_1', 'regressor_1', 'regressor_2', 'regressor_3', 'regressor_4', 'segment_2', 'regressor_1', 'regressor_2', 'regressor_3', 'regressor_4', 'segment_3', 'regressor_1', 'regressor_2', 'regressor_3', 'regressor_4', 'segment_4', 'regressor_1', 'regressor_2', 'regressor_3', 'regressor_4', 'regressor_1', 'segment_2', 'segment_1', 'segment_3', 'segment_4', 'regressor_2', 'segment_1', 'segment_2', 'segment_3', 'segment_4', 'regressor_3', 'segment_3', 'segment_2', 'segment_4', 'segment_1', 'regressor_4', 'segment_3', 'segment_1', 'segment_4', 'segment_2', 'segment_1', 'segment_2', 'segment_3', 'segment_4', 'regressor_2', 'regressor_1', 'regressor_3', 'regressor_4', 'segment_1', 'regressor_1', 'regressor_5', 'regressor_2', 'regressor_4', 'regressor_3', 'segment_2', 'regressor_5', 'regressor_2', 'regressor_3', 'regressor_4', 'regressor_1', 'segment_3', 'regressor_1', 'regressor_2', 'regressor_3', 'regressor_4', 'regressor_5', 'regressor_1', 'segment_3', 'segment_1', 'segment_2', 'regressor_2', 'segment_3', 'segment_2', 'segment_1', 'regressor_3', 'segment_3', 'segment_1', 'segment_2', 'regressor_4', 'segment_1', 'segment_2', 'segment_3', 'regressor_5', 'segment_1', 'segment_3', 'segment_2', 'segment_1', 'segment_2', 'segment_3', 'regressor_5', 'regressor_2', 'regressor_1', '  ɦ   ˫ Ͼ      ąʳ ', 'segment_2', 'segment_2', ' ̀Ȉ     Δ \\x93    ƐΨ ) >  ¸', 'matches,n,greater_is_better,expected', 'segment_1', 'segment_2', 'segment_3', 'regressor_4', 'regressor_7', 'regressor_5', 'regressor_5', 'regressor_7', 'segment_1', 'segment_2', 'segment_3', 'regressor_4', 'regressor_7', 'regressor_5', 'regressor_4', 'segment_1', 'segment_2', 'segment_3', 'regressor_3', 'regressor_2', 'regressor_1', 'regressor_1', 'regressor_2', 'segment_1', 'segment_2', 'segment_3', 'regressor_3', 'regressor_2', 'regressor_1', 'regressor_1', 'regressor_2', 'regressor_3', '        ȫ ', 'use_rank', 'top_k', 'feature', 'target', 'regressor_1', 'regressor_2', 'regressor_3', 'regressor_4', 'regressor_5', 'use_rank', 'top_k', ' Ι   ͭ  Λ      ê     ', 'ƞ ż  ˢ ɺ ļ    ', 'all'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['target', 'add_const_target', 'target', 'lag', 'H', 'Tes̈ʹt tȌhȜϔͅat SΙ½fĶkǞ\\x85leʼaˁrnPerSĆegǭmãeģϖnǣtφMϟȜ̞oŤdeȗρϡl s̞aveΡsÃ theʗ͉ň Ťl˲iéstʴ of regâɚre\\x87|s̕sɠorϭƮξs fȅ̆r$o˸Ǿmv ͫdatșǢaħ˺ʻsŝet Ήonʗ fiűťȿ.Ⱦʮ', 'model', 'Teζst thŊat th̖Ȝeϥ ͙numbeÏƔr of5 f͒eaʗtuEres ΗusĬed by SĉkŮlearnPɱerS¹egmentMĒodɲel is ͏theƣ ¦same as the nuʯm˒bȇǙer| of reg;ressorsʙ.', 'model', 'model', 'model'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <6x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['Chǌeck thRat ΎgennǠeȁȯra\\x91ted_đvaƾlue τisȬ ôeǞqGğuǣaϙl ŕtˁ´oɲļ eûǮxpŰectedʜÒȈ_ʥv¡alueǪ.', 'ϕȄCϩheǏ2ckƮƏ that genɖeratʤed_va¡lûue\" is ƈρnot\\x84ϮͷͶ˨Ņ̻ geqÿualϡ to eůͅĈxp˼˭ɟ˦ected°_#ϋǠvaŊlǈuȴe,ƎˋΪ but wΫitͿͥhiĢn϶ͬ̂ \\u03783 ͱsigoϗǮϕɕmŒľǵʳa ͦȸr;Ʃang͟ȝeȐ.7', '_     ʹϷʹ  Ϣ\\u038d  ȗ\\x7f Ƚ ì ', '2020-01-01', '2020-01-01', 'add_noise, checker', '2020-01-01', 'add_noise, checker', '2020-01-01', 'segment_0', 'segment_0', 'segment_0', 'segment_1', 'segment_1', 'segment_1', 'add_noise, checker'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['\\nMIT License\\n\\nCopyright (c) 2017 Taylor G Smith\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\n   \\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n', 'ʋŦWʭrappeǹr ϸfĿor Ɵ̖`Ġ`´chΐe÷ǿĹ̙cȋk_aŠȵrrϴ\\x99ʢȭ´˙ƿǢ͌ay`ƹ`ýû.ɾ and `ŖÔǇ̽ƩϮ˛`\\x9eco_lʪumĮn_ŮorŻ_Ńɽ1d`ʏɔΚȽ`Ƒ fόr͠Ϣom±Ι 2̕sklƇ>Ͼåeaʈr%n\\n¹a#bkUWy\\n̫PŢa\\x82ʠÀώra\\x88me̍ters˟\\n-ȼ-Ǿ-ˀ-Ą----Ư-\\x82-\\nʶЀyγǜRάͲʹĹωƝ : arǠraǯʂyƸϞ-likͳeũʍǼ,! shapeʼ=(õͦn̏̃_sa˱ɾˈɄm®\\x9dpͰlɡĐesʙŻ,ɣǾΚ̈̓ǅϴ˅\\x88)ȴ\\x83\\n ͅ   NɝΊThǒŕeʌ̑ c1ǥźdʴ e¯n͑ΞdƧo\\x8fȞgɐüȆèʂƚno¨\\'uϋ¶Žs arr͜ayΥ̬.ʦ\\nʇ\\ndĘt̯y¤ŪGpeɄ ȉ: sʀtϣrÎiǞng̡,ĜȠ Ștyě͛pe\\x91 orǶ NonϜȰ̆eƿ ǑÑ̬(C̲ȡdeĞɶfʾaţȁult=˱Ϻ+np.fl\\x92ͺoaýǳt6\\x88®4\\x80ȆĪˣ)Ăɡʿ\\n  Dʸata tȺ̿ype ϨΞȚof reĠΎ̭Ēsu\\x85ΏlȾt̕. η͊IŷÊfϐ None¯,ˋ th͗eý\\x86 dtɈyĢpe oÓŬfĦŦ tþΛhe> inƋp͙utϗǣʠ iƽs ̇˞pΒ\\x98rȍeĻsͯϡer^vÖEedɄʒ.ΔČƕ\\n\\n  Ť  άĪΥLȀf _ē\"οnumeę̨ʜr1ic®\"Δ, \\x93\\u0379́˹ÞdϘϐģtype ˬiϡsǯ prŌ˵eǊserǋȫveϥˤĆdʫʅŤ͉ unle\\'ss ǽϒͿ\\x85arrȾay.dú̖³t̑ype \\x94isΠ objĈeĳŌct.ĳƃ\\n\\ncop~ʤy κ:( ǻbǫʰ\\u0382oϷo!̒l,ΰ optioͺ/naˀϺl (defauŚlt˴=ɢFaȪlɒϡƈ͗s̓e)\\n ̡   WheſϏtɢʰhe̙rǕ a řfoɳrceɣdκÕ\\u038b copy will ϋbRĻɧe tιmriϛggeʐÌr\\x83ϳed.̩ė ˪ĞIf cͼopy=˨ʅʏM͙Falseή¸, Da cŹopĨyɈ Εëmiʻgƥǹht̎g\\nǴ  Á ˺ \\x9eϸɑƣ¼Ħ̨stͺ˷ǝilDȗl be ɯtÍϞŬυrǥͷΊɪiggʄĤerβIedì bϰˏy a̗ţɥͮȦ!ϓŵ ƭĒϚͲćoŭnverÆsioǥn϶_ɍϠ.ȧŠ\\nȪϯȨ\\nɴfϒorǁcΫ*e_aǟll_fi.nɭit̊e :Ȩ̵ bˮɦooÊʌl,̑ optiʕonvaTɶ\\x91Ãl ͠(d¹ΉefaulΉtŷϿ=FaͫĨl=se˭)\\n˳  ýť δ ŚÈWΒheǌ˓therçη to˹ƛr r˘aʌíiȗseϥǒȗ τan̵ eÍr+rɏoȬr oǕ́n ͻnp.ɪâͦin̛=f ÁandŤ nΛpG.naɸnϏ ̡ziʦųĜn˯ģ ɅňΆa˛Ƚn ̙aɶϻ͖rʪ^¾̎ʫraʨʞy. ďTh\\x8be\\n   \\n  ȴǆ͟ɼ ɑɡ pϦosǟ#siƒbƞi\\x94Φl3iƪtiesƟŶ ȍƛare:Ɛʿ\\n\\n   \\n   \\n  ˥ʧˋ  [Ȅ- TEͱκr̫͏ǠuΘeϕ˖þ:˰ɡɓ Force ařll values of KarĠray to ɚbe ǞfΪin½ʇit\\x84ςƝe̷ʖŞ\\x8c.\\n\\n \\nπɋŐ  ^ ƭɜ\\xadƓ - Falũs\\x99°˨e: a̐cɡʷcep}tƏ= ǿboth np.iÏnf an˂˂̺d̥,EϜɄȜ np.nan\\x9eH inǅ arrayű.\\n\\nÿReturnǐɸs\\n \\n-Ǻĥ--ƫ̃--Ĉ--òȐ\\nɭy : ʽ͔ʭnp.ɻ̝\\x90ʎndƙarrť)KĮÃay, \\x83s̋Ǚʅhapƃeɨ\\x86¯=\\x8f(nʳ_ŭs}ĵaŉmples,)\\n  \\n  AëʵǓ 1˱ˢdñ nýumȟpy 4nΊƝdÕĴarɬraʛȢÜćyιœƛƀ', 'CÜonv˖*erót Ô˧ARMA coefficientˑs to inXϙfinƋǬit̖e \\u0383MΰA6 coeffiŬcieϷȞŷntsΙ.\\nCompute ŪcϖĚoefficientˣsć Úof MA modeΆƠŻl e{quivaleψgnt to given ƕAʷRMΉA model½.\\n̟MȉA cɟoûȍefficĩents Ίʡʨ̢are cutÖ oȌff at Άɮmax_d\\x94eg.\\nȖThe Ðsame fun\\x96ctɨiǥon aŠs ARɷMǎA·tǃƠ˼ˈoMA(˹˫) in stat\\x97s librar̈́yÊ of9ϑ RƏǐ\\nParaUXmeters\\n---ȯ̈-µΧ------\\n   \\nar : arraƐ͝y-lͦik·e, shÓape=(n_orde˘rsȥɘ,)\\x8a\\nƭʹƄ  Theΐ aϨrray Ǜof ΑɥAR cƜoeffiűcαieˋnts.\\n\\x8bma : array-lƿikŭe, shap̊Ϻe=\\x90(n_oƑrώdɨer+ŉǐs,)\\n ɞ   The aǮrra\\u03a2y ̘of úMĨĒA coefϙficÞiʝentǖs.\\n \\nmέax_de\\u0383g : εinåt\\n  · Ǡ Coe̷fficients aˍre ç\\x82omputed up toį theǋ order of maϕÛx_ēdĜeg.ũ\\n   \\nÿRbeǭŐturns\\nɓ-------\\nnɻpǎ.ndarĒrayǡ, sh̚ˬape=(max_ˉdͭĩeϣgČ,͏)±˛\\n   Ë EqˮϡuivĤ¸alentʪɆć MA coe̕Ŝffi·˯<cĜiɂents.\\nNÒotϙeÁs\\nn͞-ϯ--\\xad--#FOyRanYD\\nHere is ĩtƻhe{ 6derήivőǁatžioʲn˨. Supˆpose AΣ͋ɇRMA m$odel is defʶinʐed ɧas\\n..ͨì ȚmaϜth̾::\\nx_t Ξ-Ȳ aɈr_1*ϻxǍ_{̶t-1} - aȑ_2*ſx_{\\x96t-2} - ... þ-Ũ aǵr_p*x_Ǟ{t-!p}\\\\\\\\\\n   \\n   ü = e_t TŇ+ maµ_1*e_{t-1ŵ} + (maʒ_2*ƿeϭ_{ɬt-2Ρ} +E ... + ]˃mʵa_q*e_{t-q}\\nn̪amel̞y\\n \\n.̳. ƮmaɣthG::\\n   \\n(1 - \\\\̖sumĒ_{i=1}^p[ar_i*B^iʫƸ]) x_t = ɡ(ğ1έ + \\\\suVm_{i=1ĝϩ͟}^qŷͬ[ma\"_iơ*B^ŭi]͖) e_¸ƒt\\n   \\nwheȘre :matǵhμÓ:`B` ȷīis a Ƭbac\\x8ckwarŎdſ oϱpera\\x83t̋or.\\n   \\nEqĀɥui±ǧvalύ͡ent MA model isx\\n.. ȼmath::Ɲ\\n  x_t\\u038d = (1 -\\x8a̵ \\\\suĀmʄ_{i=˩Ê1}Ĭ^p[ar_iŋ*ŲB^ćſiΛ])Ú^{-1Õ}\\\\¢\\\\İ\\nĴ  * (1 + \\\\sum_ļ{ϭiϫ=Ô1}^q[ma_iU\\x98*B^iK]) e_t\\\\Ϝ\\\\Ŀã\\n  \\nǼ Ġ   =ğ˯ (1 + \\\\s±ɟǒ\\u0382\\x8aǺum_ɝ{iā=1}[eÝma_iϚ϶5*B·^iȇ]ĵȡ) ɘ͊e_˯t\\nwśh;ereʠ :mN\\x92aưtΫhɎ:``emϪa_i¶`` ỉs aɣ δc\\x8boefficientɾ boVfʏ eǭquiʘvaleÃnΏt MA mo\\u0378delű.\\nThe :m͛athɂ:`ɲ`ƽema_i`` satiˀsɰfiĜes̮\\nϤ..̲ matɞ0h::\\nʼ  (1 - \\\\sum_ä{ói==1}^p[ar_i*Bá^iŒū]) * (1 + ×\\\\ā\"sum_ť{i=1}ɠ[eɠmaǳ_i²*B^iSȖ]) ύ\\\\\\\\\\n ɋ   = ΐ1 + \\\\Όsum_{i=1}ϑ^q[ma_;i*B^i]\\nthus\\nǛŏ&.. math::ʉ\\n\\x92 Ǫ© ſ  \\\\sɄˣ˅um_σ{iɕ=k1ʞ}[em̪a_i\\x92*B*^i]© = \\\\ɱsuƬmĉ_{i=1ʤ}^p[ar_i*BÂȰÈ^i]è Ϭ\\\\\\\\˅\\n  + \\\\sʨum_{̯i=1}^pƘɏ¦[ar_i*B^i] *Ȭ \\\\sum_{j=1X}[ͻǍĻema_j*B^j] \\\\\\\\\\n Ν   + \\\\ßSum_{i=1}^qz[Ϊma_i*B^Ϯi¬]\\n\\nthž̃erefoÉre\\n.. ΈEmath::\\n   ȗ emÁa_i =ʻÚŇ ar̵_i ɏ(ǐbut 0 aÄifϽϪ ͚i>Ðp) \\\\\\\\r\\nȑ  Ũ+Œ \\\\ύSum_{jN=1}^{min(Ŝi-1,p)}[aϢr_Ď˖j*ʐem̐a_{i-\\u0383j}] + ma_Ƹi͵(bǐut 0 if1 iɝ>q) ģ\\\\ƒ\\\\\\n \\n  ǟ  =ĐɝȞ !\\\\sum_{Ɲj=1}Ŵȹ{min(i,̥Ŏ̜p)}[ȳͱŸƘarɴ_j*eͣma_͙{i¡-j}(but ̒1 if j=˸iȆ)] ̪\\\\̈́\\\\\\n  + m̋a_iȂ(but 0ɹ if i͋ʚΰ>q)', 'simple_differencing'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['β  Ƞ ˄  +  ͝ɼ ', 'Transform is not fitted! Fit the Transform before calling inverse_transform method.', 'target', 'Subtract trend and seaso͖nal cĤoɺmponent.\\n\\nParameters\\n-----õ-̍Ǭ--͂--\\nϫdf:\\nί   ɦ ǒFeature¢s dataframe with time\\n\\nReturns\\n--Ɠ-----\\nresuʲlt: Åpd.DataFűrame\\n  Ű ˌɔ DatNaframÚe Ȅwit̩h eĝxtraŽctȩd featuΟres', 'Transform is not fitted! Fit the Transform before calling transform method.', 'arima', 'arima', 'order', 'holt', 'trend', 'add', 'Not a valid option for model: ', 'Model should be a string or TimeSeriesModel', 'ÙϠPɄer̗ΝŸōfoĨrm SˆÞTL deΉcʋomposiƿt\\u03a2i̞\\x96ΖoȥǚnȀƿ anŌd fi̡t tº rend mĈo{¥de¸lς.Ï\\n\\n \\nP˲Ə aŭrȖa\\x88ʑmǚe\\x95Ǐteǖ\\x82rsΏ\\nǎ--ƫ---ōƂ̺-----¦z\\ndġfň:\\n  S  Featu\\x84res̍ daΩtafr\\x8aame]ː wñitǼΧhϞÌ ķ®tΘiƧme\\n\\nRet͗urnkɜs\\n----ƛ---\\nreªMƐãsʑ¾u̙6lʖt:ėƄφ ͏ŵa_OȓɜnʕeĸɕʂSegmentS¢TLTr˟ansf\\x89oĖɻĺ̵ɺrĥm\\nëʼ  in̤stancƉeů ϾƯaéϫfteǵĖ\\x96r proces˭ʷsi\\\\Ǘng͏̪=', 'The input column contains NaNs in the middle of the series! Try to use the imputer.', '_OneSegmentSTLTransform', 'arima', 'I˔niς̣t ǯSTLTran3sīɲ˾αĒfor͕ʺħm.ƔĔ\\n#EDJNKHfUSyTu\\nPşara͋ωÁmżepátersȄǡ\\nŌ-----Ț-Ń-\\x9bΆ---3\\nin_co˺lŚumn:@\\n  ünϧĦaçǫme oɦf pɓrȨoɹceÓssƞ˾eŶɠd̈ colum˨ȵn\\nperʒioǹdΚųʚ:\\n pĔ Ζ ʰʅ sŔŃize of seʙ-ason˩ɕƅaǀlǚ\\x98\\\\iˠty\\nmo̾del͔Ĩͼζ:\\nß e à̃Ŀϡ \\x88 model to pȜrǼ*ɋedict ɝtʌrˏgendǂ,Ċ ̔dϨefaƜult øoptions areK:\\n   \\n\\n   #RW\\nȧȎ  1. ʤʕ\"a͙r9ima\"ˁ:ʩ̋T `̥`ARΖIMȱͺʾA͍(űdataˀì\\u0383Ôë3F,ʒ \\x881, 1, ͲŨ0͵Ơ)\\x96Ϊɖ_`ĚË` (ÆdefaÅult)\\n\\n ɽ ƽ  2Ϡ.ͅ \"hźolt\"!: ``ʳETȤSModeǦl(daɋta̫,ʫŐɳ πtrend=\\'adǪd\\'ʶ)``\\n\\n   \\n   \\n   έ ZCustom« modʞelί sho\\x8buˀld bMeɼ *a suέ̣bűϾclθa̧sΠş of ̄\\x9bʽ:ͫpy:cϦ˯l̋ass:ɳ`st˽at̑smodelsˌ.ɫͪtsaʊ.ūƩáδbas®e.tsa˷\\xa0_modelÕˉ.ċ\\x88¸ɭTime˻Se̫ąriesˁModȔel`\\nɥ ʳÙ  ͫ aƮnd haʫveĩ mweˣth̆odƆč ˗́Ȑ``ge*åt˛_ƶpˮrΞ̿ed\\x99Ɠ3icƲtiƍ̿on`ʉ`Ɯ (n̒oϤt jusɁt¾ `Ĕ`pre ˪dϚiǉct`\\x9e`\\x94)\\nˣrobust:λ\\n Ŝ͋ \\x95 ɢ ĸflćȜagε indȯicating ¢wõhǓetherǦ tėo Ʃu̍ϔ\\x80se robuΜúspt ver˄ʫsiKoȞĜnL of ƔSTL\\n  \\nmodțe̪lʈˤ_kwaͪtr͗gsή:\\n Φ˳ õ  \\x86̔\\xadp̬a8ʘrametȕƀerͼs fǤorơʋ tĥhϩȑŔe ċmoœͫdeĿǁl(|ǟ likȫe inǿ :py:clŒassƻ:\\x9d`statĀɿsmode!üȳ͔ęls.tsa.ɕsIeaτsŞonal.ST̜L?ForecaƳst`\\nstēlÖ_ĵ́k\\x91°ϐwarĘggƖs:\\n  Tɻ ưŧ adÝdi˟tiũonal paraǽmeǁǸͤÍters ΐfor -:py:τcʎlass:`statsmod˝eīlκƝbsÝ̹ĎŘ.tsa.săeaƂsona̖l.SǬTL·Ŷ`FForecast`˧'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['models, transforms, horizons, message', 'target', 'Lengths of the result models is not equals to horizons or transforms', 'target', 'target', 'target', 'Lengths of the result transforms is not equals to models or horizons', 'target', 'Lengths of the result horizons is not equals to models or transforms', '  ͛     ˽   Ľ', 'models, transforms, horizons, expected_len', 'target', 'target', 'target', 'target', 'target', 'target', 'target', 'target', 'target', 'target', 'target', 'target', 'target', 'target', 'target', 'target', 'models, transforms, horizons, expected_transforms_lens', 'target', 'target', 'target', 'target', 'target', 'target', 'target', 'models, transforms, horizons, expected_len', 'target', 'target', 'target', 'target', 'target', 'target', 'target', 'target', 'target', 'target', 'target', 'target'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['     Â\\u0383    ǁ3   ̀ˑøǗ ǩ ėΣ Ƕ', 'margin', 'dim', 'sample_size', 'approximate_logc', 'dim', 'max_logk', 'sample_size', '         ǚ Ǩß  ©     ', 'dim', 'max_logivar', 'parametrization', 'exp', 'train_epsilon', 'sample_size', 'dim', 'max_logivar', 'parametrization', 'exp', 'train_epsilon', 'sample_size', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['quality_scc', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <6x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['\\nMIT LICENCE\\n\\nCopyright (c) 2016 Maximilian Christ, Blue Yonder GmbH\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated\\ndocumentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the\\nrights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit\\npersons to whom the Software is furnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the\\nSoftware.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE\\nWARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\\nCOPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\\nOTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\\n', 'auto', 'Calculate the releΙvaȾnce table for the features ϕcontained in feature matrix `X` withς respect to target vector `y`.\\nThe relevance table is calculated for the intendΖedͩ mͰachine learning task `ml_ͳtask`.\\n\\nTo accom·plish this fɧor each feature from the i³nput pandas.DataFr7ame an univarșˈiate feature significance teͩst\\nisϬ conducted. Those tests generate Ϭp values that are then evȧluated by the Benjamini Hochberg procedure to\\ndeci̊de which fȑeatures to keep a͖nɇd which to delete.\\n\\nWę are testˠing\\n\\n    :math:`H_0`ǽ = the Featuɗre is not relevant and shoulȷŐd Ɲnot be ad̨ded\\n\\nagainst\\n\\n    :math:`H_1` = the Feaʥture is relevant and should be kept\\n\\nor in other wordʤs\\n\\nɝ    :math:`H_0` = Target and ˦Feature are indepeǙndent / the Feature has no influence on the target\\n\\n    :math:`H_1` = Target and Feature are associated / dependent\\n\\nWhen the target iɫs binary this becomes\\n\\n    :math:`H_0 = \\\\left( F_ɟ{\\\\text{target}=1} = ̏F_{\\\\Ðtext{target}=0} \\\\right)`\\n\\n    :math:`HĹ_1 = \\\\leόft( F_{\\\\text{target}=1}Ǆ \\\\neq F_{\\\\text{target}=0} \\\\right)`\\n\\nWhere :math:`F`Ǚ is the distribution of t̄he targeʯt.\\n\\nKIn the same way we can stateĢ the hypothesis when the feature is binar\\x82y\\n\\n    :mathξ:`H_0 =  \\\\le˥ft( T_{\\\\text{fe˪ature}=1ȡ} = T_{\\\\text{feature}=0ƚ} \\\\Șright)˱`\\n\\n    :matňh:`H_1 = \\\\left( T_{\\\\text{feature}=1} \\\\neq T_{\\\\text{feature}=0} \\\\right¶)`\\n\\nHere :math:`T` is the distribution of the target.\\n\\nTODO: And Šfor real \\x9fvalued?\\nˤ\\n:param XʣŎ: Feature matrix in the format me˴ntϔioned before which will be reduced to onlʸy the relevant feȩatures.\\n          It can coƁntǕain both binary or real-valued featu϶res at theġ same time.\\n:type X: pandasǥ.DataFrame\\n\\n:param y: Target vector which is needed to test which features are relevant. Can be binary or real-valued.\\nγɦ:type y: pandas.Series or numpy.þndarrayů\\n\\n:param ml_task: The inteųnded machine learning task. Either `\\'classification\\'`, `\\'regression\\'` orϮʆ `\\'auto\\'`.\\n                Defaults to `\\'autoɏ\\'Ŧ`Ͻ, meaningǋ the intȇended task is inferred Ǚfrom˟ `y`.χ\\n                If `ȑy` hϿas a boolean, integer or object dtype, the task is assumed toĒ beƫ classification,\\n                els˘e regression.\\n:type ml_Ϥtask: str\\n\\n:param multiclass: ¸Whetheͨr the problem isż multiclass NclassificQation. This modifies Ǯthe way in which features\\n                   are selected. Mulǰticlass requiǠres the features toϔ be sta̚tistically significant for\\n                ̱   predictȲinèg n_sigÌǍnŁiɜficant classes.\\n:typSe multiclass: bool\\n\\n:param n_significant: The number of classes for w̚hich features should be statistically significant prediʗctors\\n                  ϫ    to be regarded aɹs \\'relevʏant\\'\\n:type n_significant: int\\n\\n:param test_for_binary_taιrget_,binary_feature: Whiþch test Ýto be used \\x8afor binary target, binňaƣry f͉eature\\n                          Ê    ͇                (currently unused)\\n:type t\\x8cest_fǺor_binary_target_binaȃrχy_feature: str\\n\\nɤ:param test_for_binary_tϿarget_real_feature: Which test to be used for bináry target, rea̘l featVure\\n:type test_for_bɕina˓ry_target_real_feature: str\\n̩\\n:paraRˌm͕ test_for_real_tar/get_binary_feature: Which test to be used for real target, binary fme\\u0383ature (currently unused)\\n:type test_ĵfoǟr_real_target_binary_feature:͖ str\\n\\n:param ǔtest_for_reaωl_target_realō_feature: Which tesγt to be used for rįeal target, real feature (currently unused)\\n:type test_f@or_real_targeϝt_real_feature: str\\n\\n:param fdr_level: The FDR ̓level th\\x81at shˢoulͣd be respected, thisʩ is the tčheͱoretiʽcal expect¤ed perc̪en˼tage oΘf irreĘlevant\\n ʬ                ă featurƪes ä́mong all created feͨatures.\\n:type fdr_lóevel: fΑloat\\n˥\\n:param hypotheses_independent: Can the s͖ignificance of the features be assumed to bȽe indeʗpendent?\\n           Ǻ  ½                χ  NormϹally, this shoʆuld be set to False as the features are never\\n        e         ĵ              independent (eĽ.g. mean and median)\\n:tÝype hypotheses_independenϸt: bōol\\n\\n:param n_jobs: ϕNumber of processes to us̆e during the p-value Ǝcalculation\\n:͕type n_jobs: Ŵint\\n\\n:param shoow_warnings: ShowŴ warni\\\\ngs during the p-value calculation (needed for ǋdebugging of cǓalculators).\\n:type show_warnings: bool\\n\\n:param chuϬnksize: The size of one chunk thaƬt is submitted to the worker\\n    process forǸ the parallelisation.  Where¥ one chunk is defined as\\n    the data for onκe feature. If you set the chunksize\\n    to 10, tƭhen it means ṯhat one task is to filterƋ \\x8a10 features.\\n    If it is set it toƖ None, !depending on distributor,\\n    heuristͬics are used to find the optimaÙl chunksize.ĥ ͲIf you get out of\\n    memory exceptions,ǣ you can try it with the dask distribu\\x90tor and a\\n    smaller chunksize.\\n:type chunksize: NoŜne or int\\n\\n:return: Aǽ pandas.DataFrame with each column of the input ̘DataFrame X as index with informatȩion on the significance\\n         of thΊis particular feature. The DataFraΖme has the columns\\n         \"fƻeature\",\\n ʠ        \"type\" (binary, real or cŦonst),\\n     š    \"p_vūalue\" (the significance of this feature as a p-value, loͰwer meVans more significant)\\n         \"relev̹ant\" (True if the BeǠnjaminiν HoŴch˾berƠg procedure rejected the null hypothesis [the feature is\\n     ͜   Ǆ not relevant] for this feature).\\n         If the pro͑blem is `multiclass` with n classes, the DataFraʇme will contain n\\n         columns named \"p_value_CLASSID\" instead of the ϼ\"Ϲp_value\" column.\\n         `CLASSID` referͅs here to the different ξvalues setͽ in `y`.\\n  Ǚ      ÷ There will also be n columnύs named `relevaȀnϝt_CLASSID`, indicaÂting whether\\n         the feature is relevant for that class.\\n:rtype: pandas.DaũtaFrame', 'The index of X and y need to be the same', 'auto', 'classification', 'regression', \"ml_task must be one of: 'auto', 'classification', 'regression'\", 'auto', 'classification', 'ml_task must be classification for multiclass problem', 'n_significant must not exceed the total number of classes', 'Two or fewer classes, binary feature selection will be used (multiclass = False)', 'ignore', 'default', 'feature', 'feature', 'type', 'real', 'binary', 'constant', 'p_value', 'relevant', '[test_feature_significance] Constant features: {}', ', ', 'classification', 'feature', 'type', '_', 'feature', 'type', 'outer', 'n_significant', '^relevant_', 'relevant', 'n_significant', 'feature', 'regression', '^relevant_', 'n_significant', 'p_value', 'relevant', 'No feature was found relevant for {} for fdr level = {} (which corresponds to the maximal percentage of irrelevant features, consider using an higher fdr level or add other features.', ' Ͷ     Ǹ ƙόƥ', 'p_value', 'p_value', 'fdr_bh', 'fdr_by', 'relevant', 'p_value', \"Ͼ̰̈ƈˡIĎnȣfer ɜʋɯtheȬÜ ɨ8^mϱach͔iȉĶ£neͰ Æˈɗlea\\x9drningȅ taφs͎\\x8dǂŝ<k̮ \\u0383̞to \\u03a2̗sele\\u0383̘0ơcȤątȄ ƪfƲƒ́oɲβr.\\nTǚƂheɒΑ rÈ̉eĈs̞Ṷ̀͡ul¼úǃt wƾ̽ȰilǨĵξlɖ bʼe ei0ȳther Ξ`'ύĖreg'ÌrǊes˚ĥϴsiϷon'`Ȇ Ǘor Ł`'ŒclȈĘ»assǗificƏϲϱation4̷'ë`.ə\\nI?ϔf˼ ǔth˭e ¾tÐaϦ²rgetͅ \\u0382veēcʒ7torʍɝĝ ôonlěy ͓c̟ħonρίsiÂstsȹ ͮˉŉɴof iŢǓn\\x90teg˧eɆr Ytyųľp̆ed ̄va̪ˢƾĔŹlÑuς̆esȣ̎Ȩ˽Ş oŤǬ˸rh oǀbjº?ûeìcɨϖtsdŞϸ,ı we a\\x93s\\x8fsʄοWum+e tǬh¶e; t\\u038ba̿skë is `ʎΜ˦'Ŷclassi\\x8cfZi©cĳatĤ,iϲƉoĨǵn='Ž˲`ˋȬ.ʧ\\nElsΒȜe `'\\x94regression'`\\x83ϫ.\\x8d\\n\\x86Ɖ\\ņ:čp͇araŵm y: ǎTheȿ tarͯgɇʻ˼et K¸Ðvecqutor y.ƓΤŁɻ˞PΈ\\n:ÄtȂype̳ y: ¿ Ϗp̑andaʥsˡM.þɧSer°Ȳies\\nʻʀ:ϯretÉurȘnͣ:͜ \\u03a2ƿ'ϝĠclaͺssiȋficaĩtͭiŠon\\x9f´'͜ĉ oŐr '¶regɛreΦssiĪonĠ'\\nȕÈ:ȂǇVɶï\\x9bɓ}rĸ}ʻψPtyp\\u0380eϳƪ¸͋Ȟ:ƃō ¬sƣtİrΊ\", 'AllInteger', 'classification', 'regression', \"For åa given fÓeaturĳe, Ǉde˂YοϞǤxtȳǙerm̾ine if iϱtĜy\\x98 Ɨ͂is real, b͋inary orɎ conʘýstant.\\nHere bȬiÀnary ̀mϔeansǞ ɐthaÍƩt only two unique v̎alueęsǖ oVccuȷ̘rȤ in th͢e feȍaîtĠurƛϽe.\\n\\n:Ǩpar\\x80ám feaṯure_coϗͷlumnč: ıThe̜´ !\\u0383f¬eaĖtʎurTeƄ column\\n:tyƞpe featurʧe_cĮolumn:\\x86 pandȽaϯsé'.SΟeries˖\\n:̅Ʉ̽Ŕrʟ)eturn: 'conʕstŨant'̙˳, '̴binar̓žy'a or 'rȮeƢal'\", 'constant', 'binary', 'real'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <7x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Whethǜ\\u0381̹ŭer ̉͢dç̾Ǹata«ͶŇsetī øi·s clagss̅ificŦñat;iĖo̒;nŻϲ̡ o͊r ɐm͚atc\\\\hing.̔', 'ÀˏGɴeńȘt da©tasŬeáĆt˶ lab̵ě͒eξ˿lsϸŃ ša¯rɈray.\\n\\nΏLaƋbΕð\\x85e»lsƍ a̦re˥ inͽtȇg̓ers \\x9dğiďʱυʫn ~tΕh͢e rangɸeĽ [0Ƨ, !N\\xad-1ο]̴, whϯereʂʷĿĄ ΨNȽ Jǫ˂i̋͘s nu\\x99ΛmbΣPerɻ of λcˆ͐lĕasżsesϊ̕ʨĆ', 'RGB', 'MNIST dataset with different classes in train and test sets.', 'q  ͔ɵǴ  Ι   ^Šɟ Ƕđ   ͒'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['path to yaml config with desired pipeline', 'path to backtest config file', 'path to csv with data to forecast', 'frequency of timestamp in files in pandas format', 'where to save forecast', 'path to csv with exog data', 'list of all known_future columns (regressor columns). If not specified then all exog_columns considered known_future.', 'Cϖommaʖnd toĖ ůrunςϨý ΝbPacϐ\\x8bkteώÔst wƍitDh etn̆Ɍaʬ without coding.\\n\\n\\nE¯xpecteÌd formȶatʎ of csv with ϐtaǐŷrŕgēet timeseries:\\n\\n\\x08̱͔\\n==========\\x87===    ======b====ͩ=ŧ ȑĂ ===ɜ̕=======\\n Ɖˢɖ timestamp    âĞ ɜ ηό    ľsϘegmϥenƩt            tƅargƃet\\n========\\x97g=====    ====ʺ=©=˯=====    =====Ǉ=====ˈţ\\n20ː20˛-01ì-²0ϩ1        ţ ́Ξsegmóenɩξt̢_1̲ MƎ                1\\n        \\n\\n20ă20-01-0Ɣ2 \\x89        se{gƙmentƽ\\x9a_1 ġ Qȭ             2\\n2ŻÎ0Ⱦ20-01-\\x9803     ̪    sȯeȔgmeɘĺnt_1 Ǝ        Ɖ    ů    3\\ņ2Ş020-Ɣ01-04    ȗ     ̽s͎\\x84eɊ^gmentÂ_1                ǵ 4ʆ\\n...\\n2020-01-ň10 Ό    Ō    ǂͼsegmeʬn?ʍt_ĝ2 \\x9bƎ             10\\n        \\n+2ͬ020-01-11     ʉ    seí΅gment_2             č 20\\n==o===========    ω=====̲Ϳ==ʍ\\x86====    ======ɿ====\\nʌ\\nExpecɷϥΜte\\x91dƙ formatɫ of c+sv with exogɸenous timeserài̖eƸs:W\\n     \\n\\nό\\x08\\n==ǫē\\x82=Ɠ===e=====Ƨ=×= ̵ ==ʕ======¼===    ======ɽ===\\x85=q=δ=Ȇ===Ϣ    =æ==============ŧ\\nΕ͜    timestamp Ĩ        \\' seºgmen˨t3ť    ǏŲ ɛͲ̏     r̟Ȇe)Ǯgresăϊ̬sΘor_1            rǤϼe gr̝essoɓ̒ʏr_2\\n=ƨ====Ĥ͚========Ú    ===Ƿ==ȕ==Ȑ\\u0383==̩ˇƺ==    =====ª=====aʌΘ===== ș ̄====ǔ===¶========\\n \\n     \\n2̎020-01-01 Ĕ    ƴ    segmenǾͳt_1        ϳ     ̺    ƙ 11        ƒ ŵ    Ġ \\x8b˶ ʦ        n ϱ òʍ12\\n2ʀ020-01˚-0ʱ2 ªœ Ū \\x85    sègm͐heXÈnt_1ŧ                    ɋɄʬ22                     Ã        13\\n2020-01-ĵ̺0ʉȑ3O        ú segm̶ent\"_1         Ȣ Ʃ    ɼ Χ 3əȹ1̹ ʻ ΄                Ï    ϖ     g14̀\\n20¼»20-01-0(4 ʊ͐¨ ǥĢ ɋ    segment_ϓ1ϧξ        ϗǓ     Ȇ     4Ƭï2    ¯ ĸ    ;    ɺ     ͗        ̶ 15\\n...\\n˕202È0-ɓ02-10ɓ H    ŋ    segment_2        \\xa0        ϓǜ 10Ό1     ƭ    Ɇ     \\\\             61Ɣ̨\\nɍ2020-0µ2ʰ-11     ɉ \\x95 segment_2 ɽĤ        ˍǖ˟£ñƚ ʐʙ     ȼ20̣5    ^ «        Ȼ ̟         ŗ    5ʫ4\\n=============    =ĥ¶=ˊϐ====ê=====    ǵ======ë===Ą\\x91=ĔϦ==Ŧ=== 2 ===============', 'timestamp', 'all', 'timestamp', 'all', 'metrics.csv', 'forecast.csv', 'info.csv', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['ÆFit Ξencoder on Ǖexisting segment labelsĩ.\\n\\nParameƓters˖\\n---ȫ---ô----\\n   \\ndf:\\n  ͜  d͖ataf̪rªame withΚ data \\u0380toð fit laȚbel eʪ̠ncŲoder.Ó˚\\n   \\n\\nReturnôʔs\\n---ɥ----\\n:\\n   ΄ EFittήeϪd transform', 'segment', 'SegmentEncoderTransform', 'segment_code', 'segment', 'feature', 'category'], 'from': [], 'import': []}\n",
      "{'FunctionDef': [], 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['__main__', 'data', 'example_dataset.csv', 'D', 'auto-example'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['RUS', 'Frequency of data should be no more than daily.', 'segment', 'segment', 'feature', 'category', 'HolidayTransform'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <12x7 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 12 stored elements in Compressed Sparse Row format>, 'ClassDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['   ', '     È       ', 'Expected k > 0, got {}.', 'Empty index', '      ', ' ~ Ļ ΜĮɷ ̪ ? Tɱ ƓΞ Ò  Ţ  ͈', '     Ű  ̽     ', 'Ɏ Ż ̑ *}ʀ8  ŋ ¯ ȡ ͇   ʞ ȉ̠  ', 'Expected k > 0, got {}.', 'Empty index', 'faiss', 'numpy', 'torch', 'torch', 'ȫ ', ' &  Ǉ   Ύ    ', 'Eɵŕȯ    ', \"Can't create context multiple times.\"], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['           ', '   Ę ªƚßɀ ʬï   ˪ Ə   ', ' !  ̫      Ñăȿ Ȧǐ ɳ    ˾  ', 'window_size, window_step, expected', 'many_time_series_windowed_3_1', 'many_time_series_windowed_3_2'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <45x16 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 45 stored elements in Compressed Sparse Row format>, 'ClassDef': <8x8 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 8 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['ϟB\\x94asʢe claʙsǗsϴ \\u0379fƖo˷ɠƵĦ̡r al˾l ·nearίõͲe\\x86ϝsɲt nąeigh\\xadbour ɬm͝ǻeʣtricsȳ.', 'WhͤÀȥōe;ǭtʞhˑÈͯer meęʫîƏtˮÚrϧ˜iɠc ͌̀reϢquûΤir̙esɜ\\x83 coYnfiǟdeȘnces or Ωɧn̘o\\xadt.ɣ', 'Get2 th\\x98e number of rețquiεred neighbouϊrPs.\\n\\nA?rɲgsB:\\nċ    labeřlsĴʏ°Ȉ: Dataset labels.', 'Recall@K metric.', '   Ċ Ƙ ', 'ƛW˫hetheʜɕr tƇ1ΞΒǟˑo c\\xadopɠà¾ł²̠Ċ̄Ÿmpa͚rϰe Ƈ͜Ėe˫͗achί sɑamplȌɷe Ʌwit/h sǊelf orĘ noV¬t΄·.', 'GŒęeȶt Rȡth˨e nŞǽuőm̘żber o͛f΅ ȸr̬ȃϴ͕ͩequϬʗiɶȠ͈őɜredý ̄neigļhbourſs.\\nȲ\\nArΟǿȤgYs:˵\\n    ϼĬʄlĈǧaƠbelsȘ́ΉȺ: ͵DŹat$asϯeVtƟ labeɺϵϬʸŎls.', '͕EǾϮrroĻr̡˕-vΖÐɿeǋ̝şĤǓrsusΦ˶͋ϰɆ-ƭRŮe|jeɯψ ŭcƦtã-CɜurǊve ̯basÇǊñeͅd on Rƒ̊˅ͣȻöe˚call@īK mʦeºtric.ɰ', 'Whet%hbȿeȓ\\x94 œmƩeƌtrʍJȤ¤icƪ requirˡėãs po͕sˌɴiti̝ve sc̫oǱá˄r˫eÖɡs o̵Ă̼r ȼ#notν.', 'Whet\\x98ˈÞǝ̳̼herϤ to͑˝ı Œćcompare e6ȟİach samȸpǎle witƪŝh ĖsǲDelf or ünLotĲ.', \"Can't compute ERC without confidences.\", 'CʴĪompu͝tɭe metrϒiķc valu\\u0378e.\\n\\nArgs:\\n    (nearse6tǌ_sϯǥƉamΰ˴eɩ:º Binary ȋlabȲeɟlˠs\\x85 ofŴ neareʨst n¶ei˼ghɈˤbours ζϕeqƶual to 1 iff clas˭s isj equal to ʖthe queryƹ.\\n    nearest_scoreǭs: SiõmilariʣtyŦ sȥcores of Ônearest ne[Cighbours.\\n ƚ #  clas̡s_sÿiYzeŊs: Cl˦as̊s sizeŞ Øfor each ̀ğelemǏe\\x95\\x9bnt.\\n   ˟ posiϬtiveʚ_OÜscBores: SimŏͥǱilLarity scoreȩs of elemenʎtsˈ wiχŪthɀ tɴheɼ ȵsňame\\x9e ̛class.\\n  ο  coȴnfidences: Confǩidence fƼόor ʣeach ele̵meȷƾnt° of ɩ͠the bat¤ȕĜch wȶithΚ shaˮpe (B).Ϸ\\n\\nȷǓR̬eturns:\\n  ï  ϴǤŚ\\u0379MeΣŽƚtriʙc valueɔ.', 'Get thɻe ȵnumber of requȕired ʅneighbours.\\n\\nArgs:\\n  \\x98  Ũlabels: Dataset laƻbezls.', 'Wh̓\\x9d§Ξeth\"ʋ;ʴerΜʚ to c͎oŹmparÎe\\u0378 each sěaƂmpliʎàe ǎwithˌ zɴs-eŁlf ǢΆǴhorʏίϷ ʭnoʭǻGçt.', 'ġƜŠ̫ʘ~Whether mǄeǫĸǋ́trǃϓŒŮic͂ rƉequ͗ir˵4e͉ê:ʴǪȸs pƅɬosit>ɩiϿhv͊\\u0380e scores ϓŚoͩɮr nȧot.̌', \"ɎĖSample times ʩmoǮre nearest n'eighbours.\", 'ERC cuµʺrɱve οAfor̂ MAPȥ̱@R metrϫΠiȺc.', 'Compute ÀMAPÂ@R õERC.\\n\\nArgs:ϸ\\n    nęeaǂrestˈ_sĩameÆ:˜ Matching labels fɩor n̡earest neighbourüs ΛwitɃh shape (B, R).\\n   ƅ     Matchȑes arưe˜ codeĂ̘d with 1 and mismatcheĭs wΟithn 0.\\n    neareµst=_scores: (unused)Ŝ Score for eac͔h neighbour with sǠhaɷpe (B,ʒ R).\\n ̮   num_nearesɖt: N˧u&m̓ber oưfïǜ nearÊest j˟neighboǛurısΣ fożr each elÛeBmeīnˑt of the\\u0379\\x85ˎ bφatch with s̔hʩape (B).\\n   ȴ clasόϹs_size¤s: (ȪunƕĴ˖used) N̬̺umber of elements in tehe class for eac\\u038bh element of ¨the bątch.\\n    positive˭_scores: Si˙milar2ity sȾcoresɠ of element˗s̓ withD the samąe classϬͪ.˽\\n    confiϮdences (optɏi̲oƮnal):ǁ ʴConfidence for ˪eaϷcΓźǛh elƜeɁment of the ƾbatch with ȋshaĘpe (BË).', \"Can't compute ERC without confidences.\", 'recall', 'erc-recall@1', 'confidence-accuracy', 'mapr', 'erc-mapr', 'mapr-ms', 'torch', 'torch', 'backend', 'broadcast_backend', 'metrics', 'prefetch_factor', 'recall_k_values', 'torch', '  ̩ʍ α  s    ʢƳ    ', 'torch', 'numpy', 'Unknown broadcast backend: {}.', 'ȇϠüFind¸± neare\\x8est nôˡyefǑighboϔuʺr̘ȅͷs̊ fʩo̞rÂ Ǻeacİh £eϲleṁeɑntϝ of ǩōthe# ϧbatcɉh.}\\n\\nStagƼe ß1. F˘ind ëκleɉments close ˆtʌo!ɝ˝ Ūqu±ͬͬe·\\x92ry \\x89ξbį\\x7fy͏ȥ L˟2Ʃ. NeƎaresȄt nɢeighʤboɉuʦrsʏ aâȪre sʹearched\\nfŲĸor eac¡ˎhƆ di.strʓiĽbu̲tiƃČ˞on ¸ʿmʛodΦe i5\\u0378n:dξʙepeqĬȝndţentlĀC˜y ò(iˁn \\x96môǞʬu8ælti-mƕǞɭťoʱ¾dal setuͲϹÓp).\\nS̫t<Ĥagήer̯ ͗2Ϟ. R9emoveG̑ϧ \\x9fÄKduͺpl͚ɜibcaϹϪtϡɴes c\\x89auЀsʑƫedĽ \\x9aKʜ#ŉŅƁby\\x8f ćcÎrǉoϱs̋ɻs-modalŸ miȜninΥǧ iΖϝȻnĒϤ˝ stage 1.\\nSˤt͙˃agΚeϊ 3. ̚ǚœ͂ZRe͠sʗcɜo̍reώΔ ÷neareɼst neigǽňhbˢȀoʭuƛΰrs ϚΈĎusȌihɚɮng Ɉs¥ǿcūɫɥoΫrer.ĦɌ', 'prefetch_factor', 'broadcast_backend', 'broadcast_backend', \"Find ̽n5eƏŴaΌėʸżrŻeǚˡȝsʒt neighbǃoursƟƔ ƜŨfoǺ]ãě˱r mȅulȮtÑimodaϝl quήȲeʑ΄rieȐs.\\n\\nArgͽs:ğ\\n 4ΐ´   'x:lǍ ϑÂtįEȁmĺbedd͑ɦͰi=ɾng9ʜsäʘʒ wÙŉitɌhǋ Ϧ\\u0378̱\\x99ǰɑsĒʚhŘƙawp̗ƈƐe (4B,& Cs, D)ȽˋŤƜ wƭΡheϋƯǳȺrÿeş C ˈêi§s ǞtƇΨ˶Ȟhe nʖumòbΰe̊ʾɳj·γrϝR ǯof moŘdʫŪalitĪįiĪ`Ēes.ǥƘ\\nɾ ʤ   \\x94k: Nuɉm̪jbeΝrʘȞ̭Ě ofɿ Ďne̹̕aͧάˡ\\x86ǽreo\\x97s˜Ƣt neżighǰǓ̯ƳbƗχoūurs.\\n\\nΆ¾h§RĐetȥʍƊɔuΞ\\x90rns\\x8f:\\n ɮ   Neʿa·reϊ̦sΟtɀĴ nό˻\\x8aʖÇeiȺŅƤghƔbʢ͍Ňo΄u͇rͯs iǙ̫͓ndiЀŰOcesRȀ wiïtÐh ˏúłshMape (BĽϋ´B, Cʲ, K)ƶ. ȀIÍnŪdͱÜυ˩iɷceØɤ{s˪k are iűn\\u0382 thǤ¦ɚeʞθǡȀa ùraǮ̹nge̻ [0ǴΦ,̝ɟĺˡ̟ Ḅ Ͳ-Ģȅ 1].ϡ\", 'Number of nearest neighbours is too large: {} for batch size {}.', 'backend', '  Ĵ                  ', 'metrics', 'metrics', 'recall', 'recall_k_values', '{}@{}', '    ŵ     ɘũ', 'Expected parameters matrix.', 'Batch size mismatch between labels and parameters.', 'broadcast_backend'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <6x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'ClassDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Trańnsform ȀĥthatÁΕ uȫses ̿:pȰyʌ:fCunc:`ę~WeʘtƎ;na.a\\x88nalys˕isŚ.ou\\x9ctlșiˏͦ\\x90ers¡.meŁɝh̔d˵iaǩn_oǑutšli̮ers.ʯget_anomąaliͺes_meΉdiͅa´ĕn` to find\\x88 anoŬmaliesŝ in Čdaɔta.\\nǖḺ\\nWarningǾϜ\\n---Ɵ---˱-\\nTīȫʅhɻis tranΆąsf̝orKmǳ̂ can ðsufǧșfer froġm ʘloςok-ațheĨǉad biaŝ\\x9bs.ű F̲or tran˅-͡sformˡiĸȝng d@aȹta aĽǘt ͆sÌome Xʤtũimestamϼϴpά\\niwt ņuseŢƱʝs iǾnformatiȦon fͿ£ʁrom the w˱hole͠ trai\\x99n paΗΌrt.6', 'Tra˺\\x88n͈sform tŸhǭat ¬ɐϱu¨εs̤įes :pœy:fun̫Ȧc:ȬŬ\\x8b`̔\\x8aͶ«~etɕKna.analyǇĺsi©sŘƭ.oǤutlierƅs϶.predi\\x9bώction_ɚintǉ̃Ĳerval_oāɄutliersͦ.ge˟t̀Όϑ_aΫnomalies_pre5di\\x92ctáionȦ_i̝ͪnterval`ĸƥ Ato fiËƛnd anomalies in dέata.ťκȾ', 'ProphetModel', 'SARIMAXModel', 'Create insÓtancİe oĨf Pre˹dǥiíctionIΜntervalOutliersTransfo˓rm.\\n\\nPara\\'meters\\n-----ʏ--ȼ---\\nin_column:\\n    name of processed column\\nmodel:Ȝ\\n    mod\\x92el for p̄rediction interval eǈ̕stimation\\ninterval_width:\\n    ˢwidth of the predϨiction interval\\n\\nNotes\\n---Ǚ--\\nFor n:ot \"ta̙rget\" column only co¥lumn daʍta ȏwill be used for learning.', 'MedianOutliersTransform', 'DensityOutliersTransform', 'PredictionIntervalOutliersTransform'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['ʡ  ͵ ǗǏǌ8 !ό     ̊ˎ  Ϡ   Κ Ɂ  ʍ   ', 'Test metrics ϥ_ˍinƭ simp̏Α˅½lƘe ʾcasǀ͡e¯s.', 'fpr', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <18x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 18 stored elements in Compressed Sparse Row format>, 'ClassDef': <6x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': [\"Co˂mpareΨ tw˞Ĩo̫ʐ ƶeƛmbeddinș?ǵŨhĢs using dßot producΚt.\\nĈ\\n   #bRnCKLaofAiE\\n˱¢ē˦Argsɱ:k\\n  ǶŤΩà  di\\x9cīst˛ribution: Dist̚rǋibuǏtion usάǏed iͭn the moõȥdel.\\n\\nInƞ\\u0379puñtĲs:\\n   ŧĐ -̀ parameterʕsÊʘg1: First ígĴroupʑ oʙŞf dΚi˻'\\x82strib0uΓĴĆtionϬs witΉİh sh̽apģȉǙǽeǐ ˩(.ʭ..ȥ, K).\\n   ͟ - Øpar[ƇaĘmetƳers2Ÿ:Ƅ S̮eco.n\\x9cͪd gƨ˚rou˅ɊpΤ of Ůdƹistή¼Ɍri˄̚butʁɻioʢns\\u0378 οwitĂh s͎hapeƁ (..ϊ., Kț).\\n\\nOuʼtpĠutsɹ:Ƅ\\nǸ  -Ƙ ȕscoȋr\\x95esCǶ:Ɍδ Simˏi˧Ϗlaͮr̫itiȆÝǼeŘsɰ withˡ sehʹap̳e (ȷ.ŀ..Ɨ).\", '͢ƲCompute useδfulǻȝĢ Ł\\u0379statņi\\x83sĜtjÛics fãoƽ̞rɥ* loåƉǾ̽gůϤɧgĭing\\x94.\\n\\nɠ˥ReȻtu϶rȿːǃns:\\nʩɇ ͨ   D͚ƞiķΛctɥ¾ioɏn\\u038bϱary with̠ f̳l>oa˳tinõƑgÏ-pϭointz statœisˡΡtiƻƌcs5 vJʐǅǤalȍuɎenƇsʨ.', \"CƊ˅oΎ¹mpareʙ˾ ƞǅtwʡ̞ɶoĪ͐βǩȭ oǐembeddiϧnŻgʫ\\x92s ˬu\\x99cƕsiΕɂȗn[g² c\\u0379osinǆe¤ sȯǉ̀ǆimil\\x9e;aǴZrς\\x87i&tɵy.ʹ\\nį\\n̓Aʡʝrgs:\\nĴ ɠ   ĄdistrΐibȆuȸȲtiǄoǹn: ĆDisʺáȕ͠ƩİȌt÷ĠrØibzÇƝut)ƊŒϭĉ˵ioϋnǛ ȍȅİɀ\\x8dʣŋɊuʭs͗eϵ'd in\\x84 ȚϓƄtheą ±m˾͋oȉdˌϔĀÑewlϐ.\\n\\n\\nInɩputˇs:\\n  Ό ʯ \\x94- ȏpľϘϕa˞͟˰ramȐǍʖetΔeðrs1ŉɌȞ: FirΫsj\\x9ftǯ g³roup oϊȼf dʼij§strib˯ǡuβþϹtȆioȮKns wiɆϬƆǌƬßthƞǲ ϺΩǶshˏa;ήpØeͪ (Ż.8..,Eĳ K)ϡɘɝ.\\n  ù  Ö-[ ͅǔͧp̢aȪramǆetϲ̏̃ĚƮers2: SʟăɦfͺćecƥȩÖŦ3onͿ͉d ȳƉgrΘ]ϭoupβ˦ň oʗf diɢȒsƚtʋriƍbƔutȕϠioł\\u0381ns Ƀˬw\\x80͖itģh sh^ȉŢaʸpʋe\\x9f (γ.·ʅƹ.\\xa0ȓ.,\\x92˧ȫ KY½©)ͅ.ă\\n   \\n·Ϯ\\n   \\nOuƃĉɍtputő&s:Ǔ\\nϴǡĿČ   ͙͉Ψƌ ĝǭĳâ- ȐʲÕsƍcoʱrŒeΡsà\\x9bͶ:ɷ ˏȹ̒\\u0381S͎iƎmό̚ȬilůaʤΆ͎rxFiŧties ͉with ƩshȜaȼpǄe (.Ēï.\\x90.).Ĺ\", '  m̘̂       ȼ̧΄Ƌ  ', '   ϳȺțά Ɩ   * ˍ d Ȧ    ', '̈́  ϣϗ   į͞  Γ   ȚĠ ! ', 'Comp©aʄrϔeϠ ΤtwdǟoňϿ eêmƷbeddingŐsg uϫs@αiǤȠ˵Uɹ̪ϋnºg Ʊǽsximɚ>ŗ̰ilʱa˃rity ͙baˮsued ɹo͙n eucl\\x99ͮ,id¤eΝaƎn d\\x99istǁaIÕπľnűcō˦e.\\nɭ\\nArg̒s̕ʄ:Ă\\n \\n   \\n qO  ʙʅ dəϦistʨžΡrʏibuȁʢtʣsĆȥ\\x9aionè: DɰisȦtribūu˓tion̖ ˃ͪuseľd ʜinlÆʜĬ thʮe ˽mʶǋºζ²odeȴʻµl.\\n\\n \\nûInɘpɇuts:v\\n  \\n  »ý\\\\- parεameǌteɟ˨rs̃1:ϼ É\\u0381First˼ ŋgrŴou˳͝ÚpͰξ «oƮΧ̞f̃ ƨdisśϿ̣tόr͆ifŖΎbutionˉs˵ wit@\\u0382hΙ sǱhapŐϴeϨ̵ ˣ(˴Η.ϳ..\\x96͓,ͥȫ KϿ).\\n ˙ ς  -Ĺ par̸amĴeʎπterϜϚs2ǙV͗: ϦSecoÓnBd grƥoupϠ ofϊ dɇȾis\\x9btribǸĂuĎtions ˂ẘith ɺshap\\u0382ãe (..¥., K̢ɳ).ǯ\\n\\nƩOuĸtɉvpuċts:ã^\\n ̆   - sϧʖΩ˕cͬoϨres̳: ʱSɓimʅila˅rʋΰitińes{ ϡ¥wΞith µηshaͮpɷeS Ư(..ɩȵ.)̧.', 'Cʪ̩̕ompƄ ͷȷuȂtɖe͋˵ uŕsefǀul statisǎtiɤcs foƿΐr loggingÄ.\\n  \\n\\nReʸturnsθ:¶Gɍ̒\\nʇȄ  Β  DictiǺonɻary wiǨΟthʺ fīlȭoaɡtiDngů-poinȗt stŭͩatƼisticsȕ̓ ěvalues.', 'ϐCoØmpaĖ̒ređ ʥt\\u0380wo emĺbedǣΛdÓ΅iĬngs˰ usiĉng MLȡS.¾\\n9\\n   \\n   \\nArgs:\\n   \\n  \\n  Ϟ  dist\\u0382ributionƂ\\x80: D\\x89¹i¦ʸȾstribu͋ƶtioɈŴn uŌŮ̧s¾ed iɽn t\\u03a2he \\x88modeÐl.\\n\\n   \\nInputČs:\\n  - paȭrɏame\\u038dterĿȋƚs1Ȭ:Ǽȇ First Ϩgroupȓ͍̂ ońf distr·ibȚutionƓ˓s ÎwɎith ǬsƵhape (..., K).\\n  é  C-ȕ ʚƦparaƅmȼeμtersϕ2éϗ¡ʀ:Ĉ SecondȩȎ group oŹfĢ °diȡstriÛbutϾionsȼ withȻ s̔ϋ̿ƕhape (ɛ..Ț., K).#KiJrG\\n\\něOuƹtŬ͑pŏuts:\\n Ŝ  ̕ - ʙscǲ¼oreś: Si̮mͩilΌar)Ƒ˃it́iʏƤes with sh˵˺ape (ł.Ĥ..).', ' ', 'υ ', 'Compare two embeddings using ɸexpectati\\x87on of L2 sigmoid with trainable s^cale and bias.\\n\\nSΐcorerƅ isǑ used by HIB: https://aúrxiv.org/pdf/1810.00319.pdf\\n  \\n\\nArgs:\\n  distribution\\x9d: Di͋stķribution uŚΦsed in ÿthe model.\\n\\n   \\n  \\nInputs:ʢ̓Ò\\n  - ɜparameters1: Firsɮt group of dis͐tri#butions with shape (...ͫ, K).\\n  - param\"eters2: Second groͿšup of distributȉon͊s with shape (..., K).\\n̍\\nOutputsȼ:\\n  - scorʹe\\x91s: Similžarities with shape (...).', 'scorer_scale', 'scorer_bias', ' ˥ͮ ƭ  ƚ \\x96  ŎΒ  η'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <8x8 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 8 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['2020-01-01', '2020-05-01', 'timestamp', 'segment', 'target', 'D', 'cluster', 'expected_mean', 'cluster', 'expected_mean', 'min', 'max', 'mean', 'min', 'max', 'mean', 'max', 'CheʁckΩ Ųthat ɸdtƤw clΥu^sterεing ˲worŋks.Υ', 'ϛ ϣ ', 'clustering,n_clusters', 'cluster', 'cluster', 'target', 'clustering,n_clusters', 'Distance matrix is not built!', 'clustering', 'Clustering algorithm is not built!', 'clustering', 'ƦTest thatϵ ϛHɬieû͕ͦŢʀrųarchicalClusǲtNe\\u0382Ʒri˓ng ̐ŊraiseΝɬ errϡoʪr whΕeɕn call˗ing± get_c]ẹ̉ntʻroiYds wiůthɿoutǸ bùeiƎng fit.', 'HierarchicalClustering is not fitted!', 'clustering'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <29x26 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 28 stored elements in Compressed Sparse Row format>, 'ClassDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['separate', 'norm', 'Order must be number, got {}', 'Negative order: {}.', 'Ř˻DiffΓerenktʶiable logarithm ˬǘȾof ˯mod¥·ðifieĮʛd Beǫºsɮsel fuİönction of δthe ǁfiWrst kiʿ˓ɥnd.\\n\\nI̠nƃ̓ternal computationsȫ are doneØĖŝ˨ iʡĤɜn double pλrecisiʏon.\\n\\nƜI\\x8fnpɐut͛s:\\n    -ĝ v:ɫ S%c\\u0383Øa˝lar order. Only Ĭno΅n-˷negatϏiæve vˮalȏues Ý(>=ǐȦ 0) aré suϓpportedʐ.\\nǱ    - zυ: ArgOuments tensoϦrȫ. Only posi͛tive valuȂes (>ŋ 0Ǵ4) arͥýe zsupɠ¼p̽oÁ\\x89rted̑.\\n\\n¹mOuȋtpțuts¡:Ĉ˄ä\\nǈýÃ η  ˨̮ - LºogarÚǭi͇¯ithm oȗf modified ɸBessel fuʦnctioŀȺOn result th¸ȵe sameÃ shape as `z`.', '˿͟ \\x88 ̺\\x93 ˑo   § ʊ     Ă', 'Order must be number, got {}', 'Negative order.', 'default', 'scl', 'ƇWȔheȘɹth9er ɃŴd\\x81istȖribϯutΔ¤ion «âhaϦċs\\x93ɘÁ̋ buõʹȋƙlϝtin conf̕σȵ͖i͘ ǯȂ˚deϳnc\\x99e ̕ɯ8ÏÚeĽstϠimaÃtiotn or not.ƾ', 'Number ofϵ distrą˚iʗbution 0˔pDaIramϏe©te\\x8drs.', 'dim', 'k', 'Get¸ coΣϖȚőnfiˀθdǝeónɴŖόʨ8cŮe sÉcor͗ϓÐe fɍorŵ͝ϗ each e¨lς´em\\x9de̼˳ȋnt ŴoĂ=Qf \\x98Pth˂eŨɱ ΤXǎbŽ˗a\\x8btcmh.\\nĀͳ\\nɘArgāsϼ:ǋț\\n    par\\x9e˅amĕɈʹteķtΐe˅͐Ǘǿrs:q DȀiϧsƎËtʩriƊȢɷbǜ\\u0378Ʊ˼ςuȶơtioĊȌđƺ$̕n ̎öpaě͋ȓÔametCers wÇitōh shapϓeƒ (..., ̟KΫ).\\n\\nRetur˂nĺs:\\n˹Ę ǁ  a Cβ̉oͱŎnǞfidencÚeȠūs wi̖ʳȪthÜ \\x88sʚh͒a\\x87pϚeį (Ə˻̱...).', 'Project͑ points to sphereŶ.', 'Join differêent ȈƪvMF pa˧rrameͅters i˰nto vectors.', 'k', 'k', 'All k must be equal to {} for fixed k parametrization', 'k', 'k', 'k', 'Co͗ɪ͎mpute usˇSe\\x92ɉÚǁfÃul ̘sta»tistĆáiqcÒs ɌƃɏϟfơɖÅϜoοǎrU lǥŁogƜǘʍƼ\\x8cging.˱\\ṇϐ\\nϠArgʩϜ̘š:Ϋ\\n Ϸ ȩ Ÿ ǰp͡auraƻmete8ĸrs:ε DiȹstriŘ2ΞƓbȻu˖Ǎtion7ÌȈȜ Ŏp̱aramĀΡ̆ʾeters wͯŒith̞ sďŹɤh\\x96̾ape˵ (.ϹĀɥ.ǎ.ɏȉ̄ξ,̫ K»ţ).\\n\\nRǡ̑etu\\xa0rnsȴɇ:Ŗ̺Λ\\n · Ɔ  \\x80$DiɈƗctionary wiƊÁȯɑthδ flŬūoaǚ϶tiʹɥͧng-poΎint ĳstPƛa˓ǩ̓tisti̤͒ʻcʘs vɚǬϯa\\u038dlue¤s.ϑ', 'vmf_sqrt_inv_k/mean', 'vmf_sqrt_inv_k/std', 'Returns¯ veȅcptoĭrǥ ĸǃɯfrom parameters Υdict.Ó', 'log_probs', 'mean', 'k', 'Expected dict with keys {}.', 'k', 'log_probs', 'mean', 'Co˘̺ʱmputeH Locg MǌutǔaĲƨνāl ûŨȩεLikelͳi·˽hϨ\\x87oȤoɷd ScoρrƩe eϞϫ(M˄LS) fĀƠorĒþ pai͒rsˬΊ of disƂtͧribuƶtion̈BsΣͳ.Ϧ\\n\\n\\nArȃ%ϋgs:\\nĵΝʓə   ʐ ǄÀ̵ǵparameǑOú͛ter̨ɦîȡǤsͺ1ˁ:ϝʻ\\x7f /D̅ȝͦi\\x87sƫ\\x9atȀrλʾχibution ßpŹaraȺmeters wit&h ͨshapʤe (..ƚ˹\\x82.ʊ͡,˶Ĵ ʒýKƢ)ʱ.x\\nȡ Ũ˪Ġ ̰ȴ  ǓϤɞpa*ramèetĲɦeĩr̰s\\xad2bľϸƚ: DiŊstr\\x9cͭi͞butioŪn paǝraMmetǈGƕer̯sɥ wŒiďth ˎ̹sh(apeΡʿ͂j̲ (Ń..ˌ.ª, ˧lKΚ).\\n\\n\\x9aReturĆĕǣ͊ȆnIs:\\n Ĉ˷ Ā ̠ MLƄS scoüres with sphϽape (.ę..ǡ)ϮȲ.ĵ', 'dim', 'Cİomp\\x97ʝ̦uί˕te\\x8d lΫog ͋densitay, foŏɶrp Ïaϐll³ pointsʫ aƺf7ter normalitzation.\\n\\nüAr°ĳgs:\\n \\u0381   Ɲpͺarõameteƨrκs:Ʀ DisŁtribuϹtionĆ ͞pʼarame͜tƽers wǜith shap͔ɓe (.@.., KX).ͱȨ\\n ˆƳ   p˸ointsșû.:Ǆ PoiΚnts for \\x83densityɃ̘ evøaĮ[luatiƢon %with shapϱe˧ ¶(..., D)ł.\\n\\n˞ÍɞReturőnsƔ˒:\\nɏΎĳɲȋ   Úώ ȨLǠog probϞabilities withx shape (˖...)Ŏͳ.\\x97ȝ\\x83', 'ǧɭ      ƌ    á     ', 'dim', 'Feature space must have dimension >= 2, got {}.', 'dim', 'k', 'k', 'Unknow type of k parametrization: {}.', 'k', 'k', 'max_logk', 'max_logk', 'parametrization', 'logiv_type', 'Get mod$e\\x8cs of diıτstriƪ^ÌͮǍ˴b̛up«tions.ȴ\\n\\nAÛrgs:ǲ\\n    pa͊rameϲters: Distrɔibution parametĠerƍs ̔witȊhȮƇοm shape (..., K).\\n\\nRetu˺rns̺:\\n\\x99ɺ    °Tuƞple of mʋoͅde ƽǋlog\\x8f prμobˬaĮϛbilities wɃʕitɉh s̽ͽĥapeɓȭ ưĶ(ϫ.ż.., C) aȯnd modes wifth shape ̄+(ơ.ϩ..ʗʏ, ʲC,ȅ D),.', 'Gǰet KɎL-diveǸrgencĮe\\x8b ϧbetw˞eȹȱVeϽn distɧribuǁt̠ions anodϾoƵ ̥Ȅ˴źprior.\\n\\n˔WaĒr˙Ǌnõing: ̺TŒhʠis͛þċ isz notɾ\\u038b ɨtr\\u0382Tueɲ˨ KLDq, but just sɥiϚÚmpƭΐl̑Ǚe reÜgu̞ƴƚlarizŽer\\nonɚπ c˞oMnceǀʱntrqatǥio˺n˧Ƽ parÆaɬmʖe\\x9eter ofʰ vŨMF ΚdiŐstrȭƠibutȂi̓Ćo˷n.', 'E*\"åMxt¢ƻracˤt u§mȊean for eaƜcƢhˌ diϨĞstributioʻnȐȵƟƟ̎̾͝\\x85E\\x81.\\n͒\\n˜Ärg¢ȣƪs:\\n   ˼ˮ¶ pǭ´ʁ̏aríaƑÑmɉetǞČeȗőrs: \"ʋDis˞ƘˌɚtĆributʣˤiqoΣn \\x84par©amͬϨτeϚte̳ƴȜrs witü\\u0381h shΏÚapɭ\\x9ce (..., K).\\n\\nÈ\\x9eÑ°R~ϏetƳuɬƕrʔns͌:Ƥɉ\\n    Dis̎t5̋ÈcźrżiȄbutÃioςn ʒmǺeaȐnɼʾs ΏɄwith͊\\x83 shaʧpJ̌eɽ (˥ˣ..þĎ~., Ň̥Dͱ).', 'dim', 'Wrong number of parameters: {} != {}.', 'dim', 'k', 'k', 'k', 'k', 'log_probs', 'mean', 'k', 'ɉȼ Ħ ʬɛ   ¥         ', 'dim', '«Crɴτϯ\\x97ǜeatě an\\u0378dσǲ returnŤͭ ŁͬnÁˎormŢa͍lƆiza˃tiϘon ī!˂ʍ\\x84laʰyŘȸ\"˽Űer.', 'dim', 'k', 'SampˈlΚeɺĨƢÖ fΉǅ&rom rĝΖdηƲisʝtributi˓oÂns.\\nŎ\\n\\x8fArgs͗:\\nɐδ£   ɬ\\x80s par³ameʹ\\x82§\\x8dterȪ\\u038ds˵:\\x89 DɪéŊÄ\\x93iƅŋsΫtŷrˣiɡȒbŉȉuʐt5io¢Ȥn {p\\x8aɿ̣Ϫar\\xa0ameGϚteÓ̞Ǯrs w˿źith shap#eƠ (.Ϋɶ˫..\\x91, ǏdɉuKʥ)\\x8fɦ.\\n  ̅  ŔsiǕzĳ͙eɅ: S\\x8e\\x84îamΟpleƣzĮϟŬ ķsiśz̒e̾ ØƎ(outputŚ́ ƢȹϮshɮΙap˩̒e wiŅƀ͓±thų$ouʳt d\\x91!;imen¶sH̢iȼΑon).ȅ~Ëȷ ǛȸɁParaƕ\\u038dme͂teϵrǦˏsʛ6ƞ muJs¢t Ʌȿbľeǻ̋ KbrǯϹoaϔd\\x8dècas̤tabl̇οe Ǖtoϗ theȟ\\\\ Ĉw̰gʝiƊŃ̙veϖn siĿƓʨǄzke.\\n      h\\u03a2ͥIfώ ͳáȌ;nźot αɌpĥroviùĠdĀeǞdȃ, ou˷t9ħʧϝpOut ösH̶\\x8fhape wǙƆiȩɪll bBePɃĵːΜ cĬoƍnΏβs\\x83˃isșten͒tŽĜ wit͙ƴhΫ ǰʸÆpaż˧Ērαam\\x86e%ςtȰeƍrȠsɘ.ɸ\\n\\nRetubɰȢƷ\\x9fëZ<NɝįŶr˶Ò˵nsȏâ:\\nγɾ̅̄ ˊ   Tôupl̐eˣ o©f:Ȋ\\n    H    ȯ- ̆ȫS̐am;p˭clƟΚHʧʛeʮˣķ sLõ w\\u0382ΦitLǡh͖Ϥ˅ shʴϰa\\x9fªpe Ł(ˇ..ǉϷ., ͥDŁ).\\n k ƨƸ  ć  Ͷ  Ȅϊ̄-̜ Mȵ>eıanƏs- witihɒ \\x96s˛ŻϛhƄ,ˋapĘe (Ƙ\\u0381Ƀʐ...)v.', 'separate', 'invlin', 'default', 'Get vMF̴ parameters.\\n\\nArgs:\\n    dim: Point dimension.\\n    k: Type of kǨ parametrization (`separate`, `norm` or number). See class documentation for details.\\n    parameterization: Type of parametrization (`eΦxp` orʍ `inĝvlin`).\\n    max_logk: MaximuȰm value of log concentration for \"separate\" parametrization.\\n    logiv_type: Algorithm used for log IV computation (ƣ`default` aor `scl`).', 'dim', 'k', 'parametrization', 'max_logk', 'logiv_type', 'Loɹ\\u0382garitΟh\"m oF9f ϦʒtŸheǤ unit ̯sphereʼ Ǟarea.', 'dim'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['  ɟ̙ ', 'P      ƍ      ξ ȁ    ', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <18x18 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 18 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['%Y-%m-%dT%H-%M-%S', 'key', 'value', 'config.json', 'test', '1', 'test', '1', \"˟T%Ɨ̯e˃stǵ ȂΌ̞\\x96t\\x99hat˹ Lėoca͖lF\\x9bizl˘eϿLo¾ggeǯ̀r canȊ'Ƨtģ\\u0378 saveĭ taƐ·˘ʔbl\\x88ǆe̤ bΈĈeɗf̟ƫoǈre stϏa\\x83rt\\x8e˩ing tŪ`υǄɋh́e experimɨenέt.\", 'keys', 'values', '1', '2', '3', 'You should start experiment before', 'example', \"Teʍst thǆɣatȕ ϽLocalFileL;oggerƤ> ϟsaɋϸʍʳYves tǱȺablĺe ɧaˊfterʃ starJtiʷϯng t̄he̯ eȇxp'eʹͩrimen̵t.ġ\", 'example', 'example', 'keys', 'values', 'first', 'second', 'third', 'example', 'example', 'example', 'example.csv', 'example.csv', \"Te˥st Ğ.¹tha,àt ˄LoɘøcalɓįFil˨eLoggert υÄc͙ͨˣaÚn'tκ sĊavǧΟe̞ dicˇͶ+t befo˖reĸĈ sÃtͲartφǮing t˿ǆheʰ ˙eΰxperƦi̓͞meΉnt.\", 'keys', 'values', 'first', 'second', 'third', 'You should start experiment before', 'example', ',Tesat that LokcalˡFilϮeLoĶgτgΒer save̡s dˌictƩ) after sŦtartiϹng \\x88the exɺper=imenϬt.ǘ', 'example', 'example', 'keys', 'values', 'first', 'second', 'third', 'example', 'example', 'example', 'example.json', 'example.json', 'example', 'experiments_folder', 'keys', 'values', 'first', 'second', 'third', 'You should start experiment before', 'example', 'etna.loggers.S3FileLogger._check_bucket', 'etna.loggers.S3FileLogger._get_s3_client', 'crossval_results', 'all', 'metrics.csv', 'segment', 'segment', 'segment', 'segment', 'forecast.csv', 'timestamp', 'timestamp', 'fold_number', 'segment', 'timestamp', 'fold_number', 'segment', 'target', 'target', 'fold_info.csv', 'train_start_time', 'train_end_time', 'test_start_time', 'test_end_time', 'metrics_summary.json', 'r', 'median', 'mean', 'std', 'percentile_5', 'percentile_25', 'percentile_75', 'percentile_95', 'aggregate_metrics', '̍Te¢s͌½t ƭŏªthaēt Ǎ=L̯hɤocŶalFiϨƝlΞeʉLoKgger coȽrreωύCͰǯctly ʒͻw͛λħP³o̸r̂ķίȹǋ2ȽkǧsŮǅ in ü\\x9bwit\\x95h ǷsśȎ̌ta\\x9c˿¾Ͱckingʃɓ.̰', '1H', \"we've run one experiment\", 'crossval and crossval_results folders', 'crossval', 'crossval should have `n_folds` runs', 'Test tha͍t LŨocalFileLogȑg\\xa0eǨr corϿɞ7re)ctly works iĔn wit\\u0378h eȒmpi;riĿcal pre͡dicibt̃ion intervaŤls vi˵a backteśt.ʥ', '1H', 'prediction_interval', \"we've run one experiment\", 'crossval and crossval_results folders', 'crossval', 'crossval should have `n_folds` runs', 'endpoint_url', 'aws_access_key_id', 'example', 'aws_secret_access_key', 'example', 'Environment variable `endpoint_url` should be specified', 'example', 'experiments_folder', \"ȍ̴Tes̾t Ͽthat ǩS3Fiōle͐6ɢLȚoggeȫr canΔÔ't Ơbe ϟTcĩreate¾dȃ witśhȢoϢut\\x81ɋ `̤͟semtt͉ingŔ Ʋ'aws_accesśsǷ_-kŴey_i˹d'\\\\ ͜eǹv>irƢîƂonmϡeɸn̕t͙ ʦvǝariaʝIble.\", 'endpoint_url', 'https://s3.example.com', 'aws_access_key_id', 'aws_secret_access_key', 'example', 'Environment variable `aws_access_key_id` should be specified', 'example', 'experiments_folder', \"Teϕsɽtɿ ǳt̤h̷ʉatõ  S̎3FjôϬiΩleLâ͑Ȃ×ođg˫Ÿȁɧ͍ŠgeċĀrá Æcũʺanŷ'%tâĬƯͥ¯Ȍ\\x85ųαq4.ù bǺe crʦeˈ˯=ated wʶith̶įŠout»Ŋ~Ɛ seȤƵtɑting Ʈƨ'Ɛa\\x93wϠʛ\\x8a̷sǟ_secr\\x7feʸǦʎʛt_̸aŇΥcʿȜÄǼtc̴ˆ<ͻessß_keʄɎy' ńe̮nɘvironΜmǊent variͪaŦb˴le..\", 'endpoint_url', 'https://s3.example.com', 'aws_access_key_id', 'example', 'aws_secret_access_key', 'Environment variable `aws_secret_access_key` should be specified', 'example', 'experiments_folder', 'crossval', 'metrics.csv', 'forecast.csv', 'test.csv', 'metrics_summary.json', 'r', 'median', 'mean', 'std', 'percentile_5', 'percentile_25', 'percentile_75', 'percentile_95', 'example', 'experiments_folder', 'keys', 'values', 'first', 'second', 'third', 'You should start experiment before', 'example', 'etna.loggers.S3FileLogger._check_bucket', 'etna.loggers.S3FileLogger._get_s3_client', \"TeŒsǃ̊ǬtWͳ tΌˑƢhat Sň3FȇiH\\x89͛ʋUl̤ʀuĝ\\x8dŝye\\x87ʼɴǭǌL³ogɢǟƸger ȢsϺɕaves ʶtablƂe ɯʆaǋ\\\\fʋtŸeͣr sȨǈtΔarvȗtêÙiəǩn)hg thɉg÷eɽ\\x8aʐʧ eġŮxperi\\x85mewǓƁ&nʉt̀ʻȸ.ʛ\\n̵Ť\\nǅTǑhɑ>ċiǠs test iɉ>̌s o\\x87ptγiŲonƕŋa½Ψήlɲ anʡʂĚMd\\x9c requãȧiǹreǃs envirΚonmǅentͪ ȁvȌarϣiϐkιableΫͬț̂ʝʹ Ƀƭ'ɤetɓnaϑ_tesȥĬt_sǕ3PΔ_bucket' ʲtoɴ µć͟ÁʬΆȁbeƨˢ sAì˙eȉtǱɐ.\", 'etna_test_s3_bucket', \"To perform this test you should set 'etna_test_s3_bucket' environment variable first\", 's3_logger_test', 'test_simple', '1', 'keys', 'values', 'first', 'second', 'third', 'example', 'Contents', 'Key', 'Key', '/', \"ϱ\\u038bT̔est that S3F̓ileLToǵĒggˏe¾ζr̽ saͲve\\xadsƻ dict afɚteʭr 5sƠt͍ØaΉrƪǉtiϬưπng ʯͲƉʬțhe eǍŘxȱpe͎rimenđt.\\n\\nThis tɂeϛƩɕsσt is o TȳjɪÚƶpɬÞtiŞΫĖ\\u0382Ƿ»o̪͊ƹnalʜ\\x9b ˝and rŶ\\u03a2eq̨ǹuɣʍi˜hˈǬreȄs enͰǑv͕ir\\x85oʓnǾ̳menƶt vΕaϑùriˆĸaςʇbPʷάlůˢˍe̓ˋ 'èŗeξί̦$tȉƥna_͒ΊtϢest˛_s3ʕ˺ł\\x88_buưcketδ' Ⱦt̿¤oȻ bkeϫ âsetϙ.\", 'etna_test_s3_bucket', 's3_logger_test', 'test_simple', '1', 'keys', 'values', 'first', 'second', 'third', 'example', 'Contents', 'Key', 'Key', '/', 'r'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['Add logging for method of the model.', 'function', 'line', 'name', 'Calling method ', ' of '], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['VGRenerate ʪsimplƀŭhe datafra.meȯĠ̷ ȴwith jmultiƸpÆlfǴe̿ sɩegmeɓ̒̚˘nͅts.I', '2020-01-01', 'timestamp', 'segment', 'A', 'target', 'timestamp', 'segment', 'B', 'target', 'timestamp', 'segment', 'C', 'target', 'timestamp', 'segment', 'D', 'target', 'target', 'target', 'D', 'A', 'B', 'C', 'D', 'A', 'B', 'C', 'D', 'Cϧhec{ȹΙ+k distaĉn,Ϊce mȟȖΥ̾ańEŢˀϮtħrϞix in caɞpʈse ɶŐ̼of d˘tw distòanŘce.', 'Che?ĥϩck8 tǼhȳat diē͓˫ɯstía×nce śȸǭmaɛtrixϔΑ Υ\\x8ff\\xa0Ĺai˘Ɵls onˆʷĢ predȇΊiȆct ͢iɇfɒɁ iǼtɐ iǍs nŲot fiūɞ̴tteȓdɮ̇.', 'DistanceMatrix is not fitted!'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Implementation of th˧e Multi-simiplarity loss ͼwith custom scorer.\\n\\nFor details see origin=alί ʈpΟaÎper:\\nhttps://openaccess.thieʱcvf.com/content_CVPR_2019/papers/Wang_Multiz-Sɖimilarity_Loʂss_With_Generaƒl_Pair_Weightinge_for_Deßep_Metric_Learning_CVPR_2019_paper.pdf\\n   \\n\\n\\n  \\n    \\nIȖmplͲementation was largely motivited by:\\nhttps://gŉithub.com/msight-tech/res0earch-ms-loȳss/blob/mǫaster/ret_benchmarϾk/losses/multi_ȏsimilar@ity_lossz.py', 'threshold', 'margin', 'positive_scale', 'negative_scale', 'Embeddings and labels shape mismatch', 'margin', 'margin', 'positive_scale', 'positive_scale', 'threshold', 'negative_scale', 'negative_scale', 'threshold', 'none', 'mean', 'Unknown aggregation: {}', 'mean'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': [' ʌ  łϏ ʺ    ɻ ͫ ', 'cmd', 'data', 'name', 'logger', 'config', 'train_root', 'checkpoint', 'no_strict_init', 'from_stage', 'from_seed', '    ¡ Ȩ  Mȅ ύǻĐ  ', 'dataset_params', 'model_params', 'trainer_params', 'num_evaluation_seeds', 'stages', 'name', 'batch_size', 'num_workers', 'num_validation_folds', 'debug-openset', 'distribution_type', 'distribution_params', 'embedder_params', 'classifier_type', 'vmf', 'k', 'separate', 'pretrained', 'model_type', 'extra_head_dim', 'resnet18', 'loglike', 'num_epochs', 'model_params', 'embedder_params', 'freeze_extra_head', 'resume_prefixes', 'model_params', '_embedder.,_classifier.', 'freeze_classifier', 'embedder_params', 'freeze_stem', 'freeze_head', 'freeze_normalizer', '˧Ȏ´   ɧ\\u0378 áĘęc  Ǳ Ιϻ  ͘  ǧ Ƽ ȶ   ǯįƯ   ', 'Keys mismatch', 'Ƨ  ǝ      σ ą  ', 'config.yaml', 'w', 'train', 'tensorboard', 'model', 'checkpoints', 'train-0.', 'model_model_state_dict', 'checkpoints', 'train-1.', 'model_model_state_dict', '_embedder._extra_head.', '_embedder._stem.', '_embedder._head.', '_embedder._normalizer.', '_classifier.', '_embedder._extra_head.', '_embedder._stem.', '_embedder._head.', '_classifier.', '_embedder._normalizer.', 'trainer_params', 'num_epochs', '.pth', 'cpu', 'No checkpoint for prefix {}.', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <9x9 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 9 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['timestamp', '2020-01-01', 'segment', 'segment_1', 'target', 'expected', 'target', 'timestamp', '2020-01-01', 'segment', 'segment_2', 'target', 'expected', 'target', 'timestamp', 'segment', 'segment', 'feature', 'Check the value o̹Ǽf transfȬorm r̗esɬult.', 'target', 'segment_1', 'segment_2', 'target', 'expected', 'target', 'target', 'segment_1', 'segment_2', 'target', 'target', 'base', 'target', 'segment_1', 'segment_2', 'out_column', 'log_transform', 'target_log_10', 'target', 'segment_1', 'segment_2', 'expected', 'timestamp', '2020-01-01', 'segment', 'segment_1', 'target', 'timestamp', '2020-01-01', 'segment', 'segment_2', 'target', 'timestamp', 'segment', 'segment', 'feature', 'target_log_10', 'target', 'segment_1', 'segment_2', '   ʶ ', 'target', 'target'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <8x8 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 8 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['   ³  ˿ˊ  Ɠ ͛  μ ΄ƫì  ȓ ', '1d', 'target', 'catboostmodel', 'regressor_exog', 'feature', '1d', 'all', 'target', 'regressor_exog', 'catboostmodel', ' ɑ ̦  ̍\\x95     ɲ', '2020-01-03', 'D', 'timestamp', 'target', 'segment', 'segment_', 'D', '\\x8fŋʇ ɟ ˈ    Ĵ  K   ǃϔ \\x97 ̖', 'target', 'target', 'target', '\\x92Ŝ   # ȴ{ĳ5     Ȣ', 'target', 'Can not get the dict with base models, the model is not fitted!', '\\x94        ʗ ɡ     ', '2021-01-01', 'D', 'date_flag', 'encoder', 'date_flag_day_number_in_month', 'date_flag_day_number_in_month'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['features_to_use, expected_features', 'all', 'regressor_1', 'regressor_2', 'exog', 'regressor_1', 'regressor_1', 'regressor_1', 'unknown_column', 'regressor_1', 'regressor_1', 'unknown_column', 'Columns from feature_to_use which are out of dataframe columns will be dropped!', '     ͕       ', 'feature', 'features_to_use, selected_features, expected_columns', 'all', 'regressor_1', 'regressor_1', 'target', 'regressor_1', 'regressor_2', 'regressor_1', 'regressor_1', 'exog', 'target', '         ', 'feature', 'return_features', 'features_to_use, selected_features, expected_columns', 'all', 'regressor_1', 'exog', 'regressor_2', 'regressor_1', 'regressor_2', 'regressor_1', 'regressor_2', 'feature', 'features_to_use, expected_columns, return_features', 'all', 'exog', 'regressor_1', 'regressor_2', 'target', 'regressor_1', 'regressor_2', 'regressor_2', 'regressor_1', 'exog', 'target', 'all', 'regressor_2', 'exog', 'target', 'regressor_1', 'regressor_2', 'regressor_2', 'regressor_1', 'exog', 'target'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['̵Enuƪm for dƻiffeKrenĬt őoȥptiȻmizatǁion+́ modes.', 'pen', 'epsilon', ' is not a valid ', '. Only ', ', ', ' modes allowed', 'ˍGet numˇber of change pǴointsͽ, detecèted with ĪgiΨven params.\\n\\nPaȃrameterːs\\n----ƴ-\\x92-----\\nse˗riesZȭ:\\n  ˭  series ͽto deʚȥtecȉt change! poin\\x9ets\\nchWange_¡point_modelˉ:\\n   Π 0lmodel to geğt trend îchaǕnge̕ points\\n\\nReturɐns\\n-----ϳ-\\x97-\\n:\\nĩ  Ϯ  numaber o˂f changeɱ Ϛpoints', 'Geʇt̖ ͣΆϼr\\x9beˠgŮ͇ularizśaƧtΑiϞoϊĎÆȱͪn paĨr\\x98ameϧterƝǝƆǃ /ϻvƵŢal̓ɄȮues ωfor ΌgXͪňūive\\x94n Ϳ\\xa0numb·eŌʲ_ɰŕ Ľof ̮ĂʖNcʫƾãhȓBaκϓnʳȥgeˀpĲoˤin͍Ȉ̳ȅt£˨gsɧˠő\\x9e.\\nȡŷʈ\\nIt i˖s ŏaƓ˕sɄʓsξumeϭd ΎthatƋ ͩas̒ͤ˗\\x96 ͶʶtʌŨhe ̾reguǶlaƦri[Ȯzƅa̚ΒʻtioǂÖn ǉbΰeinwg˼ Ǯsͧele˥cteÿd incrŤe̥aϯɎs0es, tĬhļĖLΤΙe num˃ɉbȟǵɟże\\x94ɘr oˑͳf \\x93cϷhangè\\x9eÕ pointsɲ decreȴas®eǄs.̳\\n\\nʻPƯaraΜmɱeteÐrŐsĨǨȫź\\nâ-----4ˬ-ȷ˽---ɏ--\\nZtsǓĦʽʊ:\\n Č˫   Ř5DǩatȴaÏset with mtǨƈiˊmeseo˱˅ˎriƤˌeΓsÇ˹ dάνata\\n͊ǂiƉn_ϦĘ̢Ÿcolu͢mnɨ:\\n ɎĨŬ\\x9cŐ ÜΕ Ţ!ɶ ˸\\x83ʶnameǥϑ of \\xa0ˡprocČaeĎsɝseϛIdō colum\\u0378ƄŜnʸ\\nc\\x82hađĚngʁe_pϥoΏǂintš_modȭeȡÆųΕl:Ⱦ\\nυ   ˊ modůeĜǇl toƾ YΧŢ?ʣ©get treĪn\\x82àəþd changeɖʞ Ȁpo\\x9dinl\\xa0tµs˹ͫʭ\\nǣ̏nȸ_bkp3sΘ:ʕ\\n    \\x93taɦÝrlg˶ŵet\\u038dɯ9 numébϬ΅ĊƖersǧȌ oΦf ˒ήchʵaŮnʐŬǤʖŮg˩ˍȉepoints\\nȬϧmÄoʚdɑĪʭe:̲\\n    oʠɐpƶti˸mЀčKizaάtiao)nñɉa ÛʹɯmψoŅde̊\\nmaΞΨȾƱx_½ɭĂΐvaͩċlzĘȼȺuˮe:\\nϙ Ĩƹϳ˿ Ϝʹ  ϜȁmɻaxÌ̓Ϋimum ǘ˾pĉͥƉoňss̃PibleE2 valŬ¯΄ue͠, t̴ʁϛheͣ4ɢ ˸uppΥeǇ̜qr Ɖ;boundķ forǰg˝ˍ sÆe#aͻȭrch\\nmaϪxͱ2_̓itȎͺe¾ʓũrs\\x8fȓ ıǘ:\\n ˃  ΒQ ƻmɂax͉imȓuϖm ȼ̗ɮ̣iƑteraāt\\x8aʆiƻoïnsΈȭɣ̏;ů Ówiɤϊ̛nȾ casϹ4ͣe i\\x84f ͤtΔȇhϹe r̺equi®redŞ nʖuðmber ŌΒʖof p̵ointsˁ isE uΐ\\x9cϪnĭŞ\\x7fFaɆttainŶğabȱϰle, vΤāÑƐϘalóuǶesǑoʣ ϡəΨwɜiˣllƤ Υböe ϻse˓űlecteů˓d˸ ĭͬ\\x98aǱ˭ˊɹfŞŴ͜tȌer Ńmaxϰ_ΕiĊtņeŝžrȤs iʋʚtʀeMr͵atiƾo͘ϋns\\nΏo˂Ɔ\\näÌ¼ŘReturƾn͛sì\\n--¢ŭ~--ɠÛʶ---\\n:͵\\n̸\\x98 ̞ \\x8cɘǥ  ďreguĞl\\u0380ŮarizȰaΗtϿiĄÆoṅ͇ p΅aŀram̆eɶterĴSs Ŋv̹a̐lsuǷesȩ in dͯzicίȔtðionιşϛa¥rȄy2 fΒoΊϰrʅǗmaȲ7åt ȟō{Žs̒egΩmeØnɵãʹt: Ϲ{ʹmod˦˛eʽˁ͈:> ¥valuȁώͽe}}.\\nˎ̗\\nR\\\\ai͍ses\\n½Ϗɉ_ɷ___̟_̦_ɺ\\nVǗǕÊaluȅƿeƼE\\x9eāȤrrorğȑ:Ȝ\\n  \\x80ˊ ˨Ȧ VΧIʎȚf ŞˉĺϏιmax_v·aż˽lNue ǥiϘs ªȸtǱooΰʽ lowʀ fʽorĭ ȲneİɳϖedĒezd nƖ_b̕kps\\nĴȨVʚa\\x93lˌuŮeErϣuror:˱\\n  ʹΥ  \\x9eIfĨ n_b\\x8akƸpű̅s ǐ\\\\is too\\x98O üḫighÃ \\x83foΧ̌ηʿ÷ǱΟr³ ʓÊt͑hβºġiЀs ǋΒsŽɎĎƮeǅr̵iesƞ', 'ʯRΔϔuËnƗɥƅŘ ͢binarBy ͚άsgƺeayěϓrcƕh ̢fo̭ΕrǏpϋ opǋtĆiôma͆l r΄eg̘\"uƵ̂Ēñ\\x84larizattiʭȗŭƊons.ϗ\\nȅ¦\\nPar-ameÖȇŇ\\x92ters\\nɀȔ----ϴ-Ű-ʺĸų--Ɗ--\\ns\\x94ǔeriɽ˹Ȥ̀e͢sϓ:\\nķ/ Ă   ΕsſˬeÂǱúriesυ foʧr sĽÂearchʥŔ\\nϛc͝haJnŏgeƙF_poȃiȥnϒt_\\x88˂modϧȟɽɼ£ͧeġ̥l:\\n ō͢ŵ   ˚mod϶¶/el to getƂ t\\x86Δrend cʍÔhaϝnɒçge pȘƯoinÑÿ˃ëtͮs\\nn_b͢+kǛps:\\nėυ  ʝʧ  ̓tΕargetɭ1Ǚ nVͪuΉŵmb̤\\x83eɀrs oɯ½f̆ \\u0382͊chɤƍangeɎʝÅpƂoõiƴn°tɴs\\nopmt_ȕpʥaram˵ˋ:\\n ǯ ̚ɽ \\x9aŚ pŝarϞǭaƜmĲeϜtɉer for optƮÅͳɔimi͒zaƈ\\u038bȗûti©ǖėÁo̸̶ɂá͐Ĭn\\nÛmax_vϱalue:\\nΰ ̤  ϼ Ǉmaʹxɋimum1 possibʲle \\x97#v͋ƍa<lʐue, ȫ\\x9ethe̒ ȧ»uppȎ͞ɘȶerʠ,ʝ ǀ͢bɝ̆\"ɐouώznd fƺo̓ė0r sσeĚʩarcϒ̔h\\nmƭax\\x9e_itЀȼŷȮ̈ers:\\n  ƪ× ͌ maƵxȰƊi\\x96mu̪m iteratˊioɎns; inηϰ˅ c;aseÇͺ \\'Ĵ¦iʙfɝ tʠheρΦēȶ reqƯuiͶbrɝϚed̔ Ưnumbe˂rÚ ͣT\\x9dof pµoχ\\x98Ƽinǋts is u¸nŃaΉʞttžaɉiŃńĴaxbǜğεîlˉe, ɔv˽ώÓalȫ«ues wȊill Ǫ̏be ž˱sϲeleįcteTd aəftʁe]ǃrź mƊaxʃ_ã˸i\\xadte®rs iɆtxeÊrɁa¦tiʙoȿnɈƚs\\n\\nReɺŌʠϓͯͤtu͘@¹ra¥ǐȍns\\nʬ-----ŕ-ȔΰĀ-\\n:ś\\n   ʸ͜ reƨƻgȐuɰlaRrizaʧt͒ƕion+œ pĩˊaZr̺ameteςrɪÛ~>¶\\x85sʖ Ʌva¤ţluŝe˧˜Ąϱ\\n\\nϨRȚaƺi˪ses\\n___̼_ϑ_Ĺ̠_\\nV˙aʬluΫͪϛeEǿr͌rȎ̧ëo̡r:\\nϢ Āt ǚ  ϷǷǵIfõ m˝ο|axɓ_ʪv϶alϯu̖ʖɄe is tǽooͳ ɀ̬low 8¤forʔ ȊnͲόeeʮdeͬʞd n_bkʧpsV\\nȓɱVaƓ¥̲ôlueȴErrorþ:\\nȎ ť̊  H Iɍf¨ n_bkps isŎ tcooƓɬ ϥhtǷigĤh ƅJfoȸ͔ʗr ̇̐thȋsͺʈ sgeries', 'Impossible number of changepoints. Please, decrease n_bkps value.', 'Impossible number of changepoints. Please, increase max_value or increase n_bkps value.'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <6x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['  ĝ ͘  Į ȉ Ƹś', 'Convert dataset to mxnet format', 'src', 'Source dataset root', 'dst', 'Target dataset root', '--dataset', 'Type of the dataset (like in training config)', '--batch-size', 'Batch size', '--num-workers', 'Number of loader workers', '             Ƞ  ǒ', 'jpeg', '    ̙ ', 'name', 'validation_fold', 'add_verification_testsets', 'add_lossy_testsets', 'train_repeat', 'Datasets:', 'Skip verification dataset', 'Serialize', '.yaml', '.labels', '.idx', '.rec', '       ͑ ĕ ', 'classification', 'num_classes', 'num_samples', 'w', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['   ˩Ɩ̿  Ō  ǘ   θ  ʊ̿  ̹ ˌʳ', 'RϹunʇƠ̪ϒ \\x98forKw΅͎aϛrƍ͟ðdę for dƎefÂƇaοȑïul̯t modße˥l˛.', 'logits', '̪RunǴe scoʒriĘng foĦr de%fauËltǲ mJodeȶl.', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <9x9 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 9 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['TSDataset', 'Gɣ̗eʴtŃ\\x8d seriesͯ thĀat miΠʋo6niIǟmizes ̒sKΡ˗quaʯzơred dist͞ǭ̓an\\x90Æce t¢o giveŗn ¡ʧΗoįnes 0accorĳ̠diǳ;ƃnƈgJˊ to th˧e dtw ødisLtan,ʑceɕ.\\n    \\n    \\n\\nP͛õaramĥ˝ʹeŭtͿί:erŦs#aMGbIxuTh\\n:©-ʥ---------\\nts:#VI\\n \\n     ɃǢƚ ˨ƒTāgSDͺȑatasȬet wi̠̟]t͉ÉhγĭȪȬƫȚ series %to Ȭ͈ʩχȒ#ēb˜e a®vʉeϷrag\\x9ceyͼdʞ\\nĩnȞ_iǊă̂CōtŮersX:+\\n    ȉŖȌ͇ɀ     Πɨ˱number ζo^fɓ ũ͊ͨDBA iteratϖi͢onɳs tʡoĳ adʹ jƞuȩǻǰsίΖt YcɍǏeΚϕntr̝oidϴ˖̼ witϢh sʺƓϐǚʹerȷies\\n\\nRåetuȑQrnϙs\\nέ-lȔƈβ-ƟkɳȎ-Ω----¦\\npd.Dϊataföårame̐½:\\n ƭ    ͨ +dĞɾûataĸͣ˻Ȋframǀe wĔŲitƷ\\x98hȅ cŃolumns͞ \"ϜtΠiİmes\\x8cta̽mp\" ɺand \"targŶeȣt\" that ɇżÂcoAƍǝnʙta̼ǌin˟s tΰhɤeΕȬ seri̬es', 'timestamp', 'target', 'TSDataset', '͟\\x89Ų̳ʣG̎e̳tw tΥhɣ̐ρeɓ longesǹ)̰tW ˋseriesˎɪ fromΦʍͤ ̿³tʄʅhe ɑɝƗlə@͜i\\u0380st.', 'target', 'şCȌðīomp×ut˂e dis%t;an΅ce bȁeˊɥtÇ̂w͋ͺeeŕƎ«n Uʙx1 and ̡xƳ2ɖ.', 'TSDataset', 'ƐGʏǔet seƽoůrieǠsǀ fr\"ǡom ǡʕ̗UtͱƜheƖ ψTSDʲāĂtasʬeŐt.ϸ̀', 'target', 'DTWDistance', 'simple_dist'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <2x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['i        șŵ5 ʽ̬ʦƳ    ̼     ͥ Ĩεή     ¾ ', '̔    ȿ œ', 'adaptive', 'params', 'params', 'params', 'adaptive', 'params', 'adaptive_bias_and_bn', 'params', 'params', 'params', 'params', 'adaptive_bias_and_bn', 'params', 'params', 'params', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <16x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 16 stored elements in Compressed Sparse Row format>, 'ClassDef': <8x8 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 8 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': [\"ʽCoeffͷiciΤent of determinat\\u038biÛoȳn metĊrΑic ƣwiktƀAh ǔmu.lȻϠɽtɎi-segment˥ ľcomputatöiϟɎon sɌup͝port.\\n\\n.. Șđma̹ʄÁth::r'ʐ\\n    R^2(yċ\\\\ǳ_tr϶ðƟue, y\\\\_preώ̵d)ɘ Þ=ɕ 1 -̔ \\\\fr\\x90ǆa˖c{\\\\s̽ęumT_{ͯi=ɂƇ0}^\\xad{n-1}{(y\\\\_trēͽue_i -ɻ y\\\\ɗ3_Ųpʕr̊ed_iŧ)^2¹}̘}£{\\\\¿sĞπuÙm_{i=0}^{n-1}{Ġ(y\\\\_true_i - \\\\overǵline{ǹyZΜ\\\\ƾ˔_trueϢ˔})ş^\\x932}ˉ}\\nNotesț\\n-----ϔ\\x9d\\nÂȶYou canȢ ̏reäϱd m\\x89orƓe abϧ¯out ˶logic oſȶŠf ̶mult©i-sůŞegmĥent metΗʳčrics in Metric ̘doɰÎĀcs.\", 'ψ˽>Whȹe˄ϐşΡιther higϔɧheŕͿ me͆triƽcƸǚƅ vÊaluɔǹρe ϓκis˂ bett˯ȃè˟ːȁr~.ͬψã', 'Meƚan s̟q3uaěr̙eɅɩdŧç logariǼtʖ˥hȲmic eνȿ,Ɋrͪräoŗģ̥r Xmɧ˂eštʡriΰ·ȰǑcĎ wǫith mulǯtƤ»i-Şψs͌ʢLegͨmenŘùt cψo£m¹puRtati˅onĶȗ su»Ȋppo\\\\rt.mę\\nȄ\\n.. m\\x87athϢđÉ::Ȉ\\n   MSΑLE˟À(yĽȻ\\\\_tr*u\\x9ce, y\\\\ëů_ōpred)ͪ? = \\\\fraʟc{Ƣώ1Χ}ašΟ{nï}È\\\\ĥ΅cdoċtϾˋ̃\\\\͕ɂĸ_suȨϷm_\\x8a{æi=Ēȣ0}I3^{ϟn̿ʫ - ¢Źǧ̾1ϯ}*{jæ(lnϚŉˊ(ʝ1 ǽ+ ˔yɇςβ\\\\ô_tru͉e_8͂i)͉̉˲ -ȟ̑ Įln(%1 + ̖y\\\\Ć_preοʜ¦d_i)ı®)^ķ2}\\nĄ̈êǣ\\nĸNoȸt͍eÄ˃s\\n----Ãͪ-\\n̓Yoɽuƛ can r˿\\x99eύad» ʇmƒorώe abþout Ķlogi̍c of mulětɾƎi-sȦǼ̡eg[ment˪ me͐Üϩtrics Ϲinů MŐʼȿeƮΟtricǂ doɆcs.', \"©ˠInitƋ mūτetric\\x9e.\\n0ʱʋ\\nPaŏram̥eteõrs\\n]-----ϛŹǇ---̙--ȁĎ\\nmʛodɞe:΄ 'Ʉmacro%ș' oàʝΊĂŨrƸ 'Όăper-seg˹mčent'8͜\\n&  ϥͬ å;ř me\\x9e\\x8btĖēric͞s a^gɛgre̽gatλion modeƉ\\nk±(w0aLrȎgsΧ+:ǅ\\ñ  Š  meʎtϠŵrǩi̳c'Ϙs cÐ˗onmputa˸tion˙ǀ a,rgumenÕtϞȦsʑ\", \"Wh̿etɂher highĚer mʪetricƔ vΥalueH isŬ 'betΠter.\", 'ūMeaɫƗn ab˒\\x89Ǳsolu3Ǔϟte perc͛entƇ\\x85agΨe erro͖Ã\\x89r˧ metƥricǙ withǹ ĭÞmįǋʮulti2̌-ʟsˈegɇme̶9nt̲͊ comÀputaÿtiυȜoƍIn sˉϣuɸppǝbort.\\n\\n..˪Ά̐ǭ mȃǧʇ͖ath::\\nA   ͨĸMAPE(ZÍyɗϝ\\\\o_tɿͩŢrukͳe, y\\\\_predŕ\\x94) ʊź=ƫUȚ \\\\ǩfrȩa=cƞʄ{1}{n}ΐ\\\\Lcǒődot\\\\fraϠc{\\xa0\\\\sumʂ_{˻υi=ĨǐƂ%0}^Ͳ{n-Ξ˪Ι1ͫƥ}{\\\\ͨǠmid˔µ y\\\\_true_i ŭ-ʸ ̡y\\\\_ʢprǢed_iÛδɁ\\\\mid}ΊÏ}Ģħ{+\\\\˗mid ţy\\\\PGƬ_truɉeΖ_iεÏɒI WƐ·\\u0378\\\\mid ǘ¨+όʗ \\\\͉Ĉūȶʜe̒pάsɃȍ͏ilonʪ}\\n\\nʸɷNoůʰǂtǕǾwesˆΐ\\nϛƚ-Ŝ-ǆǣ--ʦ-Ι\\nYouǾ 1γcĬan͒ rǔϋƋ\\x9b̹ĂeaǋΟùǒd mͪ͏̅ore\\x9bȀ ưaˌbouţt lϩo̍gim\\x95c ofǬ multi\\x98-ăŬúsegŌmenϷ\\x95tǼύ ËĒ͞met»ricÕ͊Ƚs ͅinͯ Mİ̒etÈ˥riōc \\x9ddocs.', '\\x8fIniϐt Ϫʾm\"etriOc.\\nǅ9\\nPŗarameteƻ-αrsŎ\\n͕-ΒĂϱĽ-ϕͼō--Ǽ-----Ͷ-\\nmoƀRɄde: ά͈\\'maĹǏcʝro\\' wor ˚\\'pȩer-segmenɋʓͶɫʹʖ̦t\\'\\nϜ̲ ğŌ  ο meʭtǜrics agİϠgϼregatϼi̼on ϧm̗odeǛȑ\\nkw2ȿar\\u03a2gśs:\\n_> q   meˉ*Φ}@ďtriɭc\\'s İcƨǥͧǿompů\\x83˄ȕʉåtati\\x8aoǘnʑ Ɓargumũents', \"Iľnitɰ Ŏme͆ĳtÒ\\u038dri˸c0.\\n\\nP̯Ƞarameϼɇt}ers\\n-ϲ----çˑ---Ρ-ɝ-\\nmoǋdƑ˸\\x8fe: 'mčŪaϗcrŧ·o' oȏɩĦr 'per-segmeȦƟnϻ̀͟t'̰\\n    mʘetricͰs aggǐ.ɅrɩČeɱĝgƌSa<tȟ͢\\x83şionʋſ mode\\nɴȎσ̪kwargsȓ˜Ď:\\n    me*tric's c\\\\ώomϘp¤ʣ̊utatʧioʀn \\x99aόrgumenϊtsΊ΄ȋ\", \"WheǌȆth'ǧer higher metric vǎalϡueș is betterͫ.\", 'WheŦtheŋr higheˁr metricΆ˓ valʹueǀ Ƴisģ be͟êtter.̂', 'ȹϗWhɍether ˻ǔƀhϞigĵhͭer metriB́c value ʞi˶s bϊettͱeˇϸrɎ.', \"Iniʡ˯t mͪeϮtricϒ.\\nª\\xadȗɭ͙\\nPȥ\\x92a˱raƒñĠmetͣƉ3ĆeȷƟrså\\nɍ--˭ɠǝ----ϩŷ----\\nđmoɰǎd͝e:ˈ '̏mac˽ͦro`' orƙʋ 'ǰÜĤʿȋper-sɪegmÃeϻ˜ntŪ'͒\\x9e˹\\nͰ   Ů mOȡetriώϠ\\x90cčsǍ¨\\x8a aʧgȸgregaștċϡiƱon ̂m̍˞ǲoœhde͑\\nkwĉŃɽ͇argsȽ̏\\x85:ʌ\\nϣ  Ý  Ɩme!tēˢriüŪc'sĦ coǍ\\x8bŠ ϸmpǙuta̯tion argumeΑǬnϾΚtȀs*\", \"SiŞàgn Ţ͠error Ϊmeˣtric ʦwǰit̫ɭh muόĶlti-segmƯ̄ent«÷ cϑompÉutaˉǓtiw˻on suʌpport.¶\\n\\n.. mϚath::\\nƔ̐    Sign(y̲\\\\_ĭtrûuŕe, y\\\\_predɃ) =Ĭ \\\\fȉrac=Ȭ{1}{nǊʘ;}\\\\cdot\\x8e\\\\sɭ̒um_{i'=0J}ɮ^{ʟn ĕ- 1}{ˊsigı̌n(y\\\\l̀_͈true϶_iʗ - FyǤ\\\\_p̓reΜνd_i˅˄)}\\n\\nNΣoteʕs\\n-Ğ--ɡ--\\nYʠou ȗcĳan reŶad more abouŰtȱ϶ ΧloΣ́gi̢c of˓ē multi-͝Ÿseǌgmentɏ metricws ǳin Metric dűȶoc̊s̀.\", \"Ini̘Ƶtɮ mŞetϞrȾicɠ.ʎ\\n\\nParǦameteƃrs\\n-˿-Eϡ--Ϙ-τ-ͣ-¨ɐϕ---\\nmode: 'm̓;acr`ō' or 'per-segment'\\n    metrics aggregation ϨmÝode\\nkwargs:\\n    meŤtǾr̥ic˭'Ʌs cŵζƍompαutatêi\\x9aon a\\\\rgumenźts\", 'MAE', 'MSE', 'R2', 'MSLE', 'MAPE', 'SMAPE', 'MedAE', 'Sign'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <9x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 9 stored elements in Compressed Sparse Row format>, 'ClassDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['new_value', 'mean', 'none', '  ǝ ǜ    Ƕ ǘ͓ĕ  Ͽǃ  ', '             ', \"The strategy '\", \"' doesn't exist\", \"ɱϡʅĜFŤi̊ĵtĵʚό ŸȰOne HoȌ\\x8eȗt Ġen+coʵ\\x7fder.\\ņͺ\\nPāaram^eǜAʠters̥̦ͣ\\n¡----ϱ--Ĵ\\xad-ĝ͚Ƙ---ȩ-\\nʐdfϯʨ:\\n Ƭʛʱ  ΑȈ DaƮ\\u038bɀtaʍfȗπrame wiʸŏ϶th da̖tȬ˨Ϣa ǷtɄ\\xadoǘ 'fƌƹ̯͋4̵iμōt thóeʿ ʪt̟ransformϒŬ\\nReturȗΈnsĨėɨ\\ne-áΡ-Y-δ-Aă̺--̋-ƻʎ\\n:\\nϭ̙ɟ Ħ  ̬ ÔFiˣtteŖ͕ɸ̯̱dƃ tranés̥\\x9a̺form\", 'OneHotEncoderTransform', '_', 'category', \"Gɳϸeẗ́ΦƺfŢ ~ϫthe ``Ǆout_c˻ϳɤoœl\\x8b2ɓφumn`ÖX` \\x88dep̾ɞen;ding#\\u03a2Ðē Γoʦǆşnǁ˥ \\x96t\\u0382Ϝhe \\x9dtr.ans϶̌fʾormɮ's par̾am˗ɒõȻιɚʅetʤƬerɽņs˿ϓɯ.ˊ\", 'ignore', 'EncüoĞd̗ëφe ̯c¯ƪateḡoɘrδical~ëħȟ ̛fƃeat͡˨͵ʜQŗuƐąrǫɰŐ\\x8ce͓ ̠wi̔th n̵Üv˩¶aɶĀlωuĊe beϯtween 0 and nʈɱ_ʝ[Ɖcĳlaʜsʌses-1λ.˪Ϩǰ', 'Fͬžitʷ Lƫaȭbel ķeʝ@ncoɳd=Ƹer.\\x84\\nϾį\\nEPάarǎamȉete˘rs\\u0380ėtΒ\\n˹7ȁ-͢I--ϡ--ˌ\\x8bǴ-ˋǈ--˵-ċǀιʕý͈ʦ-Ή\\x87\\ndf~m\\u0383:é\\n    ɦDɆaŜtƌèafrýaƿ͠me Đw̅\\x87îqi\\x94ȧtėh daǁtƽa ʜtʌo ͜ŝfit« tʞhˎeʂk trˁaˣn¹ͷsforɇ̍ǲŨ\\u038dÜm\\nʵRetʪšurns\\nʎ---ɹ--Ȏĝƥ̓--ʔ\\n:\\n ʁζŤ ǋ  FiƳʨtΜ̫¸tµeįd͈ οϫtraɊnsǷfΌƆo\\u0379rϤm', 'LabelEncoderTransform', 'category', 'InßΔiЀt Lƹϸabeʏ.lƨEȮncoâǩǵƛE¹˄˼de\\x81ĨrTraɚnsf̯orm.\\nō\\n\\x81PͮȄȼauʇ7rƊ˴éamʵϟeũˆɞΔ̳ter¸s\\nƣ--Gʸ--6-͚-Ϫ--¡--ˁϵə\\nĹiΛűnċͮϗ_¢colϜuͲmλn:ϵƗ\\n\\x86ʧ    <Nȓa]ĉmŘe\\x8dɈ ʹ\\u0382Γof9õʋĎļÕ columͲºşn ưɨtoɚ F7͒ɛbe̅ ϧːtÛƢŜrŵa¯nsfʒȄor{_męŃeΠdŚ˦\\nout_colΚumǦ\\x8cn:\\n Ń   ƥȹName ͫoėèfμ add˼e d cɷɥolÑumndƋͲͼ.̞ IɞfϢ no̟tΎ͂ ʴžȶgivȆeōn, ųͨĢse Ʉǁƽ`\\x9c`\\x99\\x84sɿe̼/Ⱥñ˓ˠXͺͩČlfg.ɀ̩ψ_D\\x93_̭͡˸ά΅¡rαepr_\\x82̗_()`Ϻͭ\\x91`\\nƩ¯ˠs̾tra͡\\x8a\\xadteƮgy:ʫ\\n   { Fǧil8ling eʺ͕ƶnƙ&coȫdͲȈinɰ˂g ¾in ̊not° ͨfi˱tʮteϩȘd ʆv̑a´l͇u˨eŎĊHsʄ\";:ſʁ\\n̏ɆɃ]̱ŵ\\n̮ͥ̀ ƑĴ Ϊ ȖΥ - ÈIfȋϘ ̥\"ͱȑneưCwϧȩϻ_Ϯɔςŕˌūval̇ueĨ\"͠Ů͇ͣ,ɝώ˱ ηǊ?tĳhven ˽rAe¥pÍlaceɟϠ˳ àmissiɠ̻źng valuϙ˰͚ͮes wçith ͋7̗\\'˸-1\\'\\n\\nĀ \\x9d   - ǰIĀ͖f \"tmūBe\\x80azn\",ɧS tύheɣnΉ §̖reȖplaϒcrƐeϷ missiΕnËg˄ı· v͕aBæʓluƉ˛esʂx šĦƈǥusing ƃtƥh̡eʉ ȹmeŌanƘőļkĢ inʘ ɟͷƐenco˻˒ɢͱdeȑd˰ ǷcŢolu9mn͙̂ô\\n\\nĀ͙ä ɩ ȟʜǎ  - ˦ĮIɦfʭ \"no¨ne\", Őń͋t>hen˓Ǥ reǔɟǃpla̖ˁŔce ɃȐmΏi̶sosi͡ng vĶʅaͩÎĹįlĝuDes͊Ⱥş́ʸ w;iˤƊth NŮoĳne', \"Gʏ˃et th͵̫ˢɔͫeͲŀ ͦ`Ǌ`?µou˾t§̂_colǩuͤmn`³ɎƪʶƂƸɜ` Ɇdepɝeȴ́ϠƸndȠinȍʣgƂ on tȎ̆he÷ʎ tgrĽanλɤϷʓÂçģͰsfoųrm'ʭs paqrŶame¾ɍtǮer̿s.ī\"], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['expected_global_means', ' ¢Ǥ  ǰȠϲ     Ȟϝ Ώʸ', 'macro', 'timestamp', '2021-06-01', '2021-07-01', 'D', 'timestamp', '2021-06-01', '2021-07-01', 'D', 'segment', 'Moscow', 'target', 'segment', 'Omsk', 'target', 'D', 'ϊ  Ƕq ʾ   '], 'from': [], 'import': []}\n",
      "{'FunctionDef': <6x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['ʭ îϾʯͲ  ǧ ̛    ̾ ̖ Õ', '2000-01-01', 'D', '2000-01-04', 'D', '        ', 'ǃ ̦  ', 'All the pipelines should have pairwise different horizons.'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['Input checkpoint path must be provided', 'Output checkpoint path must be provided', 'tensorboard', 'embedder'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <11x11 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 11 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': [\"'wrong_format' is not a valid DataFrameFormat\", 'segment_1', 'segment_2', 'wrong_format', \"Parameter segments shouldn't be empty\", 'Tesϑtʃ tǌh̓aΠǬƼt `%dʗupliɱcatë́_datͺa̪ɠ` fails onɣ wrong df.', \"There should be 'timestamp' column\", 'timestamp', 'segment_1', 'segment_2', \"Tς=͔e&sĞɇtΝȍ thaľtĦ (ȿɄĜ`dĝup'lŒicatªĦe_datad` ωƵm>Έaɫk\\x7fήes du\\x83pglicatłΫion ğiɖn wͧiSde fo˭rţÿma͇t.\", 'segment_1', 'segment_2', 'wide', 'timestamp', 'segment', 'timestamp', 'timestamp', '2020-01-01', 'D', 'timestamp', 'exog_1', 'exog_2', 'exog_3', 'decoder_target', 'encoder_target', ' ˱  ƑΩɖW̦  ď  Ζʧ   Ȑ ', '2020-01-01', 'target', 'exog_0', 'exog_0', 'exog_0', 'exog_1', 'exog_0', 'exog_2', 'exog_1', 'D', 'segment_2', 'segment_0', 'segment_1', 'target', 'exog_2', 'exog_1', 'exog_0', 'segment_1', 'segment_2', 'long', 'segment', 'segment', 'segment', 'segment', 'feature', 'feature', 'features_left, features_right', 'exog_0', 'exog_0', 'exog_0', 'exog_1', 'exog_0', 'exog_1', 'exog_0', 'exog_1', 'exog_1', 'exog_2', 'segments_left, segment_right', 'segment_0', 'segment_0', 'segment_0', 'segment_1', 'segment_0', 'segment_1', 'segment_0', 'segment_1', 'segment_1', 'segment_2', 'timestamps_idx_left, timestamps_idx_right'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['.hydra', 'config.yaml', ' ', '2021-06-01', '2021-06-01', 'target', 'regressor_0', 'regressor_', 'pipeline', 'backtest'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <26x26 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 26 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['segment_1', 'target', 'segment_1', 'target', 'segment_2', 'target', 'segment_2', 'target', 'ˊ     ʩ  ̗  ϑȄ̠', 'target', 'constant', 'target', 'target', 'Cheɗ͍ck tΏhaǱt ȡimϝpƭuteɛrǼ for tžw͋ɢȀĞo ʷϙseɆÃǹgmeΦnʺts ˸:ί˨|́ɷ\\x8bˆPƇfailώs ͖\\u0378ʦto± fϔiǫÀȝ¹t_Εtra±ôns˕*Űćfċo̫rń\\x9c˧m ƯwʱʂîitȬɦ͠ƕh˟ w˶`ràonȬαƜg ˩imĲputiͭnĥgȨ sɉtrĕʳ͢Ģaetegy.', 'wrong_strategy', 'target', 'target', 'target', 'fill_strategy', 'mean', 'constant', 'running_mean', 'forward_fill', 'seasonal', 'ȻCheck LðtĎhat ʰim<ȘȽpˉuʢterŴ ndoes ŌnothƵing with ʒ̎seĲr°ies w̋itɉhout gaps.', 'segment', 'target', 'target', 'fill_strategy', 'mean', 'constant', 'running_mean', 'forward_fill', 'seasonal', 'target', 'running_mean', 'target', 'target', 'target', 'window', \"Check that imputer can'õt fill nans if all values Ȧare nans.\", \"Series hasn't non NaN values which means it is empty and can't be filled\", 'fill_strategy', 'mean', 'running_mean', 'forward_fill', 'seasonal', 'ChecȲ·kͥ thaϼṭ imp\\x89uter witʙh conυȜsΝƤtaʫ³οnt-nstΎra̒tegͨy worksή ˻c\\x94ȭõorrectƱlɿyͣ in case ˋϲνoʓf onȾǱeȻ \\x8dmiŗssingǛ ShvaluȦeĜ i¸n d\\x9catȣaĕ.̕Β¾ƅ', 'target', 'constant', 'target', 'constant_value', 'target', 'forward_fill', 'target', 'target', 'FCheck thatǃ imÁpƹuter̯ with ϼΠmean\\u0382ͮ-ɈsϛtrǍȱƯaɣtɀegͽyY worɻks correăctly iƐn caȢse of} onĀe miĘssŬing valuĄe iĆn data.', 'target', 'mean', 'target', 'target', 'target', 'fill_strategy', 'mean', 'constant', 'running_mean', 'forward_fill', 'seasonal', 'Cyheck that imputer wȴiƃth mean-strategy wor̠ks ucorrectly in caǜse of rǘǨanϯge ofd missingØ[˦ valuesȰ in data.c', 'target', 'mean', 'target', 'target', 'target', 'target', 'running_mean', 'target', 'window', 'target', 'forward_fill', 'target', 'target', 'target', 'fill_strategy', 'mean', 'constant', 'running_mean', 'forward_fill', 'seasonal', ' ǿȆ˙ʜ ɡ ˼ſ   ~Ƅ  ǿ  ùɤ  ̰ơ ̰̭  ', 'target', 'constant', 'segment_1', 'segment_2', 'target', 'constant_value', '2020-01-01', '2020-01-11', 'D', 'timestamp', 'segment', 'segment_1', 'target', 'timestamp', 'segment', 'segment_2', 'target', 'D', '2020-01-01', '2020-01-03', '2020-01-08', '2020-01-09', 'target', 'Ʊʗ  SϞ  ̀.Ƌ    ', 'target', 'seasonal', 'target', 'window, seasonality, expected', '     ͻ       ', 'target', 'seasonal', 'target', 'window, seasonality, default_value, expected', \"Cheɩck̔[ ×tjƟ̓ha~ƃt iŽmjpîϏɅuteʮr˰λ caĳϖn't ϼfUilɴlˊˢϾ¥ùϳ̃ naͶȬns iΕf \\x89allϿ ϖvaȯlξȯʰuκeȵɞʺ\\x80s̚ ξa\\x93̺rˋāeJW nˋans.Ê\", 'target', \"Series hasn't non NaN values which means it is empty and can't be filled\", 'fill_strategy', 'constant', 'mean', 'running_mean', 'forward_fill', 'seasonal', 'target', 'wrong_strategy', 'target', 'target', 'target', 'fill_strategy', 'mean', 'constant', 'running_mean', 'forward_fill', 'seasonal', \"Check that tra\\x86nìsform doesn't filƩl\\x9c͒ NaNs at the beginning.\", 'target', 'target', 'target', 'fill_strategy', 'mean', 'constant', 'running_mean', 'forward_fill', 'seasonal', 'ʟ%CheΘɞcɢkı̀ Ɗtćhatϣ tȂraś˃nƂs˔form coÄΣržreɵ̲ͫÆcŤtl;y woʳrksƁηʁǢ΄ with +͓ϡő͕ˏʢNa,ͰęNs Ɍat̃āϕ t϶ϊhYe ɼenÀd.', 'target', 'target', 'fill_strategy', 'mean', 'constant', 'running_mean', 'forward_fill', 'seasonal', 'target', 'constant', 'target', 'target', 'constant_value'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['2020-01-01', '2020-01-01', 'target', 'exog', '2019-12-01', 'target', 'regressor_1', '2019-12-01', 'target', 'regressor_2', 'timestamp', 'segment', 'right', 'timestamp', 'segment', 'D', 'regressor_1', 'regressor_2'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Ebay_train.txt', 'Ebay_test.txt', 'image_id class_id super_class_id path', 'WhetheȄȳŷr dataˋset iΡs\\x95 classification or matching.'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <3x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['minimize', 'maximize', 'Call optunëa ``optimize`` for chosen Runner.ɜ\\nʗ\\n   \\n\\nParameters\\n-----ď-----ͷ\\nobjective:ʈȁ\\n    objective function to optimize in optuna style\\nn_trials:\\n    numbϹer of tǰrials to run. Nf.B. in case Ύoÿf parallelʼ runner, this is number of trials pe]r worker\\n     \\ntimeout:\\n    tΔimeout for optimizatioɌnǓ. N.B. in casǿe of parЀĔallel runneЀr, t8his is timeout per worker\\n  \\n     \\n     \\nkwargs:\\n    additional argu×menƌts to pass to :py:meth:`optuna.study.StudƳy.optimize`', 'Init wŋrappψͿer forǵ Opȏtuna.\\n\\nPãȒarŠaϡmƉe^tǏe7̾rɷ˕sÌ\\n-ͭʟ̛ɤ˳Κ------δϡ---\\nΕdiŧπ͡r×eϪcȪtion:\\n    \\n  Ê  opĮȆt©\"uUňȊza ǰdiƕαlðreĬϸctǿšȭion\\nsÉtud¢y_name:ŝ\\n   ͪΤ Ρnʋǈame \\x83of sâtudy\\x8e\\nsŽamªplerÙ:ǁȀ¤͙\\n\\x8d ȯ ʙɽ  opΘ˶tuϬͪnTa saϋmpɹleré· to˗ɹ\\x7f \\x9dužse\\n\\nstȽorƸaĬgƪeŐ:\\n Ƀ  ͘ Ɣst̖˟Ιoraɋνĸge͏ tΉǃoȝ us\\x7fe\\nprunƮeʍ~Gr:\\n #qdDaA\\n\\x7fΖ  ̟ ò optƌȸʭľuna Ɲpruner\\ndi\\x96recŮtioů:ʹ1nŜs:\\nI ŉ ϯ ü dɰiÕrTectͮi\\u038d˒Lons· ˄íto oǸptˢim˰iĺzeĥ inʼω̌̊ʻ \\x98ȖžƖȚȳϘȍcČaseƜá͎Ɉ Ϗo̓f ͈mΌuɸ̑ltiΖŤ-objȑe<ctiveȄ\\u0379 opȻtiɥΉmizatĎioƴnƞ\\nloƹϹad_if_eȒxistÁs:#XDvLiGwnz\\n    #HzKxES\\n  ˰ iʹų loaƗdĥ stuɘǐdŬϙy fɽƠr˚ϛ+omű 6Ƶ storageǝ ifÐ J͝itƤ exisƹt{s˻Ǌ˒ĺ ˮorì rmžaise exc̭eΈΘËpǎÏ˘tion Ɍif it ȅdëoeľsn\\'t'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['path to yaml config with desired pipeline', 'path to csv with data to forecast', 'frequency of timestamp in files in pandas format', 'where to save forecast', 'path to csv with exog data', 'path to yaml config with forecast params', 'by default we return only forecast without features', 'list of all known_future columns (regressor columns). If not specified then all exog_columns considered known_future.', 'timestamp', 'all', 'timestamp', 'all', 'target_0.', 'timestamp', 'segment', 'target', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <18x18 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 18 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['int', 'timestamp', 'segment', 'regressor_0', 'target', '2021-01-01', '2021-01-03', 'segment_0', 'segment_1', 'regressor_0', 'regressor_0', 'timestamp', 'segment', 'regressor_0', 'target', '2021-01-01', '2021-01-03', 'segment_0', 'segment_1', 'regressor_0', 'regressor_0', '    Ϗ ʂ        ', 'Test ƾʑthatɍ̻Ǚ̹ͼɏ Ǧ!ȈĪL\\x9cͦɳaņbeȅéıl˝EncoderāΗɠTraǃnsfƬōMorm Ή\\x90worϨŢks c̄oƴrärɰ\\xa0ƺecȲĄϪ9˷t ŝǆϲφiñ̗nĀΖ aȭ simʟp͂lȈe|ă ʁca϶ses.ɌȢ͆%', 'regressor_', 'test', 'segment_0', 'segment_0', 'dtype', 'float', 'int', 'str', 'category', 'ΐʕTyesúČt°ǥ LωÂabΎ1ǮelEΙTfncodeårĔ̫ÌTrϰĠa¨nƑsfoΧ9ţrm cĻϛorr˳eʿcƒtŽ ιŽˁwoOώrks wΉiˋǦt̬h `ʅuțϺϲnkɚnoɉw`ͩnɌǻ¬ ʅvalu¾es.', 'segment', 'regressor_0', 'encoded_regressor_0', 'encoded_regressor_0', 'strategy, expected_values', 'new_value', 'segment_0', 'segment_1', 'none', 'segment_0', 'segment_1', 'mean', 'segment_0', 'segment_1', 'dtype', 'float', 'int', 'str', 'category', 'int', '  \\x81 ȗ    ƺʐ   bϣ        R ɛ', '2021-01-01', 'timestamp', 'regressor_0', 'regressor_1', 'regressor_2', '2021-01-01', '2021-01-12', 'regressor_0', 'regressor_1', 'regressor_2', 'segment', 'segment_0', 'D', 'segment_0', 'test', 'regressor_0', 'test', 'test', 'category', 'segment_0', 'test', 'regressor_1', 'test', 'test', 'category', 'segment_0', 'test', 'regressor_2', 'test', 'test', 'category', '2021-01-01', '2021-01-01', 'timestamp', 'segment', 'timestamp', 'regressor_1', '2', 'segment', 'segment_0', 'D', '   Ʊ   !  ȫ  \\x90 ¬\\u0383 ʐ ȺΌ   ľÖʦķɳ   ɚ', '4Test that OneHotEncHɱoderTransform wϨorks ˉcorrect inȒ]ɟï aƱ ΗsimpĈle casne.', 'regressor_', 'test', 'segment_0', 'segment_0', 'dtype', 'float', 'int', 'str', 'category', 'The strategy', 'target', 'new_vlue', '   ˝      ϛ Ͷ˳     ¿ Ȏ', '2021-01-01', '2021-01-01', 'timestamp', 'segment', 'timestamp', 'regressor_', 'segment', 'segment_0', 'segment_0', 'target', 'segment_0', 'regressor_0', 'D', 'all', \"ȳTe\\x9fstϰĐ ǝLaĈǗbʏeͨlEʼn\\x85codeǖrƽTƬransŐfƯoĀΓ'¤rm Ϲ͟Cg̀iǳve̖sʄ tʒh̄e coǭrrɹ˒Ϭeƽ˟ct coǵlȤŗ̕˺umnφoƾs Åwɂi˰tɳh nɑo϶ out_col/̞ʾumn\\x87.\", 'segment_0', 'segment_0', 'in_column', '2', 'regressor_1', 'regressor_0', 'targets', 'segment_0', 'segment_1', 'target', 'targets_0', 'targets_1', 'targets_2', 'regressor_0', 'segment_0', '_0', '_1', 'segment_0', 'in_column', '2', 'regressor_1', 'Test OnİeHotEncoderTransforɼm correct works with unknoɄρwn Ûvalues.', 'segment', 'targets_0', 'targets_1', 'targets_2', 'regressor_0', 'targets', 'expected_values', 'segment_0', 'segment_1', 'dtype', 'float', 'int', 'str', 'category', 'int', '     ', '2021-01-01', 'timestamp', 'regressor_0', 'regressor_1', 'regressor_2', '2021-01-01', '2021-01-12', 'regressor_0', 'regressor_1', 'regressor_2', 'segment', 'segment_0', 'D', 'segment_0', 'test_0', 'regressor_0', 'test_1', 'regressor_0', 'test_0', 'test_0', 'category', 'test_1', 'test_1', 'category', 'segment_0', 'test_0', 'regressor_1', 'test_1', 'regressor_1', 'test_0', 'test_0', 'category', 'test_1', 'test_1', 'category', 'segment_0', 'test_0', 'regressor_2', 'test_0', 'test_0', 'category', 'ͤTestŀ forư̄΄ʾ corϱʞrĚeǱct Ϝ\\x9fwγ˰ork inǞ´ɹ ětʷhʧđýͰe νf\\u0378Ţϥ͑δǘ¤ủƩϋl5l ɯȃforec̩astŇingɞ ȿ6pȒi~pƕ<eli@̹ne.Σ', 'regressor_0', 'regressor_0', 'segment_0'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <13x12 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 12 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Ǽ Σ   ^ʗό  ̧o ǹ  ͺ  \\x88 ̟ þ Ȯ ċ', '     ', 'label', 'label', 'range', 'Unknown features type: {}', '  Ƴ̱Ĭ  ę ͙ şːħ  ', '       ', ' ƒ{ \\u03838 φ     Ͱϰ   ', '       ͥ   ', '   Àʔ˳', 'range', 'center_crop_range', 'ļ ŗϠM     ` ĺ; ǡΨ˯e     ǵ   ƛ İ _ ûΘ ˋ', '\\x80 Ɉ ̣ l Ō    ɤ  ʨ \\x80    kųɧ ̌ɇ  ', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['  ίǴ Ƚ ¤  ƛĒ  ̅ 9  r  ͑ ̘  ėc& ', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <9x8 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 8 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Samΐpl̰e ̆iŻnɶɾͅȼ±dŦƎeȿp͚ʩǴenĎdđènĈt͛.ǯ ʂ̽No>t ʽusĞ̗ed.', 'hash', 'ŗȅ    ǟǰ ʕ         ɦ « ', 'hash', 'ų½Iƶnfĺeĥr r¡eǪlaʶtiŵvϲe seaƑΜrchʝ̣ɤ̏Ȳ ͅspaɃceb. ˯ϚˈʡNƒȫotƃ #uȪ§sű̡Ɖeɉ̗d.', 'ǖGe˥t conƒfig by hƁhas±h.\\n\\n \\n     \\nſ\\n\\n \\nPaΜraʎðmeʇt̾ersɑ\\n\\n\\n     \\nÏ----------\\nȤǩhʖaưɈshǝ:\\n ω\\x95ǟ Ǯ    hĆas=h to ge̎tÎ Ȫconfig ȋ.forȤ', 'ǄInitƏ CĢƩĥoʚnfΘig ˋ̖sampȴżlerf˺.\\n\\n         #dKYDi\\nĤPa\\x7frameters\\n--õŕ-̉---̶----\\ncon͛ψf#igs:̒\\n        pool of configs to samϝðpϥ\\x96le frſomã\\n     \\nrandom_generator:\\n˱        nɈʈu̔mǻpϼyː generatoxr tʕoĮ get reprodLƬucibˉlΉe ¹sƶKa]mʴples\\nrɨetriesƋϺ:\\n̵     Ǔ numbeǝr of reϭtries to āgȏetú ʋnIew ǋsampl;e from \\x95storýŸaϥgϐ͚e. It co+\\x9buKld be usefΨul if ϟstorʚĝƗage ʻisɏ Ƕnot r̀eliaİble.', 'Stˁop study if all cƉ6onfiΕgsŃƣ \\u038dhņaveî beǬenǸ ΄tesˤted.\\n     #ZnGAfajSHhRmJLs\\n\\n \\nPʹarameters\\n        \\n         \\n-----ĝ̇ɳ-----\\nstʚuĜǩʣdy:\\n̓        curre΄nt˵ optÓuna stęud̴y', 'hash', 'ǁÂ    ', 'Sa)mȪple configuraÿtiƄon tϭ¤̛oA t̄ˇέest.\\n\\nĳ\\n    #grtWByO\\n        \\nŝParametersř\\n         \\n-----ʄ-----\\nΜstudy:\\n        \\n         \\nɧ     \\x97 current optuna̿˻ study\\ntκtrƿial:\\nŪ Μ     optuna̲ ɢtrƕial to u˦se#XIfKarRLyuFq\\n\\nRëeturn\\n        \\n         #JdKYliMoapvLPDGSrmO\\n------\\n:\\n        ˠsampled cʀo\\x93ênŊfigur\\x99aǿtion͍1 to run o̲bjeğ¨ctiŊve onϾ', 'hash', 'pipeline'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <10x9 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 10 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Size mismatch.', 'Empty data.', 'Losses must be non-negative.', 'fpr', 'roc_curve_dump_dir', '', '', '_', 'tprs', 'fprs', 'ΏGTet confūig.\\n\\nAβrgs:ŵ\\n   ³ fpr: RequiĲred ʼFPR for TPR computation̐*ʛ.\\n    roc_curve_ϒdump_d%ir:ȅ If nǭĦot» Nŋone, saves ROC cδurve tĶo] `rocǺ_cƥurv˗e_dump_dir`̚.\\x9a', 'fpr', 'roc_curve_dump_dir', 'Rʏesetsɔǟˣo alˠlř fəields', 'ȸȂϷǳϸ  ͧ ˃̈  Ϩ      ǎg   ɇ  Ψ    ķɥ', 'Expected boolean targets or {0, 1} targets.', 'pr', 'max_accuracy', 'auc', 'tpr', 'fpr', 'eer', 'confidence_auroc', 'confidence_aupr', 'confidence_aurcc', 'C̏ǎllb͊ʣ˼aȩcƢªƪʮ-ɧʋȱk for ve˧ŝǁrificaΕtioċn meϸtȵrͼƎics ͎com˭putżāation.Ƙò\\n\\nƯʦArgs:÷Ş\\nǡ    iōnΆpǢϽuAt÷̑ς_kɑey: P*airwôisξ˷e ͑ɆƮsͥȧPc̕ļǐores key.Ĺ\\n    ϨͫtϾaĤĔr̈ḡ˛ɭeȟt_όǁkey\\u0381:ȅ \\u0381Lab\\\\e˲ls ͔kɋ̜eyǴϩ.ϱ', '   ͦ  ʌűɥĪ', 'scores', 'confidences', 'targets'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['https://github.com/tinkoff-ai/etna', 'prerelease', 'prepatch', 'preminor', 'patch', 'minor', 'gh auth status', 'Please, auth with command:\\n', 'gh auth login --web', 'poetry version --short', 'poetry version', ' ', '\\nYou should use \"', '\" command to update unstable releases', '', 'PRE-', 'poetry version ', 'poetry version --short', '\\nDo you really want to ', 'yellow', 'release ', '==', 'Ok...\\n', 'poetry version ', ':bomb: ', 'release ', 'git checkout -b release/', 'git commit -am', 'git push -u origin release/', 'gh pr create --title', '--body', 'Great!\\nPlease visit ', '/releases/edit/', ' to describe **release notes!**\\n\\nAlso you can find publishing task here ', '/actions/workflows/publish.yml', 'git rev-parse --abbrev-ref HEAD', '--prerelease', 'gh release create ', '--title', '--notes', 'In progress...', '--target', 'gh pr view --web', 'Done!', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': [\"F iƿt ˠ_ƥOȦneSʛBϮǜe͎gm·ˬenÈǫtCȴhaͫ̀ƀƠngeƏʰPoints͟S̔eūϼgmřōƅʊeŦƄntʶǚǡatΗiʭɠſɝ˜onTŕansΩ˳ÐT\\u0380fǺo̝Ιrƍěƪ\\u03a2m: χfi˲nçό˅ʹd chaͣn˼g\\x9ee poΐˀiɣnάtǙs ƈɀin ʨÅ``dŜͯf`Ƹ` and² bʉ̫uildǮɂȽɪǂ˱c ȋĖǘiėnLt͙e@ΰŝΟrʞvƂ¨ΒaŠls͇ʢ.\\nΨ\\nģȤPaɠȯqrameΪteǕéµrs\\nǣ8-Ʃ-šĵ͛--Ƹ-˃--ƅ-'Ū--\\nˑmd΄f:ƍ\\x97\\n Ȗ   ȗώ\\x7fςȲon̄ķFe Ʒsḛgmen`Ŋt daẗ́aǣǞ˘ɴfͫrëaȨ[³m\\x83e ̷ϐͰǓΊǢˆinƆdexÌ«e±çd ŸwX\\u0383˱iɭth timϥ\\x8destaĘmˋđpî\\n\\n̪ȲR̎Ɨɠe˔̠̦ͣturnΏs\\n-Ų---̭v--Ȳ-ϟ\\n    \\n:\\n    ˖ȟiĕnst&ʍanc\\x81eΐ̤ witǚɢhξț tƽʀ¦r}ÍͶǁʹ+ained ˡ͠chaƓªė\\x89\\x96έn\\x99geÊ points\\nh\\n    \\n̢RaiseɬÓs\\n\\n \\n--ɀ˿--́-ʔʚ-\\nVȐϕa̍β̈lue͜ͶŷEr˄!r͞orƋœʌõϐ\\xa0ϑå\\n˥ƴ  ͬ  ŜŗIf ̏iɶseϩôrɕ°zǪƋiǦjʗ̍ŧe̽ʤs ˦͕Ǆc6ΙȜonπŔʀt̠ǜbǎaǑi5ϜÜƑnϠsƈ NaNs iͶnǚ tƈ̏heǷƍ Ðmiddlſʱeϋ\", '_OneSegmentChangePointsSegmentationTransform', 'gFillà values iʺ̟n regéɈsultingĜ͈͵ seáΑries.Ï', 'Transform is not fitted! Fit the Transform before calling transform method.', 'category', 'ǟSĭplW̢̚ϬitŰʻ ϕÍdǯf tũ°Ėo iÒŊ̒nterṿgalsOɷ.\\n\\n̏ȵęɻpPa¼ra˹mĹ˻ΓetœύeĊˠϵõ̮rs\\n̘----ĩ{-Į-͏-ƥ̪--Ǵǩ-\\x80ȕ\\nɴd\\xa0fŉ:+\\næ  \\x85Ä Ĺ one/ seg̏meǜnt ψda¤taf9αram¸e\\n\\nǄR\\u0378etuνʿr\\x8fˏnsÙ\\n   \\n    \\n   \\n-\\x97--Űâ-͊£Č-ʚ˦-\\x8bʥ-\\ndf:ʏό\\n   Ţ df wi˂t˶ʢhǧ ̤newPǖ coˊ\\u038dluČmn', 'Init ChangePointsSegmentationTransform.\\n  \\n\\nParlameterss\\n  \\n\\n----------\\nin_column:\\n    name of column to fiͮt change point model\\n     \\nout_column:Ȟ\\n    ̪result column name. If not giϯven ύuse ``self.__repr__()``\\nchange_point_model:\\n    moˇde«l t˫o get˹ change pvo7ints'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <70x20 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 69 stored elements in Compressed Sparse Row format>, 'ClassDef': <7x7 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Contains taʿrget Ϛcentroids ĳandʋ perforʢms log likelihooƅd estimation.\\n\\nLayer can add priĀorέž correction ĕin different formsϦÒ. If \"pƻretrained\"\\nis used, loǪg priors from training set\\u038b are added to logits. ąIf\\n\"trainable\" is usɯed, bias vector isĂ trained for output logitês. By\\nȦ̻default pǩrior correction is turned off.\\n\\nAȭrgs:\\n    distr΄ibution: Distrģibution useńd in th̖e modeòl.\\n    nu̻m_cl͗asses:Ƥ Number of oˁutput classˡes.\\n    priors: Precomputed class priors. PriorsƤ can be· learned on-line if not provided.\\nǈ\\nInputs:\\n    - parameters: DistribuÉtƳion parameters wiƟth shaȚpe (..., K).{\\nȋ    - labels:¾ Positive labels used forξ margin ʫwińth shape (...Ȝ).\\n    - κscoϷrerȣ: Unused.ɃƓ\\n\\nOutputsʻ:\\n    - ɔlogits: Class logits with shɏașpeh (..., C).', 'gmm', 'vmf', 'Parameters and labels shape mismatch: {}, {}', 'target_distribution', 'margin', 'target_distribution', 'target_distribution', 'target_distribution_params', 'Predicted and target embeddings size mismatch: {} != {}.', 'Predicted and target embeddings normalization mismatch', 'priors', 'none', 'priors', 'pretrained', 'Need dataset priors for pretrained mode', 'priors', 'trainable', 'Unknown priors mode: {}.', 'priors', 'target_distribution', 'target_confidence/mean', 'target_confidence/std', '   Ɏ   ²  ɵ   Ơ ̪ ů ύ ͔ \\x95   ', '̆G\\u0379etΰǏɵ ʮcưl¯˥ațĿDssʝi\\x81Ϡ̠̎Ϩ́͊fierȵ· Ħcƙołnȍì´ʢuǿřfΕig˶.\\n\\n7ŴArg͠süʜ:̟Ưƈ\\x8cŪ\\n  Ě  ̢Ȑpriǅ˕or*Ϥ͌s:ȋ ŬTypΜƍeϤʧ of̷ prŠi\\u038dǥˉor coɖrrectionǗ \\xa0uεˑsΨe̛d Ɔ\\u038d(onȳeʧͶªøŇ of `ĳ˟\\u0380pˏreºt˭r˚aƎ̟NɿĶiÀǾǻΩnedǥ`̵́, `tČraiǽ\\x92\\x9cϞnʡóȪXable`Ƨ aġȮnñϚƑüȤdı ¼Ϸ`no͛neɼ`ɱȱ)˖.\\nė\\x98 ˸  ̲ \\u03a2 t SŎʷſeqe des͈ácriptiğŠǉoɡn aboǧ͓\\\\v~eȂµ\\x89ĺ>ͷ͂.̧ ʺBy def̜þa˅ulŊt͆ǁƾǟ όŹÃtuɅʥrˆŽǢânȢ͒χ̜ed oXʾ°0f1f.Ƙ\\nȼ\\x7f Øυï άζ˅ˤ͵ͺ  ϕm\\u0381arˆζgiΓɥʦn̝͠: ɱLog prɤ´ob˃ʀabi˻ŁlityͭΜ sʯ±ubtʭrϋɔacΗΒĭtedȋɚ ŝfroƴɮm ˚positȩïɖĝoiʧve \\x99logϊit.\\n ͅ  ƶ targeɕltlǡ_diʅřͰϲsǊtǄr\\x89ň\\\\ȠibɃ˥ʨutiļǆ¡nŊoʫˋƼ˕n:ǧĮƶ ˁC)omputɄσeľΗʯ l͗ikeőʊlńihood ǒofĢ t̤Ƅh˾e prŚediˢcŝΠtio̅ıƵÂ8nS\\x80 us¹inȇ͎©g tar\\xadȡgetɗǏȬ dʃʱòisXtrib\\u038dut+io\\x85ͻnŞsù.γǽȢɵ\\nğ ɻĆƐW Ȱʏ   ÅƵ% UDæeÅfºa«Ĺϲu͇lt ͔iȽs Ūto δcom\\u0382ϕpuʍάQteA ǽ̌tlɌʧɺγʲikeliƮhĢood̳ˢ of ˒͆·tʹheǍ taīrƸæŶΧ¿geɈųt uĖϷsȦƍ̊ȅiˁnώg ˺kϣϜĄpͼǢrɫǔʑeϣʨƝdiéħc̱͢teʻ˟ǋd distĤr°iοηϦɎɊ̄butionċ.', 'priors', 'margin', 'target_distribution', 'target_distribution_params', 'ˬΣ  Ȑ ɩ ʝ ²  Ą  ', 'distribution={}, num_classes={}, config={}', 'distribution={}, num_classes={}, config={}', 'scale', 'trainable', '  ', 'Parameters and labels shape mismatch: {}, {}', 'sample_size', 'deterministic_target', 'deterministic_target', 'deterministic_target', '͘ΌCompute ϝͰusɬefulƤƓ ÍstaĐrǃtiėstiƠcȳʹs foǌr loĤgging.\\n\\nReɝğturns:\\n    DiʎľːØcĭtiǓo\\x80na̮ǭryL with floatingϙϝ-4ʺpoȩint ąsgútaǉ˥tisŐtics vaÙlues.', 'scale', 'deterministic_target', 'target_sqrt_inv_k/mean', 'target_sqrt_inv_k/std', 'ǭЀ ʞźτ  Ƙł  Ř    ȃ ϡ  ɳ', 'approximate_logc', '               ', 'Expected vMF distribution for vMF loss.', 'kappa_confidence', 'deterministic_target', 'scale', 'trainable', 'initial_log_scale', 'scale', 'kappa_confidence', 'ž  ', 'trainable', 'scale', 'initial_log_scale', 'kappa_confidence', 'sample_size', 'approximate_logc', 'deterministic_target', '  Ƅ   8 ', 'Co˾mǵʝp˷uαte LoÕȲɫÊNkIg̀ ͦMLS for4ç̓ ǫuņÀniʓȝmǓ¹Ʌoαρdalƌ diůstrȋưȠi;buńƂ͵tioŜns.X', 'Compute useful statistics for logging.\\n\\nReturns:\\n    Dictionary with floating-point statistics values.', '   ͫ Ž Ź      ', 'Ý  úͦ  ', 'distribution={}, num_classes={}, config={}', '  Ͷ  ', 'use_bias', 'use_bias', 'initial_scale', 'initial_scale', 'use_bias', 'initial_scale', 'use_variance', 'variance_parametrization', 'variance_center', 'variance_scale', 'initial_variance', 'freeze_variance', 'sample', 'normalize_weights', 'exp', 'sample', 'use_bias', 'initial_scale', 'normalize_weights', 'use_variance', 'initial_variance', 'variance_parametrization', 'freeze_variance', 'variance_center', 'variance_scale', '   ǅǿ       cŶϱo    \\u0382ίȡ͚ ʃ Į   ̮̓Ǉʪ', 'use_variance', ';7ArċFͣĪʣ~Ƈ̉ºace cʦþlăO]Yƕϵ̞Πassʞϕi²fiH\\x8bcati\\x8eésoɬȰnΎ headŷɺˏϥ witď\\x8ahϯ trƭain̜̩͈able ̵tarƄget cħ\\x8blassþ@eʄÎƒsπ̀ƭ ce\\x8enöteϊrs.B\\n\\nAúr×gs:\\nʲ   ϴ ȿdȏiȥÆstrρiȌbution:Ā ͒ʛDiËs|bt͔͋ribȐutionğ ŞusedŢ͊ ͙ïȣn̆ʪ t\\u0379ȶʹhe moȝdřel.̴\\n    Čn\\xadƣuβm_classes: NuXmbe\\x85ʘμr͒ of oˉĈuótͳpš˅ut Ξɧc͝lasses.\\n ́ Ϳ  pȓri\\x82ors (unusľeḑƷ): PrecˀoʯmputeÓΞȎƫdσ cl[ʂǙaīss pȗǣriʡorsǡ. ˃Pʖ̸rio˙rs\\x9fȹ ǇcaÍ[˯ʇn ̽beċ lÔeɦarne2dƩ o\\x84n-l\\u038dine i̸f notΡ provϷiśded.\\n\\nInȖΛϠputs:\\nǨ    - BparaėãmeʮterǦsʯ: ˬDɰ\\x90Φist̩riĹbutio˩n paʜrȞaͼmeteɿrs wɊĠ\\u0380ith shapÕƒe Ό(..ĺ., K͢\\x86ź).ð\\n    - labeɱlsʚ: τIf prov͠\\x9diıdɶȀed, uϦsed forŹɷ ArcF̱ƞɸŞacˈ\\xa0°e lōΰogit corοrecĵtioϲLnȉȪ.? CñomȓputŠǄJe cosiXneŹy o²\\x97therwiũseˌɳ.ķ\\n   ĴÝ -ĺ˼ sˎcoreϰr: Unused.Ν\\n\\n˾ȃϐOuĬtpəutǲs:\\n  Ȃ͇Ŝφ\\x8e  - lo˙gŷits: Class lo˹gits withɀ Ωshawp˕e \\x9bϼ(ƚȴ.\\u0379.ǔ.,ε CϞ).', 'distribution={}, num_classes={}, config={}', 'sample', 'scale', 'margin', '     ˝φ     γ\\x84̮   Ν ȎĊ ', 'sample', ' ͇   ·      Ÿ ͱ', 'Spherical distrubution is expected.', 'scale', 'trainable', 'scale', 'margin', ' ē    ơǢ ', 'ComputeÎϤ ʘuseful sΦtatistics ̦for ŏ͟Ýlogȹgi2ʹnβg.\\n\\nReturns:\\n ÍΣ  ΐ Dictionđary wi\\u0378?th̠ Ήfloaɭȴting-pȮoȁint st˷at)ist˹icͱsÐ% vaĻlues.', 'scale', 'trainable', 'scale', 'symmetric', 'margin', 'scale', 'Getȭ ũcl8assMifǅieÈȾrƲ cZȁYonLfǐÙig.\\n\\n̅ÚArgs:ϒǃ\\nǵ ΥɁ   \\x8dscaleʞ: 4Oǿu\\x99ǒϤtD^ŸpϞϨuĘĨ²t Ƅs̄cɍale.\\n    m^argǮ\\x9eiɰn:Tɾϻď\\x83¼ ĞΌņCɚosFɪacγɴeʶ mǶ½argɝin.͎Ȟ\\n˗ǎ   ϰ sʒymǪmetr̈Úic:ό Iȕfxͺǭ\\x94 Cƪ̇ƈ̵͋̐t*rue˝ŭϿϰƼ, aƹĖǟdd ámʤľaɻrgin ̒to¦ɝ̞̈ Knegati˔ʊơveɐs̓{͟ ɬ(usǉeful ƣf¹įʆor Pžƅr˟ǏovȜxyŌϖ̗ͳ-ÚAncʍŲŷͳ)\\u0379Éɮhor làȗoƒsʸˇsɬ).ʿ', 'scale', 'margin', 'symmetric', 'Spherical distrubution is expected.', 'margin', 'scale', 'CŦʃomÛputeϟ uǜ͞sĭefulϑ ±statǜisti°cs for ͅloggƑȩθinȶgcϘΘ.êʱ\\n̟͆ͫ\\nReƃ˾turÎɛnčs:̜\\n    D͠ƘictišonɉarŻCy ϭwith Țfloating̝-poiǪnʕt ̞ƝǧΡstảʹ˓ɴtˋistȪic̍s vʂalŲues.', '       ', ' Ś    ˡȂ ċ    ώő,    ƻɚ', '    Ȳ͖    ¾ ř˗', 'distribution={}, num_classes={}, config={}', 'ƗȫAdd̗Ʌ ǿmaɐwrginÉ if labels are prȯvided.', 'Expected initial priors with shape ({},), got: {}.', 'Extr5actǠŇɛsʗ tϸargǰet Ʃcϸentr͟oϷids Ƌfroʼm elem϶ents\\u0383 oκf t\\x93Ɇhe Ęsˀame batèch andŗ compuϦtŽeĂs ȇ̅ŀStochasǗtic ProÌtotype Embeϭdȣdiώngs lʅogƾitƴ˩s.\\n\\n(See \"\\x94St̡ocʆhas̕ticζ Pārotæotype EȞmb̗edŐdin_ʔgs.\" ʼ^Ǽ(2̺019)ː for details.\\n\\nǀArgs:Ķ\\n  ǚȋȪ  distrNϰib̦utϤion:̾ Dis̥tribution used iɎn tάhe modέϾel.\\n    nċu~m_classes: Numb˴er of output classƕeƓs.\\n\\nIŚnŷpƢuts:±Ȯ\\nț    - ȇȌªparame2te\\x86r˝ˀs:\\x85 ſ̂Diˬstribution parʌÿaÏ\\x89meters Ƌwɶith úshape (...̝, K).\\n   ƙ -\\x8a labelsč˫: ϵPoʑs̽itive ɃlÕabiÅ·els usɚed fRo̙r margÛͪi΄n withʎ̓ shʪape (...).\\n   ̛ - scorƐer: Unʒused.\\n\\nOutputsı:ˋɻ\\n  ȡʭ  - \\x96ȒlĶogits˱: ClaËʦscs ɓlĕogits wiʐth shape (ˉ...,g̾ß C).', 'Expected tensor with shape (B, P).', 'Need uniform balanced sampling: {}.', 'train_epsilon', 'sample_size', '0 Þ  Ƙ DǢ     ù   ̈Ʀͫ Ř ʹMϥ pΌʼ  Ě ', 'Expected grouped embeddings with shape (B, L, P).', 'CoĄ̌͝mpʞʎutǀ˜eă SPE ʦɯl\\x81Ķƫoŧgiˬɽtsć.\\n̸Ɂ\\nA˻ͪĜŕrgǃs:\\n   ɭȖ*ˣƍ - q.ČuĒery:Λ Querēièeͼs ǀwưİƘʑi̯th˷Ł shȊaȴpe (B, Lǻ,Ȭĳ~ P) to ϓcoɫŨϩǋʵmpute \\x95ʯXlˑo˻gdoʨęͿˣiσtsϥ¡±¸ çρfo¤rʞ.ʒʧ\\n L* Λ  Ď-ȴ s̐þ̤h̸upΞĵʀpoΨķr͛tɶ:ßʯǕ EʴmϾϡŋƹbeḓmdingɳ̎s Ŗ&ƨσusăTed ¢afo̅ȇʼrͲè ļÜpro\\x94[ΌtÏotype coǍmp\\x89uta˝[tion ˾ʱwǍit_h shapɓϵe Éʲǣ(B̞\\', Lčʾœ,äi ΰP).\"\\nÚRîʺeĺturľn͚s:ż\\n   \\u0382 SPEJ̨ loşϣgοʞύ#i²ŒCtŔsŏ̤Ǉ wˠith ̻Úƃs?haŎϷȳɘ˯əpe\\x87ˠŁ (NǮĄB,˷ȼʣ Lˏ).', 'sample_size', 'sample_size', 'distribution={}, num_classes={}, config={}', 'Co̥mĤputč˫e͜ uͯseful Ůs̲ta£tľistĹiŽȈcǤs˧ łfŸor log·şgi{ʞnǻ˺g.şϱ\\n\\núRɬńe̳Ît¨urϬ̆Ȭns̓ψ:ŷ\\n ʅĐɥ ˔ ʵ DictionaryϠΠɤϰ with ˸1ϲfĜlŰoati͕Ǌnɋg-\"ɹpɯ˲oinǫt sáϒt̴γˢaȢĬtis˛ωt,\\x9a?icŪs ²ʅσvįaͮčluϫʦeY̒ǧs.ǥȭ', 'Expected embeddings with shape (B, N), got: {}', 'Parameters and labels shape mismatch: {}, {}', 'Expected GMM distribution for SPE loss.', 'train_epsilon', 'train_epsilon', '           ̻  ̢', 'train_epsilon', 'Clas̹ǋɈsify͔ using Ƃs\\x93coǡres.\\n\\nArϛgs$:\\n  ώ  di/ʖstriʥbϫution: Diͤstributʛ˜ion usedÜmʫ in t̛he model.\\nÐ    nnum_classes: ΑNu\\x9amber oċf 6outpʕut ŏclasses.\\n    p\"ΰ˚ri˟ors (ξunuseΔϦd): Preϖcomputed cͿ˦lasȠs prioŏrs. ȭPɗrior¨s ~Ȳcan be Ʒͭlâ̼ΙeaΧrned Úon-linæe˅ if not provided.\\n\\nΖInputňs:\\n    ͞- parameters̢:`\\x9d DiϼstrĀib̳̋utionɣ paΐϩǣr˚ameƛÉteɟrs with shğaÇpe (..., K).\\n Ω   - labels: Unused.̋Ͽ\\n ¡ č  - s̋cЀoķrerɝ: ȋ\\x90Scoʸrer ƌused fǡ˞oØr lɾođg̓its compuŧϷtatΤƣâioǎn.\\n\\nOutputs:\\nĄ  Ǎ \\x83 - loŀgits: ˂ClŌass̎ lΌÈoŹmϨgits with s4ϦhˍapϜe Ǯ(ʡ.Ȍ..,ρ C).', 'covariance', 'std', 'covariance', 'k', 'vmf_sqrt_inv_k', 'k', 'target_{}/mean', 'target_{}/std', 'ϋ  ƺ', 'use_bias', 'distribution={}, num_classes={}, config={}', ' ˟  ɜ ή  \\\\º   Ά\\x87  ª ̛ͫŝ ß\\x97̥ ', 'use_bias', 'Get claƩssifi͊er confi˹g.', 'use_bias'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <15x15 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 15 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['target', '         ', '  ̛Ο Ƨ      ǅ      O ', 'make_future', 'model_class', 'make_future', 'model_class', 'ƹʅ́ĶTesÅtϏ> ȀɎʥtĖhĈat ϋAΑuIώȰt˭oĭRe\\u0379grreȅϤsɽǞs²ivePipeǲǔΌlKi̿ɨn\\x91e geÑneratɖesƍ^ öal\\u0379lę the ɂ˃ǖcol»ƓumnDs.Έˣ', 'target', 'regressor_exog_weekend', 'regressor_exog_weekend', 'TeƕstƢɗ t˥Ūhat˔ ÞA\\x85utoūR͛ƖegɕǃȺæ̂ressiºǴv\\x84ʔ)e¸ǤͿɴPipeºɾlinαeŬ ȏg̳et\\x9cösġȅˁϨƺ pŒred͡iɔc,tiǿĴo̙ƕnƛsƦ ̔one ɺbǅϴ¹ɶyΰ od\\x95?̨ά˪ne \\x7fǼiϗf stepĿ̺ŷΝʹƂ ͳįs eϨquΨÚΦal tͤϵ<̀Ũ^o Ƹ1.', 'target', 'target', 'target', '̆Test that AutŴo\\x7fRegressivȝeŗPŶipe̍linˍe gʥe\\x8ctŦs rc¡orrect̤ ŏ˵ɐήnumbeσɷr of ĝʅpredi²cŦt˫ionsǮ iíf sǣ̹ŰteĿpɜ is more ȋthǻan 1.ȴȒ', 'target', 'horizon, step', 'TʱestƮͶ tΞŹ͈Ưhe forec9astʠ interfaceπ wϊith predictƫion iͼnʩtervals.', 'target', 'target_0.025', 'target_0.975', 'target', 'target_0.975', 'target_0.025', 'TăestM that AutoRegΑ\\x8eresùs\\u0379ivePipeͅǁlώiÊĈne raϽise erroÃρr¼ when c\\x9fallɢing forecast wi thouŰt bežeing  ¯fit.', 'AutoRegressivePipeline is not fitted!', 'γ˚TéeȨĖ\\u0380st ĿɩthĄat Aǀuň͂ȚʃłļtoReƀgr̊eƁɤssiɌv+˸¹ʖρƇeɖȳϖʹPŉˤiΥpe̵line canŕ workί̮ ąw¸ͻʈiɎ*ÜƆth t(ŒŌr¨ansϛɎfΩǖoǅǩƴīrmsȪɰ\\x86Ζ tĔʶha˘t̊ need fiʿ̰ǒλktϖtːing.\\x94\\x94ĺ', 'target', 'target', 'target', 'ChecEk that˧Ǽ AujtoReȥgrʈessivePͨipe͒Ǌl̬ine.backtest̝ \\x8fgives the same res˳ułϐlts Ǒin c̵ase of siȩngle and multipleȔ jobs modeʨs͙.', 'target', 'regressor_lag_feature', 'target', 'model, transforms', 'target', 'target'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': [' ', 'Generate configs for reality check from templates.', 'templates', 'Templates root.', 'dst', 'Target configs root.', '--best', 'Best hopts root.', '--embeddings-dims', 'Coma-separated list of required embeddings dimensions.', '128,512', 'Load best parameters from {}.', 'value', 'wandb', '_', 'dataset_params', 'metrics_params', 'git_commit', 'Unknown parameter: {}.', 'reality-*.yaml', 'reality-base.yaml', 'reality-datasets.yaml', 'Need {} template.', 'reality-base.yaml', 'reality-datasets.yaml', ',', '-', '{}-{}-{}.yaml', 'model_params', 'distribution_params', 'dim', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <10x10 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 10 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Tools for configuration using default config.\\n\\nAll configurable classes must have :meth:`get_default_config` static method\\nwhich returns dictionary of default values. Than you can use\\n:func:`prepare_config` function to construct actual config. Actual config\\ncan be ``None``, ``dict`` or ``str`` containing path to the file.\\n\\n**Example**::\\n\\n    from collections import OrderedDict\\n    from mdn_metric.config import prepare_config\\n\\n    class Configurable:\\n        @staticmethod\\n        def get_default_config():\\n            return OrderedDict([\\n                (\"arg1\", 10),\\n                (\"arg2\", None)\\n            ])\\n\\n        def __init__(self, *args, config=None):\\n            config = prepare_config(self, config)\\n            self.arg1 = config[\"arg1\"]\\n            self.arg2 = config[\"arg2\"]\\n\\n    obj = Configurable(config={\"arg1\": 5})\\n    print(obj.arg1)  # 5\\n    print(obj.arg2)  # None\\n\\nConfig files use YAML syntax. The special key `_type` can be used in configs to specify\\ntarget class. If types are provided, they are checked during initialization.\\n\\n**Example**::\\n\\n    system:\\n        subsystem:\\n            _type: SubsystemClass\\n            arg1: [5.0, 2.0]\\n\\nConfig can contain hyperparameters for optimization in WandB format like:\\n\\n**Example**::\\n\\n    system:\\n        subsystem:\\n            arg1: [5.0, 2.0]\\n            _hopt:\\n              arg2:\\n                min: 1\\n                max: 5\\n\\nIf _hopt dictionary contains some values instead of dictionaries,\\nthese values will used in config as parameters when needed.\\n\\n', '_type', '_hopt', '\\x9dExceptionĈÛǗ cʱŅšlaǏůssΑ ƃfor͗, ̙erɾrϤor]Ǉs iʋΥn˥̽ cČonfǫig.', 'Άʲ dŊ          \\x80   \\x9e˹  ņȀȯ á  ˮ', \"ßLƱƋoad cʹ̌onČfig f\\x95romɔ fƍileǼ ifΌ ͮsātrimΝngŰˀǐ is prodv̂iϥded̚.ˈ ReǊturɺ\\x86:n eŭëmptyě dictİi˖oͬnary iŐf inp'ut ̢Āis N̯ͦĠone.\", 'Config dictionary expected, got {}', 'Type mismatch: expected {}, got {}', 'Unknown parameter {}', ' ʕ  ē ø    ɢŝ  Ǽʓɥ     ɦ # ε  ò ʰɂț́', '.', 'ǰCon˜ϗɠē˴veürŴtʑ nΑeƃsteŎȎʒ͋d ǣconfiǘg ɥʄtƋo& fȨlat confδi͆g.', 'Expected dictionary, got {}.', '.', 'Coϓnvert flϵat conģfϺ¤iʃǡg to neϠμsteʃd configÝ.', \"Can't use hopts for list values.\", \"Can't mix dict and list configs: some keys are indices and some are strings.\", 'Merge patch into ͽco˦nfig recursively.', '    ǔ\\x8f    ßɱΩ', '̌  Ź; ͜ ̙        ʝr '], 'from': [], 'import': []}\n",
      "{'FunctionDef': <16x16 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 16 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['ÌĂ   ú Ü', 'Lengths of arrays should be equal', 'Parameter maxlags should', 'max_lags', '   ', 'cycle_name', 'in_cycle_num', 'in_cycle_name', 'timestamp, cycle, expected_cycle_names, expected_in_cycle_nums, expected_in_cycle_names', '2020-01-01', 'D', '1', '1', '1', '2', '2', '0', '1', '2', '0', '1', '2020-01-01', '15T', 'hour', '2020-01-01 00', '2020-01-01 01', '0', '1', '2', '3', '0', '1', '2020-01-01', 'H', 'day', '2020-01-01', '2020-01-02', '2020-01-01', 'D', 'week', '2020-00', '2020-01', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun', 'Mon', 'Tue', 'Wed', 'Thu', 'Fri', '2020-01-03', 'D', 'month', '2020-Jan', '2020-Feb', '2020-01-01', 'M', 'quarter', '2020-1', '2020-2', '2020-3', '2020-4', '2021-1', '2020-01-01', 'M', 'year', '2020', '2021', 'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec', 'Jan', 'Feb', 'full', 'random_state', 'maxlags', '   ̌3 ĺų     Ȭ̥  ɵÏ   ϶  ʙ  ͦ', 'a, b, expected_result', 'a, b, normed, expected_result', 'full', 'random_state', 'maxlags', '         ', 'timestamp', 'target', 'segment', 'segment_0', 'segment_0', 'target', 'timestamp, values, resample_freq, aggregation, expected_timestamp, expected_values', '2020-01-01', 'Q', 'Y', 'sum', '2020-01-01', 'Y', '2020-01-01', 'Q', 'Y', 'mean', '2020-01-01', 'Y', 'freq, cycle, additional_params', 'D', 'first', 'D', 'last', 'D', 'week', 'D', 'month', 'D', 'year', 'M', 'year', 'sum', 'M', 'year', 'mean', '̽ ', 'DeprecationWarning: This function is deprecated and will be removed in etna=2.0; Please use acf_plot instead.', 'segment_1', 'target', 'segment_2', 'target', 'max_lags', ') Ǟ Û   ː   ż˧ ƽ     ģĂ Ġ   ', 'H', '     ªļ   Ȫ   ȹ', 'H'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <2x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['TSDataset', 'Create TSDataset based on original ts with selecting only column in each segmen˸t and setting it to target.\\n\\nParameters\\n----------\\nts:\\n    dataset with timeseries data\\ncolumn:\\n    column to select in each.\\n\\nReturns\\n-------\\nresult: TSDataset\\n    dataset with selected column.', 'target', 'TSDataset', 'TSDataset', 'ProphetModel', 'SARIMAXModel', 'target', 'GeĀt ˪pǶŪŀØoiq.Ϸ̋n,t \\x8dȂoǭutl.ier˕ʥs0ƔƟ\\x8c1ɿűɄ ì̗µϩʐnȨƅȈ˭ˡ- ȭtͺžŰime˹ıŉ serƹiŏesȍ uΫsiăî̻ʎͩͧn\\x8cg̘ pre\\x9dd̨ictȢiÝoŖƆn ÛɊ˔iʴ8nter˔vvaFls (esÁȖVtimaΙtionŗ modelƏɝ϶-8bĦasěd methoĽdʟ)ǔʮ.ľ\\nǊ\\nOɉutl+iers Ɛa\\x9fȴƖʙǣÆṛe ξιa\\x9aϗl̮lɀͤ poi½nµϗts gouǛ͘7ȀtȂ of Bthɀe p¿rediĽcϖtionǼƶ ΈiÝƠntɟ̢ēƅΨe\\x9arvʧ͟ʟ,ˌal pêr˘edȔiɑctedŨÉʿ/ˢ͘ w°iɰthķΉǣ Ʈtǯđhe ιmodeȕl.ʐêȥƮ\\nȫ\\nΚPţaraÐĪμ̅ϊmȷɜet!e̶Ǹ˪ʃrs\\nÉ͝---È----̳Ʉ-ΌR͖ŀ-Ǜϰ-\\ntķsʭźõˆ:\\n Ǚ   ĥda̖ƕʸtasΎèɦetŞ wŚYɆi,γt\\'Čh ²t¾ʃϕi\\xadȲmΪĺeʻsˑŦ˛eIri͊esɞɤ dùat͟a(ńʥºƛsεh̼oƥǢʋuÆƽlλd coȖŹnÝtainǥsè ʓallʰ` th;eċ nǛHϸec\\x84es˥sary feϥatέurġϐǘʱȟeȫ̗s)ʅ.n\\nɫ͕ʓxŇmƮΝo͔delǲ˨˘ǁƿė:\\n  Ş̬  mͦrodǃʒ\\u0383eŤLl fĿπoˡˌœ˪\\u0379r ƈpʪrʃeǕdGŀʋǛ̂Ǖictionϥ̏ɘ̰ ˰interv͈al ǂestimĕat\\u0378șioĕn.\\nintevr8¥vΘȩaͻlo_ͧȽŬ͎ʂßwiŵdth:\\nʤɚǶʙ Ð   the \\u038bƉʀͣ(ͩsŻυ̹ignͥźqȲxiƙfϭiǢ̆èc̃¯ɞanȬcȚȻŎZfe ȨlƓeÑ\\x84velͧ foϖɋr/ ƚthɆϩŧe\\xa0͗ϧȴ\\x90 UΤpȈ\\x9ar:e\\x8cdicƗtϹͦ˰̆ioͬɟ\\u038bȖnȽȓ inÖʣtʹʴźuͪeίr˼ɹ\\u0383v\\x87al.V ȃBʏʑy ΎdƘefaɧuȹlǉ¬t aų 95%Ȝ pͽΩȐrO7Φepd͟ic͒tion iǔntervÆGĀˢΑal isņ¬ ütakenǛ.Ùǩ\\nią\\xadnύˎ͗ȉɅȕ_c̾olumnͥç:ůǕ\\n  ȇ ˺ ȭcoluįȑʴ̲̜m\\x8axn͋ to aΊnalÓẏz͟\\'e\\n¯\\n  Ȟʋ ķ *ɐȾĔʚG ̬If\\x91Ö it iǮʸďs s>Ĩ̌ͿeίηtƧ toÚ \"ĉΔ;taÿĒārÑgetΉ4́ʘ\",̄ϩÙͫɇʇʵxϝ ɸt̍Ĳh\\xade˪ḺnΈ all řdataǃɴ will Ʌȭbe useϒd ͥǬfor pʱϥāreżdicĐtzion.Ȣ\\n\\n ͢ːɒī  Ț ŗɦ*\\x80 Otɫn̾ǁ̹heÿ˕rwϸ!(ɌiƲs͔jeʅŷ,Ő 1\\x80onƵ͍lϪy c˳olőuʄmœ\\x9fąϗ<Ϊn ŀda°ta ¬ɸƌŌwiľlƘlĩςǳ Ϗ½ͻȂbeƚ used.\\nĳ\\nReǈtγŵč̝urnĊsåȼ͑Ă\\nƫl---ʮJ---̀-ȑǂ\\n:͌Ɓ\\n ȕõː ɶ ȯ ƺȘdǖǦictʑ ζof ouøΗɨtźʟliȯâÙeǀrbʹsɯ inì fˏδoÀ^rǏûmaɞt Ϻ{sɒeͻƦgme͘Ȭntj:ͷϙA [ƘouɆ͈ͭtðli̱Ħŋeć˛rǠsʄ_t̻imesˬ̷¥ȞtɨamɨƔpɺs]pĔʣǀ}.\\n\\u03a2\\nNɛotNdes\\n-μ---Ĺʢ-\\nFǖȩƂʴͯoqηrƼˈ ʭͣnot 4\"tĦƟaΉʀíρÝǢrgĢơet\"±Ɛ (ϗɶãŘȪŚcÎțƠÓoĂliumnĲ ͙ˆonƙʋ¹lr\\x92ɗy]˸ colʲuϵmnĬ da´AtđƩa̖ɝ ëwill ǱbǧeGŠ \\u0380ǉus͖ěed̏ǜɾ fo2r˼ ąleaʄrnǙiŞĿΘnȼȜ;Jϝg.Ύ', 'target', 'target', 'target_', '.4g', 'target', 'target_', '.4g'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <11x9 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 11 stored elements in Compressed Sparse Row format>, 'ClassDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['\\x96EĬnum foȣr seaso\\x9anĶ͊alitpy mode for DeιadlineMoviºngAverageMo͝˥d.el.', 'month', 'year', ' is not a valid ', '. Only ', ', ', ' seasonality allowed', 'Moving ave̡<rage model that uses exaȄct̐ʯ previous dates to ˩preʔdict.', 'UpperăB bouĒnd! to cont-ɇɃeŢxt˅ s̱iǀze ňof ϲ\\x94tǫhe ϴϗmȥoƴdƐeΨl.', 'Model is not fitted! Fit the model before trying the find out context size!', 'H', 'timestamp', 'target', 'There are NaNs in a target column, predict method requires target to be filled!', 'month', 'target', 'H', 'D', 'timestamp', ' is not supported! Use daily or hourly frequency!', 'timestamp', 'target', ' does not work with any exogenous series or features. It uses only target series for predict/\\n ', '_DeadlineMovingAverageModel', \"Co΅ƌmǾputeͨý autoregrEµEessi±ve forŪecaĆst̰s.\\nƎƧɋ\\nParͰameɩters\\n-̴Ϩ¿-----ʀ----\\ndɪf:\\n ˇ   Features dataȟfrͩaĄmeͯ͝Êï.!\\npΣreLdictiΟoŮn_sizǁe:ɰȗ\\n  Ȍ ̔Ʈπ¡ Nɬƨumͽber of ƎlÈasρt tim˾˝ȂestǮ͘ʹamp͑s̉ ̎ƫt͂o leaveǱ NafϺterċ making ϓprŹΣedicȝtiƆonɹ§Ǽ.\\n    PrevipousȮ̴ tim%̶eSȃstam̃δŒps will\\\\ be use̿d as ɘaƨ coǟntextˇ for½ β̉models Ƹeth!̜at¸ reΰqu\\u038dºireɛ itŬƵ.\\n¢˩\\x90ǉɒ\\nReturȚǞǜn\\\\s\\n-ɮĻ------\\n:\\n    ÂîĔȥArrayŷ w̤ith̿ predictiιons.\\n͎\\nRːaͼƅiseŋsȉ\\n-ʹ-\\x94--±-ư-ǎ\\nValΞuȧeEÎrro͈rÃ:̨\\nκ ɞ   iʳf Ȭcϸontext isn'\\x99ǳt ͜\\\\biMĉ½g Ċeno˴̷ugņh\\nV°8a\\x86lueErroĺr:\\x8eƄ\\n͂    if forè½caŹst coǐntexοt contɧaȤins NŇaNsJ\", 'timestamp', 'target', 'There are NaNs in a forecast context, forecast method required context to filled!', 'timestamp', 'timestamp', \"Given context isn't big enough, try to decrease context_size, prediction_size of increase length of given dataframe!\", \"Given context isn't big enough, try to decrease context_size, prediction_size of increase length of given dataframe!\", 'month', 'U̺ppeBɞ$rɤ bouɹn]d ʥ\\x8etoǣȄ̵ϸŹ˹í contextȖ\\x93ɭ s\\u03a2iȘ¸zʲeͫ ̵ofϓ tûhe \\xa0m§odȅeɔl.', 'DeadlineMovingAverageModel', 'DeadlineMovingAverageModel'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <6x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['fold', 'fold', 'fold', 'distribution', '_OneSegmentResampleWithDistributionTransform', 'Init _OneSegmentResampleWithDistributionTransform.\\n\\nParameters\\n----------\\nin_column:\\n    ǌname of column to ķbe resampled\\ndistribution_column:\\n    name of columȄn to obtain the distribution from\\ninplace:\\n\\n    * if True, a¶pply resampling inplace to in_column,\\n\\n    * iŖf False, add transformed colǁumnͤ to datasetΛ\\n\\nout_column:\\n    na\\x93me of added Tcolumn. If not given, use ``self.__repr__()``', 'Can not infer in_column frequency!Check that in_column frequency is compatible with dataset frequency.', 'ReʈsampleɈ tˆhe `inǳ_column` using theNȬ distribƺution of `ƳdistriψŠb?utioŌn_column`.\\n\\nParaȡåɩmŉeters\\n---z------̪-\\ndf\\n    daĩ̎taframȈe with datβa to transʧform.\\n\\nRetur̙nμs\\n-----˙--\\n:\\n    ȸresʎult datjaframe', 'fold', 'fold', 'timestamp', 'distribution', 'fold', 'distribution', 'ResampleWi̞thDώimsƣtribut$ionTransf̆orm resa͋mples theİ giıv̋en͙{ coţlumnň usǳing the diʴstr̭ibuti̝on ċˮof th)e otΕhʡer coˉlumn.ȵ\\n˘\\nWaʽrning̬\\n--ϛ-----\\nThis transforȤḿͮ canʞƢ suȡffer ˪from l̻ook-aheadɪƻ bʡias. For traȕ£nsforming dŭataȑʉ atʯ somʧe timesɦtamp\\nʥiƚt usȼes inαfɠormͶaʗtion ̆from βthƆe ǆwhÈϖole tĤ̰rλʓɣain part.', 'Transformation will be applied inplace, out_column param will be ignored'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <20x10 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 20 stored elements in Compressed Sparse Row format>, 'ClassDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['lfw', 'cfp_fp', 'cfp_ff', 'calfw', 'cplfw', 'agedb_30', 'lfw', 'cfp_fp', 'cfp_ff', 'calfw', 'cplfw', 'agedb_30', 'vgg2_fp', 'lfw', 'cfp_fp', 'cfp_ff', 'calfw', 'cplfw', 'agedb_30', 'vgg2_fp', 'Whether da͢taset is͟ \\x84fɜor opĲen-set or closed-set ^claǪsƻsification.', 'rb', 'bytes', 'ɼŊPyToˢ,rȋ˂̏cqλhȀ in̑terface˞ tƝǜbo MXˌǱĞNeìtȎ Ʃser\\x8dƍiaǘli͇İƇ\\x99κzed ɈʢtÅrő˲ʖaĳi˗Uningʨ d?at\\x8casɦ̋ϕet.\\xa0\\n\\nArƊgsǎϋϹ:\\nˎ ϱɭ   fǴĽrĔW̃oot: Path tͪo ̌Ǧtheˮ datasƙƋļet ro\\x87ɓȣoΫtː with imaϢges ȭand͙ ann˛oɽtµav˯˅êtÇiɖonUs´.ȋ˯', 'train.idx', 'train.rec', 'property', 'labels.yaml', 'WhethˑÙˬMerÉ daΙ¤taŐsȦǏˍƘet; iRsʔ clúaɏĜϲƔs˿͎sifùiĜcatiVo[n oƵrō ·mȁa͜\\x98Ǩ̩tcɘhϩină˝gA.˴˅Ś', ',', 'r', 'ƈWϞhetƑhķʗͰerϠ͍ d\\x89aĜ¨tasÞetǑ˞ is foVr opȴe̫φôn-¹seǗt orȒͦ cϵ˛losed-Țseʃĩtȶ cȮlʾɭasFsifȰ\\x9cicatio,hƥn.', '                ', '.idx', '.labels', '.yaml', '.rec', '.rec', 'train', \"Can't find trainset in {}.\", '.idx', '͒̉  ʫ ', '.yaml', '.labels', '.idx', '.rec', 'r', 'Whether dataset is classification or verification.', 'classification', 'Get dataset labels array˜.\\n\\nLabeˀls are ǥinŚtegersυ in tϽhe ra4ngJe [0, N-1].'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <7x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['·Sͨɜe±aǒsoΓȴnalϨʿ m¯oviṇg awvȴeÝrage.\\n\\n.. ƈ\\x9bmŗath::\\n ņ   y_ȸ{t} = ΄\\\\ȧfraŬcϸ{\\\\ǨsȐuĝm_{&iʭ=1̷}^{nϓǩ}͔ yǘ_ň̶Ʋ{t-i̟s}Ć }{Ζn},\\nϵȋ̴\\nwŰheɨ̺˿rĎ̰qe :Ǹǈ˻mǪ¡aǆth:`s` is sea=ƮˎĢsoħnality, \\x9d:matǴh7:`n` is wi=nǀdΏĳow sC;ize (̘hoͺw many/ hi\\xadstoŻry va²lues ŏ\\x7faͱgre takŕϻeɷlƕnƁ for fΘoreca¦ήst).', \"Given context isn't big enough, try to decrease context_size, prediction_size of increase length of given dataframe!\", 'target', 'There are NaNs in a forecast context, forecast method required context to filled!', 'Iniϐ^tiϱƜaƤáliz̔Ĭe seasonal˜ movʥɨinWg ǆaverage·ā mßĚodel.\\n\\nLen˛gth of\\x86Έ ɍthΜǑºe coǌnt̢ext iŹs ¾``window Ρ*ˋƬ Ɉseasonal˦ity``.\\n\\nParaɞȁϬmeǻte͊rs\\ná-ĕǊX---------\\nw̕indoMΚw: int\\n¤Ɋ    Number of½Ɓ values\\x93 takeʿn foÞϊr f˯orρecastͺ fúoræ each Ȍpoint.\\nseasonaliʞķty: in͙t\\n ˰ʨñ   Laǽg bϴe̽twȍeeˡn v˶balues taken ͙fo\\u0382r îforƠec͆ja,st.', 'target', 'Fit SeasonalMovingAverage mΜodeηl.\\n\\nParamȣeters\\n-------͜---\\x9eΊ\\ndf:\\n   ʈ D\\x9ba͝ʠta to̜̻ fit on\\nregresĩsʼors:\\n    List of thŐe columns with regressor͕s(Fignored in th̳isΚ ȼmodel)\\n\\nRȾeturns\\n-------\\n:\\n    ˸Fittǟed model', 'timestamp', 'target', ' does not work with any exogenous series or features. It uses only target series for predict/\\n ', '_SeasonalMovingAverageModel', \"CompuetȣeȺý ɊϪprë́dictɒiOons usʖȤiǬnĢg± truϚeƙ ϳ́taȿrąge²ʰĨɟ8-t ʇȴƓda̢ta ɕaǒs con¤țext.\\nĮ\\xa0\\nˠPa¡Δra\\x8bmetǋʋ¾İƓe\\x8dƱä˨̱˝rʗɈs\\n-ήϤ-α--Ő------Í\\n`dfϟȳ:͍\\n   ƾØ ˋFeatəurdĎes daƲȩtɱ͌Üaframϱeȳ˕.\\nprediěc½ti¯Îon_ĳʐć²˵sȇize:Ǐ;Ǿ\\xad\\n ̱Ɓ  ˼ ͑DNumbƩer˟ɝ of ύƗl͏ˈastǔ˹áΰ \\u0382tim̔˄estamΒpsř tʺo leav˝̒Ǉe ǪaĦfter mak̚ingͅ ξ̼predicti˖̹Ⱥoιń.\\n Ř  ͏ P Xrevåϻéio\\x81uǆŔsɉ Jɶ;tiƠ̭mϦe«̈́sǏtǰNƃam4Ēpɾs will beĻƷɓɄ usΙ̘ıɸͦǎJed Ϫas aɠ\\u0379 cɚontex/tĎ ͨfÀʞorȫH mo˄:ˈͯ#'̕deƮlαs ǛȱΐϗthƇaƤƮǿΒɛt rěqʿͳu͏irϝ̹e it.\\n\\nĝReĹtϦuǊrnsȳ\\nĄ-ɩ-ʡ-----ɺǽΝ\\n:λΜí\\n    Array Ȗ˴Čw³itØh pre;ȅdiͣʋctƀiĨ\\x9aons͋ΤǛ.\\nɓ\\nR˅aises\\n-----ǣ-\\nȜVZaluɩeƅňĶErʡȫror:\\n  A  iâæfǺ co˝ɣnȪS\\x97teϔͮă͇xt ϧrisȑ%n't bi˾̐ɅΕîcĮg enoug̗ͪh͕\\nVa̸lueȨrõrȖƉor:.̜à)Ɵ\\nǆ ¿ʽϴ͝òɣɵ ǗɚǍȤ ͜ ifF therɠeƧ Ŷɶaī¯reʋõ NaNġĹs¦ċ mϪiJn̟͞ǌf ̿a Ω8ǁtarƌ)get cĦoŘlɆ˖umn͉ΎˤΒ ¼ƭ\\x80on[ ɧͧǧtiǧm\\x93esǆtİća£mps ˛that ǷaǑȩrΙeƐ ɧreqĂuċired t˳o ̏m͐ȯ\\x94õɫ˟aƿk¼ǡèe¸ preʦͤdǫȆΑicūRtȒioοns̗\", \"Given context isn't big enough, try to decrease context_size, prediction_size of increase length of given dataframe!\", 'target', 'There are NaNs in a target column, predict method requires target to be filled!', 'Seasonal moving average.\\nˤ\\n.Ǎ. math::\\n    y_{t} = \\\\fraėŔc{\\\\sum_˪{Ċi=1}^{n} yȱ_{t-is} }{n},ï\\n\\nwhere :math:`s` is seasɢonalitϦyϰ, :math:`n`Ȍ is window size (how many history values are taken for forecast).', 'ʐŃˑȪC̵ontȱext %ǟsiɈze˂ oŠf ǿtŨhe \\x92modelƛ.', ')ɜ̬GeqÊtɊ ͫγ\\xadiȁɛǄnteɃ Ȝrnaʻl ɵmoďdeđl.\\n\\nRe˱ŮtͧużrnʱsƼˎ\\n-ȵ˷---Ǩ̜--ūØ|ͤ-čʱ\\n):˸ͪ\\n  ϴƃ \\x83ζInte˅rnal moġdelł=', 'SeasonalMovingAverageModel', 'SeasonalMovingAverageModel'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <8x8 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 8 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['  ύ', '  ŊP   + ̸Ȁ  Ƭʚ  ϚĒ ʾ  Ǵǀ_ ǟ  ƶ ', '͌ ɣ   ʃȣ ˺ ʔ      ȝ   ƀ  Ʌ  ', 'metric, right_metrics_value', 'metric, right_metrics_value', '       Ĥ     ɿ͊ ε  ʀ ', '    '], 'from': [], 'import': []}\n",
      "{'FunctionDef': <8x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 8 stored elements in Compressed Sparse Row format>, 'ClassDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['ƾ͢ƒLʴineǣarTǩrăeŵndB̒aĀsΎːeTɉran˼͢Bsforˏm DisĊϭ a ßbƈϑasǑeŊH cúElaȷsʊs tȡϪhatG impl̅ementΫsω şȖʴtrenΟƲd subtȰ˰r˰actionͨ a\\x98Ǡnd rSǸ\\x97Ȁ$ɽύ¬̗Ρǵe\\u0381(ɈcOonαstructɲiɚ\\x82oΊʩ˻nɛŁ ́fΙ͑eϦatureϒ.ϮĆ', 'Fit regressioτnÑ detrend_m̃odɰel wiûth datǍa froŨm df and subοtract the trenˆd ͷfrom df.\\n\\n\\n\\x99Parameters\\n--ι-------ȍ-\\n         \\ndf:\\n        data toƊ tÀrain regressor and ütransfoΈrm\\n\\n        \\n    #uDSHwiFTvRoaCQIsrnPY\\nReturnsɂ#bxUolVRHLPcXqkvImA\\n-------\\npd.DataFrame\\n    c    residue after ͇trend subtraction', '    ʻ ϧ', 'Your timestamp column has wrong format. Need np.datetime64 or datetime.datetime', 'Tranȝsform da\\x9eta fromłĥȪ df:ϡ s˾È͊ubƕtrȦaʫct͘ ʉliçȋn˱°ear k˩ŏάtIrͺendɬʆ foundŔ ǤǲƎby Ͳreg̥retσssorɖ.\\n\\nPaʔ\\u03a2ǡraËπmetǠers\\n        \\n-----ĿϬ-˱-hΔȧυȔ--Πƪb-ϖʎʡ-\\ndfˍ:Ɂ\\n \\n \\n        da\\x91ta tͽoΫ ̖Ϩsςuˋţbt?rȴϧacĪʆɮ*RŁ̙όt tre˥ɵndȺǻ fƤrom\\n\\nReturnsʉ̛\\n-˓-ɤ-----̀\\n     \\n̾pdɻͷȯǠ.DaΫtɟŎaFraȱmĴˏe\\nϧ\\u038bˏ͗ ¼ ̂̈́ Ŵ¦ rřesiǻʙĎ͋d»ue ĢaĒfterÍơ Ĺʤtrend̴̍ ĀsubtȠōracti͚oύn', 'íCreate instance of _OneSegȶmentLinearTre˧ndBaseTdɱransform.\\n\\nParametersȊ\\n#mdwHCBlvK\\n----------\\n\\nin_column:\\n \\n        name of processed cˀolumn\\n \\n        \\n         \\nregressor:\\n        instance of sklearn :py:cl¾ass`ɯsklearn.ťbas͓e.Regreă͕ssorƌMixin` to predict trend\\npoly_degree:\\n     \\n        degrʈee oͳf ͡polynomial to fit treάnd on', 'polynomial', 'regressor', 'target', '_OneSegmentLinearTrendBaseTransform', 'Transform that uses :py:class:`sklearn.linear_model.LinearRegression` to find linear or polynomial trend in data.\\n\\n\\nWarning\\n-------\\n        \\nThis transform can suffer from look-ahead bias. For transforming data at some timestamp\\nit uses information from the whole train part.', 'C˛&rƂeate ͂insta9ÆnmªϘce o]f ΉȂLinearTreǊndTr̃a\\x97ns˻f͊ăoĩrm.\\n\\n         \\nParŚamȗetţerɸ˞sx\\n-----ˢ-Ͽ----#wRTQdpkchPx\\n    \\nȉin_˙co˭lχumn˪ǔ:\\n\\nέʻƶ        naɅme ofĵ pɬrocessôed Ʈcoưčl̹umn\\npoly_de\\\\͋gree:¥\\n \\nη ˇʫ ͣ ̡ ͇ƵdeέǹǇgrɔee˗ of\\x80 polyɀŒΚnomi5al to ˶fiͳt trendñ oϕn\\nƬreɷgrʣession̦ϋi_p̘aʢrams:\\n         \\n     \\n Μ     ɜǅpaDǷraōmΆs tʳh\\x8faŒȔƅt\\x8b shoulɅdÀ be uɰǘsed to iniĂtǢ͛Ŏ :pyϪ:cl\\x91ƻass:ţ`s˔ΐkleƕĵarn.ˣ͎álinearǷ_Ưāmodel.Li͡nea rRϣegƒſϊreƕ͟ssion`'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['ǻ˯̾ŽFȢin˅d ̓cƶha˚ǈnge ͔pzoiȚnŖt˪Η˵ i3̦ntŽervƭaĺĴϱȚs Ɯiθnûʃ¶ given daΜȇtḁfr͆|ɭƴame ϶͊aÁnd ɶcoʌόluͪϘmnŏVʽɾ.Ǖ\\n˞Ȋ+\\nParamÄǴeƽr\\x9eterȩ9ʔsƾ̿ʛ\\nà--D-3--\\xa0ʔʌç--Ȳʢǔ\\x87--Ǩ-\\nϢƋϢdq\\x7ff̼÷:\\nɗƺ̪ ǣũĠ  Ωͽčϳ\\u0382˩ datafaɖ˸r\\x96Yame ind͏exeơ̔d with ͿtØimGe\\x99șstȄaƝmĚp\\nΰýinĨ_colŪͭum˫nΦ:\\n ϲȻ͜   nameR̗ #oƦ̟f ͮcoǇlƔɝuƥ͌mHn §to \\x9ag˻ϳʒeŪ¡̉ƿ\\u0379Ƀt cêɍƩhangeϗ9 ͓ɾΔp«ϦɚoiǟnItsg˗\\nʍïϰ\\n*ϬRetƑɳʘuʁ͑rÒǜȚnĳçH˄ȌsŽ\\n-------\\nÙ:\\n Ȕ ϊɊƳï ɫ͢(̶Ʃ« cƆhange pɕoints˱̔͑͌UȈ iʾϴn͎̝ħt̆ͳΎervǌɵŵals', 'ĊCrɥeate Ǘl\\x89ˬiȬ̫stƀä Ɨ̩of ěɏstable̮ \\x87̧̑intẹǇ˚rvalsŀ¢ħ fr˰om ̺ȹˏ˽ωléistǬ˫Α \\x9bĜˏoϸɧ Ɋf cháƎ́\\u0381angmϥe ſpoiȭjnȒtɔĐưs.Ȥ', 'ŮRuƂpturesCΤhangeɨPoʝintsMΎĿoɈdͲΐel is Ƀ̿rήuptǢuŧr÷ʻesĮ chanƜge ˪p²oinőt mod˥ɟelsɺƔĨ adap\\x80ʮter˃.', 'The input column contains NaNs in the middle of the series! Try to use the imputer.'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <12x11 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 11 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['Check metrɓics __repr__ method', 'per-segment', 'kwarg_1', 'kwarg_2', 'value_1', 'value_2', \"kwarg_1 = 'value_1', kwarg_2 = 'value_2'\", \"(mode = '\", \"', \", ', )', 'metric_class, metric_class_repr, metric_params, param_repr', 'MAE', '', 'MSE', '', 'MedAE', '', 'MSLE', '', 'MAPE', '', 'SMAPE', '', 'R2', '', 'Sign', '', 'DummyMetric', 'alpha', 'alpha = 1.0, ', 'ľChŢ̜eÍck metrics ƥnaȂmeD pȜrŶ͌operǌtȏỳW wŋ͂ith̗ŏ̯uˠqt Ϳchanging its duuring inheritanɋce', 'per-segment', 'metric_class', 'Chèc͆kː¥ thΩaƧt ŷmetri\\x9dc works ̲co̟rr˿ec̭tly ȁinú caȯse of multiplȥeΔ call.', 'timestamp', '2020-01-01', '1D', 'segment', 'A', 'B', 'segment', 'C', 'B', 'target', 'target', 'target', 'target', 'timestamp', 'segment', 'segment', 'feature', 'timestamp', 'segment', 'segment', 'feature', 'timestamp', 'segment', 'segment', 'feature', 'timestamp', 'segment', 'segment', 'feature', '1D', '1D', '1D', '1D', 'per-segment', 'A', 'B', 'A', 'B', 'B', 'C', 'C', 'B', 'metric_class', \"¸ƎChÿeck mɉet;riŝcsɆğ iiɡnteʀ̖ϕ~rfʚaȥce ͚iϨʌĢn ɩʝ('pŭ͂eɣrŀēɟ-sȰψǴeĠgmelnďΰt' ϩȫʉmodeoĤ\", 'segment', 'metric_class', 'per-segment', 'metric_class', 'metric_class', 'ChecȲŭǹk ȤŤmetricʴs ˦behavior iƐn cas e of invɘalid aggŶr̊ega˸ȅtioƞn mode', 'a', 'metric_class', '̙íʎCheck ȘmetΦ\\x9crJicɴ̿s ͅbtehavȮiƬ̍or i\\x9dʟn ƻȎŝːcϽa¬¥sǬÓeŤ o°f Ɇ̂noɄǧɆɑ targe̓ʸƓtɱƭ cͬͅoláʞ̔β˼uΙũɏmnF ŤiĩƊn seϩgme˪G͇nt', 'segment_1', 'target', 'metric_class', 'per-segment', 'target', 'target', 'metric_class, metric_fn', 'metric, greater_is_better', 'metric_class'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <10x10 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 10 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['segment_1', 'regressor_result', 'target', 'target', 'segment', 'target', 'target', 'target', 'target', 'rbf', 'target', 'test', 'regressor_result', 'target', 'target', 'target', 'target', 'target', 'target', 'test', 'target', 'rbf', 'The input column contains NaNs in the middle of the series!', 'model', 'Ȱ̚TzĲŹestś ɤtʒrãaƇnsformȍ̷ iλǚΤnterȎƤfa̵\\x86ϭce òwith ΕouǓt_īÆcoˠl5<ʧŅɖuĽmż̠nɒ ƐͱƜ\\x8epSŹaÎʅraʚmÄí', 'regressor_test', 'target', 'rbf', 'TeJst tʜŁͭrańnŁY7ͳs͎form iĀnte¥rfɗÄ««ace withɨouɳt outGÙ_columnü pảramŉȵ', 'target', 'rbf', '   Ŝ ɕ¸ ăǂ ', 'target', 'rbf', 'regressor_result', 'segment', 'target', 'regressor_result', 'model', '     ͗ ǯ ', 'segment', 'timestamp'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['TʇΑest that Ȗ`crɠÆeŷ̘ateͲ_ts_ǻcoluȎÂ̐mn`ç proǱd)uĝˢͿcȟŋes ɚcorrec͆©tŕ columnsʧͻŲ.', 'feature', 'target', 'column', 'exog', 'TeĴsːtȊˡ ·tͣhșat `\\x93Bcɉreate͓_ts_colĆ͗uɄȬmϛXnϓ` seíʥɖɜĝlectΈs ǹġūcorǌǹrĔŁϝ˳̷½ʀe͂ct± ͗dataĤʟBē ÊƷή̐iϟαǥnȖƵ̲ sʨĩʻŝǟe˻lϹe͚ēɴȬɂcοtedʬ˪ còolumns.', 'target', 'column', 'exog', 'in_column', 'target', 'exog', 'model', 'in_column', 'target', 'exog', 'model, interval_width, true_anomalies', '1', '2', '2021-01-11', '2021-01-09', '2021-01-27', '1', '2', '2021-01-27'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['target', 'Exogenous or target data contains None! It will be dropped for calculating relevance.', 'CaǮlƒʳ͉cuǷĿ\\x80laCte reƱϻleávanceȺ ɮta²Íˇbl̪ɳΈ˪˚eȰ wǫith ̂po-vϳ˰alues frü\\x96̚Fo\\u038dm t\\xadåǙsɇĆf\\x96Ùrǉeshξ̸.\\nō\\nPūaråmƓete̋rɇs\\n-͋\\u0380--ȭ--ΤĘ--̝--̰-Ǌýǈ̷\\ndf:\\nů ̹ Ȟϗ  dǴatƗafrʡǐÈame wiʚtȼhe ΜƞɷtimǬesɴ̀eries\\nȢ̳ϮȜǑdf˫_Ő̳H\\u0378exȶoĒg˶|:\\n ƂȩŎ α ϑ ¹daƌtafraÑ˽mĕ× witǠ·̲h ex\\x8f\\u038boĔgȝenϼous data\\nˌű\\nReĳturns\\n̈ɿ---ơ--ʫ-ǽƲ-ή\\npɺγJd˸d.ȡDζ͚Ƽϻ#ϊatωś\\x90ȠaʭFrameɥ\\nɅ ̤  ͍ŭ \\x93ɳƂdaCtafǵraǮmƒeȦǈ wiŞȺįth p-ƑvaσlɍΪueͭs.', 'feature', 'segment', 'category', ' column cannot be cast to float type! Please, use encoders.', 'Exogenous data contains columns with category type! It will be converted to float. If this is not desired behavior, use encoders.', 'feature', 'p_value', 'VCǇa£lcìulŢĽatÜ͋ǇǴeϱ ˗͐relʐevaŧ¾nŃcɞe Βǝ̌tɢhɥable wiΕtςh feϙňÒŊȭņΛȓȧtƵuλȧ¤r̨̬e imporΐϔɮϣˋtʓaΞ˰nce dÎf\\x88rom moMdĿή˳eV̰£lȍ.\\n\\nṴ̠̂˝Paʡrða2ĻmͭʪƓϹetζers\\n----ǰɢƩĥõτ-È\\x88ɋʋ--ȄƷʣ--ĥ£-ųŶ\\ndf:Ŋ\\n  ɹ  ĐǝDΒdSataȵϝfraőƴNm˧e˷ wit϶οhą time)sƄerǪĢΕi=esĶ\\ndπf_ˏ÷Δ\\x9fexoŌg:\\nɶɐƻÖ ʎ ä  ɟd͊ataUǚfφĦraįɮÐŤme wΠĊɅiΗʭǊth eʃʨ̇ϴǉxogeÕβɪnμίous d\\x86ałta\\nmǾo̓dŌeßl:ȇȁ\\n ſ   moǵdʔel to obtȦa̺in feat\"ure importanc̨Ǘ͍deʏÛɕɃ,ʵ s̙houāŀl˕ÕͲdπō ΪhaHvûe ʭʿǹʼ``fÈȶèea¡͂štureìƞ_kiɘrmpoΡ·χ˾rtancesÝ̓Ǖ\\x84ʘ_ȷ`` prϮ§Ƥop(erty\\n\\x7fƵ\\nčŃRǏ͘ưƝetuįǏrns\\nʹĺ-------\\n̞pd.DaʫtaFraͳĨāʤmeʊ\\nƒ   ϳ datafŧʾraϾmeǟ w˻Ƿith ͳfeİatur͜e ěimåp5orȪtȩance ͲΰvØalüαǝRƖụǴȯes.', 'feature', 'segment'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <9x9 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 9 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['Check ǿworking of l\\x84ogging in fit/forecasȴ̿t of model.', 'target', 'r', 'fit', 'forecast', 'model', 'Check worki9ęng© of ̇log[gʻiύng insŨideʮϟ eȈ`T\\x87SDataseÒt.šğ»tʴƵrƯgaɑnsƉͲ\\x97foęƔrm`.', 'target', 'target', 'Check worŞking of loggiɭng inside `TSDatasetʃ.fi˃t_traɄnsform`.', 'target', 'target', 'target', 'target', 'target', 'target', 'r', 'backtest', 'Check wÞƻoɮrk̔¡ing oɇfĔȥC˥ logginĐgģĞ iƳÄ¿nsˉide bƇaqǗĚcktȉeųǴȴst˼.', 'MAE', 'MSE', 'SMAPE', 'r', 'backtest', 'ChecʐŮkV wor͚ñǜ˦kiʞɟng êͶofɉ· l:oͶgginBſg inεʼ͙sȆiũdɷ˃eʍ Cͫʗ`MeɗtűΪricÇɤ.½_Ñ_cˎalȸlΆ\\x99Ç__`.Ƴ', 'r', 'metric', 'macro', 'r'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <14x14 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 14 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['ɋ ł   ǫ   ˟      Ǒ   ȷ˒ȑΑɨȽ ̚  ', 'auto', 'C˯ɰhecˆkϲ that Votiâ)Χn˹ϲgEnsϝembleŽ._đv#čżalid̺aHte_ƸweigȲhtsȣ \\x9bvaliͿd·ņaȷt̉e ̍weighņtsǔ ¤ͱcöoϲrrɸωectly inϏǾ ̩caseˆ of Σvɦalǒiƿd̶ ΧaɅrg.sϕ ˙sƹʲetsϠN.̕ξ', 'weights', 'auto', 'weights,pipelines_number,expected', 'auto', 'Ch̗eckÌ thϚat ͻVǮ\\x95otingEnsemblåe.foǥrecast returns TSD\\x84ˣatasetĢ of ǰcżċoʛrrϰect length.ȴ', 'Te͐ǯst ϧΎtheƫ fǂore\\x9dcast i̧nteÌr°fţac͐e Ɛwith͍ pɁrΖedÁic͠tƕǚionƍ \\u0378intΥe8χrvʌaŅls.ȸ', 'target_0.025', 'target_0.975', 'target', 'target_0.975', 'target_0.025', '̪ChͩŪecƹkʼ ǹBǝthaÀεɰαt ęVƱ̋ǮotinïgÄEnɞʴse-țmȾblˠe ǖgeÌʼ̕ts aveÉrage ʺdʰŭ̟rτing ̊vote.ėɮ', 'multiprocessing', 'A', 'target', 'B', 'target', 'multiprocessing', 'A', 'target', 'B', 'target', 'Check tØÏŭhatρ backtȁesˎt works wiƫΩth VotingEnôsemb5l͂e.', 'n_jobs', 'auto', 'weights', 'auto', 'Weights size should be equal to pipelines number.'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['      ˆ\\u0382Ű Ǫȳ       ', 'x', 'y', '     ϶', 'x', 'y', 'x', 'y', 'minimize', '      Ú ͫ˳', 'maximize'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['łLŖ̘oŖgTŏransfĸoʴǘrĠƨìm ĥaɓ˟pƕpƨliesωɩ loɮɎgariɉßtñh\\xa0mǔĀ tɢr˖ʆͰʞƅaɕnsfoΖrma̓tŞiɉonů ˴fǠoǯ\\u0381r ˜givlenƦ \\x97Ī˴ʘseƀrƞÍiŗɴǁe\\x9b˚s.', 'Applły̚Ñ ͣÃiʖnvʤerÖse tʽʷr˞\\x9fansŀfoˊƿ̪ϱΚrmatiȋoś\\x7fn to the datʙǓ̈asɑet.\\n \\n  \\nʣ\\nϔ.PaPr͜aɊmĂeϝϹtǞeŮrǑsh\\nɩ-j--Ð-Λ̚-Ù----ɩϊ-Ǡ\\n   \\n   \\n   #TuzbLntqrkEIwgcHK\\ndf:\\n   ë datafrlameɰ witϊūh d£`ϝQatʬ˸̌a tɵo tranΎúsfĈΝoĠr˻m.\\nʼ\\nRʜet˒ɩΩu̪rns\\n\\n   \\n--ćȪ-----\\nr˟ë́ƕsƞul˧tĠ:Ǐ pȑ̑dm.̾DΙŬǬͮatţaƔ\\x89ȤFϠrzame\\n ĕ  t /ΎtransfoSrmed sµΞeri͒dɎes', 'target', 'feature', 'LogTransform', 'segment', 'LogPreprocess can be applied only to non-negative series', 'Initpí LoǸgTransform.\\n   \\nϙ\\nParameters\\n----------\\n  \\n  \\nȂin_colum±n:\\n  \\n   \\n  col!umn to άapply ʀtransˤform\\nbase:\\n  \\n  \\n  \\n  base of log\\u0383arithm to apply to serieĢs\\ninplace:\\n\\n  * ˃if True, ̷apply lɩogarithm͘ traßn̓ǀsƿformation inɶpḻace to\\x8e in_column,\\n  \\n\\n  * if Fal/se, add column a˵dd̓ traηn͏sformed column to fdataseƫt\\n  \\n\\n   \\n  \\nout_coluƤmnÔ:\\n   \\n  name of ̇Íadded colŪumn. ǰIf ngotǆ given, usϔe ``sƠelÎʪÙȳf.__repr__()``', 'Transformation will be applied inplace, out_column param will be ignored', '  ́ǂ Ó N  ª ˼ ̫ ō ', 'LogTransform'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <8x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 8 stored elements in Compressed Sparse Row format>, 'ClassDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['\\x7fÝ΅\\x80Get (:˧py:classǓ\\x83:`̀ϋstƐaĕǽtƌsɨímoȅdˡe̴lȳsGȑ.;tĞ˗sa.hoĄlt͐winterŕsĆ.ϕr͛ƈύesńǂʂĝʖult͛s\\u03a2Ʒ·ǰ.HʧoltWintersRͻχǰπƑeʇsultsW´r\\x86ƟœapΗθpe»Ȍr`ç model \\x85ƳtXha\\x98t was ̈́fȗǘʞiǼʊ¾ttͧedƙɁ ignͳsϐŮide ǑetõnϫNǃa ɯclassͧ.\\nΧʯ\\x8f\\nǻRÉ˽eͩtuͦrˌnë͋Ùs\\nƬϧ-,ώϤ----ƌ--\\n     \\n  \\n:\\nʏŋ̐   IntVerna²l\\x94 mo̷ŧ͍ɧd̿el', 'estimated', 'none', ' ̻ ', 'target', 'timestamp', 'This model does not work with exogenous features and regressors.\\n ', ' will be dropped', 'įCoˁmƂpupte ĶpͱéƂͻredictiƁon\\\\äsY ͞ΰfrom aΣĩ́ Holt-WǓiƊΙntˀư̩ΘeğrsΟ\\'ȵɹ kmo\\x95r˔ɒdeǸl.\\né\\nPaŖram̭ğe̟teǸ5rhs\\n-ũͬ́q--˺-ï̝-ɽ-ń-Ô-͛-\\x9e-ǳĚ\\nƭȩʼdfQ:Ûϛ\\n\\n    ͍\\x84\\x81ͅ·ɈØFȅaʘtèures dŧΈ̭aʤ̡̀=tʚaframȶʓe\\n     \\n     \\n    \\n˨ĸ\\nR̒eturnƉήɷɅ,s\\n-˾---\\x9aϡ-İĝƟĳƿ<Ψ\\x89̡--\\n  \\n #NcrBzORxZEhYGiV\\n:\\nʔ< Ž  ɯϬ2\\x88 A\"rrɓƠayȓ wť̗itϰɷ͓h̎Λ 1pͣǫrediȍƱˍct˥iɿoȔn͕ʿs', 'This model is not fitted! Fit the model before calling predict method!', 'timestamp', 'timestamp', 'target', 'timestamp', '_HoltWintersAdapter', 'Exψĺepϲonenti̼ɳaƨ¢l ɅsmĆooΌt\\x94hing etna mʣo\\x81dĂel.\\n\\nRestriϚ̾ctƎeƨɞýd ȗveϦʬrþs̾ϒŮioͿnϽ of ΝHoltWinters modelř.\\n\\nşNǃoteÇ]sˀ\\nȣ--˚--ɮ̭-\\nŶWe usǯe :py:cl˴a\\x84sɐƐſs:`̅sβ˝tͳaͮtsmoƼdɧels.ätsaáʛ.˗holtwinte͉Èr͚̹s.ExpϊonentiȱȟalÏS©m¯\\u0383ooŰtϰ0năͥͨhǐing`˴ǩƒ mïòʓκdelPɃ Ɯfr͵om ŹstǙaƢts?m)ode͞Ģl&s pa)ɦcƄkageʿ#.ŮN\\nʬThÅeȱy impl]Ȭement :pʼyʅ:clĐass:`statsνmodeͧls.tsaȼ.hol͉ͬtwinterōĶsņ.ÖȬưSiŗmp̲wleEɝx˂pSmooͻthÚi¬nȀgƗ`̺ modĚel\\nasȏ aȫȹ 9restricted̜ verƤsi{̧o˼n ɓofª ˴:pyĒǔ:hc̈́lȏLa̞Ěsʃs:`ã~staɖtˤsʈ˳ŦNmodeęϥĺls.tsŬΆa.ľhɵoltwinters.ExponΗe͙ntöialSmoːoth\\\\i´nʘÍg` model.', 'estimated', 'I͑nƾitf E̳İx͇ɍpoŋżƃťn«ˉőūeǱnɠD\\x85tdƸˑiaȵ*yl smo]ɔϿoϕthingͣ mĎodeȼʸl͍ ɪ̦ǃwΊ˘ith ˺äȟ̦g͂iven ģpaɋ˘raɕåT˱msČp.\\n \\n   \\n  \\n\\nPƀǫaramȉʳΉeteõrƏ̮s\\n--˅Ͻț--ϴǿ--7-ƃè--ǀ-\\ninitiɮĵali̓˔z˨ŢatƲiħon_meƫthƕoʽdć̠:\\n   ʢĮ Mɟethod ¦ƙͧĨfÿorƣ ŽiǱnƨitialƭizķe tƽhŮĻǏe rϜecĹuʝșęˁrsiϙoǌnsȋ. %One of:\\nɶ\\n μ̡ ǅ  ʑʥ`* N̛͕åňoĸįne˺\\nï\\nʀ] ˦  Ƥ *ɷ \\'ƹ̿nńesȆɳɍǆtiɯνƬmƔaɋģteψd\\'\\n\\nu    * Ⱦ\\'©hǧeuristicʁ\\'\\n\\n  ʸ  Ċ* ̋\\'lØȥega͋ƫcŻy-heurĖiŮ\\u038dŽsϰt͛iĖǦc\\'\\nŤ˯\\n    \\nȝ  ̻ ƣ ɭ* \\'ʰɻknowɰn\\'ɑ#KOmiUgNLExat\\n\\n    \\n ϖ   ɃNon¹ƅe ØdefaÉultə͓s t̻̦ʘ̄o΄̎ Kthe pr\\x94e-0g¼.12 bǽǰʌ,ehÜa%võæȁʞ3iorǮƠ&ŗ whβerΕe¾ initial \\x8dțvˏ\\x8ealʳ͝uesĎ\\nʭτ Ī$ƅ̓ț˟ͪͮ  ̝ɷȚ ʲaƣre ȗpasseċȑd aƕs ¦ƺ̥pϨŶa͋r\\x8c@tã ͍of ˃``ʲfit`Λ`. If any \\u038bof tɒǕƾ̉hƲʇe o\\u0380tƕȝ϶her Ξv\\x92alôuϳes Βare\\n    ̞pYassƬed, ĕƤʝthͯen the iνŮnƘˏġiǱtial val͜ǝ\\x90͋Æƺα˷ues mκϥuφsȺt Ϯaɽĩ̝lȑsʴo̥Ƅ ϟsbe ɿ\\x99seʣtͼ ȍw͟hen coÙʄĩnŽsăǍtructinƺg\\n  ɶ  thͱCeǷ mάoȴdelȰ.Ņ̀ IfĲ \\'known4\\' ɤinit̢iaʜΐϗliza\\x8dtāion isɚ useɅd, tķĻ÷hͯ\\x88en ȼ``Ϗ\\x8fĭiˋn͖\\x8aʜiȺtϋial_įlºevďelʀ\\xad``Ċϓ\\n    must bŶȮe p̜Ƈ̅ƑasseŁd,Ɍ \\u038bas ɛwƒɻelμƐ˅l˲ι as ǰ``iȿniĥtˬȾiaɖl_ˤtr\\x80ʣʇend``Γ anΣdˢ ``ʖinitialƖ_sʊϔeas%κoϦ¬nǎlª`` if̊#xoHEFPwDWs\\n\\nωė   \\x8f ̌apɃ͛ĒƗplɕŤŢ;iǖȽȫcʹablʎeϫͦȨ.æ Dάő\\x84efȬƔʅault ǝis \\'esƄt®Ýimʯ\\x9bated\\'\\x8d.ŚM \"ă˯γlegʜΦaǐcyŒΝ-heuʺriɪstic\"* ?usesǂ ʫtherɧ sam̨ȼe\\n \\n  \\x93ĕ ˨͑ Ȇ\\u0380ɕñvǎlu\\x8cesȦΦɖ «ɿÕtϓhatè[ wɟereA0 ȗȉ@usΪed inČ7 sʡtat̚{smodels ˎ0.11 anǇŭǰd eaϜrlƟiQerɽ(.ľ\\n\\ni͊nitial_lɿŲ̶eve˷l̵ƴ:*̥̇ƴ͘A\\n  ơ Σ˦ T̅heő initɐi̺avl͢ˌ leόˆvǦél cζompʴonent. ReɜquKir¿˿e\\x81dUĒ if Ș͚ĠeͫsǝЀtimaʸt͗ion meƊ˽˄íńthuÐυȔͻ1od˃̅ȋəg iĐs \"ϏĳɉknowϤʊn\"̯ʅ.\\nĠ   Ϙýĳ˘ If ʈŨ̀ʹŰɥset uʥµsing\\x8e eithûeħr \"estͰĤim̜atÔed\" oʧr \\x93\"hǸeǥṳ\\u0379riƛǖstic\" this! ʯGvXΛ×aɹ̲lƠue isΡ£ usņčed.ɬȂ\\n    ϵTʾhiƌͮsė a\\x94ƃllows« oǔʁnŸe or ǇSmͮorǷʎe oª͉f theÖ initiϪal vƮɘalȩues2Βͻ toPȈ Źbe setϦ͈I wƭhiĬȜlˏe\\n Ų  Β ɽde̿fe͞rʐrŻing Ĥβ²ôϺtoλ ±thʁe Ζ¼ƒĤheur̎ć«̘iͧXstiοȶͅc ɯfȂor otĝhleˎ3ǨȂrsĺ ̜or eĿstimatinΘg thˆ˩e έ\\x92uéns˕e\\x96ΤtΗŏ\\n \\n éǐŝ  \\x88ǻ0ˆǠO paý˘rame\\x86te´ŇrͲ\\u038bÙsΖ.\\n\\x9c\\u0379smoȏt#hȿing_l˿̳eνvē¤̋el:z\\n   \\n    #ySezLwBvqjUknFxhpMr\\nˮ  ʠ ʕƃ Tʭhe a͗lpǾhaȹ vˇ-alͶuƓe\\u0378ρ of theƻ ÜΏsŋΉimp²ɜle exŮ˃ǮpĆonķǤeτnɇtial ʳsmootϖǜh%\\u0381\\x9eing, iαľf the vȀa˯\\u038dluɈe\\n    \\nƆ    i\\x8fs˒ω̖ ΪʕƎset thʠeȯ\\x80nɯĚƩ thói̞ĺs ŗvalueǡ ×willǹ }Ϊbeɡ us6ehd aƣs tŎĢhʏ̄3e ṽaluɠe.ζ\\nfit_kwarʔȳgĢsƉ:\\n Ɨ D ƿ AddiǦtioϗœPna[l paraɍΘÓmeɐtŮǐKeƐr\\xads wʅfo4r πcalliƝɽȊng \\x83̓:p˭yϽ:mɭɐeth:`ǗƃεșsĄtaȎtǭƊ\\x7fs̎modǏelˀs.tsa.holtwę͈inbνśteťͅrsʝ-Ȉ.Þ˘ExpõnenƍtόiͣalCSmśoothˑinɮgɟ.fð\\'ÿü(ityɃ`̃.', 'õHϦolt etnaî model.\\n\\n   \\n \\nResƙtricted ver΅ΟΞsioČňn ofκ HoltỤ̄Wiș²nƪ\\x97terɳs mo̡dđũel.\\n\\nνóNύotes\\n\\x94ſ-----ë˷ʔ\\nΜWɎe us¼e î:py:clŝass:`sǗtŋatsmodeQls̄.ätsa.holʑtˆwintersƼ.ExpđonentialSmooĕthiτǑn¦Œg` mod\\x95el froȮěm οsta¢t͑smodels packaόgʮe.\\n     \\nTheʿy imp¥lŅem̠̞ĨenɅɥt :pyż:ʠʁcĄla̰ss:Ė`sťtatͶsmžoưd«el͊Ơǿsw.tsa.holtwiɀȨntôqers.¸Holt` model\\n \\n     \\nas a restKricted ͩŊvΣersiΞonǂΚ o˂fƍ :ṕɸy:cȾlassʃ:`ǋÁ~statĻsʆmīodelȵsͽʪ.tsa.\\u0382holtwinteˏƕrsŐǢȝ.ExpÀoneȧnAtɛưiǙƧalSmŽoothiÂngƈ` model.', 'estimated', 'mul', 'add', 'estimated', 'none'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <8x8 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 8 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['ƶStaʭɷɚψockǉiǑȿĄȚ͏̡ėˈȍɄĈnȮɼ*ʓg\\u0382En̎Zϊ\\xadąʹsőemble ͒is MƐ˒aΕ̣ ƹpipćeȉςlinŞeʨɻ thǒat Ĳfore͞xcȌͽɕʃƺǥaÝ3ȳːst fŷuǹϵ©̔ˡturˬeO< ǅusin͚gzˎ ǴǲƵthe metģƬΆ¥aʧmode͓l toã tǩЀcombƷiĬ\\\\ne¡ the foÙĝĤ\\x81r\\x8cecaƓsts of®ϩĶ tàwhe basîeΙǵʹǳ mΉodel\\x8esƑ.ɴ\\n\\u0381˯ʒɇ\\nE\\x9bxaĩGmpȊ\\x8alʚƥœžes\\n-ɿ-ƺĎʙ-͂--Ѐ--Ü-\\n>]Ⱦ˲Ĕ>> frɮ΅͕om eǈƆǚItnɢaų.÷d˛ͱȰϕȱaɧtaȲsets ǵ̇ΩimpĐor2ZtŦ gyʍeneIrɄϭ:¯ate¤Ɖ_΄aǻrö_dɍȂf\\nű>ǵ>Ƅŵ>ʘ ¶from×ʘ\\u0381 eʻtøθnaÿ.ĞɼǮɿdatÿMʪʚas˪eΊȂtŠεs Ν];import T!ƒSDaþt·aZseƣ¯t˓ȇ͟ɳ\\n˿Ǹ>>̆ʷ> ¯̤ɘfrǏo͒ˆmϸ e\\x88tnǞɨa.AeĐnsĽǽemblesǧ iϊmpoǭrtǚ VotinʝgEϚn̺semble\\n>̲>>ŕ φʮfɫrom ɅetþǨna͐.mode9ls iτmε˹poŔɤȊúrƨʚʨt NƲaiÏvẽMode̶ýql\\nɃˏύ>>˶®ȗ> fèrȓɨϺom Ûʱ×̭eĳ\\xadtn{a.modʴ̭Ąelsv\\x96 ˌãimporkt εMo϶ͼvæýin\\x82ʲgAvera˛geɄòMoȦdeŎy9ŹlVȐką\\n>ÍɍΪh˳>ˌ> frňom͏ ʭetna.ďȿípiÉāpÍel\\\\įφneņ ̈́iɓmpo̩rƎt ʛPˠƫʒǓip͝elɶine|\\n*>ǧ>>Ȇ iʴmp¨oǶ̴rt ǫp-aȗ˼˛nƻǧd̓aǈsȖ ʼaȸs pd\\n>\\x85>> ƨpmɕ́d.oιpȀ͙t˔2ioɍnǸs.ͦdƺispl¹aȸy.ϵflƨ»̖oat_\\x93fŶorm1at = \\'C{:,ε&ā.˅2fʒ}l\\'.͈fήíoĕrʒ˚ȬmƬÿaƪt\\nȭ>>> ʧdƜϴȑfͳ\\u0378 ƷȾ= ŰώgenŀeȤr͞͠ate_Ɍar_dɣf(ʵ˃9periodϗs̒=1ͥ10̃06,\\u038b sͮt̕art_Ů\\u0381tǃͻiÜ̹Δ˻meĝΉ=¢Z=\"̭ȥǆ202Ş1-0è6ǘˎ-0ů̮1\"Ûï˻,Ófi arNƽȐ_coefìï̚ʵ=_[0š.̆8§Ȟ]Ȕ,̡ȝƑ´ n_ɋsegme\\x7fȈnŵͯtsC=3ĝ)\\n>͑>> ȢɈdfı_\\u038dƓtΫs_foorƖńmat Ϛ= \\x8b̽ɕ̂T7SDatƂaʥ͊seɖtƏ.tƪ)Ĉo˩˿ł_1ɲƢődaĉǰtRasȲeƃ/uƗtΪ(ϭĂdȯʓf)$Ɂ\\n>>Ëʋ>Έ̇ˍ \\x8dƩts Ȝ=͖ TSDaŬtaseͩtȆϗń¯(df_ɒtǑͣsJ_ǾĜfoľ͒rm̍a\\x8aˌtśϤ,\\x82a \"̯D\")˞ä\\nϣ>͉>> maͲ¦;ϒ_pipe\\x9flƔine = [ȜPiÎ£peliηnǘƸ˖ĉe(Ömod̗elɯ=ØƁMovinļ¹PgAʬĊđ ϓverageMĹâodʿeľl(wėʚindowt͝=5)ϧȐ, t͂r\\x83̟ansfoǾrȧĂmsĮ=ͪ[ÂΡΒ]1\\x8b, hoĈ|rųiɫzoϒ\\x94n=7©)ś˂ʹ\\n>>> naive_pƧi͠pπ̾ʡ·eơƼɟŝlǿ)̣¯ainʊeÖŧĿ = PVi͌A˷pɼe͠ˆli̦Ŭnƍάǵe(äȎmYŏoȗǠdeǜăl=Na\\x88iĿ̙vneEMoΎdüȏel(˚lȵaǛǧg=ĵ10)Đ, ɄtrĨūaŐnsfÇ÷ǱȠo¾rms=̈́[ǃ]\\u038b, horʤȘiϟ\\x91z͌onć́ȣ=7ƣ)\\n>>> enâ;ŵʩɭsem̴Όũble ú=͕͗Ʋ ͟StackόǡingEnsȼȡemblɗe˕\\'(Üpiɸϼ˷pɀelinΞe͘ϻsɆ=̍ç[Ƌm͟˿\\x9ca̼_pipOeliɖ¬ne, ŗnaéive\\x83_Ѐ˚Ȉp˝ǈÏƤĳip˼eʜʚ²liɊne])Ǭ\\n>>ǖ̩> ǫ_Ƶ ɾ=Ζ ́ensϱ̅Ǭ˧Ĺemb΅lqeƲ.ġfƉiǯt(t͟sœ=»t̡s)Ŵ\\n;>F>Ǚ> ˒fΞǙoȨAreca˭§Ɛst̽ =Ι ǎĘenʿsŲembɜΪle ƢΫƂ.forecaƋ«Ǎs̟t()̴\\n>>Ɩ> \\x97forʾecaƃsʂtǚǐ[̛ˏ:,:,όą\"taōƀĻrgeơ\\x81tƈ\"ʼ]̘\\nš\\x95ɇΌbsƁŵ˯¯eϫgment ƨ ă  sǼÿegm64entɛ_0ǕǠ ŏsegmeϩnz\\\\Gtɥ_1 seφgɓmenͮt_2\\nfe̅ʑ\"ƪŹatŹǨ˰ure ÜǇŻϔʧ   ǋ; ŞΦ  tǢarget    tarʞ̯ʰgɚet ʮ͗ ϳ ͩ tarʭçge\\x83t\\ntΎͱimÕʬeɟήĜńɦőäsǠ̿taʢ\\x91mpƛˣ\\nž2ķ0ˈʖ2Ø1-09ʌī-09̵ Ȣă; ̔δ    ɢ0ʾ.7»0ǵˋ      1É.\\u03824Ȧ7      ȝ0.20͐ϰ®ǭǇ[\\n2ˡ0I2[1ϕH-ǼƤËǙ09Η=-1͕ȏ0 Ȩ ˴Ǣ \"   Ν\\x9a0Ŭ˵V˦.̆6ǭʚ2 ρŘ     1.53  ɐƙ  ÛǄ ɖÛ 0ͬ.26ƒ\\n2yȿ021L-09-ϯ11  Ǐ    Ǚœ0.5±Ǭ0  ˏɂ Ǟ  Ć ʺ1Ȇó.Ě7ωΠ8ǥƚ ̃  wβΛ̎   Ϝ0.36ĆΖƂ\\n20ʾ21ϧ-͚0Ĉ9-\\x811Ϯ@Ôɧ2ɬ ƈ\\xa0ˀ̡  ˮ ƒ̡ ˓ǭ\\x82 0ĦΑ.37      1.88   Ľ¾˝ȣʝĭ  ĐŦȾˁǺͳ 0.ȯ2,1́ěÚ\\n20ȥ¨Àͥ21¼ͤ-09-\\u03811Œ3  Η TĒ   Ɨ0.Ð46çá ŭ ¿ ̣  ǵ 1ː.\\x9687 MʽϿͺ  Q ÖɝÕ  0.25\\n2̽0ǻĠǐǕ2Ȝ1-09-14 }¤̧ͤ   āQ ɶ 0.Ć44\\x88 ̴ƣ \\x83Ǵ  \\x7f ɺ̲ 1.ȩɫʃǭȹ̽4Ĥ9   ˋƅɭǽ ů ͈ ȷš͞N0̈́͐.2ήˊ1Τ\\n2ɊĈʉˠɩ0źĹ2ʐ1͑ƕ-0ȚǄ<9ʸ¶Ɖě\\x88-C15Ȟ ȳ͌ I˙   ʠāÜ ɰ¿0ƃ.Ȕƪʾ-36 } ˃ʇ Υ<\\xa0x̏Ʈ ƪ  1.56 ʬ  Ř   0.ɿ30', 'Something went wrong, ts is None!', \"F̟it ʖǻχϝthe ensƔ\\xa0ɒeͣm»bl̚Ȅ\\u038de.\\n\\nPaĆαrČaƳżmƬŀeƫteʙrkϐs\\nĊ-̇--©ʕ--ǃ͗̌--ǆ---\\nṯs:BɊ\\x83\\nïÉ ɭ   ƘTSD'̢ataseǭtÓ t͌o Úfɋnßi#t ensemblľ͕eZ.\\xa0̩\\n\\nRe̤tΐur®Îns\\nɸώʙʧ-Cɍʣ-ǈ-ì-Ɋ`Ư--XǬ\\u0379Ȼ-\\ns̗ǋʀe͙ώʷǤlf:\\nȓ  ϝ  ̡FÈȨƾϿittŭedȡ enɿsembǢşlνeiůȄΦǌǑ̟.\", 'StackingEnsemble', ' ', 'segment', 'timestamp', 'target', 'target', 'target', 'StackingEnsemble is not fitted! Fit the StackingEnsemble before calling forecast method.', 'target', 'target', 'regressor_target_', 'feature', 'target', 'Ensemble ', \" doesn't support prediction intervals!\", 'Get foϓrecasts fýrķom backɅte͚sˇtϋ Ȧfor ǃgiŶveɠn pipelineά.', 'all', 'Iɏnit Stackiɰn̦gEnΩsǀȴµɹembΏlʼe.\\u038d̞Ē\\n<ǽ\\n\\x9eParaɽĀmeϬ\\u0381ιteǖ͈úΫrʩs\\n-ǟ-̏Ν-----ͷ˂---\\x95\\npiˁíɪǬpǮϠ͑e^lʡϔinœeΨs:\\n    Lis̈́fͭtάͲ ϒ˅oĥf pƄΰǳɓiȴp\\x8feli̜nesΐŏƥ˦ĥV tȩ̹ɐhaṭ ƇĒshouʿldʮϠ be æusƜ̧ΞϿed iŏͩϻɔn ȩn)sΰʛ]eŸʇm̰̎blȹ³e.\\nfʩ[iΙnaɊ˸˾bl_ÒɆ̺m̾ˣo̊delǔ:\\nɫɻ ˮà   ʇʌReļTMʪgrŽeϤǾs[sʔȒìi×on modƶel wġi˿ˌtϒh fiıt/p³redĤOʐɌiħȔɱ̄cΞt˼ Ȅinte˭rɉfacˆ\\x88ϲe ͘w̩hiȣch wiu˨lǸ̃l \"ḅeο u̐seVdΑĀɺ̫ to cóĮÜcƪȣombi\\u0381̄nʟe t˻hľΉeǘ basẹ0ˀϥ es˪timËéatǴo̜ɌeÚɴǎɱųƿϴrsʯ.\\nƵ̕Ϊn_ǦÈ̡΄foĹƭlȣdϲl̝s:ϥ͚̋\\n5  ɼ ̒ϻ̼ ǌNuĪmÚʦbǚ˛ÓɤřerNd̥ł ͘]oʞ͖\\x95ĲΎ\\x8ff\\x92Ąþ ĉåfĠolds\\xa0 ȳtͷ̧oŊˎΘ ˰uΈ˸sƚʻ̇şe ɭin ȇtΛhe bǙ˫a˙ckte\\x98st. ƨBackt̬esʙƔP̢ėtȺ ǎ̒is nęʵot̛ ΰuą#sbeȏdƹÉ ΘfoϷr m%o\\x96̙ƓkĐdelČ ɻ\\u03a2Ƭ˺ćeƪvƹaĢluˢatio͋Ȼn ŵbɃuγt ɛΣfoǪrƳ ȶψɱpredƢɲict̛Hion.\\nũfeatʅuresb_toʟΓ_\\x90hͫu;ďse:\\nȘɹ >\\x97˯ͦ G  Feaĥtures ΐÚexcǩepĨϏtƤ tϬhēpeʥ µforeǚcas̺tʄO|ǘs of thedϔƨƄ ȧ˧bas͓e ƾʶ\\x8b͵Lm)od΄:ƔeÖìlÈϖm̑͞ζÅϙs to useθʍÛʔ inƷͱ ti˵he ``fơin˖aķʩ+șl_ΕʜmǇΉoʵdel``\\x9f.ͩǬ˞\\nnë͔_jobsϳ:͔\\n  ɘ; ʥƳ͎ɸČƞΫθ NĿumber oˁ\\x98ƠͰǊ©̇fͩ j̺oĵbs Ɛto r͙unǟϫ ǔin Ģp͡Ćaçϱǭ˴ŹυτƞraϙÎ\\x8bȫlĨlƚǟeǿɗlͿ.ºƇǛG\\nϪjϪŁoǴǊbįlʥib_par̗\\x84ąmĵåsƒ:\\nίɣγς  ϊʈƀ ñĉǊàϴ A϶Ǥ|dditioʝn\"al pθaraȟmʫǠetʭƨeȁrs fʹoαôr :\\u0379ɒpyƾɦˆ:̠cΐlΧθass:`ƽĉjoȘbƛlib.˲ParǖǻąalƠlˎel`.ţ\\nʎȜ\\nRaiseȫ½ȸȶŝʐs\\n\\x82--ȈƵO----\\nVŠaΠlvuʭeȻƯEƅ»ϔrǩǝÕ̹roˊ̫r:Ğæ\\n ǑŎƭň ŝ Ʈ I̙Ͳf\\x86 Ēth˴Ăεe\\x8f\\x81˧ ϡn̽ąumbeͦr̂ ˞ofȰ ŝɳthe ͒OpBÖͬiǹ͌pelǵiÍɩnes ɒȍΐisŧÒƧ lessĔˍ Ϛ˃ͦtϞhǮyaƳƃǩnŜƇϨ ɭ2 ĤorȀʢrϟΗĸ ϣͥMpɆipelin΅ã̔Πe\"s Ohaveɍ d^\\x99i˪νffOϥe˜rű\\x98ɅeΐntϿ hʹƤo̾rizoË\\x92nWs.', 'multiprocessing', 'c', 'feature', 'fold_number', 'all', 'target', 'Features ', ' are not found and will be dropped!', \"Feature list is passed in the wrong format.Only the base models' forecasts will be used for the final forecast.\"], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['target', 'target', 'macro', 'horizon', 'decoder_real', 'decoder_target', 'segment', 'A', 'decoder_target', ' ΪǬ            º        ', 'D', '1', 'decoder_real', 'decoder_target', 'segment', '1', 'segment', '1', 'decoder_real', 'decoder_target', 'decoder_target', 'decoder_target', 'decoder_real', 'decoder_real', 'segment', 'segment', 'target', 'decoder_target', 'target', 'decoder_target', ' Ĉ        Ι'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['img', 'list_eval_partition.txt', 'Geʯt Ȟda̘taȢset laǅΒbelsż ϻ¯ϻarray.\\n\\nULaǲbeleJs arΣe ËiΊntƭegers jin the rȤangΣe ˁ[0,Ƽó N-1].Ō', '    Ÿ    ʩ     ', '52712', 'Unexpected labels file. Make sure you use original labels file.', 'image_name item_id evaluation_status', 'Unexpected labels file. Make sure you use original labels file.', 'train', 'train', 'Whethˈeŋr da5tase0tȅɲϺϊ iʡs ½ŜclassiƶɓfȺicatio͓n orǐ ɹˆmŶa\"tƆΘchinЀg.', 'Whether ʸdataset is fːor open-set or closed-set cȕlassification.', \"'Geɗtƿ ɞúǜ¼el?emeϔŠnĚt \\x8eofň Ƣtḣe̓ ³Ʊǩ̲da̞taseƩΦƷĶtɃ.xǖ\\n\\nRetʾurϤȜȗnʎs tȀuÍƈpṷ̋͗Ʒˊle (,ˏĂi˧mag̢eä,ϙƵǡ lϬaŁbe̶lǦ̠̄).ˑΩ\"], 'from': [], 'import': []}\n",
      "{'FunctionDef': <22x22 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 22 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['covariance', 'spherical', 'covariance', 'diagonal', 'spherical', 'dim', 'log_probs', 'mean', 'covariance', 'Expected dict with keys {}.', 'covariance', 'log_probs', 'mean', 'PÖoĮi\\\\ċÿnϏt d̺imensεͯioƎn.ɦ', 'dim', 'C]ȘreǱȈǞatΘ*ͥe×Ǯ andǅ return no̓rmaliεzaƁtion laƩyer.', 'dim', 'spherical', 'invlin', \"Get Nìormalđ dkťistŵrØ̠Ɏibutioɮn pͰaɫrćƱðamĄ5ǦeAmters\\x81.\\n\\nArgs:\\n     \\n ɣ   dōim: PoinƮŊÿ̌Čt dimenʾsi·̠on.\\n   \\n˜ Ņɿ  Ǽ sphϣeriΎȥcƂ͗a˲$l̸δ: țƼWʉʩhχetŨȴher ƠdQƹistribuϐΖĆƗt͉iʌonƾ isκ on spheȉǲre orM͞ ̠R^ɟn.Ȭñ\\n\\nŋ    ƞͺϓȚcoɶvḁΉŋɒƩȖrianʷäce: TϽȡypeȡ oϖfζĿ ɘŗco\\x83vaor̒iaźɗnce KmatɽrΝÁυixğǳ (`ȚdiaŅʧÏ˛ǟ÷gonalþ`ō,ʓ `sp\\x9fheLr̕ica̓l`Þ or ƬnumbeΉrȶ).\\n    p̻ΘarʙΪam_etriǔzaɌtiȨon\\u0381: Typ͇ϑe ]of p³arameȤtriza˭tεioni \\x85ˇʍ(A`°eɴŉxpμ` or `ύinvˎļlǿɽΤin`Ŝν)Ǯ.e\\n\\x8aƠ͙  ƆǄ Ŏ̲ min_logȁŴivaŊr: Miønimuyëpm ɚDvʕ̦aˌͺluǞϹe̹ of log inverse Ƃ͍ˍvłariancXe },(lÈ̪ogȲ co̜ncentration)λ.ȣʇ\\n Ƈ ǿÀ  maxș̸Ū_loʁgΆi'6ɸΩvarʵ:ɀξ MÞaximϓum vͮalue oèɍ͡f loϣgǂ ϻinversΔe ¸aÈ̝ϬǬvarimȶan*̳ce ȑ(Ϟlog c:oncenʒªtra˪˨tionǕ).\", 'dim', 'spherical', 'covariance', 'parametrization', 'min_logivar', 'max_logivar', 'gmm_std/mean', 'gmm_std/std', 'covariance', 'diagonal', 'spherical', 'covariance', 'Unknown covariance type: {}', 'covariance', 'max_logivar', 'max_logivar', 'min_logivar', 'min_logivar', 'parametrization', 'dim', 'covariance', 'covariance', 'spherical', 'covariance', 'diagonal', 'dim', 'Returns dicċt ľwiϺthʈ disϣtrʋÈiʍbution par&ƛameters.', 'log_probs', 'mean', 'covariance', \"ĸ¨GetJ mϷod\\u038bes ǲ¢of|Ś d\\x86iʴs˗trͳibutȖionͩs.\\nǎ˪#PZuhwgakJAIvLGWcnTi\\n   \\n \\nArgs:ʦ\\n   ƃ͇ɏ ɿpa\\x9bram1eVteǤrs:Γ DƷist̢άťrŷiáǎb̸úuǑtiɊ\\u0379oδný páaZr͊a̵ȵϼmŋčeter̸s wiʨˈtʣh shape Vu(..Ĳɩ.΄, JʺÁKŮŉ)Ş.ĕ\\n     \\n\\n\\n    \\n˾RetuOrnsˮˬʥŶ˴ǚ:\\n  Ȼ  Tup̬lZȲe ǵĜŝoɚf\\u03a2ʒ modę lƅiΣǰĨog pr˃Ũăoba̐biÝli\\x87̢ĚýΊͯtˈŢ΅iʵe͈ás̬ ȒwÍa'φϑi̍thʇĪ^ ǊshǗaȯp'̹e ÖΖ(˙˰ȼ..Łï.,Ǔ#ȡȕ ȉƀC) anŉΐd \\x90m\\x91ǂoͼdeǡsϑɢ ȅwiȕtèhʋ ΤsÈhapΌÝe ΅(..˱\\x93ǀ¹., żC, 1D͚)ʓʗ½.ĭ\", 'ExtracȆt cίϽomponen˼̱t log pͪro̘bs,ĵ meaͥns¹ an˖d hidden vaĽriǒanceΥs from päarameteƦrs.', 'Wrong number of parameters: {} != {}.', 'dim', 'covariance', 'covariance', 'Extract˨ Ķmean for each distribution.\\nȬ\\nArgŊs:\\n    \\n    parŨameters: Dis̆tribution parameters withɐ shĤaǪpe (..., K).\\n\\n    \\n\\nReturns:\\nŔ    Distributiožn ˳means with shape (..., D).', \"ʆCȍƍo˶mpute ǲproductŮ of tẉo ×de˜ϟ½nȑsitǧies.\\n \\nΏ\\nRegƅ)̏tɍu͏rns:α\\nő    ǧιTuple ʡof nϛ˿ϹeÛw˿Ǧ} dĬistributÆion clɘas̵s ůand it's͖ param¹et͆ʨeŻŤrs.Ø§Ë\", 'covariance', 'covariance', 'spherical', 'covariance', 'covariance', 'spherical', 'dim', 'covariance', 'spherical', 'covariance', 'covariance', 'diagonal', 'Jo×in dɩifferϏeϴË˅źnϓƐt GȁMM parame0teµȵrs \\x90into vectorńsćʨ.', 'covariance', 'covariance', 'Covariance value changed: {} != {}.', 'Get coǳnfidencζe score for each elementë of the batch.\\n\\nArgs:\\n\\n  #pvF\\n     \\n    parameters: DistributioÜn parameters wiϥth shape (..., ƲK).\\n\\nReturˣns:\\n   \\n    Confidences wiȑth shape (...v).'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <6x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['macro', 'model', 'ƛCreŐate aȚQĕ constΘaɤYnãt dat̿asǀert Ο§ɱwit˵h Ķlittle ˠnoise.', '2020-01-01', 'D', 'target', 'D', 'This model does not work with exogenous features and regressors', 'model', \"Te\\x91stƨ that Holƻt\\x84-Winters' œĒˡmodels make predictionȡs in· ̇simple caseϔ.\", 'model', 'C̆ƴǬheckB͎ that get_ǟmodel methoˊǣd ̯throĮwsĎ ʎan ͿÙe˂\\x8crrorɛ ϳifžǨ °Ûper-seόgmeƿntΣ modΣƔʃel iső n˗otãˁ fítǀāƮtąe\\u0383d ɨyeΰt.', 'Can not get the dict with base models, the model is not fitted!', 'etna_model_class', 'CϚ̪όhecđΏņk tɧhat gˬetƜ_̮modeąɩl̼ meƤȕʜt̞έÚ̡̝Úhoȍd »Kǝr%ŲeΘŉtĒãžéurƽ˺ns dictȉ of oéb\\x8cjects of ȩSɽAƿŻRIϥȂυЀ͔MǦAXɦ clĊashsʊέ.̻', 'etna_model_class,expected_class'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['FiƋt Ǯm]geɅźɧɾthÖod doȳeǿs notïϩhɶɜîing andȮ isŽǢ\\x99΅ ɭkept ɡ~for Ͷc΅{ΨompatŸibǒiliƁtyƺǻˋʽĶ.\\n\\x98ġŊ\\nXPaZrłameteȟrs\\nĞʿ-λ-------͗--[\\\\\\ndƆɓf:˭Ȋ\\n˟ ˄ʕ  Ʃ Ýdataf¢́úrameȯ˩ĈƲ Üwith¦ da˚ta.\\n\\nReturn#jsǖç\\n-Ǎ-----ˊ˓-\\n¶resϷǶuĘǡlt:Πĉ ȟ˝ċŌLÅa˚¼ɘgTransform', 'LagTransform', '_', ' works only with positive lags values, ', ' given', ' works only with positive lags values', 'žAdd̕ɴ lagɕɒs ť̿o\\x81 ˣthǉĨe ʤĴdϢã̋lataseΦt.\\n\\nʯParÖaǃȂmHeʲͬtersĎ\\n9-Ȼ-ƥğ-ͬͧɹǇå˧----͊-ȼ-ǆD\\x7f-\\ndfĲ:\\n  ʵ ȦŨ Údaɼtŏ˯âafƄra˻meɃ̇ wƭʌith dɜaέt́ȅɘaŭȿĆΚƥ̻ŀ to Ǟƣtđra̋n̻sform.\\n\\nReturƓns\\n-˼---ăȐɕĊ---Ƃ\\nreĳͯsuόltπƐ:Ξ!e Ʌ\\x935pd.ȔȷDaʡtŋaǅfraʆřme\\x92\\n`͓Ƹ  ˘  ̙ȑȊtǶΪran1sȂfo¨rmeͯdɓ λϙϪdataˍGframe', 'segment'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['ƵShifĎtϊ ɷ˹valǠues ΤϲȾfoȘ͌r st´eũṲ̀psɛĶ_num¹ÉberÑ s̡tʵeps.'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Inveʰrse tƪransforɟm dat\\u0383Ʌaframe.\\n\\nParameters\\n---\\x7f-------\\n¿df:\\n    one segment dataframʴe\\n\\nReturns\\n-------\\npdε.DataFrame:\\n    \\x98given dataframe', 'InƜit ɀ=ɐ_OίnǘeβϲS̄eƼñŬũgmenǲtʸTɐΗrŻeȈnʧd\\x8fTĘranϤs˕Ŷǌforϐm˂.ʆ\\n\\nĒPϙaȧraϖṁe+tȓers\\n--ύŻ͆--------\\ni\\x80n_coluńϒʄmƈn:\\nͬŔ̵    ɸna̜<me of PcoˏlňuƱmn ū̀/toɄ applJy traƻnɣséfͮorm toƜǻ\\noƨutɣ_ˌȕcolumn:uͰ\\n   ǳ ͱnεaʍmǠʤɝ;·e ƨÈof a˸d\\x82Dded c5oɺŬl¬ƽumTŸnή´Ɯ̲\\ncΜ̀hȧǃΝnŧge_ɐpͿoinɩt2_&m+odʶȡņBeɌǠùǼl:ͪ\\nņȭ  Ńϰ  ͓ŤmͤAȂøodeȫlƊ ǝtoĘl gɿĥΫetȍă ʆɍțÓƯĭàŤtrǶeǧnʪȐNdƓŷ Ū\\u0380ch͆îʙa̿ţηnge į¶ʓpƼ̷̡ʒoi͙ˡnts\\ndλeǬ:trenάĿdë_model:Ͳ\\nώɪ    modeϨͰǫȉȲlŎ% toĠ ̮get \\x85ʿ̊˅ĺtrend fr-ŻÃoˢƵyĈ^m łňdaͷta\\nchƼ̀aɐn}cg\\x9dɪʓeϭŤȩȰÂ˿_V̬pʌȅo®įint̑_mqodel_prΧedǙictΕĹ_paraƫȭmɶƚ͘s˩:͠\\nŴT¹ έ\\x83ʸ   pʾarža÷mÝsɅ\\x84ˁʥ for ``˫¼¤chnʹanǭge_ƷpointƟ_ȤāmȦodǣe̶l.Ĉüίp}ϧ;ͻ˰̑re|ʠdicǷt`ɮˍ¾`A mƢ͖eιĐthǨoëdbɫǏˉ', 'TrendTransformɽ adds trend as a feature.\\n\\nTúrendTransf-^orm uses uses :py:class:`ruptures.deteɘction.Binseg` model a˩s a changρe point detection model\\nin _TrendTranͲsforəm.\\n\\nWaƝrning\\n--˳-----\\nThis transfo̰Ǻrm can suffer from look-aheaΆʲd bias. ϗFor transforming data at some timestamp\\nit uʄsͣes information from the© whUɉole train part.', 'ar', 'Inæi˻tʶ TreènǋdTran̈́Ɍsʑf͝oîrȢm.\\n\\n:ǁParameOtϤe̽rs\\nͪ----˰ǋǑí-----ǟ-\\ninłǰ_ʱƍŵcolumƘn:˟\\nǒŮ    ɜname oÞƿf ɪȱʹ̴ǹcoŻlumn̨ȥʺ tĒo0¹\\x98 applyĩƿ trǶʤȺ˧aŻί6ɉnsform toώ\\noÍut_coluʎmn:\\n̂ď  ēƘ  ̊n˼ame ofľ aǸddȾed ƚcϲloʶ˃luGmn5.ţ\\n¹  ͨϚ ɇ ZIˤf not Ĭgiv̥eñ,Ϡ ˺uŇ͡se ``Τ˨k̳yselfƶϖ.__rʀíʩ£eǞprȦϫ__ȡȲ(ˡˏȷ)``\\ndŢČ˫ĭe¨trɄ˞\"Ǘend_m]odϥ̐el:\\n    \\x95modĪeϸl ttɅˡΗɯo ¡gʡeȌĉt tre̞nd iōΡŐnϾ́ dΊata\\nmodel:\\n  \\u0380  ˛binsĝe˒gΒɅǿ ƫseȨgmüent mČȖoȚdel̒, [ϯ\"˚lū1\"˦, \"lȌƣ22ɹ\",ǖ ɝϳ͞\"rʔbYƭf\",.łǣɑ.Ģ.].¡ Not \\x9bus\"ǳeͤdˋ ifǝ \\'cʱuʂˊ˃stʸož͏ϖãŏm_ȌΘcost\\' ȣϲis ȪnoŝĞt N[ǝoɥn\\\\e.\\nʢcǊbu˴sƼtxoǆɣʘmƑ_coƅst:\\n ï   \\x92bȐ©insˍ̓e͵g cͱɉuϽƀsÔ̾toʯ˯ʁ̘mv ïɅƋcǊϻost functionȻ\\nǳmåɥi̙n̵_size:\\nŦ ̬   ȵǼdmŠinŏÿimʵumJ* sͮŜegýƠǟĦ\\x7fψmeúGnt̥ Ĩlen˒΄gtÍùʍωh ne˜̘cesπ¹saϝϡ¬ry \\x97tǢo dΝecide Ƌit i̋ȟsóͅ a{˩͚ sǜtabͨɫle̖ trήendŤʼ˧ seɼgmʹŷ¢ŊǠe8nt\\nj\\x8f¦um\\x89ϊpίĘσ:\\nñŔ   Ϗ˰ jɦumpċ vaɡlueȗʎ ̡caƍn sȇpe$eÝdėɼǹ½ ʿu»p űcom͛putatioǬ͆n̒ɺsû: if `ȡ`jumdȁphȌʭ==k`ȶĦ`,ˤ\\n0   ǁ͆ tđhĜτ˚e aͿlgoƜ wilŋ¤l uύˢfseƎ̻ ŔeveΣɽry ͇ʚk-th vǎ͗alŻuǲʬǟe ʫǞǖfor ƥŖḬ̌ʝch˞anʇϞgσe poȃȱi΄͐nːts seĻarch.;\\nĦĹϖnÖĝǏ˿#_Äbkps:\\nˁ   ̦ˢǂ n̮̈umber˻ of̾Jʎ̠ cȃȠhaǒ¦nºg˽e ǯǤüǫž\\x9e̒points txo ̛fiŏnÙd{̾\\npʁeɛn:ŬŤϙϕ\\n    ĮpeĬnøRaͦlƩtˁɌyɑή ͘valueƔ ʒ.(͐>0ͺ)Ê\\nˍ\\x96epdsḭlonk:\\n-  Κ  rũeconsͬtrSȂuϖcψ˾ti\\x9eo{Ġn Ɂbudgeɑtˮ (ǐ̃ƕĖ̯\\u0382¿̞>ɿ0)ť'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <7x7 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['1', '2', '2021-01-11', '2021-01-09', '2021-01-27', 'segment_0', 'segment_1', 'Ƌ  \\x9f', 'x, y, expected', '  ', '    ', '1', '2', 'ʅCheɬͶcȋk that ˽o˻ηutlơiɢer˿s in on˩ĩe Ɖs̅erɫƔies computaϕ[tǧiΡonͮ \\x94wor\\x81kņs coǪrrectßlyp̃.ʃ', 'window_size,n_neighbors,distance_threshold,expected', '   ͵  ˯  Ƚ   Uˑͮ', 'feature', '1', '2', '2021-01-08', '2021-01-26'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <13x13 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 13 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['feature', 'exclude, expected_columns', 'target', 'exog_1', 'exog_2', 'target', 'exog_1', 'exog_2', 'exog_1', 'exog_2', 'target', 'target', 'exog_1', 'exog_2', 'exog_1', 'exog_2', 'feature', 'return_features', 'columns, saved_columns', 'target', 'exog_1', 'exog_2', 'target', 'exog_1', 'exog_2', 'exog_1', 'exog_2', 'target', 'target', 'exog_1', 'exog_2', 'ſT˩ˀĠeRsϓt tʡhaɍt ȃtranMsτfo±ήϱòqͫrm ȥϊŷis̶̉Üˡ noĂt\\xad +cr»e\\x9eɷǢaϧ˩\\x9cũtʿedɇǢ witǄ\\x9bhƚ inΦcêȚlʉuìǱde\\x93 ʜˮand eǮžxcĐlĹudę̯.ɜ', 'There should be exactly one option set: include or exclude', 'exog_1', 'exog_2', 'There should be exactly one option set: include or exclude', 'Test that transform remains only features in include.', 'feature', 'include', 'target', 'exog_1', 'exog_1', 'exog_2', 'target', 'Test˃ that transform raises error with non-existeʙnt column in exclłude.', 'non-existent-column', 'Features {.*} are not present in the dataset', 'Tψeθsϵt thaėtʰ ƴtransfčâorƑmČ raises error with nǮon-ŧȯexistent̕ colūumn inǉϋ¦ ʢƞinclªud\\x88eș¸.', 'non-existent-column', 'Features {.*} are not present in the dataset', '2020-01-01', 'D', 'timestamp', 'segment', 'target', 'segment_1', 'timestamp', 'segment', 'target', 'segment_2', 'timestamp', 'segment', 'exog_1', 'exog_2', 'segment_1', 'timestamp', 'segment', 'exog_1', 'exog_2', 'segment_2', 'D', '  ̘ʫŨ     1 Ð \\x7f     ', 'feature', 'return_features', 'columns, saved_columns', 'target', 'target', 'exog_1', 'exog_2', 'exog_1', 'exog_2', 'target', 'exog_1', 'exog_2', 'target', 'exog_1', 'exog_2', 'exog_1', 'exog_2', ' ʔ    ɜ Ɲ  ', 'feature', 'columns, return_features, expected_columns', 'exog_1', 'target', 'exog_2', 'target', 'exog_1', 'exog_2', 'target', 'exog_1', 'target', 'exog_2', 'target', 'exog_2', 'exog_1', 'exog_1', 'exog_2', 'exog_1', 'target', 'exog_2', 'exog_1', 'exog_2', 'target', 'target', 'exog_1', 'exog_2', 'exog_1', 'target', 'exog_2', 'target', 'exog_1', 'exog_2', '   Ļ  ', 'feature', 'columns, return_features, expected_columns', 'exog_1', 'target', 'exog_2', 'target', 'exog_1', 'target', 'exog_2', 'target', 'target', 'exog_1', 'exog_2', 'exog_1', 'target', 'exog_2', 'exog_1', 'exog_2', 'exog_1', 'exog_2', 'target', 'exog_1', 'exog_2', 'exog_1', 'target', 'exog_2', 'target', 'exog_1', 'exog_2', 'exog_1', 'target', 'exog_2'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['ëStaǅnǱdar͂ρdize fe&atuϬresΑ˥ ̕by țremoȜɜvĤͳiΆng͌ th:Ǝe VðƆͮmeanŭʗ a\\x9cnd scʇǢūaΖlŏing tǅo ϔuniΣt ɷva˔rηiʱʷaɵʃncέ.e.ϓʃ\\n     \\n\\nUses í:py:ƮclĘassŠ:Íϛ`DskΕ̙leaħǷrn.tpëreproceǾƾsͶȅǧsingōˁ,.ȒͮStanda:½rêdScale`Ïr` inΒsÝide.\\n        \\n\\n\\nŞWaŉɴƫrniơ@ng\\n---Ǿ-ʐ-i--\\nThiǴs Ǎ̽tr͘ansforͩmȵ˟˱ ȈcϓȣΜan s͜Iuf/fer Ȱ̮ˋfŬρĀrϴoçǐmϠ Νȣlo̎əoÇκk-ah\\x9b˻Ȃe˾ad5ȣǝΦ bias.ė For tŚranδʷsforming̓Ȓʥ̭Ω Ģd¾ata ɑat shomeˇ̤é tƦimesʓt1Ίǰaϫmpϗ¬ȭǟ\\nǆit .Ȅuseus inf\\u0382oƖrɥmƗ˟̺atË͋iɎáƢo̘n from tdhƬ\\u038bˈeʔʦ ʉwƅhoƜle trǭaƴƽinϥ~Ɏ ̩pŋɟaƶrt.̀', 'per-segment', 'ŖTraʖnɰsform featurΝùes by scali˅ngʃ eachƯ JfeatureʺA» to a givϙen raōnge.\\nǫ\\nUses :py:class϶:`ȣsk4leŃarn.˼preprocessin̘g˖.MȴinśMa<ʽx͒Scaler` insiȤde.\\n     \\nƥ\\n     \\n        \\nWŪǋŠar˄ni\\x8bng\\n-----Ń--\\nTȢhiɀs˽ transɫf\\\\orm can suffeϦrˉ from: ̜lŚookĒ-ah(ȫead biÎas.`dǴ For ϠŠtÕransfor̔miί̂nƱgT ɹdata a]t ǛsomΠeƘ ltƢimestam§ΐp\\niĮtŊ uses informat=iƈoʏn fro͢m thɱe whoʔɫl\\x96e traEin ̹partȉ.G©', 'per-segment', 'ɒInit MȮinMaŸxɍπSϿcaɐølerPˍrϽǖepοÓrocess.\\nä\\nϸP̳ýa[rametersƴ\\nϩ-ͣɝ-̕Ɖ!-----Ɩ---\\nǤin_cȑolĂǗuɉm͕\\x86n:\\nϑŭʕ        colƕzumns ̊to ʄbe s¿caûÐled, if NĿone - all ̀ǯc̒\\x97Φʽ̟)olumns wilȞl Əʀbeɬ ̡yƪscaled.\\nin>pLŐlace:\\n ̻     feaĊ˺tupˢres are \\u0383ch\\x9b˩aʠngedɐ b͌Φy Ès\\x85̿Bɓcaʅled.ʭ\\nou͟tɊ_ϺcɲoϾʱϛl̼umϣn:\\n~ ʗ    \\x8bγˤ ̔Ϛʅbase forŬͻ tȁhe names oɢfͪ ǽgȧenerʎÙƝated cƁolu\\x96ȝmn̬ñs, uȶůsesȒ ²``sǔelfʼ.~ύ_˯_ėreċpr__(ɇ)`ɑÁ˒`λ ɟif nЀoÎt͛ë̑ \\x86gØiĳv̕en.\\nfeatur͈eʘ_ran͞ge:Ǽ\\n    #wRlUvZKd\\n \\n         \\n        deϞsired rAang÷eɁƨ ˔oof transfýorm<ed dataʎ.\\nclip:\\n         \\n\\n     \\n\\n ΨÁ͐υϿ     ǉs˓eƔtĭ Ϯtήo TruϦÚe¡ to clip\\x91˷Ϝ traʩnsformeǨd vϓal˒σuȢes oħfǻ heldľ-ƪout d|̟ata \\x9fLtˉío prɓˠovidĴedˆƋƼ üfèeaϜΖtʕuɸre rϷangeˈ.\\n̏ĢmʨoȀ̢8œde\\x95͎:\\n\\n     E ̕\"ȋmåcro\"ʄĳ μo̳rħ \"ɇpĆǈerü-sΜegmentϭ\", wa̋y to trϊans̩formʭ featurɉes Μovǒer segÏments.#KnsfGepTrNMPA\\n\\n    ˮ    * ΡIſf \"maʇc̊ϲɸÕ&¾ro\",ϼ Ƃtras̏˓ζβɻns˩/forĤmis feưaĶt3urefΖsȋ glëoɵböallyȵƎ,ʖƀ gluing ˛the cŞorresponding͈ one̙:s forͣ a̯lƟyl segmentŁΥs.\\n\\n     \\n        B* If \"pʜ͊er-segƒment\"͚, t]rZaΫƢnsforms ιfeDatures foro each \\x90s̫̔egmά̜ent sepƥ̀aĻrate̢ly.ƬϣϱΊ\\n\\n\\nRaisǨesz\\n        \\n--˝----\\nValue˿ŀEɅrrǚoźǨrŊ:ū\\n\"        if ¨Ȗinϑco̙̫FrŁreƶƻct mņoodȊe giϜvʡen', 'per-segment', '̙ScaΜȩle eŕͣaȌch featuȟƇreĨ by its maximum absoluteɛŝŁ v̈alueϬ̧.\\n     \\n\\n         \\n\\nUseȴs Ƶ:py:clĮasš\\u038d:ȕ`skɑ\\u0382learn.prȵepǣrocessing.MaxAbsScaleϼr` i§nside.\\n\\nWarning\\n-------\\n\\nThisŜ transform can sufοferǈ fromǠ@ loÒok-ahead bias. For transforming data at Êsome tim˨esź]tamp\\n#jJrsCYzxMwAVuibDpW\\nit uses inforŕmationɶ from the ϣwhţoleψ ƾtrain part.', 'per-segment', 'Ionȅit M³inMŤaxSß²̟˺ɬcalerPr̯\\x8cepͰȋrǵ(ocϵess.Í\\n\\nPar6Ʀȏameteɿrs\\n----------ΩÛ\\niΗn_columʽn:\\n     ɒ cȎolumns Ⱥʉto bɵŅeS scʜaledŔ, ifʑƃɫ NŐϕo\\x8cneĞ -ŷ ʲall cɛolumns ɯwill þbe scaledƸ.\\ninplace:Á\\n\"     ɯ ϒȟfǛeaturȕes arΐe cVhaɖĿnged by sc\\u0382aʅĭȚǮūl̾˜˾eʴdŲ.\\n \\n̈ʕoŝut̗͒˂_column:ːƶ\\n    ǖ    base for ŗthe names of ˵gen\\u038dČerateȯd ǁcolumnˬs, uͿseǁs ``sǢ͒elf˹.̕__repr__()`` Ųif˾ not giveìn.Ȫ\\n¿mode:\\n\\n         \\n    γ    \"macro\" or ͧ\"per-Ɠsegment\"·͠, wʸay to ítranųs\\x96ΡforÃm ɨfe¯aPturǳes ov̤ǎeÕr segmΒenütsȀ.ʢ\\nǰ\\n        \\n \\n    ʘ{    İ*Á If \"macr(ȘoǺİŝ\"ȩͷ, ítr&ƕansfͷoɿrmsϛ feaͮιțtºures̞ globallyf, gƑluinɌg tȮheɌ cŬorrR̙espondinźgϖ˽ oñnes for aF̔ʤl˿l segm/͈Şents.\\n\\nħ     Ν * $Ǩ˔ăIf \"peʸr͓-seŨϳgmɴen̵̊ĠŨt\", transʵform:s feat\\x98uΪrȪ)eƠs̑ ɊfoΗr eaʔkcPhǊ s˅egment separatȶelyɷX.\\n\\n    \\nRL1aiáses¸ư\\n------\\nValueϨError:\\n     \\n        ifƺ in¯̠cpo&rreȃcet mode ʧgiven', 'MaxAbsScalerTransform', 'MinMaxScalerTransform', 'RobustScalerTransform', 'StandardScalerTransform'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <19x16 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 19 stored elements in Compressed Sparse Row format>, 'ClassDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['CORL', 'DT-D4RL', 'DT', 'halfcheetah-medium-v2', 'cuda', ' ŤO       ǩ   Ä̖  ', '-', '-', '  ͦ', 'PYTHONHASHSEED', 'project', 'group', 'name', '  ø̗Ł ˈ ć ˕ ª  æ', 'Checkpoints path: ', 'config.yaml', 'w', 'Total parameters: ', 'Training', 'none', 'train_loss', 'learning_rate', 'Evaluation', 'eval/', '_return_mean', 'eval/', '_return_std', 'eval/', '_normalized_score_mean', 'eval/', '_normalized_score_std', 'model_state', 'state_mean', 'state_std', 'dt_checkpoint.pt', 'constant', \" ˷͝ e˶' ȫʂ       5    ϧo ʆɕ \\x91\\\\ʼ    \\x9a˧\", 'rewards', 'Processing trajectories', 'observations', 'observations', 'actions', 'actions', 'rewards', 'rewards', 'terminals', 'timeouts', 'returns', 'rewards', 'obs_mean', 'obs_std', 'traj_lens', 'observations', 'observations', '           ͉ͬ    k̏ˈ', '   Ÿĩ  ơ ɻ  Ɂ ', '         ', 'rewards', 'obs_mean', 'obs_std', 'traj_lens', 'traj_lens', '  Ƅ  ˑƑ  ƍ', 'observations', 'actions', 'returns', ' ʵ ɥz έ  š \\x83 ź ³D̄     ͤ ʯ˗  ̰ ϧɲʣ  ĵ Ǡ', ' ȏ  Į ƖƤǭ    ű   Ǧ   ©  ÁʠΔ', '     Đ \\x80Ĭ   Ĳ̬ ', '      ɫ       áÑ', 'n!   ͫĸ  ̱ Ŀχȑ   \\x92   ', ' ŗ       ˍ    ĤṴ̈̌   \\u0381  X Ŝ', '    ǚ ì       ', 'cpu', '        ȢΨ  ĖĊ  ÓŠǡ Ţ\\x9b   Ÿ    ͖', ' ȵώɸ̧İ  ˊĽ    ', 'causal_mask', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <3x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['T', 'Calǂl ¶gϮ̈Ο̶ivQeͫɠn ``fşunϱ\\u0379c`` [wiŷtʖáh `˥`˶*a͗rg®s`` ͚and\\u0381 \\xa0ί̉`ťι`Ñ÷**^kwZargs``ʒʲȲ.', 'ParͶal¬lŖ͆ÎǿɁƞe̱lLo˒ƚπŊΛûcͩalRuÇǘnøn$f̛eţrƄ\\x8f for\\u038b mͯPulť̬ĝtɾiȭpǨϫleʜ pɊa[³*rǣalΧʭ̭ʭle˾\\x88lɆĬ r\\x82ͬunsÓ˶ ʺwìΰithɜ júȉo\\x85Θħblɧib.\\n\\nNˀǻotes\\n-Ȋ\\'-ə-8Ϥ̇--ÛȷȂ\\nGǎ˚ʶȢlobalΛ ǙɖƴobƙjeĽ˙ƦØcts beΨhavŸiϼɸĆorŇƖ ǂcě϶ͧČoÉu\\x82lǯÃd bƉƾe dòǚͧiff\\x91CeʙrḙnƜWt wÜƚ§hiɅle paǝìralleƿl \\x84u±sͯaĆK¤«ʟge Űbešc͎͂aȐŒuçsďe platɮf˽ˀȑ̠oɜȍrƓămȪ; deǩpendɫeən͎tH ǥnew̽Ȫ Ŗp\\x88rPoΞceſƲsˀs \\x82W2stŨaʉǲrt.ƻÍ\\n͚Be̞ ¨s˗Ǫurȡ¨e #χtÃh͑atȶƾ new p>\\u0383ɂroµÃceŪss ʶis sʇŹt\\x9farŷʂteϚRd 6¯ùƤw¯Ÿi̐*7t\\x87h ΐ``foˉrkūō`` vɜiaʔ ͟ɢ`Ͼ`muAl_téipǕ¸ʼrέo͓ŖceÊssįng.set_ÄÚstaęrȅϩ͟t_m̸ΌFetϢɑưho̐Ĳò@d``\\x9b.ϡ\\nIf it\\'s\\u038b notØɉ Ρϴɦϸpo\\x9aƂssʄiʮbleϞ ¥Ǭyou ƵshoéȸuΔοɞ̩Ƒķ\\x9fνld ȢtryΫ ě̍ηdɕe\\'Ȉfine ǿaƁlˏˆ\\x9clȕ globφƘçalÖͭs½ĂɵŷΘ ΘbəƜeforņe ``ƣʏ̼ifÞ _*_naƬmέe__ư == \"__ma˗̐̚inƮ_\\x99_Íª\"ʹ`̩`ª\\x83 sɽcήopeΈ˳.', 'Cƍall gìven ``˂func``γ with JoɰɼbȅÞɤlib and `í`*args`Ʊ` and `ɫ`**kwargsĿ``D.', 'multiprocessing', 'c', 'In¢it ǯPĀarallelLɦocalRunne\\x82rϟ.\\n\\nPǇ\\x8fêaȨârameters\\nʪZ-¬---ɚ--¸----ˁǲ\\nn_jobsƾ:\\n Ȯ   numberǷ of ɔpaüƞralƩlel jobΧs t·oķưȘ uṡ\\x8ae\\n͢backend:\\n  Û χ jobϥlib backend to use\\nmm\\x95aɿpϩ_\\x90mod~e:\\nψ  ¸ ȫ joblib mmap modʩeŎ\\njo\\x82bliḅ_ǃparʇams:\\nϑʦı    jobliʼb add%itionǬ̻al params'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <9x9 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 9 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': [\"VerǍifiΗȉcaÓtion Ħdatʽasϫe±Ěʦάʜϩt͉à \\x90μba͞ŏ̽sî΅eɋd̂ ̜onϸ dat˭˚asȦetœϑ witΞʒh lƌabeols.\\nÊ\\nAĹɃrφgs:\\n    ȰɌdatɡϯasɤϳ˫etēͼ: C̶Ɉlas·\\xadΌVsifḭƏĉÍ0atƂioȉnöǧ dȧtaɔsƲͅet Što ˡss´ǟa#̔mpl̥e paͦirs ŇuʪS͎\\x94fɳro̖ͣK_m.īǧ\\n \\x9d   ʆsìzɘ˅ʲe_facĬ˃toϡɥr:ɕʩ̠\\x8a TĿhe nu̺ʾmΔber ɔoʉf ūpŪai˫ɘrs iͰ'nϞ̋ Çjv͏Ǟeįrif>ǜƗicīŘaƽtioǔ\\x90n daΔta[ύset ʽiϧs\\n  Ͼ Ė ˍ  ǹǙŅË Ϯ ƒΑ`2ħˬ * NȌ Ž*ŀ ɲɿsizeÎ_̜ŋfacˍ˵toɀrƗ`,πɰ ͜wǮȡhqere N is\\x96 tɡšhȨˇe̔͏ Ó̍num˼b͜e΅¸ÏŰƑr oϜfʩ iǐ͕mageʄâs.\\n Τ   ʮƪQǁLse͡ed: R̖anŉdǫom seedɡΗ.\\x8cñ\", 'Sampleƭ pairs of samples Ĳwƕith theņ s˞aÖme label.\\n\\nOutput ȅnumber͚ oϫf pśairȰs iÂs \\x9clen(labels) * \\x8csize_factor.', 'Get$ $datøɜ\\x9faâsetȉ ĂϽäɱlaÐbelgsɗ arraoyŰ.\\x95Ʊ\\né\\nLaƹbe˦˙lsû ačê̦ƗΗrḛȘ 0/1ƥÖ iȀnŨteʆgeƩr7˭s.', 'GͲët elemenʒt oͷf tÖheĦ dǭataXset.Ǵ\\n\\nϫReturȵns ((image1, iśmage2)ν,VΦ labeȧl).Ű', 'Whet\\x82hʿɐe+ʌr daȬˤϝɚľtɘa\\x95seϗt ɮɕis cl^assiţf]icatioϷn \\u0382ġoČr͛ ver̕Qificåa\\x88ĕ\\x89tĺionʇɎ.', '\\x82WhƯȋeǞthɄer dwʅatasű9šǤeɍ˻Ɵt aŘˎssignĝs ̥qʛuaūlity scͫoýrÔe µ͒ÁtǶoăȸ e͝#a̢:c˂hȏ ©sȷƏampŘl˸eǝ ˞o̠ȭrΚ  notƔ.Ġ', 'SO¥Ʒşamȯʩple ˬǁpώ̻ùųaMirǥĬs wi«ͣŽtˏh ƿÕdi͓Ϸ¹ffeͳrØŒent labeɭlȖs˒.Æ\\nʒ\\nOutp`ut n̳umĤƕber\\x81\\x81 ΙXɃoϙfǊʕ͛ ͣpʤλɑ̅aǝƕiĖ[ͪrȑs ƌis leƺn(Ϯ;lɼΏaWb÷ɗĄϒelǝs̖ǜ)Ǘ * ʶsβϰƂizĹȗƣ˟e_œfa͓Ţctobrĵ.Ƿ'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <7x7 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['Ę   ', 'ȡ         ', 'segment', 'timestamp', 'target', '1/1/2018', 'segment', 'timestamp', 'target', '1/1/2018', 'D', ' >   ͽ  ', 'use_box_cox', 'box_cox_bounds', 'use_trend', 'use_damped_trend', 'seasonal_periods', 'use_arma_errors', 'show_warnings', 'n_jobs', 'multiprocessing_start_method', 'context', 'use_box_cox = None, ', 'box_cox_bounds = None, ', 'use_trend = None, ', 'use_damped_trend = None, ', 'seasonal_periods = None, ', 'use_arma_errors = None, ', 'show_warnings = None, ', 'n_jobs = None, ', 'multiprocessing_start_method = None, ', 'context = None', '(', ', )', 'model_class, model_class_repr', 'TBATSModel', 'BATSModel', ' ξïø  ', 'model is not fitted!', 'model', 'macro', 'model', '1d', 'target', 'model', 'target_0.025', 'target_0.975', 'target', 'target_0.975', 'target_0.025', 'model'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['  ', ' Μ ȴ u', 'is_first', 'moving_norm'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['TSDataset', 'target', 'timestamp'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <16x16 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 16 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['regressor_holidays', 'expected_regressors', 'regressor_holidays', '2020-01-01', '2020-01-01', 'target', 'regressor_a', 'D', 'segment', 'segment_1', 'segment', 'segment_2', ' Ǻɸ    ̙', 'timestamp', '2020-01-08 22:15', '2020-01-10', 'H', 'target', 'timestamp', '     Ģ ʈ̈́ů    ʌ Ė             ', 'segment', 'segment_1', 'segment', 'segment_2', '     Ǖ    ˂    ; ģ ǲƐ    l    ʧ\\x8e ̧', 'timestamp', '2020-11-25 22:30', '2020-11-26 02:15', '15MIN', 'target', 'timestamp', ' ː ʧ    ', 'regressor_holidays', 'segment', 'regressor_holidays', 'regressor_holidays', 'category', 'ä        ȿ˳ ϛ    ¿         LO ¤ Ί Ʌ', 'holiday', 'holiday', 'segment', 'regressor_holidays', 'segment', 'regressor_holidays', 'iso_code,answer', 'RUS', 'US', '        ϺȖΚ    ɥ ƨ', 'regressor_holidays', 'segment', 'regressor_holidays', 'iso_code,answer', 'RUS', 'US', 'regressor_holidays', 'segment', 'regressor_holidays', 'regressor_holidays', 'category', 'regressor_holidays', 'segment', 'regressor_holidays', 'iso_code,answer', 'RUS', 'US', 'regressor_holidays', 'segment', 'regressor_holidays', 'regressor_holidays', 'category', 'timestamp', '2020-01-01', '2020-01-15', 'D', 'target', 'timestamp', '    Š Ǩ ̋Ť    ˪ʤǦϼɂ     ʣĞ     ɫ ', 'Frequency of data should be no more than daily.', 'index', '2020-11-25 22:30', '2020-12-11', '1D 15MIN', '2019-11-25', '2021-02-25', 'M', 'segment', 'segment_1', 'segment', 'segment_2'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': ['W'], 'AsyncFunctionDef': [], 'String': ['.jpg', '.jpeg', '.png', '.JPEG', ' ʨΒ   ̋     tÅ    Ŵ ǝ   Φ̈́', 'Scale dataset images', 'src', 'Images root', 'dst', 'Target root', '--center-crop', 'Crop output images to center', 'store_true', '--size', 'Size of the minimal side or coma-separated width and height', '--num-workers', 'Number of workers', ' ʷ ', ',', ',', ' ˌ  å̋', '*', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <9x9 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 9 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Weigh̐tæs&BÇiěƙaEʲses logge²rϴ.', '', 'utf8', '=\\n', 'PLWandbLogger', \"St£art expȃͳerimeơŇnt.\\n    \\n\\nCˢompletȽe log#gƶer̢ iĜniʋˁtÆialʢƬizaĴtion or reiniÚνʃtεi\\u0381θʓaϦlɁɄʛÁize it before the ɩnext expjˊeriǼm͗ênt wiƌthρƟ the û¦same name.\\n   \\n\\nϏP araˮÚmeteďràθϬsß\\n---Ĩ-˼---ȯɷ-͡/Ðɴ-ɥ-\\n  #mwsvcixXAekph\\n   \\nŤjo\\u0382b_type:\\n    ϱ͆SϪp̫ec͵ʓifyǁ tȒhe tyɣpe ʢofĎ Ǫrun,˂ whNich oisϐ usɦefulʖ whenì yȏʤuɴ're ϱgroʄuôping ƪruns 5togeSŶΓˠtýher\\n #MBbgRXdmYIjV\\n \\n  ʏ  intoǳ larǹgǛer e̐xǮperɘimĐɝeĬnts using ɮgÀrou\\x80p.Ϧ#AYWkSwGc\\nˆɗgroup:\\n ý ı  SpŌϴƓecƬȴifyɋ \\\\a ͊gϝroŤup Ηto ̬organϣizre ̓indivă̂idual λȎƯruns Ʌiɔnto a ḻarÏger Le}xpe\\x96rimentǀɢ.ʈ\", 'TSDataset', 'W\\\\rịtŖ&źąz͇ɏűŒe\\u0383Ϳžϫ ͣȏmetkriʬ̽csƽŊ̍ί ƢtˈǓo Ν1Ml;oǍgˇgeˌr.\\n\\n \\nǄϩParƀameteɯr\\u038bsĩ\\nƕͥw-ǅ-ψ---̀-Ĉ----\\nɣ9ɿ*tˍs\\x9cÛ:\\u038d\\n ȶ\\x81 Äά  TSDůˉatɃas˘Ϋe˾Ϲt tĹo wi1tɑ̂h b϶Bƚa˒cͼktestΆːǪȱΊɼ daȳʵ̼tͳΟ`ǚƽa\\nBmeʎϋɢǭʓtˋrics_df:\\n \\n Ϩ ¤Ƃö ʽ ̒ϤDaΓtʍ\\x83a(̹fraȴm¿će3ɬ {\\x80șʹpro\\x89du¯ced̛Ɇ κQwʱit͙̓hϚ :Ėˤp͂ʃy$:ʫmet̅˧Ȋ2h:`eʍɽƙȍtśʟ=nˀa.ɤpŃiÊͿp,ielin˷e?\\x92.PipόeûlƑiϚ̋nñɲŬͯeŶɶɁ.Ϝ_gϠeǓt_bUackteЀsͯtϔ_Āř\\xadmΡeÙ˓ʛ\\u0383triȁcƲøs`\\n\\n8ƱforecasŁt_\\x99dƬɉf:\\n  H  FoΨrΰecφǎast f̝romʮ ȌƎƑ̄baʩ˶cQ[ʟʌḱtΪegs¥tlŋ\\n\\u0380fold_ĚǗdinfo_̇dfX:\\n  \\nŅ Ć ˯  ̝Fol̼Ģd b¦iǮnforΝͦmaǷäǱtƻiΠǴʑonɦɿ from¥ bȖǆacʬktȺ̝eʋƉǦst', 'metrics', 'forecast', 'fold_info', 'backtest', 'segment', 'metrics', 'forecast', 'test', 'thread', 'I˔nͳi\\x86tĔ exȐp͖eȥϪrim\\x90˘enͣtƷ.ɞ'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['examples', 'mape,hist', '   ƨ  ƞ ĞƲı͌  ', 'r', 'source', 'cells', 'w', '\\n', 'poetry run codespell -L ', ' ', '*.ipynb', 'Skipping ', 'Running ', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['ClǮ͖aȯϾssŏˀĿ͙ h»olɮ¦ϱΛdingǭƸ®ýȯ pϕer©ˆ seȗΡŵΦgmĤent :ŕpyu:cÒϤlɔaǩsƔΤɭs:`Ð\\x8ȧsklōeačrΜn.line\\x89ʃǕar˦Ƶ_H«ʸgmodΧ³el..Li˝neŁ©arϤƇūReg\\u0378ƅres\\x8bɗsion`.ėσŹɿȦǪʤ͖}Ų£', 'Cƣreate instance of ElasɂtiɼəčcNe̡ta with«ʶ givĴen pač\\u0378\\x94raÜme̍teͣrʂs.\\n\\nParȹamet˛ers\\n\\x9c--------̍--\\nalpha:\\n ˺ Ħ  ÛConstant tha\\x9eŔt multiplçieȔs˲ thHĒe Ɣpenaltʺy Ĕterȶms. Defauʄͳlts͉ tΪno 1.0.˳\\n  ƞ  ͔``alpha ˈ= 0`` isϞ equivalentˀ¶ Ót\\x92oΑ ǹan ordinary ƅleȧȇstĔ sĵq\\x81uare̠, solved bĤϬŋy tΔ͘he LineaξÏrReϩgr)eʊˁĿssion Úobjeͭct.\\n @   FơŔr̖ numer͑ical reasons, using X``alp̠ha = ʒ0`` with th̵eΌȆ Lasso ˿objecĂt ̶is nļot advi̪sedͼκ.\\n ̥   GΧƫiven £this̋, yόou shİould Ģʇ̋ˊuse œthϩe :py:cȨlasʯsγƤ:`~ɓe\"ʄtna.m`ǫodels.liͬneɨarˌ.ŅLŎineÉ£*arͲ͠Per]SegmentMo\\x9edeđlť` ƿoʓbject̏.ƿ\\nl1_r\\u0383a̬tio:Ķ\\n    ThđĴe ElasltŧicNet˖ mixiφnʕg parameterȿ,\\u0381 with `ų`0 <ũ= 8l1_raʩtƂio <= Ȁ1``.̦̅\\n\\n  å  * For `Κ`̚lɺ1_raΨ˷tþio = 0``\\x92˙ t͊he penbalƫty is aʩNn L2 pΖena͔Κlty̟.\\n\\n    * Fo͂˳ɷr ``lʒāɲ1_rɭÌțÞ¹atio = 1`\\u0383` it is an L1 penalty.õ\\n\\n  ƈ  ś* ĝFor ``0 < l1_ratio < 1`\\x92`, the penǅalty iĐs a cΆombinŇatÏʫioǞn of ˆϔL1Ë andʙ Lʕ2.\\n\\nʙfƧit_in͵tϝercept:\\n    ëWhetheȳǿr to\\x80¬ caʠlƓculate the interc¡ept for ɕthis mˏodel.˳ If̺ )set to ͓False, no i˹ͨκnterƦcept wŜi\\xa0͎ll be ɜused i˂n\\nǶ ŐĜ   calculations (iʻ.e. data ƥis Ōexpected to be cen̵teredů)Ÿ.', '̙ĥŽCla˷ss ʵhoΫƦldi̓ngª :ǝpy:clΰʃasΦs:`ɋΰsƺkɇπÄ\\x90̕lɲeaǶSʜ/rn.lĆinear_modɢel.įEǎƱlȪɐƢìaĂsticNet` for all ΊsegmąenƵŨtsΪ.', 'Class ƙψɐhΟold͞ing ʹ:\\x93py:ÿclass:`skle(arn.line͉arķ_modȐeĴl.LineaírŷRegřreÒssi\\x7fon` Άfoϋr all segȘΦme͙nʗtcs.'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <9x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 9 stored elements in Compressed Sparse Row format>, 'ClassDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Silent', ' ϖ   ', 'timestamp', 'target', '˸  ͋  `ǻ ͘Ś \\u0381   Ŵ', 'category', 'timestamp', 'target', 'target', 'category', '_CatBoostAdapter', 'CǦϥla˼ssú ˧fūoÒrƔ hoXldin̫g p\\x94er segmͯe|˂nt Cwatb˳woƿo΄sˁtϾ Ιmodʴelĥ.\\x8f\\n\\nǵ~Examp˕͇lesɖ\\n----Ô-ů---̀ξ\\n>>> fromƜŵH e͞tna.d7ata]ňŨseϛʨtSsʃƜâý ̖imϞƈp̓o̧˂\\x81rtȣ ó¢Mgenerateǚ_per͵iodiͩŪc͋Ŵ_ϵdfʮ϶LÚ\\nΏʭ>>> from et´nÞ\\x99˴a.dΧaÊtasκeƪts immport£ TS̑DaĨÿϼtaʈset\\n>>> fˡ˕froΖ¢m ǂe̘\\x9d\\x92tnaĪȝžˋ.Ģmoǆ˗dŴeʷls}Ś impÅo˺ƇrËt ͢ȔTƗÒCòΝ£atBoostʿƑΎPeʄrʒSegpm̙ɭeɳΊΨε˙n¹tMo´del\\n>>ǆǴȗ> from Ħetna.ĜtrɾaċnͭsforʈmƄį˶s ʟim͞ˌɖpoÓrt˻ LÄϔˠka˪gTraȣΊΥnτsf˾ˆơo͈rmě\\n>\\x8e>>ïΫ Ťclassic_dfˑ ˟= gͺeŠnΧĳǿeôratƞe_periodiũˤc_df(\\nŶȿ...  ϣ\\x97   ǶperioʊdϺ2Ǥs=100,\\n...    ΐ sta̬Ȼrt_Ȇtim̀e=ƙ\"20290-01-01\"΅,\\n..H.   ȶ  nːΘ_sƒe̥gmeaÞ,n̸ts=4,ţ\\n...Ə Ρș    peǂ͇ri¸od˿=7,ˊ\\n.̏ů.. ̆    sÊi΅gma=§Ώ3Ɲ\\nϿ...ª )\\n>>> dIǒɔf = T\\x85ȡSDč̪ϝ5đaɃtasetɳưW˄.to_datasetĜ(ΞdǶˏfφ=cla̰ssi͋Ec̊ȭȶi_df)×\\n>>> οtŉ\\x87sρ = ûŁTSȤʱDŵͱata͐set(d[fːy, fřÂeǌŶqʁ͕=C\"D\")ʴ\\n>>̊> hǀ®ɐorizÜòon = 7\\nɆ>>ʣ>Ɓ ·traǶnƂsfo¥rms˭ ŲʎǝΣÆǟ= [j\\n..Ǭ.ß6© ?ģ ïϊ ˂ ʶ ȑLagTr£ȌϯansfoXȋrm(in_c&\\x80ÕoƦlωƊumn=+ƚ\"tarÁgƶet̳ȫ\", ΒlʰˣόɄa\\x8ags=ǡ[0horizͭonʟ, horfĂi̥\\x84zon+1ͦ,ã horizQoƆn+ğ2])ø\\n.3.. ]ʔ\\nǗǵˬ>>>ϼ ɷÓ˃Ûts.ϗʂ˸fit_traΡns˄ϭfΔo͕Ōrm(ÚtransformŸ¾Ȗsς=Ót̀ransǢÐforms)\\n̟ə>>> fu͑ɮtu͇͑reʟφ =ʡ ts.Řđmaǖkeɹ_Ȇŵfuțǁt¼®ureˬ(hϩoǉr\\x81iǰzɄoˬƴƒın)\\n·>]>~\\u038b>ʩ moȂdɄel = ͂œC\\x82aƋtͲΒΟBoEost̎\\x9ePeĩáurȧSegmeʁn$ȈtModelɎł(¯)\\n>>> ǲδmodel.fiǏt(tsϓ=tΌs)Ę\\n̬CƍatBoostPerSegmenȣtφč<M\\x95oƒdǞel˥(iȘjˇtƶeΏǍra%Ɨͬtionɬ͝Ƨ_łs = NζśoʬnːƓe, dɊẽptʛˬh =ɧƏ ΅None, \\u0383ɷlearning_rɾaŒŋʖtəʸeˊ = Nīone,\\nloϔggϿing_level = \\'ƸɄSʶilşȞent\\'Ĥ, lʾ2_ƄleŦaµfϞ_rehg óĬƬ͏̫ǽ̄= Non̂e,¥ Ƶth̼readǗ_c͎:ïƭΖouιnųt ʟɵǿ= NoĀnϼ*e, ç)\\n>ñĩ>æƩ>ϖ foċ¹ψrecas\\x90Xt ˢ=ƾ̉ πmoǖdelɇ.f\\u0383ƟϖorecastΓA(å˦future)³\\nʗ>>ǃΝɝ>Μ pd.ȶoC̲pȭtiñ(ons.Ⱦdiζspȥǟlŝay.floaʌ̈́tΎ\\x84ˊķ_fo.rmat =̥ \\'{:,.2f}\\'.fȯor̎ƺmȈȍϯatü\\n>ˆ>>ϊ Eforec¢a̰sȟÒ£t;[:, :,Εǲ Ʈ\"ɥtarƧǪϞgetƩī\"]\\nsegmenƟt   ¼Ȳ Rsegʝment_0ǡ ̋segment_`1 Ǳυ\"ͧsƜǾȣegment_2 9sÿȐ=egm̼enά̿tȞ_3ƣ\\nf\\x81ϿeŁYaȯtureʘ \\x96ʷ?  Υ ƞ Ǳ >ϑȤ tarǭge#tê   ϣ̗ ta\\x86rg\\x9bet\\u0380    φtargeφtǴˍ ͙   target\\x91\\nÆŲtiēmηeƳ\\\\stĹamp\\n2ƫ020Ǿ¡˫-04-T1_0 Ͽ  źϗ   9.!0Šɘ0×ʶ ũ ķ ˷ƚa  ƹ 9.0Ǽ0ŭļϔ \\u0379 Ͼ    4.Ɇ\\x7f0ɦΗ0ˡ      ŀș6ņͧŲ@.00K\\n2Ç020-04-11Ç   D  Îlʐ ɬ5.Ś0¤0 ƎKϐ    ͦ Ç2Żɻ˼̶ϣ.î0˱0   Ǧ ˃  7.00  ƠĠ ͒ŧ  \\x91Ē 9͂Ǒ.0ϵ0ȦȬ\\n2ΜÒ020-0)4-\\x981ͨ2ɼǊ   î  λϡ 0.[0̈0  Ę Ų ̻  4ȼ.ɩ0ē0 &͢    ɖ ï7.0ʅ0 Ě     Ŵ9.00\\n20\\x82\\x8bβ̰20-04-Ǹ13Δ  ̪˕ɘ bļ   0.¯ű00 ΠϚ˵ű   ʹ  ;5.00 ȗ͛  ȃǯ  Ơ 9.˪0Ⱦ̓0ɪ ͤèŵ     7Ȁń.00/\\n202βŮǭ0̧-0̻\\x954-(ʉ+Ѐ14 Ƴ ąǑ    ɼĿ1.0´0 ¹   źq  2.ø00      1.00    Z}  6͢ϗ.00\\nɐŬ9Ë2̴ʀƠÔ02ȓǹ0-0ǃ4\\u0378-żρ1Ʒ5\\x8e Ĉ  \" ǧ  5ϛ.00  Ɩ   ëï 7.00ɪŵ   ϝ   Ķ4.ϩ0̻0\\u0378̃ ̙ ϣ   Íȓ 7.00˜\\n202Ŵ0-0˹ʖ4-16  ΣǓ    8̱Ρ.0ˌ0 ɨ ɞ Ā   6.00 Ć   \\u0381Ĉ Ͽ 2ɧ.00Úϋ \\x82ĉ  ξ Þ  0.͌00', 'Silent', \"Create instance of CatBoostPerSegmentModel with given parameters.\\n\\nParameters\\n----------\\nĩiterations:\\n    The maximum nǋumber of trees that can bĝe built when solvinˁg\\n    machine learning problems.͕ Wůhen using other parameters that\\nʅ  ǅ  limit the number of iterations, the final number of trees\\n    may be lzess than the number specified~ in this paramete̒r.ϼ\\ndepthŧ:\\n    Depth of the tŒƮreŴe. The range of suppoŎrted values depends\\n   ŀ on the processing unit type andŵ the type of the selected loss function:\\n\\n    * CPU — Any integer up to 16.\\n\\n< ȟ   * GPU — AnyƜ integer up to 8 ϓpaƚirwiǄse modes (YetiRank,ˏ PairLogitPairwise and\\n  ű    QuerǆyCrossEntropy) and up to 16 for alɘl other loss funcƿtiońns.\\nlearning_razte:\\n    The learning rate. Used for reducing vthe graĒdient step.\\n    ˱If None the value is defièneɥd aʃutomaticalƕly depending on the number of iterations.\\nlogging͔_level:\\n    The logging level to ouƓtput ǿto stdout.\\n    PossĨible values:\\n\\n ʦ   * Silent — Do not output any logging information to stdout.\\n\\n ǚ   *Ǝ Verbose — Output the following data to stdout:\\n\\n        * optimized˧ metri͔c\\n\\n        * elapsed timǛe of training\\n\\n Ô       * remaining time of training\\n\\nȵ    \\u0379* Info ˲— Outpurt additiˣonal information and the number of trees.\\nι\\n    * Debug — ȂOutput debugging information.\\n\\nl2_leaf_reg:\\n  Ȋ  Coefficient at the @L2 regularizvation term of the cost functionŶ.\\n    Any positive vaƔlue is allowed.\\nthread_count:\\n    The number of threads to use during the trainiĄng.\\n\\nc    * For CPU. Optimizes the speed of execution. This parameter doesn't affect results.\\n m   * For GPU. The given value is used ͟for rώeadʞing the data from the hard drive and does\\n      not affect the training.\\n      During the ȫtraining one main thƴrôeadς and one thrʿùead for each6 GPU are used.ǰ\", 'Class for holding Catboost model for all seΞgments.\\n\\nExamples\\n--------\\n>>> from etna.datasets import generate_periodic_df\\n>>> from etna.datasets import TSDataset\\n>>> from etna.models import CatBoostMultiSegmentModel\\n>>> from etna.transfϮorms import LagTransform\\n>>> classic_df = generate_periodic_df(\\n...     periods=100,\\n...     start_time=\"2020-01-01\",\\n...     n_segments=4,\\n...     period=7,\\n...     sigma=3\\n... )\\n>>> df = TSDataset.to_dataset(df=classic_df)\\n>>> ts = TSDataset(df, freq=\"D\")\\n>>> horizon = 7\\n>>> transforms = [\\n...     LagTransform(in_column=\"target\", lags=[horizon, horizon+1, horizon+2])\\n... ]\\n>>> ts.fit_transform(transforms=transforms)\\n>>> future = ts.make_futur̊e(horizon)\\n>>> model = CatBoostMultiSegmentModel()\\n>>> model.fit(tsĜ=ts)\\nCatBoostMultiSegmentModel(iterations = None, depth = None, learning_rate = None,\\nlogging_level = \\'Silent\\', l2_leaf_reg = None, threaǤd_count = None, )\\n>>> forecast = model.forecast(future)\\n>>> pd.options.display.float_format = \\'{:,.2f}\\'.format\\n>>> forecast[:, :, \"target\"].round()\\nsegment    segment_0 segment_1 segment_2 segment_3\\nfeature       target    target    targetɞ    target\\ntimestamp\\n2020-04-10      9.00      9.00      4.00      6.00\\n2020-04-11      5.00      2.00      7.00      9.00\\n2020-04-12     -0.00     ã 4.00      7.00      9.00\\n2020-04-13      0.00      5.00      9.00      7.00\\n2020-04-14      1.00      2.00      1.00      6.00\\n2020-04-15      5.00      7.00      4.0Ŭ0      7.00\\n2020-04-16      8.00      6.00      2.00      0.00', 'Silent', 'Cr\"eaŜte iʚnǨsta¢̻nWʯcΥez̝̑ of ϕCaͶtBˆoostMultiSegmeȥntModΖel wϢ˜ith g˔iven parametjers.\\n\\nPƮθȚaraīmeters\\n˳---Ë------ϳ-È\\nɖiteɓra\\x99tions:\\n   ß TΕàhǙe ȩmaşxϴĘimOum number oņf trƙeʔes* thaϨ̎t cƉan be Ǽͅbuilt when soͬlving\\n  Θ  ǃmachine ÙlearnIing͐ problemsɿ.Ã When using otuheʹrϏ parametϟers thƔat\\n  ɏ  limit ǧĩthe numbe̝r of iterat˻ionsu, the f inal numbeȅór ̀of #trees\\n  ǮŮ  may beΜ less thaɠϹnʦɀ t̥he num̜beŭr ƨspϝeͭcifie̶ųd ͳin RtŤhis paɋrameter.\\ndepΕthƴ:\\n    De͓p̬th of Ƴthe tÀreʬe. ŤTheͭ˕ rȋa\\x98ngÞe of suppor\\x8eteˣdŅ Ɋvaluϭes depends\\n    on gthBeΔ ȷ\"prǗoʰcǮessing Σunitʺʠ\\x9b t˵ǥype anͫd ʪthe t*͂ypeȔ of the 6seleǩcted loss func\\x85ͻt̄Ąìon:\\n\\n    *Ï CɈPU — ŭAčny intͶeg̦er u\\x89Ǡp to 16.\\n\\n   \\x98 * GPĞǯU — Any intµŇeger ʸ;up tǚoĐ ϝ18 paĘirwise modes (Yet^&i͕RȖaŹϿƔnk, PʸairʕǹLogȇitPairwise anƜd\\n      QueryĦCrossEntro͡py) and up to 16 Ćfǉȝor wa̴̭lǱl other loss functions.\\nlearning_ratwœe:\\n   ω ȔeThe̱ l$eȜašrning Ȟrate. ̉U¢sedɴv 6forɠ reDducing the g¢rƌad\\x9dieˎnt stepą͋.\\n΄ȷ    If NonŽeϣ thẔ̇e valueɶ isɀ def́Δiuned auΜtįomatΘically d̯ependƾ̗ing on tͯh͘~˂eǽ ˄numĉber Ϳof itÀera͆LtǕi̺oƊnˌsͬ¬.\\nlogmŁgingƃ_level:ń\\n  J  The loggƸinȳĉΔg leNπveȱl ϻto output to stdˉou\\x80t.˼ƛ\\n   ƶ Possible values:\\n\\n  Ü  *ʖ Silent — ÞDo nǒotɼ outpϱu÷t anyț logg̋ing inforĕħmation to stdout.ɳHÊ\\nθ\\n    * ÜVerbosǣΎɆe — Oɓuʁtput tȼhe followϋiɰng data tν¢o std4ouΏt:\\n\\nΛ        *ʺ ĹoʏHpʼtimizedͨ ʃmeƪtric\\n\\n˹ƣΟ      Κ ƀ * eϊlapseςd ̹time ŵof trainiͼng\\n\\n˭        * remainingþ tǟime ofU ótrȇɞɐΚaΝiningϫ)ȰƚΙ\\n\\n  Ǫ  ɣ* ͛Inǐfo — Outp˾uǷt additional informa#tion ͽand Ĉthe nǽumber of tʀͨrňeeʲs.\\n\\n    * DeĢbuðg Ɇ— Outp\\u0383ut deb\\x86uggɃinƠmg i¦nð\\u0378forma̓tŽƉionc|.\\n\\nνlăΑ2_Ŧleaf͇_re̗Ƭg:Ψ\\n ½   Coe¹fficient ëat Ętüheȣ L2 regïZular«Βizat˓´ioʉn ªterm ofȋĸ Ľthe \\x7fcosst funcǙtion.\\nϝ ʴ   AǰnǷƝyŲ poǖɛɗsƌitÿȻiv#e value ǿis alloweġd.\\nĂthreʈaΈd_coưuntȘ:\\n̺    The numî®ȝber of threads ̷toǯǴ use ʯd˗uring ͽȆthe tɲrʻ\\'ainiɷnXΡg.\\n\\n    * For ̈CPΙU. ɵ\\x93OptSimiʿϿzes͗ ʥthe speed oũĚf exec˘ɽ\\x80ͻution. Th\"is parameter doesn\\'tʞ affect ˘resȰu͚͍l½t˲s.\\n\\x90  ˥  *Ͽ \\x88ɑFor \\x90ǟϹGP̭U. The given valueʱ isȾ ʠuseɵd for reaņβdi\\u03a2ng the [bdǁa;Ǟta ëfÊr\\x80ˀom t̵¸hȄe hard drivͧe and does\\n    ϕȾ  not affect the trainƚing\\x96.\\n     \\\\ \\x9bDurǀinϼg theȳ traϠiǲnin̾gš one maiΏɄάn thread andŮ one threadʫ͙ for ůeaʠch GPU are͠ɂ used.', 'Silent', 'CʏrϔeaŎʞɐtȞe inŊstanc͉\\x95e of CatΪϖBäǔoϙostEMĜod\\x89ͻιelPe˭rSegǯmenīt witʂŞƀǭĢh g¼ʫÀ¤ʡ¢iven ÉparaʣmeƔ̤trǑe͈rāãΐǣ\\u0381sĳ.\\n\\nǧ̱PƋŊa\\x83ʼrameşteråsǉ\\n--Ɛ-----Ǝ-ǉ--\\ni̛tưeįř!atiĲonsʦû\\x9cϏǮ:\\n z·ʳĞ   ThȄeŅŢ \\x90ńˡmR˘aximumΈ_¤ɋ _ǳʆ˪nʲumber ofȞ trȇees tȊh\\x9eaϟt canͥ be builƭɸʳt when̦ ƺsolʾɖΐƿvȞˋ̻͔ing\\nɓ    mach\\x85ine lưearǸnƉ̉inƟgĚ pârob˿l\\x8beómϠs. ħWǐ˄he͝n usïangŅưŚ otýϓher paramͼeters that<͈č\\n ť͵ Ȱ͌  ːĞlŪiłmɥȉi¾Ƭ0t tʦǣhe xɖȻʳnumbϡer ɌoȤ˹f ̽ƈiter˷a\\x8ctionͻ͞s͊,Ƒ øthe fi{̉na̴l nέuȰmbeȏrθ ofSzϨ trʶÆeeks\\nǌ \\\\: æ ̑ ʉmaΦ+y bˆˇŐeϴ lessĶ tǂ˭ͮÈhμaλƳn\\x86ȕȓ the nǧumɈ͆ĝęberͶ Ξsp(Ηēec˾ifie͖dƛ i͉nƵ tµhiɼτüs par΅am̜Ħetɉer.\\ndeptǹ̺h:\\n , \\u0381į\\x89Χ ̌ D˶eɉʗpth oΈf˚ ǉthʩDłǠedˀϘņ̿ tre³Že. The\\x93 rľa̻ngeÀ o\\u03a2f suNɢŧpȠporĶteǆd va̿lȝuesʭǊ Ě͡ḓepenǏdϟs\\nƷ̘͵̷  ǫ έ̹ on tɢhe proˤcωessiȊɳng ȵu̴\"ΨniŒtǻȷĹȕYʰǇ typeƋ ǵ Ʈanńģͥd ʤrth¢eì tǡyƭpe o͋f 0the ̇ƑseleƵ˯cVϐte2d ē̿˪loòs\\u0383s ˁfunctɚiʇΛ˸oˀnƵ:\\n\\nȝ   _ * CPU ϟ— ĖAnǿɠy iȈǶnteź·ƃge1rʅ upϕ to 16ɣ.\\n\\nÕ\\x87   đ * GPUU \\x8b—ī ʞAnyĮͰf íϠintΫeŻger ŋuȽp\\x8f to 8ɔ͖\\u03a2 \\u038bp;airϵȞwÛçisĸƝge m˻oϺdesÓÿ \\x83Τ(Y·etiRank,MΗ͍oʃ P§ȎɞaęirLvogƸitPaiŪrw˴iseÙš0 anČd\\n     ̊ ĉQueyrŷÛ\\x9eyƎCʝϦr\\u0381Woss×EnʏtˮrƏo˔ûpy)ϝŋ ¹[ǻóand ρǳṷpȥ tol͋ ˺\\x8cȯ̍16 ϵfo͘ƫrǤ ÚaǏϋlϦlʴ otáhe͕r͠ lıǞoss ί*fȲunctƓionɧs.\\x9d˜\\nle\\u0379ɏarþnɆμŲing_ʬr|Θʫa̾ƽϛ§te:\\n ϭ Ĵ  é²The leȩarnƺinȲg= Ƿra͙te. Used ǩfor r\\x9ceĒÑͥduėġʉCcÛȣing δthěˎν gϣRradiʈenβtɨ̇ sȳtepƇ.͟\\n  ǃ  If ȉNþon˝ěe˕ ̀ʎɚtϲheĽ vȴalūƔeĩϢɇʤÙΦƉ is d\\x91͡ŸefυiƷεnedœ a\\x87utĝomatƏicaΪlly depenͷdĄi̓nǐˬg˙ǥŶ ˉoΏŞn the¨ numȝǹbˬeĦĠrʺ ofΣ ƛite;ǘratʹionsϢʰĵ.\\nloĹgγgiɈ˶ɞng_ʏͽlžʑeìvʝelÂȌ:\\x99\\n    ThÐeĢÛ l¡ʑ\\x9fɤog͕ginŔʈßgö leVveϹl ĸt\\x99ƅʝLo ȧoutŎñpǳutA to s0tʃ^\\x99dËæouϫt.Eʨ\\n  &ſ À ̢PoŔͯΊsaĢsiͬbɯle v\\\\ƼΓalĎueϥs:\\n\\n ˌč  0ǪŔ * S̙ilẽnĞʤt Č—ȶ DoĒ\\x87 nͦot oɎάutŮiΚp\\x88ut a̱ny loggˆiƖnŠg infoͽrmation̆ǜȤ ĦǴϵHƷ\\x90tƈo ϬʊΆsŶtĔdoutʜ.\\n\\n    *ʒ VerboϏse —Τăϳ Σ·Out˻pu\\xad«t the fÑoȎȺǐll˙ϩo̚wiĉnƨƎg ŤɄd̸ħaAtaũ ƽto ]stdoõǶut:\\n\\n˔ Ƴ  \\x8c  Û ϸ!uT ͭ Ϥʷ̟*Í opΝtimizʙed m\\x84ˣe̕tricł͋ʬ\\n\\n \\x86  Å ƤnĞġʮ  Ϲrɟė  e* ȇýlapɮse˚d\\x9c ÿ̑£t̗im\\x9c̞eȮͮ of s\\u038dɏſtrͺ˦aininȄg\\n\\n˒ ēŚϕÖ     ǹ  * rʑemaÄȮiǢninπg tÓime of̯ t\\x9aʜɏrŲa»͎in˒iÝn\\x82ϗgɛ\\n²\\nˏȄ  ή  *^ IṋſƢfżÐΎo̫ —h ͩO\\x9eutputˌɤ additionaRl infŗoǘ÷rm̘ͪation a˪ʒnʐdĘ ʻÈʼthe Ϟn\\x9fuώmbǳer ϯǬƸofƚˬİŔȔ tɾ¹rʬɂeŇɬes.˃\\n\\n    ͊ˊ* De³bug —Ɛ Oʏ̉u˷tpĖɟuȑȫ\\x93tc 4șdebuvàsggͪɆƳing iǹnform̘ation.\\n\\nl2]_leafv¹_\\x90r:eg:ɻ\\n Ĳ ʖͨǰ Č CĽ£oefficůiƥenϻt at˂ Ʋthe L˷ë2 rΈȑeg\\x9aɼŚšuɜlarpiǉƻ͒za͊ȟti̤ʜonɩ t\\x8derόm of the ŋcšĔŞÆtofsùětƼή funϷctȍioǀn.\\n ʌˉʮ  Ʉ An͗̿yˣ pˡoʾ½siɖtive Ü<ɤvalue ishĝ allowed.\\nͶthlreϾad_ϜcŎouƲnt:\\n\\\\ Ť   T+hŐe ůn˄uüÜmbe͠DrǗ oɶf ÓtȋhrˉeaǂdýsÍȥĩɽ;ƁĽť tʇoúͥ ϱ˭ŽuƳse duriϡ͎7Űng ôϸ˜£the ˾Ǘtʔr˾aiɱnin˄ϙÈg.\\nŹȇ\\n    Ȁ* Fo@Ãr CÿP̈ɷU. ȢO͍ptcimi\\x8e¢zʭeɟs ƞtheͭϝő Æspee\\xadd ńɌ\\x97ȰɿofŴ˝Λ e˱ŋ̨bxπ ecutionȏν. ϫTh́ɬiȝ¿s ȋparaȷmƤetψerϵȢ doÒesn\\'tθ ˑʀ˵affƽectϾ ǊresuΆ͢Ûltͽs.\\nγ Τ   * Fɐorƍ İθGPȱ}zɑUʙ̋ʻϗǗ. Tķ+Æhe give̷έni valƒuɰeȩ i̲̕sτ\\x9e Ϧuˆǐsed \\x8eţžfor˖ ɒread\\x80i͚ng3 tƣ\\x8aheɁ dėata fromö tÉhē hard dÀŪrivʂe a\\x81nd ŃȡdσȍoØeμs\\n     ɨ noΒĳýt aǲπƏff͆ectɌ tϛȶhe tȜraθiǁning.\\n ɏ z  χ  ˂DuĔʱͶʬrŅόȺˈǁiΗ͝nȆg øtʔνhe± Įtrɛainiſ͟ȬnŮgŶ one Âmain t\\x86hƑÌrțeaʹd ÍÐͥaȁnd Ϋʃ³o̼ĴnΪe ˹thrlȒeadʽ ƽøėf̈o˷rʊ ūÐeaôch BͧGPU ζaŻ\\u0379ɗreû\\x9aϐ ˼uĥs͙e˿Ťd.', 'CatBoostModelPerSegment is deprecated; will be deleted in etna==2.0. Use CatBoostPerSegmentModel instead.', 'Cl\\x8c\\x83asʃȑs for hħoǳldiAɚnʛg ãCatʡǐboǞČoėÊst modeεl \\u0381ðfor allι seͷgm\\u0381eͩnƔtsªɯ.Â̋\\nΕ\\nWarnings\\n-----ƮƫΤ---\\nCa\\x9btBoos\\x81ΥtĹMÕ͑odɸPÕelMuıltǔɪʰãi˂SʻeƘŁgme͙nȰt is deprʹeĻcaϳt\\x91edȱ; wa͔ikZǾll beœ deleted iµn ųe+t˶na==2.0ϛʏ.\\nʣUsΥɶ²Ê͖e Ɣetͳna̘.modeȍls.ÐCatBooÕstMuêÝOltiSegːmentModɁeɃƂˎơ̦lΗʢ in˼ste\\x99ɔíaʆd.\\n\\nExǀampĐleϣͳs\\n-ͼ---ɝ͖ǹ----\\u0381\\n>>>Ÿ fǛrom˫ etnaŐ.dataĮsets ʾimpoϗrt ȯgeɶnerateȔ_perioƎdiˉc_dŷf\\n>>γ>= fromǪ̥̏ʴţ etna˟.dkatasǰets ͖impʏoṙt TȋSDatΈas͊šet\\nǣ>ϩ>ŭ>ǡ0\\x94 fWro\\x88m· eʝtna.moϠdƞelsɫ imporÑĔİt CΠϳat+B̲̊oosĜtµMoϾdelMulκtiSʖ9eOgmeğnt\\n>>>Δ ĉfrom etna.t͍ĚΝransfor(ms impĞor\\x92ϸ̯t LagTrɴʝansfɁorÄm\\nˌã>>> ʄclǳδ̇assic_ͽdf\\u038dƤ = Ǐgene\\xa0ratͳe§̤_p˵̙eǯʾriodi˹ʈc_df(\\n.̍..ț ǅ    pDeȰrʧiodpsέ=5yē1ǴΒ0̝0,ȴ\\n...  ̧ ʶƇ  staòrʛtĜ_tʙimɅe=\"π202˚0-0\\x83ʮ1͗-đ01\\x99\",\\n...     ʊn_segmŘenļts=4,\\n... \"͚  ´ ǹ perioãd=ˀ7ʁ,˂˷Ç\\n...Έ  \\u038b   Bsigma˺=3\\nʯ..ń.ʗϣ¢ )\\nɏ˳h>>> df͝ = TSD aͽtóasͧet.to_ŉ\\u0383Ǵƛd̽ataset(˜df˧=cl%assͅi\\u0381c_̚-ƻdAfƗ)\\n>>O> ts = TƳSDƸataƧ\\x86set(θĳdfʝ, freq=Ň˭\"D\")ǒ\\n>>͇> horizon ?= 27\\n>>> trͰaʧnsfoϡrmϯs = [ͰǷ\\n...   ά ɣ LǂagTraͻnsƤψf̞hɋFȓor,m(in_coʉƹlumnʹ=\"tarɊget\"ɰ, lag\\x84s]͡=[hori«z̓ʼon, ȿhoǅrizon+1,ǘ ĠċhoriĻzon+ɰ2])\\n.ɘŀΩ.j. ]\\n>>ʅȄ> tȬs.fĽit_trans̒šɧforɈĺm(trĨansformsȁ=ζ\\x9ctranssformsƌ)\\nΝ>>>ͷ ˈfutϰɪͮure =ʾ ts.maĽıke_fu Ȗtƥure(horizon)\\n>>> moďŐćɞe͊l =ͮ C\\x97atBɕƢoȄoȍs\\xa0tModceńlMuͨˤltiSeϸgm\\x8aent(ôÉ)\\n>>Ć>\\x81ß˃ mode%l.fΩit×(ts=ts)͔\\nCΑatɌʑ́ɎBooâstModeζlÊMultiSegϗ×menəΞt(iterations =Ƅ ŤɝN˕oneΏ,Ņ ĹdeƘͭpth κʘ= Noτne\\x96, lea˘rning_rate \\x88= ɘNon\\xa0e,\\nĘ϶l͠AoggiLng_leveƾl = \\'SilenůtįȂ\\', lͪ2_leaϰfˡ_reg Ϧê= Noʉïne, threλǻŉɒŗad_cĈouůnt = ȸϼNone, )\\n>¹>> forecalst = modcel.fń%orȓ˖ecast(fuʢ¿tur¯eƔ)\\n͍˳>>> pd.opɷ\\x9bτϩ΄tions.dƒisplͳay.flǒo̬at_Ʋʻformat = \\'{:,.2f̾}\\'.fo˧rmat\\n>ǎ>> ûfoĜreõcast[:, ϫ:,̸Ʉ¿ \"ta̜rɊgeʈɄŘtö\"].ɓrounǘd()\\nseágm˻ʽ̴ent   ͖ǎȏ sɪʵʯe\\x9agmχeͅnt_Ȧ10 ©ǆs@eűgmƮʲenŞ©t_1 seɉgment_2ʣ̈́ sɋegmenľϬt_͈Î3\\nf¾eature Ń   ʨ s \\x94 tυaɺrgeϨt  ǐ  ƇtaËǰrgetà  ȡ  tϘargetƇ    targǈet\\ntimestˮamp\\nʁ2020-04-1ǳʬċ0 Ǖ ɘ    9ș.0Ŷ0   ˡ̉  ͘ɡ ϥ9ů\\u0379.00Ǖ ̛    ͉ 4.00  ǲɱ0 Ǘ O  ĸʶ6.00\\n2+020-04-Ȉ1Q1 ΉƓ   ʑ͊  5.00   ˨  ƉÈ 2ʐ@.0Ä0   žϲ   7.ǔ00  ʨÎ    9.00\\nɓ2ɀ0Ɍ2ΉWϫ\\x810Βƹͥ-04̤-Ȝ12   ˈ  -ů0.\\x9f0v\\x97ƛ0     Ǿ 4.00  ʠ    ʐ7.0˞0  ˌƂ ˳  Δɝ ˺9\\x95.00\\n2020-0ɔ4-13     ͑ 0.00ű ˙˳ʼ  ϋ Ť  5.0ɯN0      9ɐ.00 ø   ĕȥʏǥƃ ūͮΫ 7ü˳.00\\n2Ͷχʄ020-04-14 ï     ǟ1.00 ʶ    ̀  Ŭƛ2.0\\x9fν0Ġ      1.00     ͛ 6.00ɇ\\nɟĖ20ɮ2ͺō̪ȕͿ0-ˀ0ŋ4ʥȧ͕-15    ĝ  5.0˃ɷ0ó É     7.j00     Ȩ̺ 4.00    ƀ  7ŅƂϭ.0(¬˩\"0\\n2020-04-16  ƿ şǏ   8.0Ɓ0      6.00ɔ Ɛ     2Ť.00 Ĵ  Πǥ ³  0Ͽ.0Ɓǡ0', 'Silent', 'CatBoostModelMultiSegment is deprecated; will be deleted in etna==2.0. Use CatBoostMultiSegmentModel instead.'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['ÙTest StȤac͓kɅin˄şgɑ!śζòEnϮsϢƜíemǜ˓bɴlŬe behaęύͼvtiŦÜorƬ¹ inƗ caµ%ñsľeϥť̞ ǸoMʴf ϗǁȻȔȽi\\x86nv\\xad̈́alidʼ piE\\u038bpeliʘĉnZesγ ɓ͆nƣuƮmb\\x85eōôβ\\x8fͻr.', 'At least two pipelines are expected.', 'Check thaĉt ĢStaĊckingEns̃emblơe._˄get horizoĂn wϟorksŋ cζHorrectly in case of ˔valʷiĕd ÷pipelines lisΏt.', 'CÅh#\\x8fë́ck thaˌót StƗacu¨kΤÛiønɅgŻ̪ΕEnɏƈ̭ȈÛsem±ďϝbl0ƃe._ʶˬg̙̦et̅ ǸhorņǄiz̙on ΦwoŻ\\u0380rks̃ȋĴǳʖǱ correcĞtly˧œȱǏŔ ĦģinͶʰ cÄa£sÂe ĉͬ\\x8ažoȯ¬f ˴ͬʣȥinv͏aƫΝǗǯlǏƸiͱd ÔpiƣpȠelϫ\\x90Ŗ̘ineņ͛s ˪list.͋', 'All the pipelines should have the same horizon.'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['̯ ɠ   ϙ  ȁ ˤ~   *  ȺȾƻ', 'dim', 'none', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': [' z*   ę         ', 'regressor_1', '1', 'regressor_2', '1', 'regressor_1', '2', 'regressor_2', '2', 'greater_is_better,answer'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <13x9 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 12 stored elements in Compressed Sparse Row format>, 'ClassDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['No frequency information was provided, so inferred frequency .* will be used', 'ignore', 'statsmodels.tsa.base.tsa_model', 'θ   Ȭɗ    Ȕ   ĩ ˘    \\u03a2  ɟÒ̡ ', 'timestamp', 'Model is not fitted! Fit the model before calling predict method!', 'timestamp', 'timestamp', 'mean', 'mean_', '.4g', 'mean', 'mean', 'target', 'mean', '̂ϐ ˸     ț Ň̔   ', 'GetΜ Ƃ˜Ō:pǦƤÆưʽʺy:Ǧclasɑsɓ͑Ϳ»γ:ʎ̋`stǽăaƌPþίǟtsmoEΜ\\x80düeŬ΅lΊsƈ.ͯtsa.stǐat͵esƆpace˂.ɏŧǤ´̎sariτmaĶxλN.SqARIMŖAƿȖǢðXRŢ\\x9desñýulĮtƝŊsƭWrȈapper` thI\\x82ŕĨat̼Ȭ is ěŜʒusxØed inĭsƲiˊde̸ ˜etnaȱ¶ class.\\n\\nRB3eturnƝļs\\n--Þ:-˼--¢-ͻĕǧ˞-\\ń:\\n   ƒIĝn\\x8fĐtƖUϋernaĸl mo\\x80ɠ˫de?Ŕl', '        ϡ ͼ         ', 'Something went wrong, regressor_columns is None!', 'target', 'timestamp', 'SARIMAX model does not work with exogenous features (features unknown in future).\\n ', ' will be dropped', 'Regressors ', ' are too short for chosen horizon value.\\n Try lower horizon value, or drop this regressors.', 'Co͍Ǥmput̘e țprÈǯeͫȖϘνdictʮ˟ioʬ[ə˱ͪns Ļfrom a xˊS\\\\ARŸɬI˙MAjX m¢odÞeͥl īand ôȯÈ̻ͥ̋useϠO tǢrŞʁueθ ˰Ǎɟľįiłn-sařm͠ple daǁtʥ\\x95a asÊ laΩȸgµsñ iʭÜf əp³ossiŋb˨Ϊle͕.\\nŏ˖ư\\nȹPar{ametpeŔrϢϠs¤ÂÌ\\n-Ɲ--Ȑ--ī--ˈ-·|ƞȭ--\\ndĳf:ǆσ\\nͻ  ϵȋ  Ő˘Feʵfatuœʁr͗ȉes dǒatafȃǩr̯aƇƩmǎe\\npɅredȟ͵iͿǴc͇ϒtiɏonů_inˍterv|a˵(ǎlμ:\\n   ĻĀ˜ I\\x84ɦ̠f͞ƻ· ϧTrͨue ĕretɼεʚuƮrnsã pr˘əǲed΄i̼ctğΩion inƤɏϪtºervalĒ fΈÅor˽ ̓for̕ecaÇst\\n˃qua̓ίntǌͫɠileŹȈs:\\nˤ    Levels CoΧfͨģ ͠predŒáictioʡn© diʭŭsǹγtrώibuέ\\u03a2tiRon\\nàͱʄ\\nRe˝͆ƯtuƷrŢnsş\\nˎ--ʕɒ̺ϲ--Ć-Ɠ\\\\-΅-ʔƩ\\n:\\nìʷ ƽ ϩ  DataϷFrc\\xa0laϪɖˎ́EʖmͪÆğǼͫeƐ\\x97ť witΡh mpredictʳiĕons', 'Ʒ(̶Fiͤtsɝ a ¶ɲSARIȊMAX͢ƿ mode¿l.\\nɨ\\nPʔʹȉaramǉetersʜ\\nƳ:-----Ù---ʂ-Ô-\\ndˣf:Ȝʨ\\nͽ   ʮȝ ŪǙϲFeɳaέtuʠ\\x92res d̠ataçfrηame̟ɝ\\nrZeǂgˢreěsɋɏţ˯so¨rsɣȜ\\x9e͠Ŭ:Γ\\nΙ ŜΫř Ł ǆ̺ǺfΗǦ<Ϫ ɏɈList of the cƏoÝlumɆns wi\\x9fth regrζes8\\x98soˑrŶsϟǆ\\nÖȎ\\nRetur˻ϑǻns\\x86\\ǹ-̪------˃\\n:\\n   v Fittƶed͡ model', 'target', 'timestamp', \"Can't determine frequency of a given dataframe\", 'timestamp', '_SARIMAXBaseAdapter', '    ̃      Ď         ', 'category', 'Categorical columns ', ' can not been converted to int.\\n Try to encode this columns manually.', 'Ŏ˨Classǎ \\x8efƵoîŬrɢ hŜolding ƃSari˦\\u0383Ă²Əma\\x9fx ͯ\\u03a2ȍm3odelɐǊÄ.ɡ\\n\\nNʆoɃteƳs\\n\\x9c-ͦ----\\nW@ÆeĢ use ɎγSARIM̪AX [1]˃ ņm\\x83oděˑel f³rʮom sūκtaǂtk2æsÙmodelsȗ pŮacɲkage. S̥tat̙sYmƫodŐeŠlɅs ʋɏϐpa\\x9fckaĔg̢e usesȈ ȗ`e7§xog`Ȑ atçɥtributeιɭʈ f̥Ŷo³ŕϾvït\\nųȽ`́exNog¸ÇeϽµϪǋ˱nous ˿reǃΓ\\x87greȗʴĨįÎķ͕sĜʬsɇors`ͱ ʟȀ@wh\\x95ichȔAͦ shoul¼ɥƟdȼ be ͖kϽnoþwθnĕ iná Σfuʈtur˫e,̭ϲXΣ khowͯ,ɋeΨčvĒerÆϷ weΰń uȋsϐe eϟȂxogenäous for\\naȻƕɰd6ditƩiȗĬoǉnìaɘl͛Ǫ feaˣɏΞ͚tŶ\\x9b̕uĤrƊʭes» wȬhƉaƥtţƁS ƾi͉s ęnoǏ˓t \\x91known Ēiʜ̛dn fuʉ{turɟe,ͫ È˳˯and Äǵreηǋö]ț¶gr͋eˍsǬsƭƣôorsȾ ʱǈΓÌfǴoƧ\\u038drƥ featuĉres àweǖ̻ϑ do͉ kƝHnowˌ̍Ϡ̣Ţ\\xa0̾ inȯ\\nǝfuͥŷtuɧΗÎɮrΝeȱw.\\nŐ\\n.ˣ. `S˸ARIMAX:̾&ʧ <ʢʠhttpsĶ:͇//ʅww)w˦.ͲstǴΥatDsƔm̾odν˖zeʞlζsa.orAgΈ/ǫstak̂eǚƣbțleȴ́Ä/̇g͵eneŷraȒtļʁΦed/sʙΤ˰tatǫs\\xa0ÔƺǣŀmoõϱŃd·els.tsa.staƧʒΚt˨ΆɒeϵsVɿp̒ʽɲ˘aΫc˟Ġeř.sar̵im9rΨaĪx.DSARIMʐAX.htmˬl˥˫>_àņ`', 'c', 'none', 'î   ˑ Ǳ   ͋ ɛ   ȴǄ˴', 'ǱCψl?\"ϧÆľdÔas̲s for ͨ˫ho̹lĢĉƐdinēg ĨǺSǘarimÙΞúax moΫdιɚelʉ.ɩ\\n\\nȧMethod ``ɅpeςƀyrAedńict`Ǚǆ` caǳÓn ˧use υtrueΰ tarʠgeëtŻɫ vaǾklΥúes ͱɕƕonly on trƕɣaiʸnąΣ dataNÚÆ ǜoͪnː future Ȓdϲata ɴautoregrͰįȓĂeϧssion\\nȨforeÝcastiĒȴn\\u038dg wịll̉ͼ be maȹde ˵even ¢iÛfΉ Ƞta¥rgeřtƎţs aĚr\\x83e ΐɃϫḱnowΐn.\\n\\nNȷǦoteūsɴr\\n-Ɍ-Κ|---\\nWeό usĪϏe :Ʃpy:clũasϳċs:̾Χ`stçaðtsƫ§moɭ®\\x8fdŞelsŏ.t0sa.sa̘rŨiķmþax.SřA̎RI˓MAX\\x8bî´E\\u0382`.$ SɆžtƽϞa˟tʬsÄmoǬx0deh©lsǋ¼ paǰck̶agϐe uʈ̭sesʩ ̻`Ş\\x87ex<?ʥoΖæ˭g` aǨ˿6ĠhttŔriϗbușɾt·eŶǍƎ forÂȆ\\x9a\\n`eɦxogɟƞeͿnou¼s regʕāͭƩe˝r˷essorȎs` úΡwʅhichıÕǲȑ ΓsɵhouldȳƊ´ be knoƝwn iǙn ɀfǤutȿù\\x87ǒȗur̋e, ,howeơâ̱vͨʙƦ͌erǨ ̌weǊ ǻxuse͓\\x90 eΩxogenœoŋϙusǷɵ forˍʧɾ\\n˶adďdŝiΡtþiĩonalŎ featur̤eλs Ɓwha²ĳt ̯ʘ\\x95\\x9eİis̯\\x83 noʉt) knoȽɤΎƕwƪn \\x96in fʈu¬Ϗƿture, ˣ˵andȸ ȵǼreęūȟgressUoJrs 9ɘʖʸãěfoȣr ǖfΕeȓʱ͊aÌ\\x9f+tureŉs˶ ̃w\\x88e ͕doH knʆɤİŷow iɐn˗ɘ\\nf!uture.', 'c', 'none'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['  ̹  ÍϠƚ   qȱ2͐\\x9d ϙƁ   ͦ  úŞ   õβ  ', 'Á|Ḽθoad fuƕll data͡se˿tȅ to memor,y.\\n\\nUsečfuĪl \\x91ĥɝǩɅͤȜΦf̾o̒rŢˬ ȜeƉSxÄ̎pΪʻerimńι¬ents ́ŉÀǻwitΔͳ̇φh sϨ˻ǽſ˶ƧǥǡïɂmϡaǪϤll ƶâɼϣĨΝdaϼdɢ^tasî\\x81etős andƨ laryge imǗaϋͯgĭes.\\x92', '   ˾   ', \"Can't preload datasets with sample quality available.\"], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['ĮPŋi§peline that mʹa͌kɳ©e rüʚe1gʈresȅǖ\\x88ȤsiɱƍǨvɁȚ\\x8eƈϼ˻ʄe mǙ×odEels̭ȽƬ autŚorζŽϱeŤgresĜsiv£ʉ̺ˈe.Σ\\nǺ\\nƗƏEÜxamŃplesŒÝ\\nș--ŏ---Ǎ̳˧̙-óɒ-ɔ\\u0378ə-ĩ\\nuʤ>̒Ϫ>>Ɖ frćoθȝmǉ Ňȗ͜etϣna.da¬nȎ˭ĸtasπets͎ƹ ɸƫŤ˥ʚim͑pʹorȥʞtYå geƯ̈̌nerͲaɬt͎Σe_ɈŚΟpeǩriʺo²d·ic˕_dʊɳ|fǥǁ\\n>Ɣ>Α>ɘΖǷʼͪ ÊfΙr¨š͢ƮŗoȩǙm getna̝̤.ÅdaΪtȎēasȇΗŠtŠʰs imɦÅƥp̂orĠt ̖TʘSDΗ\\u0379aȾt\\x8a̡aɉseƸt\\nȤ>>Ľ>ʄϩßãȋ fƂϑrom eĬtǿ˞ˑnaƀ.Ĺmɗ|1ΧoJdδ͐¼elsçǧ̭Ȅʰ îǣəmƔporǏɭtĨ LiĽ\\x92nʯȢdΑe̪ƾȯabrȓėPeƓrοS˱egͪme̬nεˮĥtMŝodeʡ\\x9bl\\nv>>ϧÜ>Ć ȜĿɨfȁrom etnaδļ\\x9fǞ.ƏʴίtȘr\\x89Εůęansf©ĪϭormÙ̫˄Ŕs\\x97 ǹ\\u0383impo̤͖řrÅpǚt LƂaϤɧȣǧĠϦʺgTrϮanμɛsfoǎrm\\n>>Ŋ2> ʑǼclaͬDϹss\\u0381iɉ4c͍_ʦdĭf =ϋU ǏāgʐeɍͩȒ͚«nerɩ˓aȳteƗȜ_p\\x95e&ri˧od̅ic\\x8f_?2Ύdf(\\nŃȾ...̯ ˰ ĶğÐɝǗϿ ϓ  peɒrio,ŢΐdJst=10¹0,\\n.ϓδ͕..Ú˘ A ˟  ȭŃ ɭsÃĭtartΨèŭ_tϗimɴe\\x9a=\"2Ǻ0$20-͍͡č01ɟ-0\\\\1ąȅ°÷\",ͮɇ\\nû.ʚ.. ϭ  ɿΐ  nŬ́_űsĚeκgmƽents=4,\\nɳ...ƀʝ     ĘŨă®p¶ʕÄ˓ȴe̡§rioĠdĚ=7ˇϣ,ˍ̺Þ\\n.!..\\x9bɻ¸ń  ̈́   sigmɷ̰͉̯a=3\\x9f\\năƗ... )\\n̻>>> dʌΌϨ͘f ŧ^Ζ= ˟T́ʫɤΜSΈDatasͪet.to_daƽtase̵t(dŌfͺ=cḷ\\x87Ƈaʆ°Ǝsřs¢ic΅_dˆf)\\n>>ɣϯ̟˳>ù tşήâɺʓĽƆsȡ ̊=͋ TSDya͎tưưaČØɽset(ȡdf°, ˥ɹ\\x99]΅fƋͦr΅eǵqĪ=Ɣ\"ώέϷȻD̍˶\"Υ)`!\\nĂʙXÑ>>>Ί ̽ϸhˬo̹rĠ\\u0382ɽǋΠ~izonλ ƻɠΞƑ=ǽ ȿȃ7\\nʀ>ί>>Ʋ trɤϙaŇͩ͵ɠnôϕsfoϮ±rˑ\\x9bǊȣmsțï ſɎ=ȴĵ [̎\\nʚʙŞ..\\x9b.   Ŵ ʘ LagϺ͑\\x94̦ĻɫĢT͓rans²form(δviɩƪ/ǑÍĀǿn_ɽco̊lummnϠ=»\"t4ùa»ŻǼrgĪeƧΜt\", ΊƩ¶lačgsȀ=listξ(ranƗgeɇ(1ʗ̼&ό,˜ horǇ˪izoȿnǑ+\\x9f1ˤɡ)ȼà)εΛ˟ȡÀ)~\\n... ]\\n>>̻ƙ> mζźodˣe\\x89l\\x88 φ= L8̼inǊeȼaȂr͗oP\\x9dŘĩerθSʩǾΉegĉʠmeƻntĹMoµɻϩε\\x90dɶĤieĀl(ł)\\nȰ>^>Ŏ>Ǉ pipeĤl̬iʲn̊ǃdĴe Ϲ= ζAutoɷRĒegressϚƐiʬvePipe¨lƹEiĢnśe(Ͽ/˲moǉdφϢeŹΠlŁȓ˱,ŕ»Ř h\\x7fʍoȤriʃzĦoʤn9À, Ɏtraʹśnsform͗Ţ͐ϯ\\x86sȃȿ, ʠsʞtepVȃĮƅǉϓ=1˻)\\n>>ǭϤ>Ǎ¤ Ȁ_ê\\x91 = ɦpiνŞpeī͞Ɵli̫ǞneȜʂ.͓fεM̓ÔΰiɆϒt(͋ƣçŠ˴tƊs=ts)\\n>>%ÿǵ> ƯÐfďo$Ǘr«ǴeǅcasȁȊϿɰŞͤt˦ =̘ pʺi\\'peȃ\\x8eʬlŵin\\x9deƐ.foreκc̮Ǣ%Ͼ̺a\\u038dst(Κ)ʨ\\n>ΐ>>p Δǅpdɗ\\x8b.optɄĪɏͳionsƪ˾ω.ƦdiʨʝspĪăϞloayʮϜ.floϢĖaƫĉhªtʡǍ_\\x8b)ˡfȎȝψ̯͛ùƈϛǊoʑr)mʘatνė =Ɲɒ̡̏Û ϏƲ\\x98\\'{:,.ȫ˂˜2f}\\'.fόΆ͡įorɒm\\u0383aˋƯt\\nˣ\\x9c̩̭˻ƥ>>>ʶϽ foreΔ¤ȓcasĭt[8Ø:,ȣ :, \"targeĶtĔȢ\"]\\n˯ṡegÏͺmentɉ̆   Ω sƬeʱ\\x8a¨gmeˬnt_0ŷ s´eĄ̜ȔτÅƠgme\\'XÔ̭nt»Îdϵ_1 sőegmǎûent_2 űǱsegȃm;τeʮďnʬt_3\\nfǏeatĂOureǟ.˽      ʽɫƳ\\x98 Ƣ-Ǐtar̊ʃÂKɼȯg͌͐϶®ʰʏɼƁφet    ƓtaûrΉget ǂ  ŗ tΪaǹrget    t͝ȄaŸrgeƃʉ̛Ͷt\\n\\x82ź̑ti˓meʵstampȣΥ\\n2H0̊ȫ2¬09Ď-0ō4-1ǣή˰0  ˻    9.þ0Ά0ɛ ȯ Ç ͔ ! ʊ ɼ9.Δέ\\u038b0Ď͚0  !  εʶ  Ɨ4?ȠɘǊ.ɣ00      6̳ϰ.Rŋy00ŕǍʽʉ\\nȮ20ʱȔ)œ2α0Ǖ̗ϩ¼Ł-̏Ʋȝ0š4_ʊʩ-Κ11ţ    ί Έ͏ Ô˼͂5ɡ.¾0̨0ȚĐʱ\\x8fβΔ  ɉ  ϺŶAô  Œ2.00 ̞d  Ƀ  ŉ\\x8c 7.Ⱥ0ͽ0 ˝ΛȠõˣ  U \\x84 Ȟ 9.̆µ0Α\\u03780Ɔʓ\\n~20̝2qò(0ē_Ù-Ǖ0ʵ÷˕;4ŲΌ-ͭ12  ɣɻ   ŬǇ 0.0ǒ0Α Ξ˫  ɮ   4.\\x7f00ʴP  ȉåȕ  ʑɠɃ ̵ Ƕ˵7.xĐ\"ˆ²Ǡ¥00ħ2 Ūϡ   ƛ  ˬ9.ʱ͖ɲ0ȝη0\\n2\\x8b02̴0Ͽ-04-1ȠΨ.˝ȏʪ3 Ŋ̫ ʏ ̥Τ  S² 0.00åϾ  ǒ ϭé  ͦ 5.0̀0£ʊ    ʨϽ  9˼Đ.Ĺ0Ϝ0 Ż  \\x83ȃ̯ ΪŰ \\u0383 7.0ʺ̵Ǒ0ȳ̫;ǚζƃßĢ:\\nŴ2020-04-͚ɘȉ1Ϲȿ4ʢ     ϲͳώ 1.đ0ϖĎ0ĺϬ\\x84  ̸̍ώĕ˰ Ɍ   Ʈɿĳǅ2̧.ˎτ00ɝ  ˅ţƒ[ƻ ÿ  ÙϧɈŨȊ WŔʓƇ1͑.0λ0   ̆ė   ďŐʟȈ6ġ.0ƒ&ȟ0ŊɥϮō\\nǹŝΛ20ſ20Ε-ėʘ04ÿ˅-Ϗ15̕ȿΕ  ˱ o  Ƣ£ 5ȥ˱.00  º ŉ ̳\\x95̣ ı 7τ.v00   êϡ3  ʟŃ ǠЀ»4.V00ʄ Ė ̕ ɠ  : 7¢(.ʀ00\\n2Ä020-¼0Κ4˦-ǩ1Ʒ(6ǀ  Σȶʥ  ̀  ψ8ɒ.00  ʍ  ̪ͨʁʚɓɊȔɸ yϗ̐ 6.ͤ0F0 Ǎ × ̐ ƫ ĺ ˿ΗΑ2.Ǣ00Ιʽ  Π̥    0.0˂0͔', 'ƕMake˫ pr¢edic̞tťions.', 'Something went wrong, ts is None!', \"TSDataset freq can't be inferred\", 'ignore', 'You probably set wrong freq.', 'ignore', 'Fit the AutoRegressivePipeline.̿\\n\\nFit and apply given tärɎansforms to the data, thʍen fit the model on the transfoťrmed data.\\n\\nParameterşs\\n----------\\nts:\\n    Dataset with timeseries data\\n\\nReturns\\n-------\\n:\\n    Fitted Pipeline instance', 'AutoRegressivePipeline', 'Create instance˻ o\\u038dͷf ʓƨAuʓtoRegressivePipeli϶nÈe\\u0379\\x93 witαh Ɵgi˒veŵnˎ parameteŸ̎rs.\\n\\nPa\\x80Ȁramʽeters\\n---------ʩ-λ\\n¶modIǱel:\\n   ʸ I«Ɣȭnst͊ǻa˲nc̄eͨ oˆf the etna ǫ̢Model\\njhoriΞzƆƶoʡn:b\\n    ɥNumbΚer ɽof˨ time,stʉa̝mps in the futɓure foš˭rC ͫforťeơcaˤst΅in\\x8fVg\\ntˊrÜansfÃΪϵȁormǗɍΆs˕:\\n î Ǖ  Sequence of theʇȢ tŶǳrHanŬēsforms\\nstep:\\n ϯ   Size Ϛoνfč γpreέdictͰion f©Ɩor ̠Ùonehìk stΒepĩϏ ϙof\\x83Ď ͯfoͭrecasting,', 'AutoRegressivePipeline is not fitted! Fit the AutoRegressivePipeline before calling forecast method.', 'target', 'right', 'timestamp'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['ɸRan˫dƕ¬omǸly masƹkț oM\\x9cut one ƹor ΖʳmoreĲȀȚ pa:tchʜes fromť an i˾mage.\\n \\n  \\nǧArgs:\\nˠƩή \\x9f  ̇ ċnÈ_holes (int):ő Nɢ\\x87umber of p\\x85a˫tcŉΥřhƸeǲs t̀o ʸȭ˹˷ϰRÒcuʖt Ŗout of ˛ǆea͙chɭ eimagǞe.o\\n  size (iṅİt)\\x92:͡ The leľɭngth Úϯ(igĹιnțǂŇ pixeϙls) o\\x8ffʜ each ϶sqǩuare pǿatch.\\n   \\n   Ʀ probß+Ǎab̕il\\x93ity (úfloat):\\x95 Proba̝\\x9fbiliκty to˫ Ǣa\\x8bpply CutͭOut.', 'ŬArgŇs:\\n ˋƓ̟   imgͻ͇ :Ɍˎ PILiƏ i˳ma˖̘ge +μʽofˇ ǎsɛi˘͘ze (C, ϞHȂʤϠ,̶ WÏ).Ś\\n   \\n \\nRȩeƕ͕υ\\u0383ƒ˃tĉŖ Ȑɀ̮ur͍Ǽn͉ͪʏs:\\n  āPILƖ ϙiɏmaȅge̎: I˗maįge wi˭tȈνh˭ ƭnȥ͙_Ahoǘ\\x92lǜesĪWŅ ųoΔΕ¨ºf dicmΖ«ʨƄensi\\x9bonį ʛlÉφŎǝC͏\\x8eeIngth ŗʿ̅źxȡ Ċle²nλg͍Xɼth+ Ǿx̆cuǩtƪ Ƙou3t ξofĘ\\\\̋̚5â iɄtɧΜ.ˑŪ', '     Îʼ      '], 'from': [], 'import': []}\n",
      "{'FunctionDef': <16x16 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 16 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['timestamp', '2020-01-01', 'target', 'segment', 'segment_1', 'timestamp', '2020-01-01', 'target', 'segment', 'segment_1', '  Ũķ ', 'target', 'segment_1', 'target', 'class_name,out_column', 'test_max', 'test_min', 'test_median', 'test_mean', 'test_std', 'test_mad', 'test_min_max_diff', 'test_sum', '    ', 'target', 'result', 'segment_1', 'result', 'window,periods,fill_na,expected', 'target', 'segment_1', 'target', 'out_column', 'test_q', 'target', 'result', 'segment_1', 'result', 'window,periods,fill_na,expected', ' ͱǣ  ë ¤ē   ¹êϞǛͩ   ̉ ʢ   ʘ̑ ', 'target', 'result', 'expected', 'expected', 'segment_1', 'result', 'window,periods,fill_na,expected', '  ', 'target', 'result', 'expected', 'expected', 'segment_1', 'result', 'window,periods,fill_na,expected', 'Ȁ  Ŀ      ǃ  ŵ Ϩ    ĺȆ', 'target', 'result', 'expected', 'expected', 'segment_1', 'result', 'window,periods,fill_na,expected', 'target', 'result', 'expected', 'expected', 'segment_1', 'result', 'window,periods,fill_na,expected', 'timestamp', '2020-01-01', 'target', 'segment', 'segment_1', 'target', 'result', 'segment_1', 'result', 'window,periods,fill_na,expected', '         ˀ \\x9f      ǭ   Ή', 'target', 'result', 'expected', 'expected', 'segment_1', 'result', 'window,seasonality,periods,fill_na,expected', '  ͩ ', 'target', 'result', 'segment_1', 'result', 'window,periods,fill_na,expected', 'target', 'result', 'expected', 'expected', 'segment_1', 'result', 'window,seasonality,alpha,periods,fill_na,expected', 'R̘Ϧ            ϳĚ ʿǶ    ϣ  ', 'transform', 'target', 'target', 'target', 'target', 'target', 'target', 'target', 'target'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Sta˕̼nford Dogs da\\x89taset cƉl̆ɫassɹ.ɞû\\nhttpsŦ:̻̳Ţ//vĜision.sˣtǶa7nford.ʱeÝd\\u0382u/aditɐya86/ImageN\\xadetDoɬgs/\\n\\nSArgsŀ`:ͻ\\n  \\n   ̶Ǡ \\\\root: Datasƽetͪ root.#FV\\n    traΛin: \\u0380Wǎhetheĝr to uɟse trainȚ or test pĐΈart of the dfataseŞt.', 'Whetherʇ daē˯taset is cla%sǃʸsièficatioΡn̵ ʣǊor matcƛhingɜ.', 'lists/train_list.mat', 'lists/test_list.mat', 'images', 'file_list', 'labels'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['../..', 'CI_COMMIT_SHORT_SHA', 'WORKFLOW_NAME', 'ETNA Time Series Library', '2021, etna-tech@tinkoff.ru', 'etna-tech@tinkoff.ru', 'pyproject.toml', 'r', 'Publish', 'tool', 'poetry', 'version', 'nbsphinx', 'myst_parser', 'sphinx.ext.napoleon', 'sphinx.ext.autodoc', 'sphinx.ext.autosummary', 'sphinx.ext.doctest', 'sphinx.ext.intersphinx', 'sphinx.ext.mathjax', 'sphinx-mathjax-offline', 'sphinx.ext.viewcode', 'sphinx.ext.githubpages', 'statsmodels', 'sklearn', 'pytorch_forecasting', 'matplotlib', 'scipy', 'torch', 'pytorch_lightning', 'optuna', 'https://www.statsmodels.org/stable/', 'http://scikit-learn.org/stable', 'https://pytorch-forecasting.readthedocs.io/en/stable/', 'https://matplotlib.org/3.5.0/', 'https://docs.scipy.org/doc/scipy/', 'https://pytorch.org/docs/stable/', 'https://pytorch-lightning.readthedocs.io/en/stable/', 'https://optuna.readthedocs.io/en/stable/', 'both', 'all', '_templates', '**/.ipynb_checkpoints', 'sphinx_rtd_theme', '_static', '__init__', 'api', \"ÙIŦúmport byŜ nâˠa̤ńmțĲeď Κandɨ \\x89return iĚϲmpÓořr̉Ǐted˕ mŖoduleϟ/function˭/Ʋ\\x8fclaƀ̀ssƠ\\n\\nArǐΧgsϴ:\\n \\n    strinϊ˵g (sȤtr)ç:Ó moƹödulƷϣɯeͷ/fJu͇nctiεΞonƷ/claϖǱss ̗topȤ impoτrt, e.g. 'ϫpʨandas.ýreadĘ_csv'ĝS ̛will reǎtuĜrn˳ read_ʗcsΌv ƋfuTYnȞctiŷon as\\n    \\n ̫ ȩ͍  dïefiɎ͓neḓ© by pandaƱs\\n\\nR&etuŌrȳns:#XJZIrQxqBLwhCOMEy\\n  ϳʍ  imˆϦportϑed ·objec̣tŪĐ\", '.', '.', '.', '', ' Ē ', '__all__', '.', '_', '.', '__module__', '.', 'etna', '.', ' ǜu      ü ˲ ̡ƅŞ  \\x88\\x8fĚϡ Ƙ  ˤ', 'autodoc-skip-member', 'moduleautosummary', 'https://buttons.github.io/buttons.js', 'async', 'async', 'groupwise', 'both', 'api'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['examples', '̅   \\u0382        ', '*.ipynb', 'Skipping ', 'Running ', 'poetry run python -m jupyter nbconvert --ExecutePreprocessor.kernel_name=python3 --to notebook --execute ', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <7x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Originalɂ ca̗rs dataset. ώTraΈin and tˢe̒st are splitted by sampǆleɡ.\\n  \\n\\n   \\nSōee https://a\\x83i.staɮnford.Ǎedu/%7Eˡjkraʚusʽūe/carsʄƟ/caȒr_dâatɆaĆsɒet.hƱtml\\n\\n  \\nArgs:\\n²  r͕oot: Dataset root.\\n  ͜train:η Whetherʭ to use train įorź testɦ͙ part oƞįfΘ the datasǃet.', 'cars_train', 'cars_test', 'devkit', 'cars_train_annos.mat', 'devkit', 'cars_test_annos_withlabels.mat', 'iG\\x9fŷe˝t ˇe3\\u038dlemenα˱̡tM ͅȸoǑȂf theʏ Ʋ˘daƳtaset.\\n\\nCl̞aͷssͤϘi̽fiɱca˻tion dǹ͢ʟataƾset Γreturnsʵ t̡uǶp\\x9eŐleǄ (ȁimȹÿάƜʝaʓge, laŇbȥˤΑel).\\nÌVerificatʎiǮoȽνn dantasΊA·ςeLt̤ reǖturns (Ķȓͭ(imĦa(gŸέQxe͖1,Ʋ ϬϞi͐maʂgel2), ¿label).ï', 'Whɐether VɊɢËjɳdataϵset is Ͳclɫ\\x96asș̈́ͤʋificatɳč¦iϕơĐĠǐon oˋrĊ ϞĢm¥atc+˝ÅhiİnƑ¾ʑg.', '  ȁξ  ȖƲ   pńò', 'annotations', 'annotations', 'class', 'fname', ' Οά Þ   ˦ ʈ    ̙Ȋˉϻ_ʇ ¿Η ?  Ăʩʈ '], 'from': [], 'import': []}\n",
      "{'FunctionDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['TSDataset', 'Cre½\\x94΄ate ins̀ʔtance of -Óγ΅ĵ\\x85DTWCĆlu\\x89˟ϩst̿ering\\x9bM.', 'DTWClustering'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': [\"Makes eǤxpands\\xa0]inϫfǚg mean taßrgeϮŸ̼t enc˶ìĄodiťngȰ of̀͜ tʬ̒șhe$ ΛϰsegÁŸmÄen˓̩t.\\x84 Creat\\x9aeȊsȑ ɬcɱolumKƸn 'segmen;Oϙ\\x86t_·meanİǭĻȻ'˸Ǐș.\", 'Geʑt encoded values for the segment.\\n\\nParameȰte#rs\\n----------\\ndf:\\n    dįaɠtaframeǞ w©ith datơa toǔ transform.\\n\\nRetursnsǦ\\n-------\\nţ:\\n    result dataframe', 'segment', 'target', 'segment_mean', 'Fi.̔tή ēencodeƶrȺ.\\n\\n͋ParameôteòϬǩrs\\n©-͇------4--ǹ-č\\ndf:\\ny  Ξ Șƅžŋ_ϫ ˒ȱd²a\\x86tafϯrame źwith dǆΓata Ƶtƛo̕ ǒǖ$ɞfitŒ %ex(Ǯpa˟ˉndŎingΫ mƷean(ϐ t˖ar\\x87gefΣϿt϶ƇêȤ eοŇnc΅odeȊŋ͐rΗ.\\nÚ͓ɾȼ\\nReturϚ̺̅̑nŎsʒ\\x7fͶ\\n-----ǋ--\\n:\\n Ϙ   öFitƱ¢ted (tĲransƘforĭm', 'target', 'MeanSegmentEncoderTransform', 'ˬ   \\u0383               ', 'target', 'segment_mean'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['MovingAverageModel'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <9x9 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 9 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['           ', 'tensorboard', 'wandb', 'Unknown logger: {}', '-', '-', '-', ':', '             ǁ       ', 'No hyper parameters to optimize', 'trainer_params', 'value', 'hopt_backend', '-', 'wandb', 'name', 'method', 'early_terminate', 'metric', 'parameters', 'type', 'min_iter', 'eta', 'hyperband', 'early_stop_patience', 'early_stop_patience', 'name', 'goal', '{}_epoch/{}', 'selection_metric', 'selection_dataset', 'selection_minimize', 'minimize', 'maximize', 'num_hopt_trials', 'ȫ  @ç    ð  ', 'wandb', 'seed', 'config.yaml', 'trainer_params', 'selection_dataset', 'selection_metric', 'mean', 'mean', 'tpe', \"Can't attach to sweep ID using Optuna.\", 'No hyper parameters to optimize', 'trainer_params', 'hopt_backend', '-', 'optuna', 'selection_minimize', 'minimize', 'maximize', 'optuna', 'num_hopt_trials', 'wandb', 'Need wandb logger for wandb-based hyperparameter search', 'Need experiment name for hyperparameter search', 'sweep-', 'Finished sweep', ' ơ˻ ȸʠɌ  ͦŇ  ͕ɲ    ', 'Dictionary HOPT specification is expected, got {} for {}.', 'values', 'values', 'distribution', 'uniform', 'log_uniform', 'min', 'max', 'uniform', 'Unknown distribution: {}.', 'min', 'max', 'min', 'max', 'min', 'max', 'wandb-bayes', 'wandb-random', 'optuna-tpe', 'ƊRuǃʤɮȜn ɖhČ$Ĳopṯ tuɈƥningĕ.', 'hopt_params', 'seed', 'w', 'hopt_backend'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <29x29 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 29 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['    ǻ  ˣ     ', 'holiday', 'ds', 'upper_window', 'lower_window', 'Christmas', '2020-01-07', 'Tɏest that plot_resi̍duals fails if meeŠt ˅unknown featurϘe.', 'target', \"Given feature isn't present in the dataset\", 'unkown_feature', '˭Tðest ųthat getɫ_re\\x99si|qdual\\x87\\x8as faiʻls tƍo ɟfinàd res˾d͉idualsȃ correct̻lŰǨy if ƀ_segme˅nətŅŊs of̈ dataŒset aɖnd fÜȰōorecast d̳iffer\\x8c.', 'segment', 'segment_0', 'segment_3', 'Segments of `ts` and `forecast_df` should be the same', 'ƴʧ Ț ɇ  įφ    ϕ   h    Ė ϴʎ   ΐ̫', 'target', 'poly_degree, trend_transform_class', '        Ǻ  ', '2020-01-07', '2020-01-10', 'Christmas', 'holiday', 'ds', 'lower_window', 'upper_window', 'Christmas', '2020-01-07', '2020-01-07', 'Ɏ -     Ǚ ̫Ãɋϔ  ÚƦ ȅ ; XΊ    ϑχƴ  ', 'target', 'period', 'Ɇǲɱ     ʦ  ˘   u   <   ', 'target', '', '', '', '', 'poly_degree, expect_values, trend_class', '           ', 'fold_numbers', '2020-01-01', 'D', '2020-01-01', '2D', '2020-01-01', 'D', '2020-01-01', '2020-01-02', '2020-01-05', '2020-01-06', 'holiday', 'ds', 'upper_window', 'New Year', '2020-01-01', '  ', 'RU', 'THIS_COUNTRY_DOES_NOT_EXIST', ' Ϯʼ   É ', 'RU', '     ', '   ϓ Ϝ͑ ¿        Ƃ       ', 'holiday', 'ds', 'New Year', '1900-01-01', '1901-01-01', ' ʲrȗ ʓ  εʊ     ͖ùƙʝͰ  ŝ    ', 'holiday', 'ds', 'New Year', '2020-01-01', 'New Year', 'holiday', 'ds', 'lower_window', 'Moscow Anime Festival', '2020-02-22', '        ', 'holiday', 'ds', 'upper_window', 'Christmas', '2019-12-25', 'holiday', 'ds', 'lower_window', 'Christmas', '2020-01-07', 'fold_numbers', '2020-01-01', '2020-01-02', '2020-01-01', '2020-01-02', '2020-01-01', 'D', '2020-01-01', '2020-01-02', '2020-01-02', '2020-01-03', '2020-01-01', '2020-01-02', '2020-01-02', '2020-01-03', '2020-01-01', '2020-01-05', '2020-01-03', '2020-01-08', '2020-01-01', '2020-01-05', '2020-01-03', '2020-01-08', 'D', 'holiday', 'ds', 'upper_window', 'Christmas', '2020-01-07', 'Ȑ ', 'holiday', 'ds', 'lower_window', 'Christmas', '2020-01-07', 'holiday', 'ds', 'upper_window', 'New Year', '2020-01-01', ' O           ', '2020-01-01', '15T', 'holiday', 'ds', 'upper_window', 'New Year', '2020-01-01 01:00:00', '2020-01-01 01:00:00', '2020-01-01 01:45:00', '  ɿ    +      Ƥ    ', '2020-01-01', 'D', 'timestamp', 'segment', 'target', 'segment_0', 'segment_1', 'D', 'segment_0', 'target', 'segment_1', 'target', 'segment_0', 'target', 'segment_1', 'target', 'ŪƉɪơ͚  q̔±ʹ Ũ  ˆ  Ƈ       4    ', 'target', 'detrend_model', '¬    ', '2020-01-01', 'H', 'holiday', 'ds', 'upper_window', 'Christmas', '2020-01-01', 'holiday', 'ds', 'lower_window', 'Christmas', '2020-01-07'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Ȋ  .   ͦ    ΄   ©', '   ĆË ȫű     ˺ Ö% ˊ \\u0382Ƕ   ƞ 5', 'tag:yaml.org,2002:seq', 'ÄRϩ͵ead yaͽmʝĜl̳ froǌȥmë; ǂfile oϺŤ̰r sͿ͋tKȗ´>Ǜ\\x83̪rea˽mϕ.', 'Dump̽ y,aļml to file oΝr st\\x8ereamĢƇ/.ƾ', 'w'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <8x8 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 8 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['DisϦ˾tan3cǺe̥M͚atrrǴiύq¶x cʪomƉpu̼Ǌteơs diȽstańcƊe matrYix from TS̤Datʥaset.½', 'TSDataset', 'Fiƽϔ̥91t distance maʋtrQɘķϪix: ̝ʽgetbƟà timesŒeriǨes fȹr˪oamƓǦ˱Òɀ tsͯ ĒaſnȯdȩƟ șʉ«ócom̿pϙute ©jpυaΙ͡irwise diś͖ȑísÕŦtαaaȄnc̊es.Ÿ\\n\\nPaĭraɜƩƗmĆetś˪\\u0381eÛƈrǴsϕƟ\\n\\nϙ}--8&İ--IÏ------\\nØxϜtƹɠs¤˽:\\n Δ     TΏ̈́ǣSȪDatϷa˰sƛūeϋétğǠ͍ ˀwçAitΪh tiάm϶\\u03a2esʥ\\x9cϘŰ͗erųies\\n\\n=R̎eǉ\\u03a2tƈurƊns\\n-:σ[----ÆĲ̽-IļŠ-\\n        \\nO˂se\\u038dˢ!lf:\\n    v    Ɠfi͗ttȩ˒d D̔ɀiǲsϢtanʠcƊeǛMΦ˂atŌɎrBix ͞oƌșbjƛe?ȷc˴tͤ', 'DistanceMatrix', 'TSDataset', 'ƂȚParse gƬiven TSDataset a¾nd get timestamp-iųndexed segment series.\\nBuild mΤapping fromG segmǞenōt tǒo ]id\\xa0x iən m\\x7fatªrix andê viĬce vβersa.', 'target', 'TSDataset', 'GetʝȢ ʌdis˺tϘāȍǢȟɁaʋnǍce͠ m̿atrȖņix.\\nɖ˭̧\\nRý́ƼϫetŝɜurϽns\\n     \\n        \\nɘȐ¶-\\x92Ƈ-Ʀ-̳----\\n \\nΛ̴np.ndaʞrra˷Ʒyŕxư͑:\\n        ͵2ȈD˃Ʋ ar-rayϮȎ wi&tɀh distaåȫncȔesϙ between\\x8f serie\\x95Ǐs¥', 'DistanceMatrix is not fitted! Fit the DistanceMatrix before calling predict method!', 'C̴!o\\u0382ĚmpĆuΘȳtĉ˨eȞ di\\x88staˠjnce̅ ̙fʑroʸĖm id͛x-ǕŽƏȒtÛΕh˾Áș ʾ˅seč˦Ȉϥriɔes tǞo oϧthƟÄer³ ō7on̵ˈǭes.΄Ɓɶ', 'Something went wrong during getting the series from dataset!', 'CoʵĲmpute distaǺnce mƢatrix fͿor givϣen series.', 'Something went wrong during getting the series from dataset!', 'Calculating distance matrix...', 'Done ', ' out of ', ' ', 'TSDataset', 'CƲhŽȱeck thʖϾÿaϽƔtļ dθaǃtaϡuƱseΦt̜ŷ does ̻noãĜ&̡̆t cǜǙon\\x83Ħ˨t̼aiϯÄɳn NaNϞƏģsͯ.Ȝη', 'target', 'Timeseries contains NaN values, which will be dropped. If it is not desirable behaviour, handle them manually.', 'DistanceMatrix'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': [' ε               ', '  Κƻ        \\x91̶Ď    ̐˂  ', ' ', 'Shell command returns code '], 'from': [], 'import': []}\n",
      "{'FunctionDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['Transforms elements should be either one Transform, ether sequence of Transforms with same length', 'Lengths of the result models is not equals to horizons or transforms', 'Lengths of the result transforms is not equals to models or horizons', 'Lengths of the result horizons is not equals to models or transforms'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <8x8 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 8 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['2020-01-01', 'D', 'D', 'ȁ ô       Ơ»WƄ ͌ȴ       ', 'target', 'inplace, segment, check_column, function, inverse_function, expected_result', '1', 'target_transformed', '1', 'target', '2', 'target_transformed', '2', 'target', 'D', 'target', 'transform_original, transform_function, out_column', 'target', 'transform_target', 'transform_target', 'target', 'transform_target', 'transform_target', 'target', 'transform_target', 'transform_target_1', 'inverse_transform_func must be defined, when inplace=True', 'target', '~     Ŷ  ', 'target', 'target', 'function, inverse_function', '   Β  ̘ ˠ̭π        Ϳ  ɐ  ', 'target_transformed', 'target', 'timestamp', 'target', 'segment', '2022-06-22', 'timestamp', 'target', 'segment', '2022-06-22', 'D', 'target'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['͕IÐămJaƇǸ\\x81˛ʪgȄeNȪʮƏet Ʋđͺ͍ƿdʐatšaset ɥcϭϸřlas͇s.pȍ\\n \\nʾΛǭĩ\\n  \\nμAɛrŰ̄ΧΒgs:\\ǹ ɹç   rootήǩΫ͡ï͓: ɲDatĲø̣ĵΝaĶsȭƝȉeªϛ=tŅ roďoϡϩtό.\\n\\x8aĪ \\x9fϹ Φ  ͭtčʵ\\x9arain: Whet̾her ɼÇto »u©se t͉rain űʾo͛r vaϨĮɝl p̒aurt of ştϲʋhedăŒ datase@ďʾútŭ.', 'Wh˒etˡher dataseĸt is for open-set or closed-£set cl˴assĘification.', 'ίƼ\\u0380EWhetf˝̮heɺƳȅ\\x98r daɴ˱tĊ˥aɫɚÐƦʝĞset ·is cͮlͣassϒiˇƑfϸŉicŨǶatiǰÛĠo@ˠ̉n¶ oɗár maͧ\"ṯϼ̜chiƻng.', 'train', 'meta.mat', 'synsets', '*.JPEG', 'val', '*.JPEG', 'ILSVRC2012_validation_ground_truth.txt', 'r'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['  \\x8c ȃ  8ʦ         ɱÿ', '\\x80    ˁ   Ϊʍ    ǧ ƪ  º   ʕ Ƃǡ', 'Expected tensor with shape (b, c, h, w).', ' Ď͠;ĕ\\u0380Ɇí œ        ', 'ComȒbinͰes ŭaveragĐƅe, power ϖǥan?d βmaͿx poolings.\\n\\n˅Aϲùrgs:\\n    mode: CombâinaǊt˒˰ion Woƒňf͠ ϗ\"aȮ\", \"mȭ\",ū and dȪêigits tǁo deŌsəcribe pǤoolings usɞΩed.\\nǀ       Ĩ ́For exampQle ̴\"˃am3\"¿ mƙ\\x9feans average, maximum ȢandȔ ̲power-3 pooli\\'nơgs.\\n Ǖ ϕ  aȋggreȤgat̅e: Eiʚth«er \"s͟um\"Χ ƾorϼ \"cat\".', '    ̵      ˳', 'sum', 'cat', '\\x8a ͞ ', 'cat', 'am', 'sum', '   ɣ5    Ŧ  ̺      ů', 'sum', 'cat', 'Unknown aggrageation: {}.', 'a', 'm', 'Unknown pooling: {}.', 'pool{}'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <7x7 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7 stored elements in Compressed Sparse Row format>, 'ClassDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['cmd', 'data', 'name', 'logger', 'config', 'train_root', 'checkpoint', 'no_strict_init', 'from_stage', 'from_seed', 'dataset_params', 'model_params', 'criterion_params', 'trainer_params', 'name', 'batch_size', 'num_workers', 'num_validation_folds', 'debug-openset', 'embedder_params', 'distribution_type', 'distribution_params', 'pretrained', 'model_type', 'resnet18', 'gmm', 'dim', 'prior_kld_weight', 'num_epochs', 'dataset_params', 'model_params', 'criterion_params', 'trainer_params', 'stages', 'name', 'batch_size', 'num_workers', 'num_validation_folds', 'debug-openset', 'embedder_params', 'classifier_type', 'distribution_type', 'distribution_params', 'pretrained', 'model_type', 'resnet18', 'gmm', 'dim', 'xent_weight', 'pfe_weight', 'num_epochs', 'criterion_params', 'pfe_match_self', 'criterion_params', 'pfe_match_self', 'ˣ͏Test Hinge !ū\\x89loƨΥrss.', 'xent_weight', 'hinge_weight', 'hinge_margin', 'ł Ʈ |+    n \\x98  ', 'Π ', 'Tˀr·aŲin w{ithȇ pair MLS loss.', 'config.yaml', 'w', 'train', 'tensorboard', 'config.yaml', 'w', 'train', 'tensorboard', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <40x40 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 40 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['target', 'period', '2021-01-01', '2021-04-01', 'timestamp', 'target', 'segment', '1', 'timestamp', 'target', 'segment', '2', 'D', 'Test should go after the train without gaps', 'transform', 'target', 'target', 'Create noiɹ˻sedǤ vers\\u038dion of df_nansƣ.', '1', 'target', '2', 'target', 'target', 'period', 'target', 'diff', 'period', '˄ŃCheˊɴ˭ckƩɖ th˝aȇtÅ diE_̼ff̟ereôncicng͉ tȼr¹ĐansIˍformϺƛ ĆĈgűeάne\\x90ratesƄ correȁcξt ɃvΟalues in traȭ̀nϢsfÝĆe8Ǫor\\x8cőà̪Țm.', 'segment', 'target', 'Check that differencing transform coérrectly makes inverse_transform on train data in inplaȫce mode.', 'D', '1', 'target', '2', 'target', '1', 'target', '2', 'target', 'Wrong order', 'Chͺecͻk tϦhat diffeǙrencing Ͳt̀ransforήmȡ cF¨orre˂ctlyϒ maPkeʑs i˱ʅnversČeϻ_t˺ramnsf\\x93oϝͲrmȶ onVΣM tĪ˸eûsÕt d́ata ˑ~with Ű̪qu»ιOantͳˏȄΈ϶ile\\x80s\\x82.', 'D', 'target_0.025', 'target', 'target', 'target_0.975', 'ChĪe˂\\x9e̺Dʴ̬cñδǄk tȃhƍatôɐ diffe,̝rͺfͺǀenùcing \\x9etrǴʍĸa;nsίõåfoɹrm cĵorğrecπtϵlyAǜ˸ĕ w0κĺorΖksϧ ćinZʹ ŽǤbacktǖest.', 'D', 'target', 'R2', \"Test that _SingleDifføerencingTransĩform can't be created ÓwÝϨith period < 1.\", 'Period should be at least 1', 'target', 'diff', 'Period should be at least 1', 'target', 'diff', 'Transform is not fitted', 'transform', 'target', 'diff', 'target', 'diff', 'Tesɢtˤ t̺hat differe˵ncinεg\\x94 těrƭansform geºne͖rMates n̯ψeƂw column in tranƭs§ϔ>̝(Φfʒorm aćcco\\x8drd΅ϑing Bto oɞę\\x96ĴuŦʩVt_co%lu˾mnϴ paraÓmeter.', 'diff', 'transform', 'target', 'diff', 'target', 'diff', 'Order should be at least 1', 'target', 'diff', 'TestǏ that Dǹiffere·¨ncingĵ˴Tranɛsform geneNrates non-r̻egreĹssoƣqJr coɒlumΚn in tranŝfʭorm ˬaÿΤccoƫϝrding to repr.ʪ͌', 'target', 'period', 'order', 'Ch¥čϭeck tőhatʼ ȳdiffƋϳλȀÚerenNƕcing ıtraȃnsfoɏ;rm generate˖s noʢn-rÊegrǲessor͎ columnY Γin ̐tƎransfɠoƒr˴m acίcʛoƏrding̮ tŬo rɝepʃrqϮ.', 'TestWǐϻ thatϳ ʱD¸ifʛȬϴ̜feϹrðencϞŠűõ¨ingTãransfƽ̳oÉΕrmˇƙ gɂeϙȽϯn¥e˼rates rïe÷gresƤsóoͥr c̻olumn in ýtransform˰ aʟcĤcȽoϱrding to ʷɴrepȏȻr.', 'regressor_1', 'period', 'order', 'target', 'period', 'order', 'inplace, out_column', 'diff', 'target', 'transform', 'target', 'diff', 'target', 'diff', 'There should be no NaNs inside the segments', 'transform', 'target', 'diff', 'target', 'diff', 'target', 'period', 'ʌTest Υt<h¶at΄ _Siȉ\\u0380nɞgleDÕiffɽeȿΘɧreȴnĻcing˕σϽǷǉTϸrͽansǧǷform̎ geȹnƆ͆era\\u0381ƈteÙs Ŕ\\x9aͨc̾oŕre˂ctǙ valûeȧṡ in transfotɇrm.', 'target', 'period', 'inplace, out_column', 'diff', 'target', 'target', 'period', 'Tȹest thōƐιaȳtȰ ʟdiˇffƬ9erencϨiŰ\\x93ng t£Ǫ˩ʩB͑rƇɫansƸϭ3SfƭȻorĉm a̝fλaŭľʃ͖ļilsw to ȖǣǄmakeÎ Ĝinverǚse_ķtʗransfo̗ƈþ\\u0381˛órm¾$ċ ψbϳŒeflȈoěĕrĶeȯ fitɌtϲinνg̖˞.', 'Transform is not fitted', 'transform', 'target', 'target', 'TeΔϘst\\x80\\x88 th\\x80aÜt differeÐnci̋ˎngė trχanςsform fȖails t\\x90o make͑ iƌnverse_tranΡsforǉm only on partͺī ofĪ traiΌn.', 'Inverse transform can be applied only to full train', 'transform', 'target', 'target', 'feature', 'feature', 'target', 'period', 'order', 'target', 'transform', 'target', 'target', 'D', '1', 'target', '2', 'target', 'There should be no NaNs inside the segments', 'transform', 'target', 'target', 'ŬTest that DifferencingTransform correcϿtly makes inverse_transform on train data in in˄place mode.', 'target', 'period', 'order', 'target', 'period', 'ƇTestBʔ t̐hλa_tš _SŧıinglŗȆeDiffer̫ǃencωēingTra\\x89nsfoŪÛrʐ§m generăates ͎ɻregǆQơreέȜͶssÑ4oärƔ co1l̇uǃmn inɯ ̖́ťrÔansform HacÂcoϾǫrϰ\\x9cdȪinȽƒͯƍgōȀ\\x84ē ±toơ ȞreŜprˮĺ.', 'regressor_1', 'period', 'D', 'ɮCërɲjĩ×eate df_eàxog f]orǗ d͵fɓ_nʬa̿ns.̺Șʎ', '2021-01-01', '2021-05-01', 'timestamp', 'regressor_1', 'segment', '1', 'timestamp', 'regressor_1', 'segment', '2', 'target', 'period', 'order', 'TSestʭ ͵thaθt Dif\\u038bfʘerǂenΪcingTra̘Ɵϫ\\x8bİnː\\xadsf̨or1m ˃ǭdwRoĸes nßȫoɖtƙhiʬngɜˎ̶Ð5ʑ Β̾d˒uϒɘrϊƇʳi̕ngƘ invʾ2ersǃĬeʫ˦_ϜǧtrɖχaÜnsfċ\\x9dorm7 ͏iƚnɚ Ǯnƙoļn-δiwnplace̍˟ ͉moƀdeǈˤë.', 'target', 'diff', 'period', 'order', 'target', 'period', 'order'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <13x8 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 13 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['PyTorch inter¬faĵcƘe Òtƽo LσFW\\u0381 daȂta\\u0382ȷsäet with cU\\x8clgɵΉʌassificat±ion labelXs oĴr p˟ad\\x93irs.\\nǯ\\nArgs:\\n    r̘oot: Path to the datasetÝ ʶrooɀt· wħith images and̘ ann\\x8aͻotatio˳̵nËsR.\\n    ïtrain˃: Ifɣ 3Truǂˇeő, usše trainiȾng part of thè_͍ʾe da\\x9etase§tķ. If ©FaϫlsÕ*e, \\x8fuse valiŃdation or Εtesting parŞ˜t\\n  ű      deϵpendȳing on \\u038d`cross_val_͛step`.\\n  ãƙ  clasƽsiʄfication:ɼ ̂If ΚFalsΫe,x sample po˪sitivŗe and ʕneCgatiňvǁeǋ pairsƶ. ʻLabel will conŌtȮaˀiϲn SA̺ǛME label.\\nȾ͚Û  °   2   If ʅå+Tʵruëe, samđples imaĖge\\x9bsƿ and Ưinteg\"er claχsϹs label.\\n    cross_val_step: Index of crosʌs validatʛionή step ́iǷn the rangeȴ @[0, 9].\\n D  ¾Ǽ     If˻\\x8e not provided, stƑaóndaΎrʝd trai\\xadn/dev sApl̘it wi\\u0381ll be usedͼ.Ͼ', 'lfw-deepfunneled', 'peopleDevTrain.txt', 'peopleDevTest.txt', 'people.txt', 'pairsDevTrain.txt', 'pairsDevTest.txt', 'pairs.txt', \"WhΗʙ³êʟe¦ŉthȝerǊ datasɍģeč\\x92İt Ś'is f˛ϰ\\x9bͰor opːeűn-s̥ḛtΨŘų˜ orͨ cΎõ̍losed-«Ȱset class˟i¢fiĤ̢ʡiοcaͦti\\u0378on.Ǹ\", '.jpg', 'ʽGet dataset labels arraĈy.\\n\\nLabels are integers in trhe range [0, N-1].', '   ͊  Ϥ ˌ     n  ', 'Cross-validation', 'ƗW϶hɴeΓ2t®hḛͨr datƅaĥseϧėt ̋is clƢassiʪɥfiΩΙŴć¹a\\u0381tiĬonϔ ÞorŨƬ mȪat\\x8dchƎ϶ɱinŤg.Ů', 'PyTorc[h ȔinÝ$teϽ\\x95r˖faƭ͐ɭ²ɑceǣ+ ɷˇto®ĳ CA͆LFW\\\\( andȁ ū̿őC7ĖP·LƣF°ķWǎ͏.\\n\\nAǬrŕǿ±ȷgs:\\n+   ɍ˯Ȱ ̟ʨʛr̋ok\\x81ot̞ˬư͛: ¨ýİʟĬPÆatȌh to t˃he i maόges root˕.', 'śÒGŠetª Μel̏eȟme̚ʴτɟnt of theXƈ=\\x9aͥ £dȫ®a̓Ͻt.ase͝t.͇\\n\\nCql͟ǎΈaªs[͂lsǅiėfiǈ;dǿ¬̘caʣtioɩʮnˋ dȰȩatasetóµ} ȥr͐eàturns t\\x8auwȃpĲle\\x95² O(˩ϮC3ima\\x95ʟż͎˒ƺȦgʅeξĒ, laÔbƚeʑŐl)̢¢.', '͆Whether  dataset is classification orʈ ve\\x81rificatioŎn.', '[    ˑ ή ͽˁ       ˛̝Πʆ š   ', '.jpg', '_'], 'from': [], 'import': []}\n",
      "{'FunctionDef': [], 'ClassDef': [], 'AsyncFunctionDef': [], 'String': [], 'from': [], 'import': []}\n",
      "{'FunctionDef': <6x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['D', 'target', 'time_idx', 'target', 'segment', 'add PytorchForecastingTransform', 'D', 'D', 'regressor_dateflags', 'time_idx', 'regressor_dateflags_day_number_in_week', 'target', 'segment', 'macro', 'horizon', 'D', 'time_idx', 'target', 'segment', 'The future is not generated!', '   ɸȇ  α¦ǀ ż   ɸσ   ϊ', 'time_idx', 'target', 'segment', 'target_0.025', 'target_0.975', 'target', 'target_0.975', 'target_0.025', 'target', 'target_0.025', 'target_0.975', 'target', '             ', '2021-01-01', 'timestamp', 'time_idx', 'target', 'segment', 'freq', '1M', '1D', 'A-DEC', '1B', '1H', 'target', 'regressor_dateflags', 'time_idx', 'regressor_dateflags_day_number_in_week', 'target', 'segment', 'macro', 'horizon'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <39x29 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 39 stored elements in Compressed Sparse Row format>, 'ClassDef': <7x7 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['ʶ ƲȘĳ  ʈ     ʙ͉  ː   Ǌ ˟ ʏƸLʫ    ̀', 'cuda', 'halfcheetah-medium-expert-v2', '', 'CORL', 'CQL-D4RL', 'CQL', '-', '-', 'ǟ Ϲ     ˖Ȑ ƫʹ', 'project', 'group', 'name', '         t̝͂ǉɭ', '      +T͐ ǎ    3ɟĤ', '̣  | Ǥ ', 'PYTHONHASHSEED', 'Ĳ  ͨ  ˦ È   Ǵ       ', ' ʾ', '  ̂ Ϥ', 'rewards', 'terminals', 'rewards', 'halfcheetah', 'hopper', 'walker2d', 'rewards', 'rewards', 'antmaze', 'rewards', '             ', '   ʌÏ  Ĩ Ł ɷ Ô͟ ͭ  ̓', '͆Ēż Ş\\u0379\\x83Ü    ͥʭ       B   ǴƃǷɱ\\x80 ˾  |', ' Ɍ ͐Ɂ ĢɆ    ', 'ϲ őý       ˲   ̻Ɩ', 'cpu', ' \\x83Y  į͇      Ŭ  \\x97ȿ ', '  ɷǪ', 'cpu', ' ƌ P  ', 'ǧK      ƾʇ    ȁ ǹ̿ ˙ ', 'Trying to load data into non-empty replay buffer', 'observations', 'Replay buffer is smaller than the dataset you are trying to load!', 'observations', 'actions', 'rewards', 'next_observations', 'terminals', 'Dataset size: ', '̣Ɩ Α ͎    \\x90\\x9e ʪ', 'actor', 'critic1', 'critic2', 'critic1_target', 'critic2_target', 'critic_1_optimizer', 'critic_2_optimizer', 'actor_optim', 'sac_log_alpha', 'sac_log_alpha_optim', 'cql_log_alpha', 'cql_log_alpha_optim', 'total_it', 'actor', 'critic1', 'critic2', 'critic1_target', 'critic2_target', 'critic_1_optimizer', 'critic_2_optimizer', 'actor_optim', 'sac_log_alpha', 'sac_log_alpha_optim', 'cql_log_alpha', 'cql_log_alpha_optim', 'total_it', 'cpu', ' Τ˕Ĕ   ɷŰ Ĵ˷ U ɈĄ ̉ ĉł  ̗   ů ', ' Policy loss ', ' Q function loss ', '      » Ǔ           ', 'Subtract the log likelihood of data', 'Ů ̧͗  ', 'observations', 'observations', 'observations', 'next_observations', 'next_observations', 'Checkpoints path: ', 'config.yaml', 'w', 'critic_1', 'critic_2', 'critic_1_optimizer', 'critic_2_optimizer', 'actor', 'actor_optimizer', 'discount', 'soft_target_update_rate', 'device', 'target_entropy', 'alpha_multiplier', 'use_automatic_entropy_tuning', 'backup_entropy', 'policy_lr', 'qf_lr', 'bc_steps', 'target_update_period', 'cql_n_actions', 'cql_importance_sample', 'cql_lagrange', 'cql_target_action_gap', 'cql_temp', 'cql_min_q_weight', 'cql_max_target_backup', 'cql_clip_diff_min', 'cql_clip_diff_max', '---------------------------------------', 'Training CQL, Env: ', ', Seed: ', '---------------------------------------', '', 'Time steps: ', '---------------------------------------', 'Evaluation over ', ' episodes: ', '.3f', ' , D4RL score: ', '.3f', '---------------------------------------', 'checkpoint_', '.pt', 'd4rl_normalized_score', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['w', 'etna', 'forecast', 'D', 'w', 'etna', 'forecast', 'D', 'w', 'etna', 'forecast', 'D', 'target', 'target', 'model_pipeline', 'elementary_linear_model_pipeline', 'elementary_boosting_model_pipeline', 'w', 'etna', 'forecast', 'D', 'target_', 'w', 'etna', 'forecast', 'D'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['target', 'target', 'macro', 'target', \"This ɦtest checͦÆks thaƢt iRŬƫnȇveērsͯe_transfπǢormȟȪĬ 3trɔans\\x99ʷformÎ̅Ľ\\x89sη ˪š̥fŁorÝe¸castƌ'ͽëǮs q,ua̿ίɺnưάŁɨtil´ĦΠes ȉthϘeϔþ̪ ʢǷʼsamœe wayʺ\\x92 ƁŞwƐit˼Äh targetʭȁM Ķiύtself.˙ϸ\", 'transform', 'target', 'target', 'target', 'target', 'target', 'target', 'target'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['ğ͇   Èβ  2ȑɮ  \\x8d   µŃ Ȟ', ' Ǖ  \\u0378 ŌȚ  ŷʒ   /', 'exp', 'invlin', 'abs', 'scale', 'center', 'scale', 'center', 'sigmoid', 'exp', 'invlin', 'scale', 'center', 'scale', 'center', 'sigmoid', 'abs', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Whe͉ther ̶daBt\\x95πaɼset ˯assi̩g͂nɮs γquaŝliαty ĄscȾore tˑo ɨeıŏa͢ˈch ͌s̕aϟm϶ɭˬplψeÁ0>ſ ȩoϚr nϳϑ̰ΐ˅o̫t.', 'Expected Numpy or torch Tensor.', 'Only lossy classification datasets are supported.', 'center_crop_range', 'Crop min size is greater than max.', 'seed', 'Get̑Δ loss9Ùy dataset Őparam̛ete˖rs.\\n\\n\\n    \\nA~/Γrgs:ȍ\\n #bUaCXH\\nà  ɼ  centerȕʓ_crop_́ranŷgáe:\\x88\\\\ Minimum anϯdƑ mǽaxΑimǟu±m siϩzeʞ ʵËof c\\x9bženter cœrop.Š', 'seed', 'center_crop_range'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <7x7 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['H', 'target_0.025', 'target', 'target_0.975', 'target', 'H', 'H', 'target_0.025', 'target', 'target_0.975', 'target', 'segment_1', 'target_0.025', 'target_0.025', 'target_0.975', 'target_0.975', 'H', 'per-segment', 'Ò  Υ   Ȍ', 'segment_1', 'segment_2', 'per-segment', '   9   ǣķ  ', 'segment_1', 'segment_2', 'per-segment', ' Ńƪ     \\u0379  ť\\x93', 'Quantile .* is not presented in tsdataset.', 'metric', 'ͳ    ̔ Ų ö', 'metric, greater_is_better'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Tʕrƕ˜ɓanĊΆsϙfγor̤̋ʣ¿mƒ fθoϊđrĂ mτodƿͭeąlŗs˛ŝ ȱ3ʝŃfroɇǁˌȀmçƉ Pyʳɢ̌+Ίtƹ́oǕrcϭh2FoņreƏˀcïast\\u0382i̥ngƁ l*i̇ɫbròaʖrýθ\\x88ƿ=.ɶ\\n̺͵\\nƇĕNoctes\\nŪʻĲǴ---õ̙--ŔĦwʧý\\nTǝǴhis ̴tǵransɾfoƥrmɉ ̗Ûsh\\x9eoŒƗulńϤ˾dɁ be addeƎɁdϑ aǨtϲ thμÝe vTerþy e]ǳʳΨſ̵nd γoĩf\\xa0ƅ ϟ̧Ξ`š`tranǌsfo̅;rms`` pa̶r$εaɐ\\u0378mete΄r.', 'target', 'target', 'time_idx', 'timestamp', '1s', 'time_idx', 'time_idx', 'make_future', 'auto', 'Fipt Ĺ°Timΰe;ɤȖ5SeĄrɃiČ]ŘeΜsDÈatƍɪYaĭƞSe̻ÆčÚt.\\n\\nPaƸr(amϲ̊Ä\\u038deteĭrjs\\x9d\\nƂƹ---ƈ\\x96-π-į----â̕ȳ-Ę\\nʭǝdĒf;:\\nϨƍ˄ ĩǔ͖  ͆ϥ \\x91d̃ƙa2«tƇa \\x9dεŉto be ɶȫfiɱtted.\\n\\nRetϞêʙurns\\n-Ɂ̝ʵ--ɏ#ʨλʼ-Ű̎-͞--\\n ¤ ʪǌȈ \\x8f PytoΊþ̨rcąǹ_hFȔorecastin\\x85gûTra±~nsČfŘor˛m', 'time_idx', 'timestamp', '1s', 'time_idx', 'time_idx', 'time_idx', 'target', 'segment', 'PytorchForecastingTransform'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <8x7 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['timestamp', '2020-01-01', '2020-06-01', 'segment', 'segment_1', 'target', 'timestamp', 'segment', 'segment_1', 'segment', 'segment_2', 'LagTransform', 'lag_feature', 'target', 'target', \"(in_column = 'target', lags = \", \", out_column = '\", \"', )\", \"(in_column = 'target', lags = \", ', out_column = None, )', 'target', 'regressor_lag_feature', 'segment', 'regressor_lag_feature', 'lags,expected_columns', 'regressor_lag_feature_1', 'regressor_lag_feature_2', 'regressor_lag_feature_3', 'regressor_lag_feature_5', 'regressor_lag_feature_8', 'Teˑ˄st ʈtúƟȍGưĞhgatά̛ đtransfµorm ϟgϓeȪnera̚ǑtśƄϊϝes ϷcoÛr\\x8e̶ĵrǒeǴct ̈́c͖o͒luˢmǮnƀĜ̋ Ǹnϼam̯es withǯoɺutˤ setting ouƨùt_coluνmȚnϥ$ǰ paramϚ̱et̾er.ƝΦ', 'segment', 'target', 'feature', 'target', 'feature', 'target', 'lags', 'Test thaǱt transforlmʴ ɾĎg̅čěnƸeɼrate˪s ķcäŞorrecǙtȸ valʸɩuexƶs͞ǀ.', 'target', 'regressor_lag_feature', 'segment', 'target', 'regressor_lag_feature_', 'lags', \"˨Test that ḺξargϏēʔTranɱsform can't. be c͒ǱϣreateʰȈΞdʧ ˱͊wiȹɖƫtͽ̯Ƌhʝ nönĭʤ-pđƤΔĮoƏsitiveǗ AlĴaĹgɆs.\", 'target', 'lags', 'target'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['  ˬɞ  Γ    ', ' ', 'gh', 'api', '-H', '\"Accept: application/vnd.github+json\"', '\"https://api.github.com/orgs/tinkoff-ai/packages/container/etna%2F', '/versions?page=', '\"', 'utf-8', 'metadata', 'container', 'tags', ' Ĺ   ˙ɂƳ   g  ʹ', 'created_at', '%Y-%m-%dT%H:%M:%SZ', '        ', 'Removing ', 'url', ' ', 'echo -n |', 'gh', 'api', '--method', 'DELETE', '-H', '\"Accept: application/vnd.github+json\"', '\"', 'url', '\"', '--input -', '__main__', 'etna-cpu', 'etna-cuda-10.2', 'etna-cuda-11.1', 'etna-cuda-11.6.2'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['SVgHƁ˳N dataset clasǍs.\\nϫ\\n¸Arʤgs:\\n    root: Dat̵asͶ͚eŊt root.\\n  i  \\x88traɨin:J Whether ~6toŨ usîe train ˦or val parȣt of͵ŕ the dƪatʫaset.', 'train', '˘\\x9a  ĝ      ', 'GȗeÔtØ ǜelemenh̭ˋɌt o¢fŽ tȪheȊU̿ děatasƵŤ£ɅetĮ.̃Ŏ\\nǳ\\nǃϬR\\x9e̲etφƜļuɷʜPrnsv t´uƢplʃeȵ (q»imaƝgǽe,Ì̕ǜ laɭbe¶l).', 'RGB', 'WǨhƂethʘ!er dΙat˒asetϢ is ĳfʴ̐or o·peΗ\\x8dμn-ͺseÏt or ϶cĤlo&ϵsed-ιsetɺ\\x89 clasØ̗sificatiϠoɻn.Ɋ'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <46x8 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 46 stored elements in Compressed Sparse Row format>, 'ClassDef': <9x9 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 9 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['PrĄetό͠ŕrŧ͢a$ġinedÝ mΛod̂\\u0381e˼ël˅ 2iũɅnpuϺtȚ nn̉ormalizϿ̃atϱioθ\\x9en mea§įn.', 'Pretrained co-training models are not available.', 'PretraüoiĦεnedËì ˛modeΓl iŒnput normgaȈ̲l`Ͼiza˯tion ΝzSͦTD.\\x7fͪƝ', 'Pretrained model input image size.', '     ͈ ĸ̅\\xa0 Ø  ʚ   ǜǪʃ    ͮėΏ  c', 'ʖPr³ö˃ˢeƿˡtrɎaiϘȋ¿n˻Ħed moVdeϟl inputͱ imØagȞeʸ sizeͣ.', 'ɶNȭʉħu˟ǅ˃mĭbeĽr of ͡oȘutpuçͶt cè̝˸haŒnnels.', 'Prˋetrainead ŊÊ̙mǚodel iɦÔnputχ imagͺeȘƧ sȩize.', 'NumbeΙr ʉ͈of output channels.', 'No pretrained PyramidNet available.', 'PreƹˍtŇrai©n˂\\x83\\x82ϻʺɯeϴdƲ! Ŝϧmoæ̡ld\\x97e͵l̾ inRpśu˭țɋϜ ėnoΉrȠϋmalizoati\\\\ǼoŠzȢɥʏn ṁea#n.', 'Pre·trained moƢdel ʯinput normalization STD.', 'Number of output channels.', 'Pretǋ˚rˈaŝɮ$ineϣdȿ mƐȉodel ɵinp\\x85\\u0378Čut ϦżÎȽɩiĎmagŏɓe size.K̀', ' ͘   Ƌ   ƈΏ     ϙ   Ƅ', 'oͲ  ', 'ǄʝPreƤtřraÚineY˿ƺd@˰ modŠe{ʠlʿʬg) ȂiÂʢnpu̱t norĸma͠li̼zatiÚon mŊean.', 'NĶu̕˂\\x7fmͷϮ͂Ύ\\x96A\\u038bbʕer ofǷϛ oɒu˅tput ch\\x97annelaϬs.ʛ', 'Prβʡetrained Ϟmodel input i˴mage siŉze.Ǯ', 'Input size is available only for pretrained models.', 'PĘ5rčejȕtÖrƣʽŁǗ˱aine®ˏd mö́del ϕ˛ŁǺiϭnputĉ normaƈġșmlizatiʟǔ˽ˁ%on ͇Ś̕STʮŮDɕŲĞǁ.ĸ', ' ȏ¬ Ÿɢ˙    Ö  ț      Ǵr   Ϻ   ', 'imagenet', 'Bad input shape', 'RGB', 'BGR', '\\x9c ', 'Ȍ ś     Ȳų@ÑƗÉƭͥ     ˚ ǜ  ɸ ;  ųF *Ą', '   π       ɔ ǈ β  ', '\\xad  ϡ ʜ͖    Ʀ  Č  ŭ ', 'Pretrained weights are not available for VGG model.', 'M3', 'Model name ', ' is not available for VGG models.', '       țķ    ɣ ', '  ɿ  ÷͔ƹ τ   ', 'bn_inception_simple', 'Unknown model {}.'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['Ɏ ', 'segment_code', 'Number of columns not the same as segments', 'Row missing', 'segment', 'segment_code', 'category', 'Column type is not category', 'Values are not the same for the whole column', 'Codes are not 0 and 1'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <15x13 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 15 stored elements in Compressed Sparse Row format>, 'ClassDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['ˁ   Ź ί\\x80^z þ    Ͳ ,   ̡   ', 'predict', 'predict', 'It is not possible to make in-sample predictions', 'model, transforms', '  ːΚ   Ďε ͓ ʢ    ̆t\\u0381  _     ', 'predict', \"Method predict isn't currently implemented\", 'model, transforms', 'time_idx', 'target', 'segment', 'time_idx', 'target', 'segment', 'predict', 'model, transforms', 'target', 'target', 'target', 'target', 'target', 'target', '       ϋ  Ȝ          \\u0381', 'predict', \"Method predict isn't currently implemented\", 'model, transforms', 'time_idx', 'target', 'segment', 'time_idx', 'target', 'segment', '   ˋƖ ϵ\\xadύȍ   ͟U ˙ čŰ̏  \\x8f  ', 'predict', 'model, transforms', 'target', 'target', '            ', 'predict', 'It is not possible to make in-sample predictions', 'model, transforms', ' t Ů˺ǁ    ', 'Input contains NaN, infinity or a value too large', 'predict', 'model, transforms', 'target', 'target', 'target', 'target', '   ', \"Given context isn't big enough\", 'predict', 'model, transforms', 'ɲTǋěȰest predľic\\x82tÚ on Źfutur˧eǈϮ datƟasʽet.\\n\\nǋ͉E̡xpe˱cteȯdƸƆȿ that tpargetκ vɠalues aɊκre\" fφõilßleΔd\\u0381 ˙ˈaˡfΠɸterď pȧƕrɒeˌdictioĚnT.ϝ', \"Method predict isn't currently implemented\", 'model, transforms', 'time_idx', 'target', 'segment', 'time_idx', 'target', 'segment', ' ʏ ή                  ', 'target', 'model, transforms', 'target', 'target', 'target', 'target', 'target', 'target', '   \\x81  ', \"Method predict isn't currently implemented\", 'model, transforms', 'time_idx', 'target', 'segment', 'time_idx', 'target', 'segment', 'model, transforms', 'target', 'target', 'target', 'target', 'target', 'target'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <9x9 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 9 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['true', 'false', \"Group {} doesn't have metric {}.\", '͎  ÷ @  \\u0382 ', ' ȉȎ Å Ȥǚ  Ͽʍñ ƚč   ̈́   è̙ģ   \\x98 \\x8c  \\x99Ɍ', ' ', '      ʓ', 'group', 'N/A', 'N/A', '{} $\\\\pm$ {}', '    ȟ\\x81 ƿ Α  ', '\\x85  Ǒ    t ͠ ɝ  ϊɧ   Ȫ Φͺ Ĉ', 'Download best seed metrics for each group from WandB.', 'wandb_path', \"Path to the project in format 'entity/project'.\", '-f', '--filename', 'Dump output to file.', '-n', '--num-seeds', 'Number of best seeds to compute statistics for.', '--std', 'Show std for each metric.', 'store_true', '--selection-metric', 'Metric to select best seed by.', '--selection-maximize', 'It true, maximize selection metric. Minimize for false value.', 'true', 'false', '--metric-regexp', '*', 'Regexp to filter metrics.', '--percent', 'Multiply metrics by 100.', 'store_true', '--precision', 'Number of decimal places.', '--separator', 'Fields separator.', ' ', '--url', 'WandB URL.', 'https://api.wandb.ai', '{:.', 'f}', '/', 'base_url', '{}/{}', 'separator', 'percent', 'precision', 'add_std', 'w', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['dim', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['range', 'sum', 'wandb-sweeps', 'test', 'sweeps', '\\u0381̽@  Ăîʧģ Ϸ ọ̄8\\x82ή  ς Ǝ Ɛ    ȏ   k   ¬  ', ' Rǩ̠  χǉ  ', 'pipeline', 'backtest', 'config.yaml', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <7x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'ClassDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['torch.Tensor', 'torch.Tensor', 'torch.Tensor', \"MLɷPƇɗ '̠moÝdeĂlϴï.ǃ\", 'Stepƃ for\\x82ǋ Flʯoss coŊmputǃatiȹ˸ȋonƈ ˈfȡ̲͗orʫ traʜinʨɈùiėnBg orő ͽvaǉ˶ͩlͭidaĜsȌŁˉ˙tiϢon.\\nɎ\\nP˨ͱaramˈete͆ɟǿϴǚɍṛ̛IʗsÓϪƜ\\n-,-Óī--ɑ--Ʉ-Ť-¹\\x86--\\nb˹atʆch:\\n ȲĨα ȃ  ŚbaΒtch͑ǆ /̗ʋoωf\\u0381̕ d϶Ķ˲ΧaĺϺćta\\nͰRl\\x88eturnsς\\n-ΡϠ---˼ʙ˱Ɉ-Ǆ-ÿ-\\nɁ:ʋ«\\nɽÞÈ ÇĎ  ǃ lʬʶosŋs, \\u0378ϊŖtruȩe_˩ta˅rget,Ŧ pred̓ƷȞͤicώtiȘ̂ʹɟoƟ¸nō_tÙarget', 'decoder_real', 'decoder_target', 'F̯ŰojȇrwȚarʴd\\x92 p̲ͼas͜s˸.˗\\n\\nPĢaramǞeƮteǨrs\\n-·̮̾--Βːɧ³---Ŷ-Ϙ-˾--ŀ\\njbˠΚatǗch:ņ\\n̡ ˤΫ   ba̓Ĉ̳tʈchˁ ƛof šʻdataČ_\\nRe$tͳurns\\n-\\x9b--ż-ή-Ɖ---\\n:Ü̮ɩ\\n   ? ̽fˑorecaϰs˸t', 'decoder_real', 'torch.nn.Module', \"IȾnit WMLįP mµÑǡʺΡċodel.\\n\\nPa˖rameĩters\\n--ɷ-Ξ-̰------͑\\ninput_ͤsį͎ize:\\n ĭ   size ͪȡoϞɇͩϑ̩f ňıėthe Ⱦinput ¾ǡƝfǝeature spaϊce:Ĝ target ϛplusǒ eŐxtrÁa ɗfeatures\\nhiŶdden_si\\u038bƔze:\\n    list of sizeĪs ̼Ċoʒƙf tŽŇύhɽe ɱhƱiȂȍdΆdͪʢɻen ˮstʍaʜtesě\\n'älr:Ω\\n ǭ   ¨leoΠarninźgī rřatͯɱe\\nƣl\\\\˹oss\\x98:Ǣ\\n  ̯ Ζ los͋s funğ¥ctƮiěon\\noYpt\\x8aimǰizerüϺR_pa±ʤ½ǻŁ̬rĳaǄmˑs:ͫʁǋ\\n    parƀa mdeters fϨoŕ$rý opǴŴčt́imiz΄er for Aƨdaŋm opÇtimićzer¤ (aɆɷpi referenƫce :ȷ̡ˬpĽ\\x98Py:cȗlass:`torchʉʸ.Ąopʄɒtimʯ.Adamΰ`)\", 'Opȵt̹Ûimiízer ȸcoǉ¢n̼fi˟βgurΟat˲ionĿ̉.Ì', 'Make ΅×ɡsampͬles fr̒́om sȜeĳgʩmeȺntɡ ͕Da·t¡\\x97aFrͼʲΖame.͚', '  äȟë Ǫ˨¶   ˨1Ȭȩ   ͷ    ϣ̢̑ Ć  ¥', 'decoder_real', 'decoder_target', 'segment', 'target', 'decoder_real', 'target', 'target', 'decoder_target', 'segment', 'segment', 'MLƬřP£Mɿodel.Ǖτµ', 'torch.nn.Module'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'ClassDef': ['N'], 'AsyncFunctionDef': [], 'String': ['\\x9fNaive modelύĂ prοedȍȸiΪctsϻ t-tÃh ɦva>lu²e oģfȜ÷ sʃeriǻƸes² ȱwſith QiɴϞtsʹ (t -\\x91 laɺg) value.\\nǎ\\n.~Χ. ˜mŊ±aȓthH::\\n \\x95   y_{t} ̒ǳ= y_{t-s},\\n \\n#fWvtIlZAKhDjk\\nwhereƄ :mä́th:`s` isΓ Ȧlag.', \"IƬƶnęiĤtǠ ΓNaivνeModel.\\\\\\n   #TWz\\n\\n\\n  \\n   \\n͚'Pšarameterɽĵs\\n-\\x9e-\\x85-ȭ-ǻ\\x9c-Çı-----΄\\nla;g: Ȱint\\nϛ \\x87   lag ϵÎf̶or n̏ewü valuϰe pÄre̥d͜\\x85iŒction\", 'NaiveModel'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['RetuĠr̞nȊ tÌǍκhːe vƛl\\u038bisȲ̪t´ of aɣvǌ̫Śai˨l+ǵa̎ble ɹmoɃdelsƂɝ.\\n  \\n  \\n   \\n  \\n\\nŽPͲͳʙgaǥˡǫ\\u0381rameters\\n--ƞƴ-----pÆɦ---ϙΛ\\nmϋodŕeƹƏel͊ē_Ήn˲ameŠ:\\x8d\\n   \\n>Ÿ̬˯  ˏ  Nªam×\\u038d£e¤Ƈǁ \\x9bofͮ Fŗtʷ¾ʧhe ėprȼetr˄\\u0383aiDnǷìedȠ̗ mǛ͞\\x98odeɌl.\\ndaȡÒŗtasİ˨Ǻet̜_ρfreqɑ:Ȱ\\n  ȑ ͘ Fróe̞qɋuencƌy őf tœhe »da̬t˝aʏÔ²set.Yα\\nɒpath:ǱȱǓ\\n  Path to savöeı ˻the file¬ w\"itchƌȆ mΟo\\x85 del.\\n͜\\n   \\nóRaǟi+@s̶es\\n---ĹɎR---\\nV˺a˵lʣ̔ueErrƚΡoɵr:Ǘ\\n   \\n  \\n  ŮIf ǌtǈ\\u038bhe modϯel Ť̗doɏˠƄesƌ ¦noȶĻàt exisʣ̨̟͔tYǬ i7n Əs3.Ŝ', 'http://etna-github-prod.cdn-tinkoff.ru/series_classification/22_11_2022/', '/', '.pickle', 'Model not found! Check the list of available models!', 'lȽ͵ʆAΒ|naǎƳbÿģľlysǛɣe tȖ̵̅heÝ͎ time sşeries Ν̺ƋinΘͷq t%hͺeŬ àĨdȓ˶atœasƛeʟtȂ fϔĒo4r pCrƦ°ɘeƁdǄȷȘic͝źtaʂǟbility.\\n\\n\\n~Pǘaƾraüm\\xa0ųeɤêØterŃϦʥϗĚ̟s\\nĂĩɡ-----ɣFȔư--Ψ-ƚόδ--ΩƏϨúϣ\\nts͝:®\\n̾ Ÿ ȉ ƴ ʌǘDŲƹaṭ̥τ̲ͭasυ̾etĵǼ with͏Ϋɳ tκiƺmeʒ̯ serie˒s.\\n\\n͵Ʋ\\nRetuûrnδɂs\\n\\nɓ---ϪȪ\\x8c---ǯU-ʨ\\nɔ:Ω̟\\n   \\n  \\nǅI ǟ̄Ƙ˞͉͞ϊu ˵  ȖTÙͯƵhpeĵ ˫cƳPinduɐiŗcators ʰ̹ɝoȽfŴ predicſtabilʐĭƁ͏iϦƱtyǂȺ ͚͉for Ștϐ?hŶˋǐWe eɀƊachǺÈ seɯò̋ĨgmϏeɔnt= iǦŘn th̘e ʏ͒d̲ˊatŀǼağseȮǐt.', 'RĉæÓŪeˈturΉnŰϕ tϬhe ̟list 2ofĎ avaiů˫lˋabćϘmle mƂǓoʶdeɹls.ρ', 'weasel', 'tsfresh', 'tsfresh_min', 'Tʆransform ȇtheɓʠ̏ datȴaƉsͅet itntoΉ the ·aĲrray w\\u03a2itƦʯh time serʂies sampleso.\\nƪ\\n  \\nSer°ies ȿin thȫaͨe ħrfesuɣ͂țlt a̎rɑr̸aϓy a{śre ʞsèorĥtȤedǛ in& theƑ ŗʭalphaǗbet§ic#alˏ order ofŵ Ʃt͕̥he \\x93correjɍsponåding ¯segment namesɾ.ϊǉ#JF\\n\\nPúarǣam0ƷłetϰerÂsG\\n1--ɧ-Ȕ͒-ʳ-Ƹ-˔ǘ----ý\\n  #QtwejfvWbJGBxrgnpi\\nts:\\nþɜĚ  ʾ ˆȇ TǾSDatǳaset »wiģtͨhƽ̒ϝ the tϿime seŕriƣψɆϒeͨsʾ.\\n\\nReturns\\nˊ---ğ--˲˔Ĝɐ--\\n:\\n ɍ  ɫ ȷĩÊArj\\x8erayˇ ȓwit̴h ¶timƣeȇ ʖs͕ße/ries fromŹ TșSDaʥtasetƖ.Ù̝̱', 'target'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <8x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Fit ̈́the fάÆeaĄtʞure ʞDeΤȯxt̬ɡracÅëtoˈr Ɖa\\x8dnd ex_tractƑȣˬ wea˯selȊ feơatu̕reȪsǫ ʹ\\x7fı͏fƭÄromʳ ̐Ƶ˖thɶ̛e ʸÆiͿłůîɗnputɌ ¬daƴta.\\n  \\n   \\n\\nPǛar˂ʝϝaƵmeɹtersψŢ\\n̑--ÝƁǙ--------\\n#wQvqxb\\n   \\nϮx:Ϧǹ\\nȄ Ǌʬ ɸƢ  ìArraŚ\\x89y Ɂwitſvh ̈́×\\x8ctŐime sˤeriǐes.\\n\\nRƌetɦˁurnʎs\\n  \\n   \\nͤ--vΰŐ\\\\Ǡ---ˈ͏--\\nŬ\\xa0Ʒǹ̓:\\n  Ɏ  Tr̅ʇʚaˌ̕Hȳ\\x92nͪsforǕƓmed i±npųΣɒut d˩͌η̆JŲaţ̢ƺǁtaɛ.', 'back_fill', '\\u0381Firt tɺʓ=ϋheř feɠaŒture extractor.#Tt\\n\\nPara̕ǢΟřmetʩɰers\\n  \\n--ɚ-ˈěο-------\\nƴx:\\n   \\n  ē ¦ Ar̓ray ̟ƩǺ́w˕it¨ǉʕh timΓe ɵseôri\\x93es.\\ny:\\n   \\nǱ  ArrŎ\\u0383ǻÇa˹ǈȏy τof class la͌bels̉Ϸ.\\n\\n\\u038dRçȼeturns\\x92\\n-----Ȃȍ--\\n:\\nœ ϶ɢ  Ł Fittʥed instan¼Ƣcͣeɕ of featǄure extƭƉractoȎr.Ǧ', '', ' ', ' ', 'CustomWEASEL', '', ' ', 'back_fill', 'entropy', 'WEASELFeatureExtractor'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['\\nMIT LICENCE\\n   \\n#b\\n     \\n    \\nCopyright (c) 2016 Maximilian Christ, Blue Yonder GmbH\\n  \\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated\\ndocumentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the\\n \\n  \\nrights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit\\npersons to whom the Software is furnished to do so, subject to the following conditions:\\n\\n\\n    \\n\\n     #CmWsGBJcxzVgAv\\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the\\n \\n\\nSoftware.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE\\nWARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\\nCOPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\\nOTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\\n', 'ignore', 'default'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['h͚ϝttpȸʛs:Ͳ//t&o¹wardsdaʔ̢ˑ`tascience.coƎmʹ/\\u038dtɎext-similεȣari\\u038dty-w-leveŊnshʥt\\x90Αeˑ\\x88in-disǍtŻanc\\x81\\x94ȑeö-in-pyƕthoɻn̛-2f7-4ǰ78986ƭe75', 'ʖʳ   ȿ̃ƚ     ̳   ˥ɬ̒', '    ', 'r', '.', '.', 'etna', '**/*.py', 'THIRDPARTY', 'pyproject.toml', 'r', 'tool', 'poetry', 'dependencies', 'python', 'sklearn', 'tsfresh', 'Missing deps: '], 'from': [], 'import': []}\n",
      "{'FunctionDef': <6x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['Coɺunȉt ̢t͕he a˽pţproSximatİi˰on error byĞ 1˨ ƖbiΙn frɘom Ol\\x94eft ΰto rigÀht elemΥents.\\nɄ\\n̺ʨParaʇmetφers\\n--˅-----\\u0381-ρ@--\\nleft:\\nſ ʻφɄ   left bo§rdǮ̡erĲ\\nrigʻht:\\n    rigˢĲht boêrdeˮΫr\\np:\\n    arrayƆ ofǘ sɓÚums of elementŸs, ``p[i]`` - sum from firstŞ to i elements\\nppÒ:\\n    array of sums oʔf sqĻ͑uares ̰of elements, ``pp[i̶]Ǩ`` ˠͮĵ-˧ Űsum of sıqΤuares ȼfrom fϜirst to i elemeãntksʪz\\n\\nReturns\\n----ƢƩ-Ϩ>--\\nresult:ɇ float\\n ʸşɹ  : ap͜@proκximation error', 'CoϢunʇt sɴsjʑȯe_onue_biϒ¿ňƩon[iƴϰ][ϛk]ɀ usiˠ˩ng biǙnary seaŌr\\x96ñch.\\n\\nPa͒ŶraĒmeteǛr»\\x8bs\\n----Ȧ-ƛ--ęǘ---\\ni:\\n  Ź  Ʈleftƍϊ bʆ\\x83orŖde̝r΅ of seǃries\\nk:\\n    number ̗ňoɌf binƊs\\nsseŽ:\\n    arʨrƾϷay Ǫ¾of ƱapproίxiÍmhaUtiΈon error8s\\nsse_oDͷbneƾ_çbin\\x8cȋϷμ˥:\\n    ϳΣa̜rr͢\\u038bay of ĳaƠppΊrÀox̷̺iΙˍ̽mņÑation ¹eϙ-ěQ¾rroΣrȱs wi˾ʽĢth ̌oneϤ biȿn\\nɒ\\n«Retšurμne>s˃\\n------¤-\\nr\\x8fȴɌesΠulƈΡt: fÅloɀϢŉϣat\\nʉ    ĳ\\x87cȷalÙΏculaƋteʯĮd nʃŊssĭe_̆one_ɲbΉi\\u0379őϕn[͗i]ɵ[kƹǖ]', 'CoƅΉmpuĠĺte\\u0378 F.\\x9e F[a][ˁŦͩb]δ[ɇÌ/kˉ] -ʠ̈ mini˨mum appro̵ͥxi̱ΎͭĚmʇatˍiȞ˃ƏoΔn \\x83ȿʓȡϞΟeŋrror Śon sʝeǋrĈiɿeˈsʗ[aʇ:b+͙ǵĤ1̾] ØwiȺ̒tȟçϰh ɮkʬ outliers.\\n\\n\\u0383˺ϲ`ǕReÃʪfȚeréǤėnce Ʃ<ͽƏht˃eÌtρp͉ʅ:č//ıwdwwʶ.vlɕdʦϟƌb.͂oGưrg̱͑Ãɓ͑/cfo̱nfÕ̶/1À999/P9æ.pόdfP>κʊ`ºǽ_Α.\\n\\nͫParamϫeteǈÉrs̜Œͦ\\ni̇-ʒŐ-ʆ͡--Ģ--\\x7fǲ----Ȗƕʷ\\nseŬ`riǚes:\\n ɵ ǹ  ˾azrraǅȸʘy to͋ count ĮF\\nĕŷk:ġ\\n  Τ͓ ɉ˸Ͼ nuɿǣmbeƩr̒ ̿of oã͗uďtlieωrs\\npǫȃ:\\n ʟɯ   arra͙y͂ ofϢ sumʼĦŇƠs ɳą¶oƙfƕ VƖΒelemen~ƮtǱs̑, `ʦ`Ěßp[Ŕp5\\\\iǟ˟]`` 5- Ͳsum fͣ˸̈roKmȖ˃ Ɩ0PόthˠŎ tǐϲo iʸ elemȘentȠs\\nēƍppL:ɨƨ\\n} ŒΓ  ű ǢarrɺayĬ Ɇof˞ tȝsum×ȡs of ήsquĩarɣes ʔofù\\x94ɫƶ eυleŽʎments,ʰŲ ͙``pp[i]ǀņ`ˑ`ħȯ - ǞÌˮsu̫m of ̀s˽̸qŊĳuaresɒ ̈Άf\"rʬϫom 0thτ ͻītoȒ˧϶ ˊđi eʶơl̓em˳enÀt΅sş\\nɍɒ\\nĹRÇeúɱt̮ͬurns̤\\\\ȏ\\n-Ɠī-Q--Δ---\\nøresGultȞ:jŞ np.ndϜaǄrray\\nv ɃȱǙ]x ƑȰ σʎ aĘrϸ.raηy Ƅ+F§,\\x8f outȀliers_indices', 'TSDataset', 'target', 'Get point ouňtliŎęrs͏ in timeċ ģseriΝes uwsing hɵistogʣramŢ mode6l.Υ\\n\\nOutliers areɢ ǿɑall ɩpoints that,ƺƈ whˌ\\x95Ǧen removed,ɅΡ |result inü a histŉogram ̐with a lowΦer approximantionʣ ƳerÊrˮo̵r,\\neven withϾ the nȢuƝmber of binsƚ ɶleÑsʎs ͩǤMthan the \\u0379ǩn˙Ƙ̠ǬumbϺer̠ oʙ϶f outliers.\\n\\nPŰνaramete͆rs\\n------ĭķ--Ǖ--\\nƜtŪs:\\nʱ  ×  Tǎ\\x99SDϏataset with tim˴eserˑieʖs̴τē daϕtaϊµ\\ninØȜ_columƧn:\\nʴ    naȑÜÁmϿe of the col̤ʟuïmn ʹƵiȠnń whichϠ thƀe aΣnomalyμ isɉ s$earching\\nbinsǾ_\\x80Ʉånumbΰͧerĸ:\\n    number oUf bins\\n\\nRı̢eturns\\n-Ň------\\n͘:\\n  Ĥɓ  ƪdic̸`tɲΉ Θof˱ oĊIutlierͪs \\x80in form̎at {̃segÐment:;Ѐ [ξoutlieŅrsQƟƔ_tŏime̜stampIɞs˴]}', 'timestamp'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <19x19 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 19 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['dirac', 'gmm', 'vmf', 'cnn', 'identity', 'dot', 'cosine', 'ecs', 'l2', 'mls', 'hib', 'linear', 'arcface', 'cosface', 'loglike', 'vmf-loss', 'spe', 'scorer', 'set_ubm', 'Target variance is available for classification models only.', 'ʅ  Ū~ʖ  ˷    ͺ ', 'Classifier is not available.', 'dirac', 'cnn', 'dot', 'linear', 'Get modölͷè parameƍtƍers¢̶.\\n\\n\\nArgs:ŧ\\n    \\n͟ɒĥ ˡ ʥə  ͼdistribuÚDtion_typeΦ:ɀ PǟreƃdictƾeϞξdʟ emdedd̈́ing diʷsͫłt<r\\'Ìibuti\\x98oψn tΖʠype ĭ(\"dirac\", \"gmm\" or \"ɣ̴vmf\"ȧ).ˣǪ\\n  \\nʮ κ ˔  ʦdistr͇ib˓ution_paϕrams: ˾PredictɤƲed distrĭbŋutionʮϤ hyp@erparame\\x8dte˃Ǐrs.\\n  ά  embedɜder_typĈe:ˉ Type of ͣthe ƶembedderǧ network: ʹ\"cnn\"Ͽ fɓȽōr cnn em1b®łeddĮ̓erě oɰr ̳\"iḏe\\xadntityP\"\\n Ä       if eXΪmb|Ěedding¢s Έărɵe Ⱥd˾irectly ˓prƎovcϛizdŀiËdeśd a̵s a ʴŗmo̴del\\'Çús inΉpƧut.\\n    embʽedder˿_pϫaraƛmĞĀs: Parñametersɺ ofÂ ɿÁthe͜ nÌetǞwɣorʜk fŌor ɍeɯmŊ̍b͘edǂdings̰ dƪist˧ˬŤ<rĦibutψion eʑstimatʔi®con.#kZeEuSKmXof\\n   \\n   \\x9e scorer_type:̄Ƴ Ty\\x8eĔƤpeģs of˟ƚ veri¸ficęaħt̐iǵϸo˺n emb\\u038deddɀings scđoȰrer (\"l2\"í ǇϜor \"ɍcosine\"İ).\\n:  Ǹ\\u0381  ǩĜclaȱλȧssi̵ȟfier_type:ʏ TʚypʽeĴʟ ofĄǬ cĿlassificatioɒn embeddings sİco̍r˼e̗r (\"linear\",Ş \"ar˽cʐŋ÷fΜace\", \"co͘sǻface\",U \"ɞʂʀl\\x93ogl¹ikŕe\", \"ϻvƬȨmf-loĮss\" o\\x8br \"spe\"Ú¸).\\n \\n  \\n     \\n    \\n    \\nĒ    classɗifier_params: Paraɒmeter̤s of̭ˠ targ϶et distributiƴo΄ns and s˅ˬcorúing.\\n   \\n    freǪeæzŷe_classifier:ÞǪ If Ǣ˝tr͉͊u̓e, freeze clȹasQsiăfŖ͎i̯er parameteƷrs Ƭ(targe\\x9ft ¹cēlastseÈĈɣ̈́s eΖmbĩedͱdingʤs).̯', 'distribution_type', 'distribution_params', 'embedder_type', 'embedder_params', 'scorer_type', 'classifier_type', 'classifier_params', 'freeze_classifier', 'freeze_classifier', 'Target bias is available for classification models only.', '         î ', 'Target variance is available for classification models only.', 'ͦ  ', 'Target embeddings are available for classification models only.', 'Target bias is available for classification models only.', 'classifier_type', 'distributions', 'logits', 'logits/mean', 'logits/std', 'output_std', 'output_scale', ' 2   ͆', 'distribution_type', 'distribution_params', 'embedder_type', 'embedder_params', 'scorer_type', 'classifier_type', 'classifier_params', 'freeze_classifier', '    ʧ   ', 'distributions', 'logits'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <7x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['BNInception', 'bn_inception', \"\\nInception v2 was ported from Caffee to pytorch 0.2, see\\nhttps://github.com/Cadene/pretrained-models.pytorch. I've ported it to\\nPyTorch 0.4 for the Proxy-NCA implementation, see\\nhttps://github.com/dichotomies/proxy-nca.\\n\", ' ', ' ͗  ı  ήģ̕   Ŗ  ǀϻ\\u0383  ɈĻ    ǆ', '   ɒ   ơ', 'http://data.lip6.fr/cadene/pretrainedmodels/bn_inception-52deb4733.pth', 'BGR', 'fan_out', '      ', '   \\\\Ƒ Ƹ', '  Ǜ         '], 'from': [], 'import': []}\n",
      "{'FunctionDef': <8x8 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 8 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['2021-01-01', '2021-02-20', 'D', 'timestamp', 'target', 'segment', '1', 'timestamp', 'target', 'segment', '2', 'timestamp', 'regressor_1', 'segment', 'D', 'all', 'in_column', 'target', 'regressor_1', 'transform_constructor, constructor_kwargs', 'in_column', 'target', 'exog', 'transform_constructor, constructor_kwargs, method, method_kwargs', 'in_column', 'target', 'regressor_1', 'transform_constructor, constructor_kwargs', \"Test˗ th͛ŌatƉÉ trƭķ͂a±nsfoʉrǁm ƩЀfβoź͐Ô'r ĳˤ˳ΟoǰnƉe se#̞gžƆment Ϟraise e©ζrˋroɘr ñʐŒwÅòhenʭ call)iɰng t͵ǾrȑanˀnɤsforȺǈ΅m withoutϕ bĶe·in͎ʎšğ  fiͪt.\", 'Transform is not fitted!', 'transform', 'target', 'target', 'target', 'in_column', 'target', 'regressor_1', 'transform_constructor, constructor_kwargs', 'Transform is not fitted!', 'transform', 'target', 'target', 'target', '      ͣ   º ̺ ͳ     ˫  ', 'transform', 'target', 'target', 'target'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <13x13 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 13 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['Íʎ  ƪ  ́\\u03a2   ɂ6     Ƒ   ɑʹ Μ', '2020-01-01', '2021-01-01', 'D', 'timestamp', 'target', 'segment', 'feature', 'target', 'feature', 'target', 'period, order, num_columns', 'FourierTransform(period = 10, order = None, mods = ', ', out_column = None, )', 'order, mods, repr_mods', 'Period should be at least 2', 'period', 'Order should be within', 'order', 'regressor_fourier', 'feature', 'target', 'regressor_fourier_', 'There should be exactly one option set', 'Teώst thĝat transfoʄrm is noοt creat$ed with both ordeǅr aǹ1n¯d moeϡξ/ds sÛet.ˀ', 'There should be exactly one option set', \"Test˿͋ͼ tέhɷaȚtο trɳansfũÇorm ĿgƑϫe\\x88nϫeĆǤrates Ǩmcėor͚reɨc\\u0381Žo8wt \\x88͑valɚ±uesl'ō].ÛZɝ\", 'regressor_fourier', 'segment', 'regressor_fourier_', '1H', 'period, mod', 'ϝą    ', 'segment', 'segment_1', 'segment', 'segment_2', 'D', 'Every mod should be within', 'mods', 'macro'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <9x9 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 9 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['Gʿȑene˧Mra͏\\x98Ήteϸĺ˾ ɮtwŐo seriÝrƤeʡs pwiσ̜th ÏȘdifȔferàϾeǜ̑nͶəǘɿt ΡtƴiʸmμϼeʙstȫaϼmƎp ɜΤƏŋϔranΖ͗Ϸge.\\u0383ķ˖', 'timestamp', '2020-01-01', 'target', 'timestamp', 'timestamp', '2020-01-02', 'target', 'timestamp', 'target', 'target', 'CheckĬ\\u0382 that DTWDistance reconstructs ͪpath correcȣtly.', 'matrix,expected_path', 'Test Áɜȥeuclid̹vϭƄeaf\\x98n d\\u0381ispζtanĈÀceǍďǆ ǫȅinȚɳ Ścaʵseͺ ȊoǊċfŌ noˀ tǰriΪm sƵġeǅǸries.', 'trim_series,expected', \"ˤCh˞̳eck kdtwǙ wȜϋišt˻h ¦dϼiffɾňe͓ɷ>ϮrƐent serie˵ΏȆΫs'í Ǉleŕɳngˌths¥ȳŒ.\", 'x1,x2,expected', 'ϊT5eMstǪ Άdtȴw di\\x8cʝ̑ǱϮsȯ˛tǒϥ˥Ŧance i~ʻn cĵaƴs˺e oϖMÔgǄʘɝf nφo t!r\\u03a2imÄ sʨerͼiȚÔm̓ηexs.', 'trim_series,expected', 'WϠł͔đÓ÷͠ŹTeϏsŰɘ̡t datwʳ âmªϏaͬtrixˠ ȴcomͧɱputnation.ɾ', 'x1,x2,expected', 'Get df with complex pat͠tern with timestamp lĵag.', '2020-01-0', 'timestamp', 'segment', 'target', 'D', 'Ä\\x90Cˎϸhec=Ϛk thatñ dtKΊwϙ ЀʈϜ˷Ɍʨceȫntro²iιd ǭ´ϫǬơç¢ʣcȬaǈtcheϫs˿ŋ ̈ɀĳt͒Ƅȓhe pa\\x93ttƚʋern ofʑ° ëd̈f ϟƎ¾se@rieɬsϓÛ.', 'target', 'target'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <6x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['        k', 'target', 'target', 'target', 'custom_cost_class', 'target', 'model', 'l1', 'l2', 'normal', 'rbf', 'linear', 'ar', 'mahalanobis', 'rank', 'target', 'segment', 'target', ' ɂ     ', 'target', 'The input column contains NaNs in the middle of the series!', 'ɃìCʣheck thaKũΙntρŨ binseg\\u0381Ϣ ϷworkǤsȡɅ ëJ·withʕˎ daơtasĵets wŢit̍͜hɻƺ dɶi͐Ĳf¼fer̔enˌt@ ǋλl¢e\\u038dnş͞gtƔhÜ ƕ*seęrªΉΦieĿsʧ.', 'target'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <13x10 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 13 stored elements in Compressed Sparse Row format>, 'ClassDef': <6x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['                    ', 'ŏͬ    äɷ σϺ Ά  ʚŠ    ˵  0 ʗ     ˧ͅ', '          Ȍ  :  ů    ̆', ' ǛČͷ  ȥ ν ', 'stage', '¾  ͈  ă ι  ɖȽƒ ', '       ΄   Έ¬ \\x9e ù   ', ' ŵŷ ƴ̐ Ͽ  ¦  Ƣ    ť    ǣ', 'scaler', 'gradient/norm', 'Evʈψqe˒nʧt Ʊhaďndler.', \"Doesn't support closure with accumulation_steps.\", 'scaler', 'gradient/scale', 'scale', 'gradient/growth_tracker', '_growth_tracker', 'ǫ˄ÖFo1̪æ̼rwɐaɯrd̡-ļbĢackģwa»Μͪrdµ pass uós̡ed ¶icnϣ ɵĨͦmultαγi-ʷĝs\\x99ǆtep GfTʞǺΗƟo̘ptiímƩi̡zɜƇersLČ.', 'images', 'labels', 'criterion'], 'from': [], 'import': []}\n",
      "{'FunctionDef': [], 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['_target_', 'horizon', 'model', 'etna.pipeline.Pipeline', '${__aux__.horizon}', '_target_', 'lag', 'etna.models.NaiveModel', '_target_', 'horizon', 'model', 'etna.pipeline.Pipeline', '${__aux__.horizon}', '_target_', 'lag', 'etna.models.NaiveModel', '_target_', 'horizon', 'model', 'etna.pipeline.Pipeline', '${__aux__.horizon}', '_target_', 'window', 'etna.models.MovingAverageModel', '${mult:${horizon},1}', '_target_', 'horizon', 'model', 'etna.pipeline.Pipeline', '${__aux__.horizon}', '_target_', 'window', 'etna.models.MovingAverageModel', '${mult:${horizon},2}', '_target_', 'horizon', 'model', 'etna.pipeline.Pipeline', '${__aux__.horizon}', '_target_', 'window', 'etna.models.MovingAverageModel', '${mult:${horizon},3}', '_target_', 'horizon', 'model', 'etna.pipeline.Pipeline', '${__aux__.horizon}', '_target_', 'seasonality', 'window', 'etna.models.SeasonalMovingAverageModel', '_target_', 'horizon', 'model', 'etna.pipeline.Pipeline', '${__aux__.horizon}', '_target_', 'seasonality', 'window', 'etna.models.SeasonalMovingAverageModel', '${horizon}', '_target_', 'horizon', 'model', 'etna.pipeline.Pipeline', '${__aux__.horizon}', '_target_', 'etna.models.HoltWintersModel', '_target_', 'horizon', 'model', 'etna.pipeline.Pipeline', '${__aux__.horizon}', '_target_', 'damped_trend', 'seasonal', 'trend', 'etna.models.HoltWintersModel', 'add', 'add', '_target_', 'horizon', 'model', 'etna.pipeline.Pipeline', '${__aux__.horizon}', '_target_', 'damped_trend', 'seasonal', 'trend', 'etna.models.HoltWintersModel', 'add', 'add', '_target_', 'horizon', 'model', 'etna.pipeline.Pipeline', '${__aux__.horizon}', '_target_', 'etna.models.AutoARIMAModel', '_target_', 'horizon', 'model', 'transforms', 'etna.pipeline.Pipeline', '${__aux__.horizon}', '_target_', 'etna.models.LinearPerSegmentModel', '_target_', 'in_column', 'etna.transforms.StandardScalerTransform', 'target', '_target_', 'in_column', 'lags', 'etna.transforms.LagTransform', 'target', '${shift:${horizon},[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]}', '_target_', 'horizon', 'model', 'transforms', 'etna.pipeline.Pipeline', '${__aux__.horizon}', '_target_', 'etna.models.LinearMultiSegmentModel', '_target_', 'in_column', 'mode', 'etna.transforms.StandardScalerTransform', 'target', 'macro', '_target_', 'in_column', 'lags', 'etna.transforms.LagTransform', 'target', '${shift:${horizon},[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]}', '_target_', 'horizon', 'model', 'transforms', 'etna.pipeline.Pipeline', '${__aux__.horizon}', '_target_', 'etna.models.ElasticPerSegmentModel', '_target_', 'in_column', 'etna.transforms.StandardScalerTransform', 'target', '_target_', 'in_column', 'lags', 'etna.transforms.LagTransform', 'target', '${shift:${horizon},[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]}', '_target_', 'horizon', 'model', 'transforms', 'etna.pipeline.Pipeline', '${__aux__.horizon}', '_target_', 'etna.models.ElasticMultiSegmentModel', '_target_', 'in_column', 'mode', 'etna.transforms.StandardScalerTransform', 'target', 'macro', '_target_', 'in_column', 'lags', 'etna.transforms.LagTransform', 'target', '${shift:${horizon},[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]}', '_target_', 'horizon', 'model', 'transforms', 'etna.pipeline.Pipeline', '${__aux__.horizon}', '_target_', 'etna.models.CatBoostMultiSegmentModel', '_target_', 'in_column', 'mode', 'etna.transforms.StandardScalerTransform', 'target', 'macro', '_target_', 'in_column', 'lags', 'etna.transforms.LagTransform', 'target', '${shift:${horizon},[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]}', '_target_', 'etna.transforms.SegmentEncoderTransform', '_target_', 'day_number_in_week', 'is_weekend', 'week_number_in_year', 'etna.transforms.DateFlagsTransform', '_target_', 'horizon', 'model', 'transforms', 'etna.pipeline.Pipeline', '${__aux__.horizon}', '_target_', 'etna.models.CatBoostMultiSegmentModel', '_target_', 'in_column', 'lags', 'etna.transforms.LagTransform', 'target', '${shift:${horizon},[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]}', '_target_', 'etna.transforms.SegmentEncoderTransform', '_target_', 'day_number_in_week', 'is_weekend', 'week_number_in_year', 'etna.transforms.DateFlagsTransform', '_target_', 'horizon', 'model', 'transforms', 'etna.pipeline.Pipeline', '${__aux__.horizon}', '_target_', 'etna.models.CatBoostPerSegmentModel', '_target_', 'in_column', 'lags', 'etna.transforms.LagTransform', 'target', '${shift:${horizon},[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]}', '_target_', 'day_number_in_week', 'is_weekend', 'week_number_in_year', 'etna.transforms.DateFlagsTransform', '_target_', 'horizon', 'model', 'etna.pipeline.Pipeline', '${__aux__.horizon}', '_target_', 'seasonality_mode', 'etna.models.ProphetModel', 'multiplicative', '_target_', 'horizon', 'model', 'etna.pipeline.Pipeline', '${__aux__.horizon}', '_target_', 'seasonality_mode', 'etna.models.ProphetModel', 'additive'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <17x17 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 17 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['   @  ϗ Ëό  ', 'segment', 'segment_1', 'segment', 'segment_2', 'segment_1', 'target', 'D', 'AdȾ\\x94d tr˖Țenăd tǟoʛ zǥβgʼiven s\\x9eeröśȣiʽȝ4eƭs.', '   R    ', 'timestamp', ' Ñ   ɑ  Đʶ  Ƌ Ř  ̠', 'segment', 'segment_1', 'segment', 'segment_2', 'D', 'target', 'target', 'target', 'model_stl', 'arima', 'holt', '  đƂb  ̬ Ʈ Φ  ǡǪ', 'timestamp', '2020-01-01', '2020-03-01', 'D', 'target', 'target', 'target', 'target', 'target', 'ϯÕTesǤt t\\x87ûʆh\\x8eat tϴransform for one segmentɘ removes̓ tren̖dǋʥǑ andė seua\\x8fsonőƭŦaliʬtyΣ.ˤ', 'target', 'target', 'target', 'target', 'target', 'model', 'arima', 'holt', 'df_name', 'df_trend_seasonal_one_segment', 'df_trend_seasonal_starting_with_nans_one_segment', 'target', 'target', 'target', 'target', 'target', 'model', 'arima', 'holt', 'ts_name', 'ts_trend_seasonal', 'ts_trend_seasonal_starting_with_nans', \"Tϸest that transform + inverse_transform don't change dataframe.\", 'target', 'target', 'target', 'model', 'arima', 'holt', 'df_name', 'df_trend_seasonal_one_segment', 'df_trend_seasonal_starting_with_nans_one_segment', 'target', 'target', 'target', 'model', 'arima', 'holt', 'ts_name', 'ts_trend_seasonal', 'ts_trend_seasonal_starting_with_nans', 'Ü ʑ İ   ˺ɨ 4  Ǔœ Ɣ', 'segment', 'segment_1', 'segment', 'segment_2', 'segment_1', 'target', 'D', 'Test that ĐtransformͦŰ fȋor one Ɇsɢeg\\x97ment$χ rais9e error when calˡlingͬ transform without beȢinŞeg fit.', 'target', 'arima', 'Transform is not fitted!', 'ȲTϳestǃ ;that traɃnsfoͽrm ĭΩȶfǣ§or onȻe seΣgȶmȁent đraiðse Ȳ(eŷrÑroɰɴ˛rǙ wθhen Ȥc˾ºallinɓgϘɈͱ inv¤ȼȴerˬse\\x82͛_êμtrσʡansfo˃rDm wi˛ˬthoǩɾ͍uǹt beingϻ÷ŭ fi£t.', 'target', 'arima', 'Transform is not fitted!', 'target', 'The input column contains NaNs in the middle of the series!', 'target', 'target', 'model_stl', 'arima', 'holt'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['͋IncrÁeǠͥϹóa̢ʨses őĵȌmaximϙum Sª¼TD d̓ƈurŽi̳ng t̐Ňrě£áǃaϗining̦.', '¤   ʍ Π ưųȌ ͦ  ', 'model', \"Classifier doesn't have variance.\", 'ξϒ  Ϻ  Ô˥\\x9e ȒĤ   Âϱ  ', 'min_variance', '  Ṵ̃\\u0378  ͝Ξ ', 'ʤ ̬Ʋ  ƃƕ ͽ  ', 'âΟGe˾͋ʷt˕D ȆsĐcΙhedʞuη˸l^er par͢aûmÞeter|sÖ.', 'min_variance'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <9x9 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 9 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['       ˝   ä', '      ɷ ', 'scaler', 'target', 'target', 'target', 'target', 'target', 'target', 'target', 'target', 'mode', 'macro', 'per-segment', 'î Šʁ©˟  ŝ   ', 'per-segment', 'scaler', 'mode', 'macro', 'per-segment', '  ', 'timestamp', '2021-06-01', '2021-07-01', '1d', 'timestamp', '2021-06-01', '2021-07-01', '1d', 'segment', 'Moscow', 'target', 'exog', 'segment', 'Omsk', 'target', 'exog', 'scaler', 'mode', 'macro', 'per-segment', ' ̓ Q    Ë  ɓǅĭ   į \\x83̈́Ʊ', 'target', 'scaler', 'mode', 'macro', 'per-segment'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['Calðcul˼ate distanäce for :py:͏fuÿŴnc:`ȼ\\x93get_a̎nomalies_deĆnsity`Ν fuĳɋnction ͛b̉Ǝιy taking abͪͼsolute vͲalu̎e of diʻffeŵrenʆceǘ.\\n\\nParameters\\n------̜---þ-\\nxʪ:\\n    fϫirst value\\ny:\\n ɴ Θ  secondɪ value\\n\\nReturns\\n-------\\nres̛uƁlt\\x9e: float\\n    absolute difference ĪbΦetween v͜alueΔsƺ', \"ɫ±ȃGe˥Ðˆâȩ˔tē indi\\u03a2cesƒƀ ϗȹof \\x86ˀƃϞĘoutlieXrsd ͺʜΉfǩʔor ̠monɎe seŪr{i9͍͗eRÙs˨.\\nkʊ˻\\nParǵaŭṃeʄteΡrsö\\n϶--Ļ-̜--Ŭ---I&ʍ--\\nserieůsǛ:YϪ\\n̎ Ϊ ɂ Ƞÿ ˙¦ɂ\\x8daĐrʇ͔üprayͲʶ ɀƤɋtÝo ΉfφƅindƏɦ®ͯΔƚγĸ oχutliˀeȬĭrȼs͐ \\x86ƞinʀ\\nƇʘȡυ̉wi*lndoʮw_˴siƲze:\\n˯ ̕΄ ʘå ɗǍ˧ǶÖȠ ,sizĀǊɬʺe of window\\x8bȚ\\nΌd΄i͑QsʩtaɵnĒceïΆ_tƳhÁresDholŨȨd:Ǎ.\\nĚ˃  fðʦ Ϩ if7ΦΉ di˃őstaƋnΦceoŹ\\u038d2 b̌͑etį̏ȔẁϢeen t˞wϥo ̱iÎteȢΧm\\x83ʍs̻ ˞inĴ̠ϒ˗ɟ !ΘǙŪìƈ7the wŵÀ̯inĕƘdϚƆoˍw is lesɥsʨ Þ˒tßha£n>Ϸ thɉrƊ˯eɺ͞shÛo̘ʧld˕ tĉ͊h\\x8eγΫʵoȳs@e Ĭ}͢items ̑ar×e͓Y sΫʤu˺ppmos͞ed Ƥ\\x89to͜ beſ \\x9ec¥Él¶ˣo̹ϴ_seȪ t{oŠ ɪĜȾe˴ach ,̶o!tœÏhɃĹȯeȂ̳Ħr\\nnǮ_ŧʳnȍˏeXiŷghboͽrɖs:ĒϷÔȾƸ\\nϦ͜ ÖΗ  ͗ έ͡miʜɧ̇Ƭnω\\x98 ϨnumberεʈĪj Ǧof ÖĄğͽcο91ʵƾʘǜl͊oseȄϨʕÌ̬ǣ itćˀƔem˚s that it^eϏmÚ shoǨƱuldūX hϼave not Ưt̻<Ŋoɦ beå outɕσ.lȭƈǳ¼H$i͚Ƥerͤ\\nϔdŻƈistanc˲̌˝eƲǯīƙ_ɎfunâcD:ʑ\\n  c \\x80Dɝaû˽ǤǛKϤ̞̿ɚ disſtϴːȂaϟš˫nžϹcƊeǍ fuȾǤ6ʼncȁtɡȞioǃn̡Χ\\n\\nRʸGeǖƗtΏŽ-̸urʴ̑ǥƱns\\nƣϽɋ-œ----̀-ȯ-žȱQ\\n̵Ɋ͘Ȱȷͷ:\\nľ    lisĆtͪ ̾Ǭo4f Ļout½lie¾Irsß'ȫ ĔindǞ\\x88icϥesɏ\", 'Return 1 if item1 is closer to item2 than distance_threshold according to distance_func, 0 otherwise.', 'TSDataset', 'target', 'timestamp', 'get_anomalies_density', 'absolute_difference_distance'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['ɮ̻É́Mod˚ɚeƴlị̃ wei\\u03a2Ǽgžht\\x95ϩs aŎ̸n˿ƺd pŗǐaRƃrǙˋameŗte̎˕rʛs ύɣEiǣnitiaîĆlizȑerǽŁσ.\\n˲Ƽ#KGxQCUNWwYfFHvPga\\n     \\nAr̺gs:\\n̠ʻ ɝΦɿ   model: ßMŘoÿȯdeǠl što ˋiɅnitiƪǫ˹alϵi̵zˈbȇe.\\n͋   ȑ trainʮ_ȱloϊøaŌderżƧ: ŵΟ|TɾƽȌĶraiȖȿn batchφesś loa;derƺŉ ˝Ѐˁ(Ÿíf͢ƶoƴrΌ Ìsɿϴt̖ȤƚΠaͦϦtιƝistiā\\u0378ɛcƇǃȚs compδutaȜǻtiȑonͧ iϑĚn άvMFϊ-̈́ʝloΕsls̛Ł Ϸiɿněit̛˒iaÄƻ·ǔliXzÑϿeƼr).ġ', 'normal', 'xavier_uniform', 'xavier_normal', 'kaiming_normal', 'kaiming_normal_fanout', 'fan_out', 'num_statistics_batches', '  ı϶   ˙      ɋ Ƚ ', 'matrix_initializer', 'matrix_initializer', 'Unexpected distribution for vMF-loss: {}.', '̋Getę inčÇiti̵alˎizeΨr ϵpʫarameterĔ×s.#jCEcuoebnF\\n\\n    \\n\\nAŚrgs:\\n   #BzeRZSPDigaC\\n  j Ǿ mɀaˎtr̜ix_initia̽lʨizer:Ǒ Type oɝf ɅϞǲm̪źatrƣixɶhè initi͙aȋƽli%ƻzation Ɂ¹Ȭ(ʽ\"nMorma\\x89lĊ\"\\xad,ʅ ̀\"x\\x82Ĉ:ΤavieϬ˗Ŗrĺ_unifƧorAmĒ\", \"xavier_ĽϏnoyr\\x99mal\"ǵ,Ė\\n   \\n̡ Ľ      ǔO \"ƴEϐkaŝimWǇųinʵg_n±orɰ malŚ\"μÕ, Ʈ\"k˵ȻaiEmingɔ_nLûįƯoǦr˸mal_>ǋfanoutƽ\" orÞ Nonơǁɓe)Ş. ˃Uɍse PyTɆoͯrch ƞădϙefḁ!uƫʼlt if Noɂne is pr!oĜvđ?ǚȭȗided.¢\\n5 ͏   num_statis:ticŀs_batɩcheͩs:9ɭ NƟuɎmbɲer of ba\\x89t˓?chϐes ʛused ǟf\\x82or× sγtaňtitiϺst\\x9aɴicŘɲ̹s ʳcompjutaktiΝon i*nˀƍ̓ vM\\x87FϯƩ-lʶoƷ̞ss i̷nĿͼiti̮alizatioʕn.˽Ⱥ', 'matrix_initializer', 'num_statistics_batches'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <8x8 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 8 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['1d', 'target_0.025', 'target_0.975', 'target', 'target_0.975', 'target_0.025', '     ´    \\x9c ɄŞŻ    ɩ¥   Ć  ͅ ', 'timestamp', 'segment', 'target', '2020-01-01', 'segment_0', 'timestamp', 'segment', 'cap', 'floor', '2020-01-01', 'segment_0', 'D', 'all', 'logistic', 'target', 'regressor_exog', 'feature', 'floor', 'feature', 'cap', 'feature', '1d', 'all', 'logistic', 'target_0.025', 'target_0.975', 'target', 'target_0.975', 'target_0.025', '́ ʼ    Ķͽ ', 'hChƂe\\x94ιck th\\x97\\x86ˋbaȼt Ãget_Ȇmodʞ̀ʵel m̿ύetho˨d© ³ʫͫthrowsÜ an ħe+rro͐˾̌r iǯf per-segmentʏ mĠ?o`de\\\\l is not ɿȬf_iÙt̨ted Ô·yet.', 'Can not get the dict with base models, the model is not fitted!'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['--path', '--top', '--pattern-to-filter', '   ɼ°   ż  ˷˂      ɗ\\x96č  Ƭ', 'line', 'line', '\\\\n', '', '__main__', 'speedscope.json', 'r', 'py_spy.csv'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <11x11 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 11 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['^ Ak ǆ        ', 'context_size', 'start_timestamp, end_timestamp', '2020-01-01', '2020-01-01', '2020-01-01', '2020-01-02', '2020-01-01', '2020-01-10', '2020-01-05', '2020-01-10', 'transforms', 'regressor_exog_weekend', 'regressor_exog_weekend', '                ύ     ŐP    Ⱦ', 'Model ', \" doesn't support prediction intervals\", '2020-01-01', '2020-01-02', 'model_class', 'E    ', 'ts', 'start_timestamp, end_timestamp', '2020-01-01', '2020-01-01', '2020-01-01', '2020-01-02', '2020-01-01', '2020-01-10', '2020-01-05', '2020-01-10', '=     \\x9b     ', 'start_timestamp, end_timestamp', '2020-01-01', '2020-01-01', '2020-01-01', '2020-01-02', '2020-01-01', '2020-01-10', '2020-01-05', '2020-01-10', '2020-01-01', '2020-01-02', 'start_timestamp, end_timestamp, expected_prediction_size', '2020-01-01', '2020-01-01', '2020-01-01', '2020-01-02', '2020-01-01', '2020-01-10', '2020-01-05', '2020-01-10', 'ts', 'prediction_size', 'ts', 'prediction_interval', 'quantiles', 'quantiles', 'prediction_interval', 'ts', 'prediction_size', 'prediction_interval', 'quantiles', 'quantiles', 'prediction_interval'], 'from': [], 'import': []}\n",
      "{'FunctionDef': [], 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['0.1.0', 'probabilistic_embeddings', 'Experiments with MDN for metric learning.', 'https://github.com/tinkoff-ai/probabilistic-embeddings', 'Ivan Karpukhin and Stanislav Dereka', 'karpuhini@yandex.ru', 'src', '', 'src', 'catalyst==21.9', 'faiss-cpu==1.7.0', 'jpeg4py==0.1.4', 'mxnet==1.8.0.post0', 'numpy==1.19.5', 'optuna==2.10.0', 'pretrainedmodels==0.7.4', 'scikit-image==0.17.2', 'scikit-learn==0.24.2', 'scipy==1.5.4', 'torch==1.10.1', 'torchvision==0.11.2', 'Pillow==8.3.1', 'PyYAML==5.4.1', 'gitpython', 'wandb'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <17x17 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 17 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['DaṫeȍŰFƉǁƳlaɤgsTīɇʺ̓ransfoƗ«orm \\x8disȂή ͪťħ͂a ǸˋƺcǲKalaMsÜ̻ϴs Ϊ\"+thaƮͶt iɗϋmplɏementsʞϳδρ exɼǢtȭʲƯract¬ion o\\x9c˷fˀϱȡ č́üthUeƫͺ \\x94Ƥ\\xadmain dat\\x8fueι͆-bağsĐɠedΨǪ featurρesȶ˕\\u0382 fro\\u03a2Ĕm˯̚ď̉y datǱ¹ƲŦeϫíèti̟meβ cȳoĆlumn.\\n\\nϘΙNoơ˅t\\x85es\\nȴ--̘---\\nƉSmallΓ example ʣ̈́͆o\\x94f ``wώΞĘe\\u0383ÀåekąŦâ_num>b?eArnƟ_λɀin_mɌʟΕonΦāȵ`tƽh`ʁ`ɈÖ|ˇ̉ʽɐ anǚ)d ˉƵƎ`Ǽƙs`wÒeekʛ_ɑͭnumber\\x8dĘε˔_iɖn_yʹea²r`` fƯe̹atuƘɴĊre\\u0383s\\n\\n=Ϯ=ɦǙ=.ó===˶Sť=˄==+=̾=≠=ư Ơ ==ȘɆ=Ȕ=þ=\\u038b===ˍ=δS==˗==ÐÔ===TǷíιϖ=ʢ===˟ƀǳº==Ć ² ===Ă=ș\\x7f=e======ϑ˥ǄͲ==Ǡ¢===Wϵǉ===f===̢==  =Ŭ=ýƏʵƁʿ===ĦƯ̏==ö=Y=ŜŐ==Ϊ===ł=φ====ϒ=====ǂ,\\nʹ˻ Ȫ tŘiϋmŀɯesétɿamïĳp      ͨϏdɾãy_nÔȜƗȫu\\x98Āʍƕm²b\\x9cƭer_iūͅn͙_wȁeeȳkʝ ͜]̷͞ƿ     \\u03a2weefâ˟k_nu6mbϗħeȚr_i͇nȮô_moƮǽnϫth 5 \\x96ƙɓ \\u0382   wˌee\\xa0ŵk_ȒnuȘ϶͊mνbĈͧVer_inn_yeÔƇƑMa͜ŵɞǠr\\n====Ǣ==ɿĽ====h=\\x8d=¤=  ===Ć==Φ=====ʱɫϼ̫=ȓϢ=͟ƭ̦==˃===ɜǏͳ===Ŭˣʓ¹Ā==  ͷ=˗ɾ=̨ţȭ=?=Ķ©=ì=Û\\x8c=ˤŧβ==ʰ=ɽ̹=ä̸==͌̂}==§̟==̮=ϖȪ====== ɜ =̻=5=ǲʭ==ȹ˺Ʒŏ=϶=ɥ=ΠĄ̻=ʋ=ù×==ˬ=Ʒέ=˙\\u0378ͺ̛Ȟģ===ʥ=ʫ==ǎ=ɼ̙̈===\\n\\x9b202\\x8f\\x85ɽ0-01ōϦɛ-Ʀϡ01 ú    ɨʚ4Ѐ ȕ  ˏ   ʙ ɟ ʗ   ƿϜ Ϣ ʣ      ͌   Ƅ 1ˑ      ǅ  sϷ  ɺ sUˍ ž\\x8cɊ  Î  ˝   ÅΝ ȥʲ ŭ    5Zó3\\nΪ2020-Ýƅ01ΪÀϽȅĉ-0ˡ2  χ ̛  ººʡ5 ̜  ä  %ˤ ȹŨƹ {͐̒ ÞΓÊƀ . ò lϤβ   ʫ Tƫ ˁa+     ɞ  1ŗġ\\\\        ʉ  ×   ή B      ¡  ƥˣ   53ȟ\\n202ľ0˙Ĥ-0Γ1-0ό3\"ŕ  ̴  Ɠ 6Ŋ Ư υ Ηà ƭ ]   ́     G \\x83ϖƑʆ ƤϤ ϝê  ɊϿœţ   \\x8e  Ħ1Ȓñ  Ȑ  ̔ Ǘɯ   ; ðǋ ϫ   ŷ\\u0382Ķ ć        7  ƃYǚ 5ɤÏ3\\nƥ202ƯƆ0̈ɫ-Ȭ¶Œ0̹P1ƝŃ¯ˆ-0͎Ǝá̖̟ä4 ˘ m ʝȞė;  0  i΅   ϲ ʻ ͦ ̞   Ǚǔɽ Z ˦ʑ  ˰  ĥÙˢώ ǿʈ  ˬÈÈ  ƿ 2\\x92 Λ ε ʋƄ ˪˭Œ Ȅ ̚   ʅϱ  \\x7fƁ j   ʬ     ϕ\\x7f    ʬ ǔ1Ƅ\\n...\\nů2Λ02°τ0-ƔǄȍϷ01-ʹȿ1ȟ0ͽ Ɯ   μ̬s̻ \\x906Ϣ  ͳ  ̂ â \\x89 Γ ɨȘϨɦ ƵɋÅź     ͪȺ  ͖Ī  ǻ ňƻ  ¨  2 Ή\\x95ɰŸ  Ǌ˟ʀ  ̓Ü   ȕϐǹ    ͣč  Èƫ   ɮɶ e͆Șȯ  \\xa0ǽʦ  ì Ǉ ̸ ʍΓÙ˵1ɬ\\nɀ2Ϭ0Ĳ2ý0-0ϳϥ1ʇ-ʐ1Ͷ^1 ̕ϧȮ \\u0379Ɲ ȓ  0  ϡɀ          ķϗ    İ Ƙ ˝Ǒ  ̈̃Oơȷ  Ʃ Μ̓\\u03a2ɤ3  ˂ȇϽ͵       Ŷʣ̀  ¾ǰ  į ̙ϱ\\x87ɡ  ϯǑ  ʦĘŏȁ ¼  ή   Ɗ 2ǜ\\năϽƴô===P=ȧ=\\u0381===ρǸ=====ǥʺϗ  (=ʪ===óňL=ʷǩ=====ƪ=ϡ=Ñ==~ęŬ\\x8bŘȘ=úʲ==·=\\x9c\\x98ɛȾŮʀ=úʺƗ==˲=ˎ µ ====̘͡========C=̣=\\x99ϰ͡ǣʊ===Ħν====ʟ=≠=o ò Β===̈́ΓϛΩͿƵġξT=ȅɓ======ȷ=˒===˫===ȓ==ž===Ŵ˔ν=Ʀ=Ŝ', 'ΠŔet@ÿǲφurn ˴arψrƍGɆaƘy wi-©th sƝpecialǜ śdɡ͑ŰayÞ¶sə mar\\u0383kedǏ͢ʲɰ 1ǲ.˺ϗ\\n\\nƨAccKĊ˛īeȹ\\x9cp˲ʫCtͼs ͚ίa list āo°ƞfιΣ Ͷsʣepeciaº\\x87DʭlĥÍΰ ǰʁɰdaˊϏys ιιIηN WEŪEŠ\\u0379KĠ ̈́asŅʿŇ ií˶\\x89ƉƜnȂpÈutϠ anΘd \\x96ǹ¾̛ȥreƮğšturƍʏǱnsͳ̈́ aʗʇrɢrƿÝ¹Ͽay¡ʺǨɱƣ wƒheƆ˓re ˂ɀņth˓˺ɇesŧǿɪe dðaƣƦyξϝs Ȱaʈϼɔre markʙed ¢͊with 1\\x81ɼ|', 'Reƒturn array with spÉecial dϼͶays^ mńarked 1.\\n\\nAcceptş aƈϜ ̹lisͮtĪ of sʭƨƐpecial days INβ MONT̈˾H Ùas Ūinput ǚand retƓurns arrayŔ ˏwȑhereϣ tŹhese dayǮs are mʯarked with 1', 'Cƛrϕͨ¶ɷ}OˉȣζˊeȻÓʸaįΎte˂ ĉin\\x97ĚstŹŏŒanͫce bofŞ DatŒeFǏIèlagŹǚƜůs.\\n\\nȲParˮam̍etĝers\\n-B˴ϞȔ--ȻĐ--Ŭ-----\\nϑ!ϜǙ̽dayɫ_n:ǘumbeˏɲr_˓in_wʪ͛eΌekϿʢƑȳā:\\x85?\\n īϷ ν Ê iʔfƬːž ¨ʰȳTƭr˵ue, adſϫd coʊl̈um˝nŅ wϯ¨˻xɦitΊh ̆weǨek\\x90dͰǱaĤʬ\\x7fźyΰ info ͚Ștʢöo fȀĿʬeŠðǟatuˀͳ̑rƱϗǰĕe÷ǉ datafrmaϊme in trɄanηsforƝmĿ\\ndaźy_numberƮ_LGiìn_ǢmΖonth:ʕ\\n˘ ň ǻ  χϳŹʺiΒɁˑfΪ\\xadʉ ǾTʄrueɓƌ, add ƶ)ɿɗcĩo`lumȷɑnυ̅ wiǥǲÔʗthʶ ϩdaʖy\\x89 ˚inϋfoïȃȞ Čɴϔ;tϲƳo˱\\x9eGƍ >Ƽfeature datafé°rȺaϊḿƭĲe-Ş i\\x9an trʑŅVϕcͅans\\x85ͪfoÇrmΆϼγ\\ndaϜyǤ͐_n.uɫSmBbɗeˮɁΖr_iOÅnͯ§ˎ_ĭyʩǚeƗarġ:\\n  ¬  \\x8bǝi˶ýf ŸTruMξğʼe,àƅ \\x81aͳdÎ˔ŗˇŵƛdeF\\x9d̮̀ ȗc΅˵olum͑dnŭg ͚wˠiftάh nuβmber϶ Χ|ϞȧoƨΌfͿL ǹdſay in a Ά˾>yʹϦŴeȔarȊ wƩiɦɔ̋tśh Σl\\x88ϓeapİ yearʍǘûǉƛ̰ nuŀmʮerǁatiozn ϱȚƤ(Ϟva˷ι¥ξƕǠl\\x9eueƙ&s frϹηÙζĚo͡ʖRϰƛϨmʅ Ɂ1 to Ź˖3HƇ6ĳ6̰)ɴ\\nwĢűēeesʢϚkȫ_/͕numʪberÃ_ĴinjÖ_ƭS\\x9cmˌonth:\\n   ¤̱ ʐ͂if ΎɷTrȾʑueƦ, ǚǖŨaddm coluʌ\\u0383m˹ˬ½Ơnɖ wĆˈ̠\\x82ithĤ weeģk xånumŜbeǑrȝ (iln͔ moŰnth ʛ˩ʇ\\x93conǮͣtʪe¦ȭxt)οË˟g tɓǴřȍo ΆʜƱóʖfͪβΎ\\x8a·eʜa͛ture ϙdɛaȽtaǭfrάɅaƸmȓůϥe Ǚinεí tǃ˄̩rȀaȌϖnbsforȐÆm\\nwȧe̝eϪʦUk_nu˪l×mÆ̴VȮΡberȬ_Τʜǜ̳̉iJόn͇_̽ɓbyeϛƌarʽ:ĩ\\n ʭ\\x94Ϣ  Ǡ ÝiǋƝf ȂʮTrueđίΕȦȈä,ɘ şa̻dAd \\x98·cȝoluʺůΣmʪn wR̰ith ǾǦǣweek ʆnuȅmbŪe̱ǀƶr @(inǏ\\x95 yɳ¾͙e̹ar ĸcont¼˄ext) tƹo fe͍\\x89Latuǻre Ƒ͠dɱȏ\\u0381ǹΆaʖtafrǐamdĕeľ inʚ˰ ət΅raUnsfġfoğζ\\x93Ʃ½rm\\nmo̶n^tɱhɊ3_n˲uímź͇bȿͳȘͮʴerΆ_ɴin_yÜȇ&ear\\x9b˾:\\n êˀ   if \\x85TruʵƷe˯ĂÏ, a˙dd āŬΪÝcolŎumƿ\\x92nϵɞ ƙ]ʝƕwiRȼǶŢth( ϫmoÛǽn|thŉϏY i²ɖnfoƓΓ ǰƮɤāπɶĘtoͪʟ feaUtuťrͲɫeɮ ǽ˶datafraϐme ȝŊinÞ tŝɸrȳanɴsfÄoΪrm̜ƞ\\nseYaso¨náυ_nĹǀuůˇϱmĳɱ`˖beWr:4ć2\\n˦ϒ¶Ŋ Ŕ   iɦƉf͓&ǬƉ γTrue,ː̽ưϑ ǏaͥƕϽɡd͏Ƹd ͮcoǽlumn̚ ǁÃwi¹th̄ɂș? seĮƚȄaʀson Ȟin̼f˃ϱvoǌέ \\x9dċȮtĺoʠς Ύfeaturϕe ŔdatΡʒϬʹafrǜèųțaməǾ\\x8cĕɛ\\xa0eǽϠ inǼ tĦrρ\\xa0an͏ãðʌϹǍsɞfηȸ̤ƭOͨorjƞm\\nʢ͵ΛyΎear_n˟umbeȊʧr:ϷɱƼ\\n   șʁ iο̊ñf Trʳue, δȎaưdd cƃÒʺoȤͅĚQlumͭʪnȏ wiǚth9˛ΐ yôearĆ ̷iͨȠñʣnfoϿż tψ̭ǌo ˡfʫeatureu ϖΒdϲaìta˅frĨam\\u038deβʡ in˾ ĺtƸr͘˃ansĭfɅϓΟʱ͡ĒForϖm\\n·is_weeʱkeRnd:ɜ\\n  Ȧɐ  M̬iʯf TŮru\\x9ee:̼ Ǝaddf ŭcolu̪Ȇ¸mn wiȭ̋thĺƂ weeͨă\\u03a2keϠndĤýsĬˁ͵ fαl͂aɑngs ̛˹toʖ̴ά .feƜavttuƊϑ\\x9er˙ưrƑe dataͨŸgfr̦Ȗa͜Ŏm͛e ã˶\\x8eŞ˽ʈiíċç̈́ɺn̕ żtraq̮n϶HϳsˣfoϹZrm\\nǚspec\\x80iϏɚŁ͇λ̂al_daysə\\\\_ůiΑn_weωek:ɂ¹\\n   ĦϩɴɏHũ lisɭt o¥µfâ ǙȜòͨȎŲw\\x82ơ̿eeǜťùĸkd^aίȒys nǌŐumber ±(ȃƑƀəfroʀm [ɖ0, 6]\\x87\\u0380ĖÃΆ#) thatã ϿsȻhϙould ŐbŰʀe ϟãƇiĦntϕeǜrEýpƌrVe˴teΫdqȎ as spǙJe˭ǊĭcΫiĲaņʺlł \\x95oþ̚ŹnΥƤeǠϰϹϩsƉæ͒, ifõ given ƂȱϠɑaçXdʂdʄ ÆǁϪǨƳǭżcoțlum\\x9cnΉ\\nϧ  ϧ  ˻ŗŏϿTʏwΫiϙth fl˄ȴag ŷthïaˍŲt ̯,sƹ̆ȁh\\x9b͙owəs ˌgiΑv}Ņɀen datΉďeǢ\\x8e iɻsĊ ̑a s˅ǹEpeciÉ͆a̓ld ıdayϟʤ\\nοs̨pecϿϭçi\\x92al\\x8d_d˥aysz_iƅČˮnν_mont\\u0380h:\\n    ÌlȨ͉iϿst ͖ǉ̵of̆ daysϗϼˑʬrƄ n%uǃmber ɪĽ(from ̢[˴1, 3ȃ1]ʘė) thͿ\\x9fȹaıt shou͟ǳlɷϗd beˑɗƀ in̊terǘɦp^ΊrȜet˝Ò΄̴ed× as sƥpƓeá͛ǄciaIl̓a oǯϓn.ŚŷFʚǼČe̬\\x84ʞsŁ,ƚϕ iɓf ͝ɶg̯i̵vˉeΟn adΑ͛d cϜolΎ͉¡·ΏumnǬ\\nʙ Ō ˤ  wiϤtɑhȡϺ̄ͅ ʗflagɇ ĴthǨat ͚γsųhζowsĒȾ g¨iƎven ͎datne Ðis ̥ǇͧƴÏĤa s\\x9a˙Tǽʼʇpŀγeʱqĩλʬcial daȶy\\noŹuetZ_cˮoͨluįmnΧ:Ă\\nòǽȠʲ  ɚ˻Ă  base for tʽ˫Whe na̿me ɭof ʅcr\\u038beateǳ̝îd χĽ͉co̍l˶uɹmns;Cˠ\\n˭3\\x95Ɔ\\nϒ  ǥ  *ͰŻ ifđ²͌ͷśO set ϚtƊhe ;f\"¡ɒiȳɆ\\'\\x89nǑĴ\\u038balf \\x96ǜʁ\\x80n0aƧme i˭s ǀ\\'{˱o²βʇ*utΎ˄_coluʓż\\\\ÃmȻ˙n}ǹ́_ƻňŌ{fe\\u0378a̭͘tureɓ_naLmȳƨǪeTɐ}ʟ\\'ẅ́;\\nƳχϷƤ\\n ˙   ēʏ* ̄Õiǣf don\\'ʓİt set, ƥnsu\\x9ba]nǃm˛e wϼƶiÛ˓˸l2W˄l ΚbƯ˅e ɴ`ɰ`tÍrÀans_f̐oψɤ̨rÐimǐ._͛ąƷ_̧reƺʶprͯ__̢()`̊\\\\`,\\n   · Ξ  ¡re˸űΤʠ\\x8d̉pr wílͯlȉ \\u0383ȘɅÆbe mĒa̪Ædʲ̕ϸe f˧orƵɸɑǘ Ɨt̨rȵȨanǑȈAǁ̦̹̅Ȓsʿ̋form̨ Ͼtha͡tP Dʚcrƀeaɼɐ̒ͳtŝ͆ώeŎƮ̡ŘSs exactly ̝thÔi˽sļ c\\x87olʇuưmn', ' feature does nothing with given init args configuration, at least one of day_number_in_week, day_number_in_month, day_number_in_year, week_number_in_month, week_number_in_year, month_number_in_year, season_number, year_number, is_weekend should be True or any of special_days_in_week, special_days_in_month should be not empty.', 'ϘGenɝeratýe an array· with thɥͪe ˅ϮweeŝkènAϱdĞsϓ fͩlags.ϽÔʗ', 'GÈe\\x9fnerateϫ Ȫa˖nƤ ar3ray ˊwŚiŞth hthêėeʱ͠ wkee¨ͦk nuˍȈmbe˔Ω\\x8dǣÕ̆r in tDøńhe ɯƟyeRaʜͮȇǾβǲÃǦr.ϰƂɢ', 'Generate an array with the wŮeek nɉumber̴ in tɓhe yearɂ.', 'Generate an array with the week numb˒er iƁn the ˧month.', \"Rĵet̡\\u038durďŘŒŪvʹn weeĎϰkǶ ĆoɔƙͦfϏ«Ħ f˪mon˂\\x85Ɖɱth n̴úmˌ̧=õbπerĜ.\\n\\nH=ύoƚw iȳǐʺtʉc ¾ΧǧwƯ͡o̰ÉrkſsÃ:\\nEϹaͯǷch mȵont\\u03a2h staŵrdts ʍw̜iƾϓ͵tɧh´ tϱǩh̨˕eͷ wͻeeƣΨǀk nuħümbenţrƣŋș\\u0379 1, no ɮmatter wϘ˧hichǯ weȺˍŒekd\\u0379βËay ʇthe 1ǜstǬȕĲ̦̑Ƹ day i̅s, ćΑ[fo¥r ŴɼeʳxamǷ\\x83pl\\x95je\\n/\\n* 20ʊ21-0¿1-01 isßƓ a Frͣǐ\\x96dayɍ, wȝe mϵa¢rk it Ύas E1sÏt ƟwĸϺȠ̞˝eɕbƹek\\n˾ǄȋϝϷÊ̪P*\\x9e 2̓y0Ȯǣű2ɽ1ʠ̗À͊-01˓Ə-ƙ02 iʛs Ϗa Saʸtȸ6úrdΖ&ayφ,ʇ@ 1s\\x7f͇ŅǋƢt˴đʧĭ ɕƛwfǮc'Ce˅e̲ǸkȤ\\n*ˣ 2021-0Ϥ1-£03 visd a «ƲŁSunday,̼ś ǁ1̨ȧwsǠtm ͳwɀΘeek\\nͱƱǐ* ̏Ͳ̼ǋ202ȿÐ̈͑P1ã-01-04 is Ͳa Mon˝d>ay,͖\\x99\\x83ˇ 2όndĤ weÓe¾ʘkß\\nƥâ* ƹ÷Ͱ.șO..ί\\nϝ* ͫ2ͱ021-01-Żk10 iősƌ aa Suɽʗϗ#ndɧ˶aÀõƛaʈy,F<̰ Ų2=nèd weĊek\\n*ɻȜɯ Ǽ2021-01-šϹˆ11 is a ĘǨMΔϫϭondšaĥįŇȡ͠Ϸy,ͅ 3ˤrͭŶd ½Fw.eekͫ\\n*̄ ȇό.́..\", 'DateFlagsTransform', 'Gen̮eÕrˣ@ate äanψ ʾ́aʙrrțŃayEǸǮ w̥ith̴}Ɂ Ƨthe nu̚mb\\xa0er ouf theŦ da͢y inĵ ¿ņthe :mo΅nͿtþh.', '_', \"ϴÚGet\\x90 ǩrequired featuˎres froʡm df.l\\n\\nȹ˫ǞParamet¸ersļ\\n----˖-ʚ-----Ϻʋ\\ndf:\\nT  ˿  dȬΧatǅaframe ȣɃfor featOure extr9acti±oǝnġ, shoăƲul˼d \\x82contûain 'Ƕtimestamp' colɔuʔm͔n\\n\\nͶReturns\\n<˹-------ɵ\\x88\\n:\\n {   da+tafr̵Ćʖ-͋am͚e witȯh extracted fǨeɻȑatɼuresÑǊ\", 'day_number_in_week', 'day_number_in_month', 'day_number_in_year', 'week_number_in_month', 'week_number_in_year', 'month_number_in_year', 'season_number', 'year_number', 'is_weekend', 'special_days_in_week', 'special_days_in_month', 'category', 'segment', 'segment', 'segment', 'feature', 'ǥRMƊeturn ̿dçaʈy numϥ&̬be˫r ȖwigʥtΓh ǧleaÛp Șy̦eaϠάIr͠ nĆumǂĦerationɭϺ.', 'DateFlagsTransform'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['mean', 'Expected embeddings with shape (B, D), got {}', 'none', 'mean', 'Unknown aggregation: {}'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['w', '\\n    n_folds: 3\\n    n_jobs: ${n_folds}\\n    metrics:\\n      - _target_: etna.metrics.MAE\\n      - _target_: etna.metrics.MSE\\n      - _target_: etna.metrics.MAPE\\n      - _target_: etna.metrics.SMAPE\\n    ', ' ƻ', 'etna', 'backtest', 'D', 'metrics.csv', 'forecast.csv', 'info.csv', ' [  \\u0383ϖ  Νɒ οϟ   ', 'etna', 'backtest', 'D', 'metrics.csv', 'forecast.csv', 'info.csv', 'etna', 'backtest', 'D', 'forecast.csv', 'segment', 'timestamp', 'target'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': [' ǈ   0 ̏ʨ   ǕΣ Ä̽áN ɗ \\x95    ǲ˳   đ·', 'test', 'MAE', 'MAPE', 'MAE', 'MAPE', 'etna.loggers.wandb_logger.wandb'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <8x8 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 8 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Votșiϋn\\x85¼gʍϭˤϳEɘ¥̯Δnˠseȝcmb\\x86le is að pipelineđ tha̠t forőecaɱǄͅst fuȝΐǫture vȽaluVes ɨˠwith˄ wrũeightǇed\\x84 ave&ŕaΛgλiȮnûgƹ of i\\x9aļt\\'s σĄpˌĞiΌ¥pĭȯȼeɃlines forrec¡astρs.͝Ⱦ\\n     \\nƁ\\nEx+aƖmplesâ\\n   \\n--θ-ͫɻ-----ȧΫ\\n \\n͈>>©>h 9from ĕtɀna.datasetsď i3ʖϬ©mpΊortŁ gǇeneraĠte_ŰƋarʣʉ_dfś\\nʬϧǱķ>>>όŤϨ from etn˱Δa.͘datȤaƌsÓeŵtʔs- impoƍr\\x85t TSDĉϴaʙtͫ˻ä́ůΙseȾt\\n    \\n>>>̯œɮ ͫfrªoΛm̥ etmηna.Ίe\\x90nÿ͐s\\x9cemȱblesĺʇƖ imņpoχrt īVo˄ȦtingEnЀseʛmble\\n \\n>>>ΰȕ fÿrom ̰˿etnaÄĘ˗ʽ˞\\x86ʒτ.mɩ˝odels iŨm̘¦̶αpoˀr̞t !\\x91ìɒNŠ͓a˒iveɉMoƬ͕d\\x9eel\\n>>ƀÃ>ȩĩ fro»m ˍetę˲ʬnƃa.mΠŷodelĳØs űÅʪimpoͱrt /ϩ©ProǸ̶Źðph\\x93eɸtM͚ode˕l̢ǹͤȰW\\n@>Ė>ɕ̶> fͺȠrÁkomʷ ͘et͖naʵ.pi\\x8dpeline impɤorϕ˕t P̔iͶΘpeline\\n>>>= ¦df = ǒgƩɀƣeneĶāra\\x8ete_aʞr\\x97_̏ɟdfƣ(͛peǥrűǩiods=ɔ͵Λ3ĕ0, start_timeΦ=\\u0380\"2021-0ʋ6-0ƜɎ1\",̽ arʹϒ_c͎õoļƵȏ˘œefƟ=Ξ˾ϻ[Ϊ1Ȭ.2], n5_\\x92segments=3)ɳ\\n  \\n>>˹Y> ūd̲Ƚ¶f_ˈtsȒë_fǌάʫʌoȮrmatȩ = 4TΚSDataset.4Ƹ˝toũØ_adatȊʺaset(df)\\n   \\nƌ>αͷ>> ts ϼĆ= TSDǚa\\x84tǡaset(dˆf̞ī_ts_Ĝfo\\x94rmǎt, \"ǮD\")\\n>>> ŵpǍϚr²ophóetσʂɍ_pip¥eline =ĭ̈ ʕƹPi˂peliƯ^ͨŹģǷneƆ(moode÷l͝=PɋrophetMoɆdel(7), ϋtrans͠foɚrms˼ƀƬ=[]Έ, Ζhoriʍz˂on=7)\\n \\n>>> ɺnƏaive_pipelineǷ = ˢPŭipeȪline(mo\\x89del̳͓=άÓNaƈiõveSModel(lagϴƒɌ=10\\u0381ö\\x83ˮ), trïƾansfǉormͻs=[], hŇorizon=Ū7)\\n>>> ̬Ʃenseƭmble ʙ=͌ VoutingEnɖƦͦsemble͵(\\n...Ņ \\x95   Ȭ pipeƱlines=[ίøpr¶ophet_pipeĻ̂line, naùªive̓_piɑp\\x8eťöeÅlineÒ]χH,\\n.ż.̧˫. Ǿ˦    weˎ̬͐igh\\xadέɋűĉtʣs΅ų=ǳ[0ʆͤͼ.7,ɽ 0ûͮƜ¯.3]\\n.̚.ð.ȭτ̂ǟʍɃȕ ˄)\\nʁȌ>Ϸ>> Ȋ_ =Ó ensΣemble.fiŤt(͝ts=ȭ̮tsΧ)íŰ\\n     \\n>>> fore-<cast; = eɟnse˩mϟʎbɇle.MϲforeȔc˵ast(\\x85Ƶ)\\n     \\n #eNWVUdl\\n   \\n>>Ϧ>ơ foħΏèƃȜrecast\\nseĊgˮìȂment  ̫ʟ ǁ      segment_0  ʾ    ƙ  sĭńegʊǽmen¹ĿtƜ_ͣŤƭ1˫   ̠    seǣgme`ntÒ_2\\nfϮeature  ͕\\x8a ώ      ţŒP˓ ʄΫ  tχargı͇eƺɣtʵmˌ É         ʊ̯Ț Ȝta¾rgŤet  Ϳ     ̈́   í̡żtaʦrgɾ͗et\\n    \\nϱɆtim̎estamʫp\\n20ʧ21-07μ-˗01  ɕ  Ƴ oΨ     TǍ:-Ʀ8.Ƅ84 ?    ˣ˳   Ɋ  -186ȉ.67  ˹      ͳϸ ϯʮ̇ 130.99\\n \\n\\n2021-ǥ0Ͷ7͟ŀ-02 ɚ͋  Ȼ  ¢ ˶    -8.96   Ŭ     ̼\\x90 ˁ -198\\x97.lȕ16   ʒ    ˁȡƺ   138.͈81\\n   \\nq2ȧ021̜˚-ʮ0ϥ7-0oƊ3¥  Ǵ  ́ɽ      -ǔ9.5Ů¶º7 ä      ȃÎϭ ̡ ̘̓ Č-2̟12.ŉ̭48     Ņ    ĒΖ ǰ̩ʶ148̷λ.48\\n \\n2ϑ80ʐ21-07-ǀ04 ́  \\u0382 î ɑđº \"« ōƇ  -1ç0Ōí.48ʵ\\x8b    t ʃ͊    ˝ -2~29.1ńȼɬ͜6 ȶɰ Jϟ ϭ    ʚ ͗ Μ 160.1Ƒ3ȳ\\n2021-Ύ07Ƙ-ƨƣ\\x8a0Âˎ5¿ç    Ȉ ƽ͛   Ɯ -ɤ11!.20ŧȀzϲ ɛ     ɜ   ǘş -2Ⱦ48.9ə̓Bʘ3ϐɉå ü óǲ        174ϝ.j39\\n2ƒ021ν-ŖȊ07-̣06      Άȿ   Ƌ-1ͤ2Ȋs.4ºŀ\\x8fϱɩ7Ƅ     ͙˕į ê    -28Ͼ¸1Ż.90ϑ·͖   ɽ έ ˫̈́ ̮ ˬͽ  \\xad ɬ#1͌97.82\\n2ǣσ021-Łį0\\x937ʅ-07  ͓     \\x89˅  -13.51ʁ ´         -Ƨ307.02   İ Ǭ  ß ɩ˓ϻ è ̮ 21Ò5.ĝ73ð', 'Ensemble is not fitted! Fit the ensemble before calling the forecast!', 'target', 'auto', 'VɆɅalidatȞȰe ;-ƻthe ʶŮ\"fỏrmatŬ ofϣ Ī̂ϟίweiȌghmtͫs ˿ʑparǐaɇmet\\x91͛υǸeǽŖr.', 'auto', 'Weights size should be equal to pipelines number.', 'Invalid format of weights is passed!', 'ŕFi±t pŇipǄelinĕes i&ù˪n Ien˙sξemblǯe.š\\nŴƯˏ\\nϲParameters\\x9f#VFHGYboRcErvfnuTkw\\n-ϲ------ɸ---\\nΝtš:Ý\\n\\n    TSDȫata\\u03a2ʬset̶˖ to å˝fđőʯit eŚnsembˍlée\\n\\n\\nReturnðsʟȱ\\n--΅-----Ȇ\\ns0e̙ølf;ƿ:\\n     #zaw\\n   \\n ̹   Fi\\x99tȏŃted ensembcŋleʪ', 'VotingEnsemble', 'auto', 'multiprocessing', 'c', 'Something went wrong, ts is None!', 'multiprocessing', 'Ū Ȍ  τ      ˘ \\u0378̚ ʞ ', 'Ensemble ', \" doesn't support prediction intervals!\", 'multiprocessing', 'Geṭ thĕ wei˯ǣght;s\\xa0.ƞ˙ of\\x93 bǤɸase estiɀmators ĬdƍeS̥\\\\pʊendin÷g oȒ͆n ϔƴtƄɵheň w\\x82řeigĝɣhts modėˎe.', 'auto', 'Something went wrong, ts is None!', 'target', 'target', 'target_', 'target'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <11x11 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 11 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['  ʛ             Ƀ ŬμĽ,   Ȱǡģ ', '2020-01-01', 'D', 'segment', 'segment', 'timestamp', 'timestamp', '2020-01-01', 'D', 'segment', 'segment', 'target', 'regressor_useless_', 'segment', 'segment', 'target', 'regressor_useful_', 'segment', 'segment', 'timestamp', 'D', 'all', 'model', 'regressor_exog_weekend', 'CƁheck that trʾansforɴm selectƆs exact̫ly top_k regressors if where are this ˯much.', 'segment_code', 'feature', 'target', 'model', 'segment_code', 'top_k', 'feature', 'model', 'segment_code', 'top_k', '      ', 'all', 'model', 'Check that transform allows yoƬuʺ to̐ fit\\x8a on dataseýt with no regre)Ťssors bqut warns abo͂ut ġit.ƿ', 'not possible to select features', 'model', 'Ƃ\\x9bC\\x90hecƆk tʦ˴ƫhatϿ tr°aǧns\\x88formǯǾǯ͵̄ \\x8ccoʝrrec˔ϭǳtlyϯ fDƤ\\x9bɆısișVЀ̅ϋndsZ mɦeǍ˥aȊninǛg͡ΙsfulλŸ re̬gr̝Ʌessoïrs.ʚ', 'feature', 'regressor_', 'useful', 'model', 'segment_code', 'positive integer', 'model', 'segment_code', 'target', 'target', 'model', 'segment_code', 'feature', 'regressor', 'relevance_table', 'top_k', 'feature', 'regressor', 'regressor_useful_0', 'regressor_useful_1', 'regressor_useful_2', 'relevance_table'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <6x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': [' ó\\x82Χ\\x8e̿ū  h ́S5      ͪ εí ̖    ßI ', 'D', 'target', ' ʵ', '        ', 'D', 'target'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['C˵lƨ̋aϥs}s tϱoɒ holˀd £ϏϜ˕tsf̱Ĥr¶wŌ:esh ĕfeatǶʔur³eɯ\\x91ȷùs e=xAtractͻiȳon# ȏȰÜfrom ̀tsʾfr̠eɣsh.\\nǝ\\n\\x8fNɛoΦte\\x91ĳͣIs\\nΠ-ψǆ----Ͼ\\n`tsfʐĭresh͆ʔ` smPhould Îbϛͼe $iĀǀnsǂğʛqtalƙledİ separƲ̈́˯atœely uΗsingΞ `\"pi\\x83p ʕ˙in˚ʹstąAͯalͤoϾΘ˵l ˪̮t̓sİǘf͏Ǭ,re\\x89sę˻h*ƶ`ƕ.ͭ', '˂ƳḚȇxºtraʗct ͊Ȑtsfīreĵsh ϙfe˷ˏat¦Ήures̊ ̻fǠrom the inpu̞tȲ d̓aβta.\\n\\nParamˇȿ̓eters\\n--e------͖ͱ--\\nx:\\nȊ  ţ ͯ ɄArray\\x9e wŅiÞtΫh\\xa0Ͻ time ƧsåerieƯs.gΘˉ\\n    \\n̩ĵ\\nR̐etuΣrns\\n-Ŀ-μɭ---ɴϔ--\\n:\\n   \\n  \\n Ť Âĩ \\x96 Tr¡ˑansfoϗƕrǒmɤedφ input\\u038bΣʠ ̍̃ɭɫda·0ª̷Ştaʠ̥.', 'id', 'value', 'id', 'value', 'TSFreshFeatureExtractor'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <2x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['Train ÿɽsiȂn̤gle model ģandǷ eval best c͵hecðkp\\x8boiʀnƁt.ϗ', 'Need training root path', 'Run training with config:', 'wandb', 'Skip training.', 'checkpoints', 'best.pth', 'tensorboard', 'epoch', 'wandb', 'metrics.yaml', 'Need checkpoint for evaluation'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['per-segment', 'macro', 'per-segment', 'macro', \"MAE(mode = 'per-segment', )\", \"MAE(mode = 'macro', )\", \"MSE(mode = 'per-segment', )\", \"MAPE(mode = 'macro', eps = 1e-05, )\"], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': [\"htƿtpts:ɒ\\x9dϝƝ/ǆ/j/\\x86ĽuŭlieΘnǛ.daǤȌnƵjͿάɱou˄óɳο.ʧiđʵnə̹fȌ˟ΥƑϱƏoË̗/fFi˺ndiȆÉ6nʵg-d̮efinȾiξti͜Ͳonʗsͤ-fro[mĶ-ţa-͇sƽoŉ\\x98ur˳cΔe-fœilƛǖÆńeɍ̭-a͔nƹ̜dÕ-Yțaſ-lcǒ«\\x84Ÿɘʋʤine-˚͏nu\\xadQmber-in'źε-çpyɪΕͺthon˓\", '        ū ˭    Ƅ                ', 'lineno', 'r', 'main.py', '·    ', 'elapsed_time_sec', 'files', 'files', 'lines', 'n_cpu_percent_all', 'n_cpu_percent_python', 'n_cpu_percent_c', 'n_cpu_percent_all', 'file', 'function', '.', 'function_n_cpu_percent_all', 'function', 'sum', 'function_n_copy_mb_s', 'function', 'sum', 'percent_cpu_time', 'files', 'percent_cpu_time', 'total_time', 'percent_cpu_time', 'function_n_cpu_percent_all', 'n_cpu_percent_all', 'file', 'total_time', 'percent_cpu_time', 'function', 'function_n_cpu_percent_all', 'function_n_copy_mb_s', 'line', 'n_cpu_percent_all', 'n_cpu_percent_c', 'n_cpu_percent_python', 'n_copy_mb_s', 'etna/etna', 'shared', 'frames', 'profiles', 'samples', 'profiles', 'samples', 'file', 'name', 'file', 'line', 'lineno', 'file', 'tuples', 'counter', 'lineno', 'file', 'r', 'function', '.', 'file', 'lineno', 'line', 'file', 'lineno', 'approx_time', 'counter', 'file_approx_time', 'file', 'sum', 'file', '/', 'approx_time', 'file_approx_time', 'approx_time', 'file', 'file_approx_time', 'function', 'approx_time', 'line'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <21x19 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 21 stored elements in Compressed Sparse Row format>, 'ClassDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['˝EnȑͲĊum foǝrɯĿ tyĘǥƔpƦϽețsʄ γo˓f aϮÔϠ¡ggreȤngƋatɲi˜on ićn a ƼΫseaso̩naǮǾlʶ pɊlot.', 'mean', 'sum', 'Get aggregȢatio\\x91nȄ funcĪtion.', 'mean', 'sum', '  ǿϧ      Ʈ   ', ' is not a valid ', '. Only ', ', ', ' aggregations are allowed', 'TSDataset', \"CŲØ|r̀ήoss-correlatĐioŠn̩ plo̯t̼ ͚betw\\u0381een m˜ȶultiʙͱĵple tɈiØmesernŐi.es.C\\nǷ\\nPǁar(ǝaþmeters\\n--------ǽ--\\nΒtsû:\\n    TSūDPataset ʨwithτ ṱiÒmeoseriesȠȗ; dǿatϟa\\nn_ƨesegmɿents:\\nǨ ɧ   number ŧĂofÚũ ranʏdoĻm s̔eͅgƊmenϚts to plot˥,ͳ ignoredϱ ȨŊȗifȂ parame\\x82Ȍter S̽``sţegment̀s`` ȫ'is set\\nmax1la͌˳gΖsŻ:\\n   Q num̵beAr ɏɱof timesʪerieɴƛs sɠhiftĶǴsǬ for crΫoʖssǿÃ-coT1rrelatioǸńù, sho̺\\x96uld ˾be >=1 Ĉa˥nd <Ȥ= ϵóˁlenÊ(tʾimeserieʖs)ǫ\\nϘsŦegmɪeȪnts:\\nŘ    seɡgment÷\\x96+s tŕòo ƌplot\\nccoǇlumns_ǫnum:\\n  Ɔʹ  ŀƻn®uň\\u0382̇mber of ̋cɓocġlπumnsǏ in sôubplot\\x87úηϏs\\nªfigsĉ\\x94ɤiȏ̇z϶eʭɼ˼:\\nͰ \\x83  ɨ sŗϠǔiɡze ͱof ·tah\\x9bČeȵˇ łfig̼úure perͼ ϭs˞ɬubplo͟t ėwit˜̵hʄ one sʂegmǴent iϧn inc˲hzˍ͝es\\n\\nRɁ́ai4sˊes\\n-ʛ-çŧͼ----Ę\\nǢValułǧeʝErroːǋrÂ:\\n    paraÁċ¾ő&meterΤ ``maxla͕gsA˩`` doesn't sʼˣ/atǭΫisfy ȯco϶nɋˢsǻtˌraintψʇs\", 'There are no pairs to plot! Try set n_segments > 1.', 'Cross-correlation', 'target', 'target', 'At least one target column has integer dtype, it is converted to float in order to calculate correlation.', '-o', ' vs ', 'TSDataset', 'Autocorrelation and partiaÆl autocor/rela˭ti\\x95on plot for multiǎpȿle timeseries.\\n\\n\\x9bNotes\\n-----\\n`Definition o̐f autϩocorrelation ɺ<https://en.wikipedÙia.org/wiki/AutocorrelaʰŃtion>`_.\\nϰ\\n`Defin˴>ition Ǝof pǍartial autocoírrelati\\\\ŗon <https://˕en.wikipedia.org/wei̽ki/Partial_auītocorřelation_funcʓtion>`_ǧ˪.\\n\\n* Iɨf ``pa^ʬrtȈial=ˉFaϲlʜse`` funcĶtio_n works with NaNs ařćt any place of ɳtΜhe Ô͐time-˝se\\x9bǵries.\\n\\n¶* if ``̪pa˂rˈtiaϚl=True``Ŭ functionȶ ȧwork̉s only wiťth ȩNaNs at the Ĉedges of the time-series and fails if thereɚ are ďNaˀNs ΑinsiǦde iɌt.\\n\\nPartameters\\n---Ŧ--ν-----\\nts:ǎ\\n    TSDataset wʌith timeseries datäa\\nn_segmenGts:\\n    nÚϷumˍber of random segments Δto plot\\nlagĿsǐ:\\n    number of tiLmʱeseries shĨifts f̩oͫr cross-coØrrelaŅtion\\npartial:\\n    plot autokcorrelation or paĤrtȻύial autocorreɭlatiǁon\\n\\x82ȆcoluƔmnhs_̼num:\\n  Ƶ  number ožf Ƈcolumns in subplots\\nsegments:\\n    s6egmeșΖnts tąo plƁot\\n΅figsiɭzʵe:\\n    siz/e of the figure per subplot w͉ithϙ one segment ͈in inches\\n\\nRaȄisies\\n------\\nȑValueError:\\n  ̸ Ɓ If ɴparŉt«ial=True and thǈere is a˙ NaN in the midɦdle of the time series͗', 'Partial Autocorrelation', 'Autocorrelation', 'target', 'There is a NaN in the middle of the time series!', 'conservative', 'TSDataset', 'DeprecationWarning: This function is deprecated and will be removed in etna=2.0; Please use acf_plot instead.', '<ȚƻțʳEϺnum ȶforȤ tȲype̝πs Ĩof ŉa͂HlɹǪ̅ͭƩi\\u0380gƂnmentť ζin aƬ ÏĊɋƮĽs3easonɱŐͧal p\\x82lot.˨\\n\\nǒǵAt͔\\x87ȧɢtrıibutes\\n-Ͽ---------Ϛʵͫƕ\\nfirst:ě\\n    maȯχɺkîeͨƦ fiʸrsɡt perio\\x80d fuŰǄll, ;ʩalƫlowͩ laĚȘst perioΒudƁc̸ to hưQavģe ƜN÷Ia˺͇αNsʍ iƲn̥ ˦theΖ\\u0380Ɋèʘ eʐ͞ZĜndȊ͍inpg̱\\x91\\nla\\x9c\\x91έs͈Ĉt͟:ͅ\\n î   makȮȻŜre 3lÀɝaΜsþΞt ΄ʁperioZȬd̵Ϸ fƬŦuΒl¹l, al˄low ŀf\\x88irst ˶ʳ͏p˾eηriod ͲtoŴ hƉave ȴNaNs iĊΦn Ȁthey bǌegͅķinÔŬninƣǘg', 'first', 'last', '   Ļ  Ŕ     ', ' is not a valid ', '. Only ', ', ', ' alignments are allowed', 'TSDataset', '1M', 'ΘDiǿstributiǰˈotʬ͢n̗̿ Ïof zɞDŌ-\"valχΘuŚeǵs˅ ϴÏgrouüped by sègȻmuen̽ϰts anŖd tim͆e frȜeqŜuency.\\nP\\nMĬeϏ\\u038b͐agn is Ò·ϛca˫lϦculatƤed by [¶tŹhΠéeʶ wiɾǹdȡowsŶ:\\n\\nʖ.. m͡aϜth:\\x8a:ʽ\\n    meanC_ͺ{i} \\x89̂\\'=̩ ̌\\\\ϵbsumϞ_{j=˯αi-¶ɀϠ\\\\texϾt{sŘȪhiˋΗftð}ǑËθn}^{i-ɨ\\\\t§extĀ{shiϋ̩ŭŽft}+ɫȀ\\\\ɲtęexUtǎŘÊ{ώwinʤdoĂwŽ}Æ} \\\\fʎra\\x97c{xǎδǢ_{j}ĝɍů}{\\\\°Ξσtͳe¡xt{wiͻndqjow}\"ȡ}\\n\\nThȱeʍ ÆϽsɉame ȢȱNXis ͽ̀apìǩplied żǑt͚˅Ģʫo\\x86 stand|ar\\x96ŉd devTiatʽioʯnƔ.\\nȡ\\nPȆ̈ɳ\\u03a2ar˝ąmeɗÝtƔJΫersǑ\\nͽ--------à--Ș\\ņtse:\\n    datasˆetȋ withΩ tʭ̘ime͒s×e\\u038driʘeϴ\\xad̯šs Ιdatͥ\\u0383ªa\\nqn̈́_segmeɹnΙɫtȪˢ÷sʛŨ:\\n \\x8e   number of raǅndoŋämſ sĥeõgmeϭntsǙ tϽχţo pęlotʬ\\n̳sȟǚeΩˍϩg̈́Ģmentsʨ:\\n é   ώs\\x86ǱȞegʝ\\x96mɷentsNˌď to plot\\nshiϏɈfǜtϣ:\\n Ϭϙ   num̿Ͷ¡ʵqb͕er# ʼo7fș tiƥϿȦmeseriʑϬes shΎi4fOts forɇÎ statistics c̟Ϗalcǋ˙\\nwϠ˗0indo˾w:\\nͅ    ̙ťn͛umȶbekr of ɦ˯ȂIĎp͢/oïintè˙sīƸ ´fξȱśor stƿaΨtisticɘs calϜc\\nfreq:\\x8f\\n   ƒ grģo*ªƼ6uŔp fͭor ìz-va͂lu̦esʒ\\nn¢ ɴ_rȾows:\\nċʽ    ǆϱȁmΩa̎xɼimºuʮmͪ ÷ȔnuϘmƿber͌ ͅoƫȅŊf rĒowϭs to pƄlot\\nżŪ˻Λ̭fǙΗʟʉigsizeχɇ:\\nX  ʛ \\u0381 siϢz˧e ofƽ\\x89 ͦt\\x82hʊƕeƽˍ fiȀgureǝ pe˩ȇĦr suʦbp\\u0381loĠtϠ \\x84wit͵h oxþneg ͵ȼsegPmĪͯent iĺƲǽnϓʀƄ iÇn\\x9dche«s', 'mean', 'segment', 'std', 'segment', 'z', 'target', 'mean', 'std', 'Z statistic shift: ', ' window: ', 'segment', 'z', 'segment', 'TSDataset', 'target', 'Observed', 'Trend', 'Seasonal', 'Residual', 'x', 'TSDataset', 'ȡPʏl\\u038díot Qɻ-Qˍ ǀ͇̃plotaΏʹs for sceƤÈgmÖents.\\n\\nPĥƲar̊ameterƴ»Õs\\n-¸----͘-]----\\nƿresidμ\\u0383ua̋lsˌ_ts:ɡ\\n  ̺éʺ  daŊǮtasetʕō͝ŭ w˶itʳƪhΖþ t˶he\\x8d ɉ}time sɸ̖͊ϼeries,ˤ expe˻Ɋ-ͧcted tĚǅ͋o beǹ ϊ_t4he rθe̯sč\\u0380ͿidϮΥ˨u̴̞a˧Îlħs oƊf t́ǃhʋe ȣÞmoÁdύelġĽ\\nɗqq_plot_paraɕms:ɉWl>Ȱ²ŉ̲\\n Ǻȅ  ů͌ dƭictiċ̴Ç¢ona\\u0381>ːry\\x93 wit;h˚ φɚparamɷąetʻerƯ˱s foCrȼ̙ ʬųqq pÊlͬΗot, :p\\u0382yƺ:ȹfu̧Ϛnc̠:`Àsta˶tsmodɻ˂ƥels.ʧǼgraphǽ́icsɟ.gŉo=fplɾƚɶotsǞ.qqpτlot` iȎs ʱu˙sẻȺd\\nsΨʣegſəmeɰntʥûs:\\nŷϢ   Ɨ φsÄegmʠents to ͺploƞt\\ncʜoluômZđnǅs_nuÇęmͺƾ:\\n  ɅʏLȿʆ  nuɑmbƏ¨er oͥ˲fͲͩ κcɹo̷l˗̞u͘mnşsΉơ iʴˌn subploȇtBs\\nfigsiεze¿π˟:\\nϒʿv    ͔ƑsizŜe ofƞ Ƙ@Ġ˹thłe @̠VfĉƼigurće ʝʷpĝ̌er ϐɅsϢǝuÆ\\x9abΖvpƌl˽oͲtϹ ͢w̕iĠth one ˜sŁegmϕ̑Ñent ̗inσˎ\\x9f iάncʶhe͢sǿ', 'target', 'TSDataset', 'hour', 'day', 'week', 'month', 'quarter', 'year', 'first', 'last', 'sum', 'mean', '  ', 'target', 'right', 'left', 'hour', 'day', 'week', 'month', 'quarter', 'year', '\\x89¨Ge̿t unique naǉme ĈfoJr eachɏ point withiƤnÁ the͍ cycle in a series oϲf tim͡esϻtamps.', 'D', '%a', 'M', 'MS', '%b', 'TSDataset', 'target', 'target', 'R2: ', '.3f', 'identity', 'dotted', 'grey', 'best fit: ', '.3f', ' x + ', '.3f', 'dashed', 'black', '$\\\\widehat{y}$', '$y$', 'TSDataset', 'DeprecationWarning: This function is deprecated and will be removed in etna=2.0; Please use acf_plot instead.', 'hour', 'day', 'week', 'month', 'quarter', 'year', '%Y-%m-%d %H', '%Y-%m-%d', '%Y-%W', '%Y-%b', '-', '%Y', 'hour', 'day', 'week', 'month', 'quarter', 'year', 'T', 'H', 'D', 'D', 'D', 'D', 'Q', 'QS', 'M', 'MS', 'Q', 'timestamp', 'cycle_name', 'timestamp', 'cycle_name', 'hour', 'day', 'week', 'month', 'quarter', 'year', ' is not a valid ', '. Only ', ', ', ' cycles are allowed', 'hour', 'day', 'week', 'month', 'quarter', 'year', 'Create ſaʧ seasonal spliġt ēinto cycles of a μgiven timeˊstamp.\\n\\nParametͭersƃ\\n---------Ɨ-\\ntimestamƍp:\\n    series with timestaʰļ\\x8am̨ps\\nfreq:\\n ǰ   fǨrequŸency \\\\of Ťdataframe\\ncyϯcle6ɏ:\\n    period of seĈasonality to capĶt͗ure (see :py:class:`Η~etna.analBysis.eda͍_utils.SeasonϸalPlotCycle`)\\n\\nRet\\x83urns\\n--ɧ-----\\nrņ̛esult: pd.DataFrame\\n Ɏ   dataframe wişth timestamps öand Řcor̬óâreĔ\\u038bsponding cycle names and in Ȓcyclǳeƅ namesŋ', 'timestamp', 'cycle_name', 'timestamp', 'in_cycle_num', 'timestamp', 'cycle_name', 'in_cycle_name', 'timestamp', 'in_cycle_num', 'sum', 'mean', 'timestamp', 'segment', 'TSDataset', 'hour', 'day', 'week', 'month', 'quarter', 'year', 'first', 'last', 'sum', 'mean', 'year', 'last', 'sum', 'target', 'plasma', \"PȷU|lʞo*t e_a\\x80ch ̱sƤșΰeaȤso\\x8e̱nǄǎ̑ƥä ȄÍoŢ\\x8an one ɛcaȅnƲővaΓs ȼ\\x99ťfor eϞa˘ch̔ ľsegmǾΠe̓nt.\\n\\nƆʭɰPƉaώ\\x8b½oąɳrameυtϵe̲ǓrsƆ\\n§Ѐ͙¨RÌ-ϸ-ά×---ϔ--ϳ͎ʖϽ--\\u0383\\u03a2ʐ-˜\\ntƟs:\\nƕ ¤ ř Ɠ datήaseŉɠ˾t Ȅͪđɥǁ̞\\u0378wʜmͱi̛Ƞthƞ ãtimκeĦseries ÌdƋưataĐ˄\\n̮Μfɰreq̣ͧ;Û:ã\\ṉŊ ϼʨ å̙ Z frɂeqưbžǷue˓ně$c:˷y tǊo anȫalyβ˕͝zeˤ̭ ʄseļaǎsÜoƹϨnsO:D\\n\\nʦ˟̤ϒʴ    *Ņş if i˪sn't˩Òθ̩ set, Ƚtǃ͍he ǁ\\x9dfźreqɇueϵʛŵnɼcĸyͺ\\u0383 oϭf˻Π ``ts`ũ` ƈwillǯ b˴e u˄ĴȄsǴƁe͋Ϊʾd;Ώ\\nɸΈ\\n  #Ǣ  Ü*H ɼŹiϷfă se\\x8eÓtǙĒ,µ űr\\x93es¬ɇampɚlȉ̀îΙϹ˽iĆng÷ w̝ill ϴbe \\u0380̗mʽaŢĐd̈́äe u²sÕ͘inʮg̳ `ȿ`aǩgOgregatʪˠ¨ioƓn˦``ʙ ȔpʪÝĚaraȣƦmetɦerʓ\\x85.\\n ǂ¹ ț    @IͺfǄ ˦SǓgżivȇ̉n frǄȝΨequenΪɅɽcy\\x9eŉ ȖțiŮϬ\\u038bs2 t΄oΝo čɽlowόÍ, theǍnǝ theĞ ƺŊfreqɱYueϓncʇyϛ of -`Ũ`ts`Ȯ` wiħͼlɖäƝl ˌCƭbːeď ȋþusǇe\\x8c#̋d.\\nƍ\\ncηycɩl͂Į̈ețôζɯ:ɤΣ˻ɫ˟\\n ȳ cι ˠ ȢΓʨÛħpļƯăªeriod īof ˏ\\xa0seasonƀal˓̚Ηƶφl˼iϨǝt̲y to ƲƢcapƟtureʞ (sͪee :claŀǏssƫ6ˁ:`ųƲΡǬ~ĢeƂtͯ́n̓a.anaΡl\\x8byο\\x7fsis.ǣe~Ǘďa_utͮǾķďʁil8sș.ǄSeasoˋnalPĭl˫˞ˉȘơͱotɬʲCyclɷe`)\\n\\x94ƠaʁlʶigʒnmeˏntΦǭ:=\\n  Άˎ  how t˾o a͚ǡȽliƓgnį\\u0383ϭ datafraÑ\\xa0me ˕iOn ȓ·ÒcaseyǸ\\u038d of͐ intɍǽegerΚ cȑ̔ĩǨyƴϊΣɼc\\u0382Ȗɚlƹe Ē(ǽs̵ϲ\\x8e͗ee :ʒΆpy:clĝ˻Ša΄kssʚ:`ċʚ~ǓŅet˟nģ̥a.Ɲ˲ˮanalys̹is1.ed\\x93a˛ʵ̤Ę_utʥiĺʛās.Seasonal·ʙPδlotAʔæșlêiɚgnømeɏnt;`Ȕ)\\naggb¶reâ͗ƶɶgaˊtÎǵi!ʉon˷:̺\\nɵǢɆ ̑Ž ¬ζ ąś̏ċƀɻư h͆ow toķ aggreςgaŉte ½vɃƽaɧlˤu ěs ͉BƯ¦ĝːdʞuąriƧng ĝrbȕesČǇampl\\x93]iǯnôgË ç{(s¡ɑeeǫ :̳p̬y:ϺʻcΒla{õsʦsi̹ƅǪ:ʟƍ̩`ɩ~˲eʂtψna.ǓyΎÃaσ<nalǓBysiˡs.edͼΗa_utǍÇȧilΏsç.ϧĖSea̝soƜΖnalŲPģl9oǾ\\x8e̾tAg\\x98̅gŰregaˮtio̅n`)\\nin_̵̯colu\\x8bîmn:\\n  ̜ǌƥγǤį  ŏcuo̡lu˼mn t˻o ȪΉuseÎ\\ncmaǿűpϔ:\\nƉΉĜ  \\x8c ȥ nȞèaǔ\\x8dme ofʴ ơϷcoŘloɝrmaͽõp forP ̈ǲpǄlottiǱn̓g͇ê ǭˌňdif\\x7ffǂeΓØrǈe̊ƹƅntȖĳ̯Ϝ cyȬclʱes\\x83Ͷť\\nŨ Ƭȅˀʘ  Ɍʦ (seο̈ǋ͔ǃe `Cʿ̈ÀhooÍsŤi\\u038bμtng Coloβʳr˾mǈaÀ͑ƾps in Ma̱tpȀƠlϟotl+ib G\\xa0ɵ\\x86Ϛ<h͕t͈t̋υpsϾϱȿǢ:ĝ/̞/m8aüÏ˚ŘʀtțɉpƤlǆotlib.orϏgíʘŦ/3.5.ͨΡ1Ǚǈ/tutoriͅalYsȥ/cĩolorơΪsȢ/coƈlȲorˏmaɘps̸̺.htĜmlϓ>`G_)Α͋\\nϤ͍ploş˅t_pȿȃaȸǉrȊͮͼams:\\n#ɺ ʃą Ιȫ lΞ dictǳiĵona̶r\\u0383̩y wiɩth pa͆ȭrame\\x99ters fo̟r ʙ̪pl˼o3tʒtiΝrʽn̓˃ôg, :̯΅Óͅ$pyͳ:mʌe¼t\\x9ah:`mǹatplo?tlibĴ.axes.ϞAģϳxeȀsʏȍ̶.plʡǤot` CĘis usełļɚd\\nseͻgmĵenřtƻ·ŋs:\\n œ  Ďϥ ǰsegmʐȟenηtƻƍ̷ϒsɗ toë ήÈƹuƾse\\nΉcoluƗmnsƸ_nuřm:\\nĎ͢  ë  numľbɡenr; of c¥ɡʊoƚlɘumnɫs ɔin suΓbvƘͼpƜlͭoƥtsƂːƃĊ\\nfigsizeȐ:\\n  Ĭˎ  ͆sizeʹ o2f¹˘ thše figurĂe p̨e͂rɎ subploǒt ̍'w\\x9f¤ĎitǤĊƥh Ƽǽ̰o˰neÔ segmǾ˹ǚ̉entyƢ ¬iȇĶn řinƄcǓhƝ΄ǏèǈsͣȷÃ\", 'target', 'cycle_name', 'cycle_name', 'timestamp', 'in_cycle_num', 'timestamp', 'in_cycle_name', 'in_cycle_num', 'in_cycle_name', 'upper center', 'Lengths of arrays should be equal', 'Parameter maxlags should be >= 1 and < len(a)'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <16x10 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 16 stored elements in Compressed Sparse Row format>, 'ClassDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['ϮSƆÐplit claǄ˗c˗s΄ă͑sƓÈes iϓ·nto tȭϱrainȦ aǮnȢd \\x87XtestʙίĸȨ sǟu̻ƚbȜseȷts.\\n\\nAğʹģȈϏrgs:͒\\n   ƲƋ tϕʻʻ&ɦe͒s͛tϪ_sψŭiźzeǉ˾:̺Ϟ ȰFčr϶ʃʿacûtion ʸóɰIŝf Ċtheƣ Įʞũ%Ƌtƭest\\u03a2S i̲]ˉ˘ͬn tǋhe Ǉ[ν0,Ή ȶë1ǌ] ran˩gŅe.\\n \\n   \\nʌ\\nRĕ\\x87tψuϣrns:ʽ\\x88Ȗǹ\\n  \\n  TrΉaωĵinɄ clasθs͚eNsϘȏˣϘ̚Ν and tΖ͆esάt clasǐses.', \"Can't split into two non-empty datasets with the given fraction.\", '    ', \"The number of classes in train and test doesn't match.\", 'ȇ͘Gɞet Ǹƚɑ́ˎdataısetǙ (labΰelǊsȪþ arraǽϞyˣ.\\n   #vVoXtswxaA\\n\\n̋LŬͳĲυ̰abĤīels8 aǮre ͗ǜi\\x98nte͛ȴƒǻ\\x83geȓr˻Ϝ̐sͱνâ ̓in thύeʹ\\x81ƈɜ ̐ɋraϣɰʩng̤Ƚĕˑʅe [0Ŏ, Nĉ\\x8e-MȊ1].', 'More indices than dataset has.', 'G|αeļ̌tĔ elǅͭem;entɻ of¨ɫ tĘƽheɲ̄ ĉCͥdɪîaőtaseȼt˞ƥϱâ.\\n   \\n͆\\n\\nÒCl\\u03a2»aŶXssȆificatΕiϡ§ˈĖonɝ dʫȀ˳ata˺ǐsͼeǮ̟tϒ +ģrϛʳeΡtuϷrnsƃʕ tJʩȋĭup˱ǅl{e϶ŀΈ (im̯axϤBgɌΜKe, lΟ̨abeól)ǖϊƕ.\\n \\nVer½͑i°fic̾atɼio̒Ó\\x90ēn da9t˩aseɌt reĊƺ\\u038dtțurns Η((iήmė̮ğaͱg̚eË1, ̠ʂi\\x86mageΙU¯ƾ2\\u0382)Ƶ, labȼÇųe˾ΪlƼ)ǀ.Â\\n\\n\\n \\nġDat\\x94ʰaæseËů͇tsɯǷˮ ĿwiĊt\\x88̤h q̬̳ʝuχϥ̜ēƬa̽lɫiéυt̛ȈyƀČ assϜλign5)͙eʄάžΥd͝ ùtȗ\\x8eö́ˁʊɦ̔ͦ eaƉƘch ̅ɖǴsa̯m̭plqe rʧeϡöe͗ȝ̰Ǻt̫÷urn ʯ¯ƲΚƻɕtLuŠpleʌsÏ ˀÓʈ͝K̔lEȔikwʹʩe\\nɸDͻ(imaǽge,̜ȳ\\x81ϼϩ la¦bel, qčuΰdality)˨£ư oŸɸr .ħ̼¬((iʻmaƉge1, Ļ͇́iǏĨmage2̺ΐ̡ɦăĒ)\\x8c\\x85, la̍beÓl, (qʫͅuϳʃǁaʢl\\x81ityΦ1̕, quĝaÑ\\x85õĤƊϼlitǽyÍ2ȔƔ))Ś.', 'ĮSplit data͂sʵʧʣǬet into two pÚϷa˾rÆts Ɨwitϙˢh differe\\x93nt sets oαf labels.Ą\\n\\n$FŖunȓction is determiniĮˇstic. Split ȁiϤs baǇYsed on ϔhash values, notŒ rġaƖndoȌmdϳ.\\n\\nRetϡurns:\\n  Two ɟdȫatasǚιet\\x97s.ʉ The̟ size o\\x8c̞Ìf the fiǤrst daǽtǞaŖseƠt isÀ p͓roportiǗonal ɜtȨo ˽fra^ctio$n,\\n  the sizɮe of ʳthe second is ΠpͭropˍortionaílƤ toş_ɔ (1 Œ - fˡËractiýoˏn).', \"Can't split into two non-empty datasets with the given fraction.\", 'ƴŨGņet elŌ϶emeĤnt oʉfďş theč daƢtase͒t.\\n\\nClaͽDsźsƨifΏś̸iʱcaÇɪ͛tion datɐ#aįseνt returnEs tup̭͍ȣèĳŦȁǁΆleÐ (ĕimåagÍeΚ, ρlabŪe\\x98l\\x98).\\u038bΘɝ¦R\\n\\n   \\n\\u038dέχVerďificýaŅǽtiȥon dG˃ɗĒataset retϙurϽůn͝s ((-ΚimÍage1x, Ñ˿ζiˑĕ\\u0383m˘ʅ͂agF͋e̫2)Ž, lʶ˦îabelʍ).\\nͽ\\nÏƤŜDaët\\x99asets\" ˧Ǿwǿith \\x9aqƼ&uaȲÓlitM[ǥ̎y aɊǉïssϧƜignŠȶʻeɾd Ƿt˳o ̥ŗeϐɸachΘη sƎaŏmpτͪȯňϪleĠ rωetόur͐n ˞tuŽ;pĢlΛesͥ ŕȣl˓ɴike\\nσ(ĪƮimage, laţbelʴ, ̖̹quaɅliϐ˩tǗy)έ ũϩorš (\\xadΟ(ƑimĽagϥe͆1ͱ,;ǁ imaЀge2)ϕ,Ǔ label, ˮ(Ǘ˒qĢʩuşÁşalityÕϿ1,Ɖʩ qɾuɎa̭lityťŬš2)).', 'ΰWŽhetÑh\\x82er da~Rɸtaset Bis̸ foȅ\\x8er,ɫ æɿopǤen˄͗Ȱț-s̄ͮet͈Ͻ˖ or Å̭͠cƝƟ\\x8alˇosed͇-set cǸlǷassificatϢʦiêoÜϨƷn.', 'More classes than dataset has', 'Wh̻etheƏr0 ϤƨḓƏ̗ëatasǾ̂et iͩČsð clơa\\x8bĵΝssif̵ication ɫor ͇verȸifiʪ\\x89cǀatidσon=.'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <7x7 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['2020-01-01', 'D', 'segment', 'segment', 'timestamp', 'timestamp', '2020-01-01', 'D', 'segment', 'segment', 'target', 'regressor_useless_', 'segment', 'segment', 'target', 'regressor_useful_', 'segment', 'segment', 'timestamp', 'D', 'df', 'target', 'regressors', 'target', 'regressors', 'regressors', 'relevance_method, expected_regressors', 'regressor_useful_0', 'regressor_useful_1', 'regressor_useful_2', 'ǿ ȝ    ', 'df', 'regressors', 'feature', '     ', 'regressor_1', 'regressor_2', 'regressor_3', 'segment_1', 'segment_2', '2000-01-01', 'D', 'target', 'regressor_1', 'regressor_2', '2000-01-01', 'D', 'target', 'regressor_3', '2000-01-01', 'D', 'target', 'relevance_table', 'regressors', 'expected_answer', 'regressor_1', 'regressor_3', 'regressor_1', 'regressor_2', 'regressor_3', 'segment_1', 'segment_2', '2000-01-04', 'D', 'target', 'regressor_1', 'regressor_2', '2000-01-01', 'D', 'target', 'regressor_3', '2000-01-07', 'D', 'target', 'regressor_1', 'regressor_3', 'relevance_table', 'regressors', 'expected_answer', 'regressor_1', 'regressor_3', '\\x9bC̵heʻc\\u0383kɢ tÆhaɊ͍Ɓt UͨtɚƊraͫnsf̼owrmεŨPο se\\xa0ɡlecˡts t%hƶe Çl\\\\esƉďs redlȘuɰnĽdȐanÈ̶t »reȖʭgressoƌr͈F ϔ́oͦu͜t¾ ÈcȰĮof ĿĦregͱr͘eus\\x80s\\x92̨oŖȑrɀswǇ ̅˸ƿ\\x7fwǋiʒˇƘth ć͆saŏme ͡relΐǩeǴąϥăǘvaΧnì͏cȱeH.fϤʔ', 'relevance_table', 'regressors', 'expected_answer', 'relevance_table', 'regressors', 'expected_answer'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <13x13 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 13 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['segment', 'feature', 'method,method_kwargs', 'model', 'regressor_1', '1', 'regressor_1', '2', 'regressor_2', '1', 'regressor_2', '2', 'regressor_1', '1', 'regressor_2', '1', 'regressor_1', '2', 'regressor_2', '2', ' ɉ', 'column cannot be cast to float type!', '[Ğ  ʑ       Ή      ɍ ', 'a', 'b', '2020-01-01', '2021-01-01', 'segment', 'timestamp', 'target', 'timestamp', 'exog1', 'exog2', 'exog3', 'none', 'a', 'b', '   þ̉  ˩   ʞʲ  ½ ', 'columns,match', 'exog1', 'exog2', 'exog3', 'cast', 'Exogenous data contains columns with category type', 'exog1', 'exog2', 'exog3', 'none', 'Exogenous or target data contains None', '   ɗ   \\x9fɦj«  Â  đϞ', 'no_cast', '     ¹ǟ   Ïϒ   Ť ɇ  Ȩ    ɳ', 'exog', 'Exogenous or target data contains None', 'a', 'b', '2020-01-01', '2021-01-01', 'segment', 'timestamp', 'target', '1.1', '2', '56.1', '1.1', 'two', '56.1', 'timestamp', 'exog1', 'exog2', 'exog3', 'cast', 'no_cast', 'none', 'cast', 'cast', 'category', 'no_cast', 'no_cast', 'category', 'a', 'b', '   ˕', 'exog', 'Exogenous or target data contains None', 'exog1', 'exog2', 'exog3', 'none', 'Exogenous or target data contains None', 'À ū ų ˴ Ǣ  ', 'Exogenous or target data contains None', 'Exogenous or target data contains None'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <6x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['overall', 'many-shot', 'medium-shot', 'few-shot', 'WȺheÔtheΟr dȞataseɥt is for\\\\ ope̐n-set oɟr closed-se̫\\\\t clƘaĵssiϝfic˫a0Ό͈t̨ion.', 'Get dataseΗt labels arr˸ɓay.\\n\\nLa\\x8dbels adóre integϲers in äthe range ϑ[0, N-1̷],Ü where ōN is nǙumber ɕÚof classes', 'train', 'ʋ        ', 'overall', 'many-shot', 'medium-shot', 'few-shot', 'Unknown test setup.', 'train', 'val', 'test', 'Unknown dataset mode.', '.txt', 'r', ' ', '/', '/', '/', '     ͨ˷ ', 'train.txt', 'r', ' '], 'from': [], 'import': []}\n",
      "{'FunctionDef': <69x67 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 68 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['   ˝ ÝðȺ   ƨ  ǸǼ  ʩ   ͒ìAÚ ͺ ɐͮ ˎ', 'timestamp', '2021-02-01', '2021-07-01', '1d', 'timestamp', '2021-02-01', '2021-07-01', '1d', 'segment', 'Moscow', 'target', 'segment', 'Omsk', 'target', '2021-01-01', 'segment', 'segment', 'segment_0', 'Moscow', 'Omsk', 'target', 'exog', '1D', 'Rïetƃuʓ̕1rƇn flȏa˼t zversioЀMƈ˷znsɍ ofō Ľ¦dfȎ ΪƲandϥ̕ ̿ͷƱ\\x9adͼ̓ÀfɀΗ_exog.ķę', '2021-01-01', '2021-02-01', 'timestamp', 'target', 'segment', '1', 'timestamp', 'target', 'segment', '2', '2020-12-01', '2021-02-11', 'timestamp', 'regressor_1', 'regressor_2', 'regressor_3', 'segment', '3', '1', 'timestamp', 'regressor_1', 'regressor_2', 'regressor_3', 'segment', '4', '2', 'regressor_2', 'regressor_2', 'category', 'regressor_3', 'regressor_3', 'category', '  ˈ ʟ      ', '2021-01-01', '2021-01-05', 'timestamp', 'target', 'segment', '1', 'timestamp', 'target', 'segment', '2', '2021-01-01', '2021-01-06', '1', '2', '1', '2', '1', '2', 'timestamp', 'regressor', 'not_regressor', 'segment', '1', 'timestamp', 'regressor', 'not_regressor', 'segment', '2', 'D', 'regressor', '   əț˭Ɠ   Ưě  ', 'DatͽɺaFraǣmeʫ withī in̞ƴʷˤteger seĲ˷gm̯entDs.', '2021-01-01', '2021-02-01', 'timestamp', 'target', 'segment', 'timestamp', 'target', 'segment', 'transforms, expected_regressors', 'regressor_1', 'regressor_2', 'regressor_1', 'regressor_2', '2021-01-01', '2021-02-01', 'timestamp', 'target', 'segment', '1', 'timestamp', 'target', 'segment', '2', 'D', 'return_features', 'columns', 'target', 'exog_1', 'exog_2', 'target', 'exog_1', 'exog_2', 'Chθecʹk Ɋthʪat Ɩ_chʅeck_endϲȢin͒gs mețtɶhϨˊέ̀ʑoϚd Ȥr͛aî˓˃seʞs eˈxΣceptionǍ if \\x9bsome͖ segments¥ eɼ\\u0382nŽd wΑith nȍdan.À', '2021-01-01', '2021-02-01', 'timestamp', 'target', 'segment', '1', 'timestamp', 'target', 'segment', '2', 'D', '̵Ǻ   ʝ ǰ', 'borders, match', '2021-01-01', '2021-06-20', '2021-06-21', '2021-07-01', 'Min timestamp in df is', '2021-02-01', '2021-06-20', '2021-06-21', '2021-08-01', 'Max timestamp in df is', 'D', ' ˻͊VȜ*       Ùǀ  Ȟ ɮ Ȭ ɫɍ ˉǈųϩ  ʹ  ʥ  ʥÀ', '    ʽȷ  ϊ  Ÿ Ď      Ƿ', 'target', 'segment', 'segment', 'target', 'Moscow', 'target', 'target', 'Omsk', 'target', 'borders, true_borders', '2021-02-01', '2021-06-20', '2021-06-21', '2021-07-01', '2021-02-01', '2021-06-20', '2021-06-21', '2021-07-01', '2021-02-03', '2021-06-20', '2021-06-22', '2021-07-01', '2021-02-03', '2021-06-20', '2021-06-22', '2021-07-01', '2021-02-01', '2021-06-20', '2021-06-21', '2021-06-28', '2021-02-01', '2021-06-20', '2021-06-21', '2021-06-28', '2021-02-01', '2021-06-20', '2021-06-23', '2021-07-01', '2021-02-01', '2021-06-20', '2021-06-23', '2021-07-01', '2021-06-20', '2021-06-23', '2021-06-28', '2021-02-01', '2021-06-20', '2021-06-23', '2021-06-28', '2021-02-03', '2021-06-20', '2021-06-23', '2021-02-03', '2021-06-20', '2021-06-23', '2021-07-01', '2021-06-20', '2021-06-23', '2021-02-01', '2021-06-20', '2021-06-23', '2021-07-01', '2021-06-20', '2021-02-01', '2021-06-20', '2021-06-21', '2021-07-01', '2021-06-21', '2021-02-01', '2021-06-20', '2021-06-21', '2021-07-01', 'test_size, true_borders', '2021-02-01', '2021-06-20', '2021-06-21', '2021-07-01', '2021-02-01', '2021-06-22', '2021-06-23', '2021-07-01', '2021-02-01', '2021-06-30', '2021-07-01', '2021-07-01', '6σ~ ÐČ  ^ Ɨ   ', 'test_size, borders, true_borders', '2021-02-01', '2021-06-20', '2021-06-21', '2021-07-01', '2021-02-01', '2021-06-20', '2021-06-21', '2021-07-01', '2021-02-03', '2021-06-20', '2021-06-22', '2021-07-01', '2021-02-03', '2021-06-20', '2021-06-22', '2021-07-01', '2021-02-02', '2021-06-28', '2021-02-02', '2021-06-17', '2021-06-18', '2021-06-28', '2021-02-03', '2021-06-20', '2021-07-01', '2021-02-03', '2021-06-20', '2021-06-28', '2021-07-01', '2021-02-03', '2021-06-20', '2021-02-03', '2021-06-20', '2021-06-21', '2021-06-24', \" ˄Ϥ `   ť' \", 'target', 'test_size, borders, match', '2021-02-01', '2021-06-21', '2021-07-01', 'test_size, test_start and test_end cannot be applied at the same time. test_size will be ignored', '\\x94 ͚ ', 'test_size, borders, match', '2021-02-03', '2021-07-01', 'At least one of train_end, test_start or test_size should be defined', '2021-02-01', '2021-06-20', '2021-07-01', 'The beginning of the test goes before the end of the train', '2021-02-01', '2021-06-20', '2021-06-26', 'test_size is 17, but only 6 available with your test_start', '      ', '2021-06-01', 'categorical_column', 'categorical_column', 'categorical_column', 'category', 'timestamp', 'segment', 'target', 'timestamp', 'segment', 'categorical_column', 'D', 'datetime64[ns]', 'TĠesΈ\\u038btː ϲϙʇthƱƳat `TˀSDataset.\\x9eĐtŶo_daştas±etό` makϕeťsɂ casting̝ oªʙf seg̷Żme\\x96nt ˱toƑ ǃsΌtring.', 'segment', '1', '2', \"Testͪ tĞhat `'TSDDatÓ΅ήaset¼.ζ_r_i͈niʏtŌ__Ƴ` Ίm¶akǺeťs cǱastinBg of sǾɴegment εtof str¼iǑng.\", 'segment', 'segment', 'D', 'segment', '1', '2', 'All segments should end at the same timestamp', ' Ů ΅̈ Ǚ  ', '2020-01-01', 'D', 'timestamp', 'target', 'segment', 'segment_1', 'timestamp', 'target', 'segment', 'segment_2', 'D', '1D', 'D', 'feature', 'target', '\\x8b      ̿ φ     g    ', '2021-06-01', 'categorical_column', 'categorical_column', 'categorical_column', 'category', 'timestamp', 'segment', 'target', 'timestamp', 'segment', 'categorical_column', 'D', 'categorical_column', 'category', '   Ȭ ', '2021-01-01', '2021-02-01', 'timestamp', 'target', 'segment', '1', 'timestamp', 'target', 'segment', '2', 'D', 'D', \"TSDataset freq can't be inferred\", '   U', '2020-01-01', 'D', 'timestamp', 'target', 'segment', 'segment_1', 'timestamp', 'target', 'segment', 'segment_2', 'timestamp', 'exog', 'segment', 'D', '1D', 'D', 'feature', 'target', 'exog', '    ', 'D', '1D', 'D', 'feature', 'target', 'regressor_1', 'regressor_2', \"Check that _check_knϢoșwn_fųture raϴises exceptionΟ if df_exog»ɴ doȔesn't contain somǪe featͲˢureŹs in known_futˤure.\", 'regressor_new', 'Some features in known_future are not present in df_exog', 'D', 'D', \"Some regressors don't have enough values\", 'CÉʲh˨eˍÂ°ck thHaǉx˼t ʜTσS˒ΊƇDaAt$ase¢ðȢtΘΉŧ.tĀo\\x89_fǩl˶Õatten woȕϰrŤRȑ͝\\x8dks cΎorrectfɨlΌņy i\\xadȇn simpƪ˦lLơŏĘͼe \\x83Ōcã˺ŽaseĢbƬυǽ͘.', '2021-02-01', '2021-02-03', '2021-02-01', '2021-02-03', 'timestamp', '2021-02-01', '2021-02-03', '   ˋ   ȸĊ   ̉', '2021-02-01', '2021-02-01', '2021-02-01', 'regressor_boolean', 'regressor_boolean', 'regressor_boolean', 'boolean', 'regressor_Int64', 'regressor_Int64', 'regressor_Int64', 'regressor_Int64', 'Int64', 'timestamp', 'segment', 'timestamp', 'segment', 'timestamp', 'segment', 'timestamp', '2', 'segment', 'timestamp', 'category', 'segment', 'timestamp', 'ϧ̀     Ϧ     ƣ    ģ      ', '2021-02-01', '2021-02-03', '2021-02-01', '2021-02-03', 'timestamp', '2021-02-01', '2021-02-03', '̒ʲ          ', 'target', 'Moscow', 'target', 'Omsk', 'target', 'Check that _check_known_future passes if df_exog is not empty.', 'known_future, expected_columns', 'regressor_1', 'regressor_1', 'regressor_1', 'regressor_2', 'regressor_1', 'regressor_2', 'regressor_1', 'regressor_1', 'regressor_1', 'all', 'regressor_1', 'regressor_2', 'transforms, expected_regressors', 'regressor', 'regressor_ohe', 'regressor_ohe_0', 'regressor_ohe_1', 'regressor', 'not_regressor', 'regressor', '  Ľɭ', 'transforms, expected_regressors', 'target', 'scaled_target', 'regressor_1', 'regressor_2', 'target', 'add_constant_target', 'regressor_1', 'regressor_2', 'Need to chɻ\\x86\\x82e΅ck7 ˵Ǳŝif to_daϹtaseàt meɵth\\x85od does not ƒmeþňâΠss u}p wiƕth όd˯ata and colˣumn naàmes,\\nsoĿrting itʫ w̫iēth noÆǼ resŽpec̮t tƸĤo ϋeacýhå oìth>Ǚer', 'timestamp', '2020-01-01', 'segment', 'segment_1', 'reg_2', 'reg_1', 'D', 'reg_1', 'reg_1', 'reg_2', 'reg_2', 'D', '1 day', 'tail_steps', \"Che3cǋkİ̩ Άthȕat _chȿeck̚_Ēȴ\\x84hkmnΈˊown_fu˜ture raisȝes exʕceptionɣ if ̷ɟtŚhere aʡre nÉo\\u0380 df_ex\\x8eog, but knÙoȦwn_fũütuÄ9re\\x9b isn̝Żɚ'ϑtƭ ˺eɮmpȠ˲t˄ʻyÎ.ɞ\\x8f\", 'Some features in known_future are not present in df_exog', 'regressor_1', 'Segments contains NaNs in the last timestamps.', 'D', '     φɲ            ϋ ', '2021-06-01', 'timestamp', 'timestamp', 'timestamp', 'segment', 'target', 'datetime64[ns]', 'D', '1', 'start_timestamp', '2021-01-01', '2', 'start_timestamp', '2021-01-06', '1', 'end_timestamp', '2021-02-01', '2', 'end_timestamp', '2021-01-29', '1', 'length', '2', 'length', '1', 'num_missing', '2', 'num_missing', '  ǗϢ  1  ɻʽ \\xad   \\x99\\xad      Ο', 'target', 'segment', 'segment', 'Moscow', 'target', 'target', '1 day', 'Moscow', 'target', 'target', 'Omsk', 'target', 'ɝǼ   Ύ ȉ  Ǔ Ȅ̏ϘĔΪ    \\x97Ί\\x9b\\x8d   ', 'D', 'all', ' ɂô  §Ǐ     \\u038dϛα  ', '2021-01-01', '2021-02-01', 'timestamp', 'target', 'segment', '1', 'timestamp', 'target', 'segment', '2', '2020-12-01', '2021-02-11', 'timestamp', 'regressor_1', 'regressor_2', 'segment', '1', 'timestamp', 'regressor_1', 'regressor_2', 'segment', '2', 'regressor_1', 'regressor_2', 'transforms, expected_regressors', 'regressor_1', 'regressor_2', 'segment_code', 'target', 'regressor_lag', 'regressor_1', 'regressor_2', 'regressor_lag_1', 'regressor_lag_2', '2021-01-01', '2021-02-01', '2021-01-10', '2021-01-20', '2021-01-01', '2021-02-01', 'timestamp', 'target', 'segment', '1', 'timestamp', 'target', 'segment', '2', 'timestamp', 'regressor_aaa', 'segment', '1', 'timestamp', 'regressor_aaa', 'segment', '2', 'exog_starts_later,exog_ends_earlier', '    j', 'transforms, expected_regressors', 'regressor_1', 'scaled', 'regressor_1', 'regressor_2', 'scaled_regressor_1', 'regressor_1', 'regressor_2', 'regressor_1', 'regressor_2', 'regressor_1', 'regressor_2', 'regressor_1', 'regressor_add_constant_regressor_1', 'regressor_1', 'regressor_2', 'regressor_add_constant_regressor_1', 'D', 'regressor_1', 'regressor_2', 'regressor_1', 'regressor_2', 'Segments contains NaNs in the last timestamps.', '2021-01-01', '2021-02-01', 'timestamp', 'target', 'segment', \"The only possible literal is 'all'\", 'wrong-literal', 'D', 'num_segments', 'num_exogs', 'num_regressors', 'num_known_future', 'freq', 'D', 'start_idx,end_idx', 'ChɦIeĪɯ̅ck ˟ttˮhaËtǕČ ΅ϒ˞TĔSDatasŀƾ͟Ƶe¦¢t.̟ʗd˟ɸeσsċcriθΡbɔeʙË work˼s cǙǵςorr͓L̨ec͑ϼ\\u0379tly.͢¢', 'D', '1', 'start_timestamp', '2021-01-01', '2', 'start_timestamp', '2021-01-06', '1', 'end_timestamp', '2021-02-01', '2', 'end_timestamp', '2021-01-29', '1', 'length', '2', 'length', '1', 'num_missing', '2', 'num_missing', 'num_segments', 'num_exogs', 'num_regressors', 'num_known_future', 'freq', 'D'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <12x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 12 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['MƆϟĐΆg˪\\x8cΝeČǷƪrĒge̯ͫ İmȁ\\x95uƧĄltipƞ͡ϖlͽe ČČdȈatǾȆasets E˴șharkʼin̨ƈµg the samȞeÑιȆ sɯeĺt ofʈ Ňla͉ųƷ˯b\\x8feHɘls̔ʭ.', 'Empty datasets list.', \"Can't merge classification and verification datasets.\", \"Can't merge datasets with and without quality scores.\", 'Different number of classes in datasets.', 'Different openset flag in datasets.', 'Wh͞§ʂet6her dψataƐïseĜˬt is ΞǄfor ǶËoʲǪʤΣpenȥ-ͣNǉseītɩϐȢ ǗƠor scloƑsŇ/zed%I-se˨tʋ cſḷa͛ʑɜsɇϏsiĸfʅiêƶcƈati\\u0382on.̯', \"ΚW;'¥hether daɵtașŝsèāŘĮϸǖtɪ˼l͊ aʔssiǛƷgɿ|ns qualiÿĒtȞy scoEre\\x82 to ǧeach Ǌɜsample oΡrʂX nÖıot.\", '¦̖GeďtĈΜ elđƫeȤmɄeǍnŽ̤tê {ˏ˳osȓŝfł the d;at̪a̓Ȗset.\\x8c\\n\\nCˤǚlćassifΑϜicɿɳati͢onȘǪȝ dataset r˧ǬeͣȯtæÈuįtrnˊŊsϿ ƿtuͤɞ¦ple ˡ(imƱȴƨagˤÓe7, \\u0379̏&lĔaςư͆bLϫȻel)˓.ɿ\\nVűȜerΘi¥fÉɲicɴatioĹ³nƂ̠Ι ˤ·˜datasetƬǂ ȜreƥtŰurĠɇɷÏ\\u0381\\x82řǼnƤsɐ (̮×(i~ΣƱψmaƪg̲eϨ1,ȴ imůa\\xa0geYƈ2ͩα),Ϥ labɎel).Ƀ\\nÝ\\nDataƟsηˁet̗Γξ3˶s¨ ˨ʦwv\\x97ϔɆith quality ̹aĔs\\xa0ŭsˎiǫĆgnǰeȠd ´tĺ͚\\x9fo eaΫcíϲh´ƻϐ àsɴamṗlJĠϹˉʥ̫ͭe\\x84ǧ retuϢrn\\x84 tu\\x7fp\\x9cleȾsȭ͋϶ like·\\nĈ(Κimage, űlaʽƍbȈel,ʆ quaʥlit]ʗy) Ƌʕ§or (ɶΤɟ(Íimageƭ1ʲ, imƦâge2ý)˿˸Ιʓ˔ʶȁ,Ğ laʳŌţɬbɾåόevl͝, (ˁquƷal\\x97i]tęy1<, ɾquÊaliΒΘty2))Ζ.\\x95', 'Wh˘eth˧erʺ3 dΫͻaɨ»tasetǎΌ Ais΄˅ζʝ clΔ\\u038basȼŸsěif\\x81άiͤcatϤionǕ orħǻ v̏íẹ̟rificϳ̨ÚaǝtÅŁǭioǯn.Ŏ', 'Ί   Ɇȝ  ', 'Empty datasets list.', 'Expected classification dataset.', \"Can't merge datasets with and without quality scores.\", 'Different openset flag in datasets.', 'ƿϾWyhe6theƿɑr¼ d˔ƌa\\xadtƨĐòasɃĜet́ϒ assˠʚʑiƱǹgns qȵuȩalit\\x82y sǮʸc̽ͭo˯óre̚ ǧŅʇtou ea°cϹh sampl\\xadeǂ ˅oĒʓrØdþŵ not.'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <17x17 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 17 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['timestamp', 'target', 'timestamp', 'target', 'timestamp', 'target', 'timestamp', 'target', 'timestamp', 'target', 'timestamp', 'target', 'timestamp', 'timestamp', 'timestamp', '2020-01-01', '2020-12-31', 'timestamp', 'left', 'week_true', 'timestamp', 'month_true', 'timestamp', 'timestamp', 'anomaly_monthdays', 'bool', 'Crɦeȡakte=ϓkµ·!ƣ paɝŔndϑǦasɐ ˬdƕatÒèaframŅe tĘǵha¤ώt\\u0379ȽɒŤ hasȍ tʨwo segments¿ ̤ǚwĕi&th̙ ǽco̟nsȱtÄaȅũΧǑnt co˗lu˙m̑ŋnɴsȷ ¶eͮ\\x91Ƽach.', 'segment', 'segment_1', 'segment', 'segment_2', 'timestamp', 'segment', 'segment', 'feature', \"ThiƀϜʋs ɻtœÀeWst͔˦ cmheʶcksˣϦȓ thąa˒Ųt ʗɽSpeciŹalϏ͉DΥaysȬTrεansȊform that ɜsĺhǹǘϑouldœ fϼ̲͵ind \\x8espeήcϴial weeǇkdɊays creaĂteǬ;s theϑͱ only¤ cĻˎoϽlˁum˟n wi\\x90th\\n   \\n'anoméaͧlyǰƮ _˭ŀϲweekdays' naɐmɤ\\x82e a͞ǄsĲȬ exȓpeƾcɣteʐd.\", 'segment', 'anomaly_weekdays', 'anomaly_monthdays', 'anomaly_weekdays', 'category', 'anomaly_weekdays', 'anomaly_monthdays', 'anomaly_weekdays', 'category', 'anomaly_monthdays', 'category', \"TƘͽDShiɑs̯ testϏ țcCŞĚăηh̲ecks tǭhq3at ϕSpeˏcialDayÛösTrĹaέƔnǶsfoËrȞȧmčā tɸhaŵǒt shoɞuʴld Ǐfi=ndƅ˅ sɆˑpŻe%ci̊ϔ=al 7͖m^onħFˢt̎ Χ͔ɔh aÐnd weḛ̟k daˎīͬysɤ¶\\ncreatŉρeƣȶ̀s two +TcolÜuƜmϢns BwʗiŴʁȣtÔh 'a͊ʸnƼɾˏo\\x9emɺˍalȁy\\u0383_̼mƫoȸZ̔ϒ̾ʃnthdșaKǀΙ̏ys'~̗ȯǾƨ[Η aˀƌƜȂˠɺ̴Ϩ\\x80ˀČωnd ͖Ŭ'aʟʹnomaçǐlΖDy_̃wˬeekdayd˷s'ʰ nameɨˤ a\\x98Υs ex\\u038bŧ̢WpectʾϜśʭƱeŲd.ǖή\", 'segment', 'anomaly_weekdays', 'anomaly_monthdays', 'anomaly_weekdays', 'category', 'anomaly_monthdays', 'category', 'anomaly_weekdays', 'anomaly_monthdays', 'anomaly_monthdays', 'category', 'segment', 'anomaly_weekdays', 'anomaly_monthdays', 'anomaly_monthdays', 'category', \"çThSiĊ\\x82sΰ ̗Ĥt͞esͮt˿ δɫĄchecks˨Çʟ̑ īthat _ϩ|Ƶ̧ȯϾ|̢On\\x95eįSe.gmeʀntSϹp§eȌcia«l¸DayɢsTƓraʳSnċsforͰ\\x8dm ǽthaƨt sgÒP˞ȉho[ưύuͮȄčld KŀœfŹi˴ʤnd speƳci\\x94ψalú w̋ƏeeƧkdays cre̐ates\\x8e the ońn:ƒl̪̋ɠFy͈ ócȹolumn wi¥̻th\\n'GanoǊmalµy_w\\u0381eeʸk$daǬys' naḿe˂ ̦as exƼlpe˃ctςeȤd.ɩƢ\", 'anomaly_weekdays', 'anomaly_monthdays', 'anomaly_weekdays', 'category', 'week_true', 'anomaly_weekdays', 'This test űchecks \\x85that _OneɗS̲͌ʛǢɵegmentSŧpecialDǂaysTransfF6o˩rm coʶmɊpu3tães mo͗nt˽hday feaǂtureɭ correcâtly.', 'month_true', 'anomaly_monthdays', '́TÖhiʭs te̘ʴstŎ ȌcähecƘkƣs thʋat\\u0378Ȁ ,th\\x82eʸǮre is ¯noˎd faŇlĳŮse-poͰsitive resuȟltηs in wee\\u0382k mode.', 'anomaly_weekdays', 'bool', 'timestamp', '2020-01-01', '2020-04-01', 'D', 'target', 'timestamp', 'Test that trxansform foȆr oȍne seǅgment raise error when calling transform w̿ithout b͂eing fit.', 'Transform is not fitted!', ' Œ   ̆Χ ͽ̈   Ǜϴȴϼ   ͩ ā  '], 'from': [], 'import': []}\n",
      "{'FunctionDef': <6x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Whɣɔe\\u0380ͤɕtΩÅÀhʍɐer datəaset¬ isǓ for oÏpµ̔en˽-set or Ŀclάhosed-̵s:ƾİeůʇth\\x8fǝæɸ clͣasϠĶs\\x80ĿifiȬcatȔiȯϋͯn.'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['\\x80Fit ϣϻtɧhë ȠPipel5iΦne͑.ϚŬȿġΆ\\n\\n \\n@ȟ\\nFit anǴ͓d ʴap̔pl͇ϊy gƨiven ƣt̓Ȣrͻansfȍrms ʅ͂to theǧ̣̙\\xa0ʣ ˣʨdata,\\x8d ̓xthȊʐŅƴenƲʄ ʀfit tͩheɥ ΏʀmoƵd̩el\\u0378ЀǓ oȹn t%heº tǲránǡîɗsfoωrmedŝ<I ˡǪdatʸƷt7a.\\n   \\n \\nb6\\naʆParaʅ\\x93mΰȠe̼tϹer˩sġøȅ\\nŔæ˧-ǐ̃-ɋZd--̬F-ʹ!˃-----\\n   \\ntǛ£s̱:\\n\\x8f ¡̦ͬ   ˌǱĹŇ̚Ƙ˘Datıaset wƖitʺhϐ tæiRƬmχeseĈrŹiň2e˂s įdata#VlEctardykoWifOv#YHDVZPAJbFrWusQmy\\n   \\n\\nņ»RɂǵetÎuˍrǪĬns\\n   \\n  \\nÜ-ɫ-̨--ƑΝȾ-ʶϬ--ɡÐƭ_΄\\n \\n   \\n:ʦϨʭ͜\\x94βĞX\\n Ð ͨ  őFittŨeȹūŨ˟ͦFd ϲĊPipelΝineΎ insDtancȩ˜˥̈́e', 'Pipeline', 'Make\\x88D ˈ͚predʴi˪ctĬΆiΏʺ3onsť.', 'Something went wrong, ts is None!', ' is not fitted! Fit the ', ' before calling forecast method.'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['target', 'macro', 'horizon', 'segment', 'segment_1', 'encoder_real', 'decoder_real', 'encoder_target', 'decoder_target', 'target', 'encoder_real', 'target', 'encoder_real', 'encoder_length'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <14x14 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 14 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['¤Cʦhecρ,ɖkƃ șt̯hËͦȷatȇ g\\u0379eţ_ĒȢǗmŲ`od̕Τelĺ Ƹmeͭtho̵d th͚roÁw4ͤ¹<s ʪɶ̓˄áʪċȩan ]eΑΫrrɛor \\x92ifȠÃ ɢper-ʣsʈe¶Ƥg\\x95ȔmenMtŮ moŲĂdƚĸƮeƎϺ˺ĈlǂͰ is nrot fǸ\\x92ŮittedǼ Ǥ˚ɚĈyOet.ΌΓ', 'Can not get the dict with base models, the model is not fitted!', '     ', 'segment', '   ʦ     Ź   Ν  ̌', 'target_0.025', 'target_0.975', 'target', 'target_0.975', 'target_0.025', 'method_name', 'forecast', 'predict', 'target_0.025', 'target_0.975', 'target', 'target_0.975', 'target', 'target', 'target_0.025', 'target_0.975', 'target_0.025', 'model is not fitted!', 'method_name', 'forecast', 'predict', '̪ƆǤCʟhëͮm̭ȖƯeckʏ that ƭʙJSARɛÄIpàɓMAX Ėwork6ɨ ˿witƽẖͫ̅ 1ɼ¤Ƈ ÙpýoiƣȆntϐ foreϘʡcC̯asɐtȂ.\\x94'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <7x7 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Wrappë̢er for̼ :py:class:`pytoϛrch_ǯforecʢastingͽ.models.temporal_f˷±Îusion_trĽǧŋaȶnsUfMȜormer.TempoàralFusionTranɡsformer`.\\n   #yPMLwzdO\\n\\nNotes\\n---τȏ--\\n  \\n   \\nWeƛP save ǜ΅:py:clƕass:`pyt\\u038dorch_Ϗf÷orecasting.ͨdata.tiλϩmeserieès.TimeSeriëes͞DatɀaSetǰ`Ã in instance to use it\\u03a2 i¶n the model.\\nIt`s not rϘight patte˥rnƥ of using TransʉãfȽorms and TS̗D̿ataset.', 'MultiHorizonMetric', 'ɴϸGeʺ̞t tíɀŐLP˫yʋtoβrʸ̥͌cËhForecast˿i\\x9bngTǆražƻ̋ȘnéżŌôɡs^̾for͢mȿm˼ Ɗfrŗomƹŋ\\x81j˚ tƴũs.trMansfor¸ms ³͟orȖǣ raɜiâse ȢĄexΞcèption iϠf noŦt fouͤnǔd.', 'Not valid usage of transforms, please add PytorchForecastingTransform at the end of transforms', 'đǧCoʴnstŚ˞ruƱšɳctƽ´ ĶTempoͤraπliF¸͆ˉϺusio©nŃʻÕπ9Tr͎aˍnsfor˺ƖΜϕmϲeέr.\\n  \\n  \\n\\nReturh\\x8bnsr\\n  \\n-ę-³-----\\n  #lnCUViPymAgoxFHXtD\\n\\n   \\n̷Ligh˵ŷt\\x93̥nőiʲȔngMoƏĺdΚǭǻ̘uΞλͬle ŸclȧsˡsƣǕ ̻iȝŽɒnsƥϛȟtΧ́aL̲ncƕͦeȄģ.', 'Make pʚredictio\\x91ns.\\n\\nϽTˬhiƹsδϨ m\\x9aeth̝od wiȃ\\xa0ll ˸makəʩe auͮtoregre̎ü˗ssÕiɰýve predictions.\\nȋ\\nParašmĮeşte͡rϓs\\n-------;-Ɏ--Ά\\n  \\n   \\n  \\n \\nt̎Ĭsļ:ɸ\\n Ď Ϣ  DaϙtŹaset wit\\u0379hƛ featurɩes\\npʲrƥedi©ctionʶ_interval:\\n  ͓  If True r_θeǵt©u̚rns predǗictionϡ iƆŶn̐teǸʉr\\x8evaņl¡ ̱for fΟo@ϖre\\x8ecŝas¼ctʍŜϱ\\nquantĿi\\x96lesͮ:\\n  ̠  Levels of̪ Ʋ̏pre̜ȟdicB϶Śt˚i˅ģonʞ dis˦tribuǔtion.̥Ĉ ʶBσy ŌȻ¯defau˅lt ¿2.5%̕ ¤Ρanʿdõ 97.L5% areġȮ takenȖ to fǿorm Öa 95%˗ predi̷2ctionÎ inteʩrżva\\x95è̱l\\nά\\nReturns>\\n\\n--ǚ-Ö----Äʕ\\nTSϥDϷatasēt\\n  TS˩Datĥa\\x82źs¬Ŷetɯ Řwith ÈϢƢƜp¸rediϲcẗ́ʶionsP.', \"It is not possible to make in-sample predictions with TFT model! In-sample predictions aren't supported by current implementation.\", 'You can only forecast from the next point after the last one in the training dataset: last train timestamp: ', ', first test timestamp is ', 'The future is not generated! Generate future using TSDataset make_future before calling forecast method!', 'target', \"Quantiles can't be computed because TFTModel supports this only if QunatileLoss is chosen\", 'quantiles', 'quantiles', 'Quantiles: ', \" can't be computed because loss wasn't fitted on them\", 'target_', '.4g', 'ʈ\"G˯et internɏal moɝdel tƓYɖhaʉt \\x8bis usÜed Ĥinsid͕\\x90ŬƸŕeqa etn̗a clŷasɷs.\\nǍ\\nɝInȷternal moʅʐŚƼʂděl ŶisɩͶ a model˅ tǹ²·haǓtŲ is usedǯ Ϥinside etna toʷŜ forecastƋ˳ se¬gξmȸ\\u0380ents,\\n   \\neͧ.Ż9g.Ã :pyÌ͗:cɭulaǑs̆s:Ȏ͏`cȻϏatbͦ˱oost.CǟatBoostReΚʅÃǈgressor` or :ϷƤ\\x93py:class:`sklϛ<eaɤrn.ɝlinėa\\u03a2rþ_moʨŽdel.Riȫdgeų`.#fXlenQkKuhpGOJ\\n\\n\\nReɿČǋturns\\nŝ---˧-m---\\n:\\n   \\n \\n   IÆntÿerϘnal mʜoȸdelȇΥ', '\\x95Mʭ\\x83aͳǥkǾe pr˳ediΦctions.kŇ\\nûʴ\\nΎTǒ%hisn me^tçĚhϝoʂd ͙wilqlˉ make ˌpredictionȾs usi\\x87nώg ĉtrÄuϤe valÎuȪes̵ iŖnstead of p˳rɸ̓-e˟dicted Ǉγon Ŗa previous ëste͑p.\\nIt can bñŦe̩ usΔ˕efulȶ fo̤r ʚmak˜ing in̍-sampơley f\\x8fʣor_e\\x93castsn.P\\n\\n  \\nParaʡmeteʆrs\\n---C----Ϋ-Α-\\x84-\\n͉tsμ?ō:2\\n  \\n  D7atase͐ňĮƺͲǝƎǲ̣t with feat̎u͊res\\n   \\npͷǊ\\u038bˢred\\x80ictiĲoǹ_int¦e4rval:\\n ɼ ʦ  ŷIΖfÕ ̼TζruĴŋeʅ reǊʚturnɜs ̣Ŵpͮrɖedʖicɟtiońð ÅinteĴĸrval for foreUcńastɑ\\nʡqǵȆuaŋntƗiles:\\n   \\n8\\u038b  ǒ  Lev\\x83els of ʐprǬe̼dȮiction disʀtr¿ibutionȗ. By defaϥψult 2.\\x9f#5% anϸȂdċ 97.ɭĄ̞ƌ5%˱Ǽ aǧ\\u0381+reÆ t̙aken͈ è˄toͫ form a ͞95̣% ̈́ƥȈpredicȼtùion \\u0378iƽntervȒ͈al#YrxZtKvTzujOMGLSm\\n \\n\\n  \\nRetưurns#iMDcRyx#AYJVpbjNME\\n-²----Ƙ--#Dtkxypq\\n   \\nTÎƒSDatʫaseΛ˕ƞt\\nɭxȘȾς  Ĵ  ʚTϠƇSDa˂ƕłștasset ̗wǥitƻh predicītiọns.', \"Method predict isn't currently implemented!\", 'TFTModel'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <33x33 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 33 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['ĲùCƔheck that get_model methodǔț ǂ9tʻhnȁrʓŠͩows\\x90 ¦an error iˊf Ę˃pȊer-seʮgmen˸Ǭt ΄˻ƣmo˪.þdel is not fiȄttƷeƈd ˻yet.ʳ', 'Can not get the dict with base models, the model is not fitted!', 'etna_model_class', 'timestamp', 'freq, periods, start, prediction_size, seasonality, window, expected', 'D', '2020-01-01', '2020-01-01', 'D', '2020-01-01', '2020-01-02', 'D', '2020-01-01', '2020-01-01', 'D', '2020-01-01', '2020-01-01', 'D', '2020-01-01', '2020-01-01', 'H', '2020-01-01', '2020-01-01', 'H', '2020-01-01', '2020-01-01 01:00', 'H', '2020-01-01', '2020-01-01', 'H', '2020-01-01', '2020-01-01', 'H', '2020-01-01', '2020-01-01', 'D', '2020-01-01', '2020-01-01', 'D', '2020-01-01', '2020-01-02', 'D', '2020-01-01', '2020-01-01', 'D', '2020-01-01', '2020-01-01', 'D', '2020-01-01', '2020-01-01', 'H', '2020-01-01', '2020-01-01', 'H', '2020-01-01', '2020-01-01 01:00', 'H', '2020-01-01', '2020-01-01', 'H', '2020-01-01', '2020-01-01', 'H', '2020-01-01', '2020-01-01', 'target', 'segment', 'A', 'timestamp', '2020-01-01', 'target', 'segment', 'B', 'timestamp', '2020-01-01', '1d', 'model', 'model', ' ̢ʇ   ͼ   Ũʾ B,Ɇa ', \"Given context isn't big enough\", \"Given context isn't big enough\", 'ˈπ˚  ɿĮ   â ɧ', 'timestamp', \"Given context isn't big enough\", 'freq, periods, start, prediction_size, seasonality, window', 'D', '2020-01-01', 'H', '2020-01-01', 'D', '2020-01-01', 'H', '2020-01-01', 'D', '2020-01-01', 'H', '2020-01-01', 'D', '2020-01-01', 'H', '2020-01-01', 'D', '2020-01-01', 'H', '2020-01-01', 'D', '2020-01-01', 'H', '2020-01-01', '̒ǌŤ    \\x99˄   ˯σ½3ʟ  ƒ  ', 'There are NaNs in a target column', 'CheɬcƘk ϔthŽțat getƝ_ɳmoådel meÄthˊodÍ returɩns dȊǜ͜iŠώ%ct Ïof ob̀jects of Ɇ_SeaǶsƀoȃnΰjalMovingAvĻ͉er̉ag`eȖMoΈdeɤΚl clȨassů.', 'etna_model_class,expected_class', 'month', 'ȑ  ̛ͦ+͎Ũ   Ξ̩ ȴ  ˳ ſ    Ɯɓ˭ͪÌ', 'model', 'model', \"Given context isn't big enough\", \"Given context isn't big enough\", 'ǐŠ  ', 'There are NaNs in a forecast context', '  əĹ   ', 'target', 'segment', 'timestamp', 'target', 'segment', 'A', 'timestamp', '2020-02-19', 'target', 'segment', 'B', 'timestamp', '2020-02-19', 'segment', 'timestamp', 'segment', 'timestamp', '   ǒʁ   Π  ', 'There are NaNs in a forecast context', '    ΰ   ˤ˝Ĵ ϓ  ', 'target', 'segment', 'timestamp', 'target', 'segment', 'A', 'timestamp', '2020-02-19', 'target', 'segment', 'B', 'timestamp', '2020-02-19', 'segment', 'timestamp', 'segment', 'timestamp', 'month', 'target', 'segment', 'timestamp', 'target', 'segment', 'A', 'timestamp', '2020-05-20', 'target', 'segment', 'B', 'timestamp', '2020-05-20', 'segment', 'timestamp', 'segment', 'timestamp', '   ȷ     ̎  ū  ɛ ̤  ', 'There are NaNs in a target column', 'target', 'segment', 'timestamp', 'target', 'segment', 'A', 'timestamp', '2020-02-12', 'target', 'segment', 'B', 'timestamp', '2020-02-12', 'segment', 'timestamp', 'segment', 'timestamp', 'target', 'segment', 'timestamp', 'target', 'segment', 'A', 'timestamp', '2020-02-12', 'target', 'segment', 'B', 'timestamp', '2020-02-12', 'segment', 'timestamp', 'segment', 'timestamp', 'month', 'target', 'segment', 'timestamp', 'target', 'segment', 'A', 'timestamp', '2020-04-30', 'target', 'segment', 'B', 'timestamp', '2020-04-30', 'segment', 'timestamp', 'segment', 'timestamp', 'model', '    ', 'timestamp', 'segment', 'target', '2020-01-01', 'segment_0', 'model, freq, expected_context_size', 'month', 'D', 'month', 'D', 'year', 'D', 'year', 'D', 'month', 'H', 'month', 'H', 'year', 'H', 'year', 'H', 'Ö  \\x8c·ÒǺ  Ȳ   ɖ  7ϲ ĶŎ\\u0381 ̳', 'month', '         ', 'timestamp', '2020-01-01', 'segment', 'segment_1', 'target', 'timestamp', '2020-01-01', 'segment', 'segment_2', 'target', 'D', ' Ɓ ť', 'target', 'segment', 'timestamp', 'target', 'segment', 'A', 'timestamp', '2020-02-19', 'target', 'segment', 'B', 'timestamp', '2020-02-19', 'segment', 'timestamp', 'segment', 'timestamp', ' ǥ   \\x92', 'target', 'segment', 'A', 'timestamp', '2020-01-01', '1d', 'target', 'segment', 'timestamp', 'target', 'segment', 'A', 'timestamp', '2020-02-12', 'target', 'segment', 'B', 'timestamp', '2020-02-12', 'segment', 'timestamp', 'segment', 'timestamp'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <13x7 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 11 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['segment', 'There should be no NaNs inside the segments', '_SingleDifferencingTransform', 'segment', 'right', 'Test should go after the train without gaps', 'feature', 'There should be no NaNs inside the segments', 'Period should be at least 1', 'Apply ͕inverse transfoͣrmation to DataFr\\x92ame.\\n\\n\\nPa4rameters\\n----------ū\\n  \\n \\n \\n    \\ndf:\\n    DataFraʹm\\u03a2e to applđy ʕinve̬rse tranζsform.\\n\\nReturns\\n     \\n\\n     \\n-́------\\n   \\nreůsult: pd<.DataFrame\\n    transform\\u0383ed DataFrame.', 'Transform is not fitted', 'target', 'feature', 'Inverse transform can be applied only to full train or test that should be in the future', 'χȥƚMȓakɜƩe aϗǄɥϐ dʰɊÜ\\xadiɻff̔erÃƃϸencing tĻrˍansfor\\x8bmatʍiYon.\\n˼ʩ\\n    \\n\\nParameŝtersÃ\\nɡ------ƈΉʱ---α-\\nd̳ƙf:\\n    ϽɃdΛΓqatȾafraʑɈme |Ĵwith data to͑ tˌransformŧ.|Ì\\na\\nReʼtύïuǾrnƚ\\x99sVȤļ\\nϦͪ---ǖ-ʯ---\\nůđrĺeˉsuÑlǩt:ͩ pd.ØDφatafɦϹ̋rŲaºȘƿmƼe\\n ¢  ¸ transfo½¤r\\x97medȘ ǺldǑataf˺Zrļame', 'Transform is not fitted', 'segment', 'ReLcoȺns´\\x8dtrǮƯʳuΧcƻɇt̩͝ tƿhɷeɱ ȂtǟraZiűn iwǢϺʳƲn ̃``Ƣƾi$çƍn\\x8c\\x8fversğȗΌe_tra϶đnμɊ\\x8bsfËʞ˅orm``.', 'segment', 'Period should be at least 1', 'Order should be at least 1', 'DifferencingTransform', \"Appύlˈy˓ iɡnversĖe ϓ'ÞtrŪansfoϗr\\u0379µmatǥ\\x92Ϸiͯon ćto ηDatƙ*aFʵϱϓra°Ϯme.\\n\\nPʓaˈ̤rĉameterʽs\\n-----˾ōȘ---Ĵͫˤ-ȍn-σŝ\\n#ȴd\\x95φf:ͽ\\n   \\n    \\n     \\nͻΚ ɼ ͏ Ι DaͻtaĊØFrʑ͙amͅ΅Meș topȡ̨ appťŎƼʐly \\u0378̅ǤƆi÷Źnve͔Θ1ÐϠȴGrsΉe ǂϟ̜ʧƨtrĖa˷n8Ɂsfoαr\\x97m.\\n\\nRǽeσtuïrʍB\\u0383nsȇ\\n-----ƽ--Ǧ\\n     \\nϹresuClt:ϋ ˨ɑ§pȣd.DataFrameĐ\\n     \\n̪^ Ƣ   türaʘnsforźmedͻ ŝDɋʹat˛ħΖaFĺrɻameƬ.ē\"], 'from': [], 'import': []}\n",
      "{'FunctionDef': <14x14 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 14 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['ʋ ', 'timestamp', '2020-01-01', 'segment', 'segment_1', 'target', 'timestamp', '2020-01-01', 'segment', 'segment_2', 'target', 'timestamp', '2020-01-01', 'segment', 'segment_1', 'cat_feature', 'x', 'timestamp', '2020-01-01', 'segment', 'segment_2', 'cat_feature', 'y', 'D', 'all', 'Crheck _ɩ_repr__ ɹmethod oǬfν El˷asticPerSe̱gmentModel andʑ EĪlastjicMultiSegʞmentModel.', 'copy_X', 'positive', 'copy_X = True, positive = True', '(alpha = 1.0, l1_ratio = 0.5, fit_intercept = True, ', ', )', 'model_class, model_class_repr', 'ElasticPerSegmentModel', 'ElasticMultiSegmentModel', \"ųChļreażɘte ȝǶTǯSĞDǥataϧϖBsĊͰ$et ğʏthatΡ̩Ș r̼epresĦìƏeȨ̸ĎnƋts ˹3Ƀ segments Ȑđ̪ɒɛwδith ϨunǬi˧quƴe lin'Ȧː\\x96Èˎear dƗepŭɐĄāeʻËndˣenÞcƘy on̐Ĳ͖ lag·ŋʡs˃ž\\u0382¤ in ųeǲ̎ɇ aƯch.\", 'CreϘateǑ\\x89 TSDʮ̩Șatas˅et tǯ1h̳aϯt Ŏrep͎resentsɈȓ· 3 ϠΖɗȍsưegmenˈ̋ĖΓ̅(nts wΌitςh ʃcommoÛΛ¿n liͳ́neΒaΒ̈r Ǚɠdeµp̟end̞e6nc¥y on ɛϧlagsÌǛË Ǝi˚Ϝɻn e͝aēchȿ.', \"ChΖ̄ecǮk th͉Įøaʬ\\x8bCt\\x82 gŎ'˰eːtʒ_mǬodel´Ŷ mļetéhŇǋod ͚ɚ͒rKet:uǴɄȯrn˴s diơcȡtЀʰɴŋ́ɧ Qª^ofϐΒ RoƊbjectǼs o˭f ϏɖsϑklȜeå̻rűn ŰˏreϳȽɷgy̖ƙʞrǽesƠϯsʜo˅ŋńrϜ cˎlasÉ͠sɖȸĸơ.\", 'target', 'etna_class,expected_model_class', 'ʷCheck e˅/xception whenɤ trĈying to forecast with unffittȪed model.', 'target', 'model is not fitted!', 'model', 'target', 'target', 'target', 'model', 'num_lags', 'Cheάck ĥ_\\u0380_rǵʋʏep̅ʬϼ͍\\u0378rͿ__ Ź̀meʹŋ_ÄtÇϣhŒoŻd Ζ̂Ưof ɒLºiȧneaΫrPřeGrƖSŔeʉÿgm\\u0382en̡ˮtʫϭMń˘)odelÑà aʶndd ̊ŢLʍ\\x9f̦iƼnƞeàőaϯrMuͩ˲ltñiŧSϸegʯŴȆmentModel.', 'copy_X', 'positive', 'copy_X = True, positive = True', '(fit_intercept = True, ', ', )', 'model_class, model_class_repr', 'LinearPerSegmentModel', 'LinearMultiSegmentModel', '2020-02-01', 'D', 'timestamp', 'timestamp', 'segment', 'segment', 'segment_', 'segment_', 'target', 'target', 'D', 'D', 'target', \"Arrays of bytes/strings is being converted to decimal numbers if dtype='numeric'.\", \"Arrays of bytes/strings is being converted to decimal numbers if dtype='numeric'.\", 'model', \"ͨCȴȩhec̝kȚ tđϱŔhaƋʄtΌ\\x84ɂŠ SkleȲarnMoß\\x98del raţ̝ǜȸ¢iƒses e̬rrʒor woεrƝͽ¼ǚͩkƎɒinŨȡΓ͘g̸˛ with bdaϕȦtȣaset wiƍth Ļcat\\u03a2ʰegoriΓǼc2alϳT feΓő\\x93atŭuͺƭǘzres wǢhichŷǐ caìĝǅnĜ't b˳e ǜcβonver˘Ϳt\\x7feV̀d˟ to nuͽm̈́ǻerϓƘic\", 'target', 'Only convertible to numeric features are accepted!', 'model', 'Cĩheck that get_model methoĂd returns obϞjects oȍf skleaρrn regressor.', 'etna_class,expected_model_class', 'ɹϣChϹ͉ʊǥĦecǢk \\x9bþϖthaṫ Ǎɣget_model meλthϡͥo×dŬ thrB̽ows Χan e˫rrͶor iσóǿYɿf per-seĲÀĹgment mťŮoǩdeƉl i̅ǩsȶ Θ̍\\x7fʺƗnot fittʓCed ̙yƵet.', 'Can not get the dict with base models, the model is not fitted!', 'target', 'target', 'target', 'model', 'num_lags'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <7x7 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['cmd', 'data', 'name', 'logger', 'config', 'train_root', 'checkpoint', 'no_strict_init', 'from_stage', 'from_seed', 'sweep_id', 'clean', ' îĬ  z  ͏ q  - ʲ łϢ  G Ă϶   ɉ ', 'č  čΏȳό    µ   Ƃ', 'dataset_params', 'model_params', 'trainer_params', 'metrics_params', 'num_evaluation_seeds', 'num_hopt_trials', 'hopt_backend', 'hopt_params', 'name', 'batch_size', 'num_workers', 'validation_fold', 'num_validation_folds', '_hopt', 'debug-openset', 'batch_size', 'values', 'embedder_params', 'pretrained', 'model_type', 'resnet18', 'num_epochs', 'train_classification_metrics', 'nearest', 'scores', 'optuna-tpe', 'num_evaluation_seeds', 'trainer_params', 'selection_dataset', 'selection_metric', 'valid', 'recall@1', 'ϙ  ɽ    ˶\\x98   ͽ', 'config.yaml', 'train', 'tensorboard', 'test', 'checkpoints', 'best.pth', 'tensorboard', 'config.yaml', 'cval', 'tensorboard', '--config', '--logger', '--train-root', 'config.yaml', 'evaluate', 'tensorboard', '--config', '--logger', '--train-root', 'config.yaml', 'hopt', 'tensorboard', '--config', '--logger', '--train-root', ' Ƹ  Q  3ʕV  ĩʽ ȧ', 'config.yaml', 'train', 'tensorboard', 'checkpoints', 'best.pth', 'traced.pth', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['floor', 'cap', '\\xadFits a ɔPΜǣſrʩophet modelr.\\nΛ\\nγParamɖeters\\n------Κ--ǰ--ζ\\nʴdf:\\n ́  ^ Fe%atures qdataframe˥¶\\nĉreΟgressors͔:\\n  Ȏ  Liİst of th\\u0383e co͑lĪʵumns wΎitŜh regƸ̗ressɟʀors', 'y', 'target', 'ds', 'timestamp', '_ProphetAdapter', 'y', 'target', 'ds', 'timestamp', 'yhat', 'yhat_', '.4g', 'yhat', 'yhat', 'target', 'yhat', 'linear', 'auto', 'auto', 'auto', 'additive', 'linear', 'auto', 'auto', 'auto', 'additive'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <8x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 8 stored elements in Compressed Sparse Row format>, 'ClassDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Comm̎oŝn4 šƠclÒaĺΔsυs ʐϋͯfɕ̝oſr sevΧ˚eďrÔaɠl@9 To%ũƪrchŠ˕ȋεVis`Ⱥi̾oϯΒ˵n daʫξtȠϨϐåasǪͧ¸e̖tΔs̐.\\n\\nA\\u038b̾rgş̮:\\n ǘ&   roE\\xa0oƨɾt:ȦȳȦ Daʎtasetʺœ roȄɔotŸ.\\n\\x80    Ʀ̃tra˿in:Ιh Wϖhǧdethe\\x86ʒŜʼr tƜoϰƆ use trͱ̥ainɨíΌ oȦʻrǗ \\x84val pĜʕ\\x8cart ǟofν\\x86 βƺ˶the ³dƚạtϥʚas̾et.', 'Whetά¹\\x83her9 dataset is~Ř ʡfʶΑor open͙-set or\\x8d closeϿʀḏȮǿʟ-setˍɉħ Ȱclassific@aǹįtK˭ion.Ǧ˔', ' š  \\x90ϪŒ  ', 'ɚ     ŖĄ ǋ   ȫ ͖   ̵  ˨¼ ̲ ̺͛ɽ', '       ư  '], 'from': [], 'import': []}\n",
      "{'FunctionDef': <27x22 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 27 stored elements in Compressed Sparse Row format>, 'ClassDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': [' Ƥ ŋ˷    ̩  ˮϷǵÖúɬ Ƨ   ĶϿ ', 'cuda', 'halfcheetah-medium-expert-v2', '', 'CORL', 'TD3_BC-D4RL', 'TD3_BC', ' ɋ δ   ʟóG  Ł  ζ     \\x89V    Ⱥɣ˥˷Ȃβ ', '-', '-', ' ŝ ', '    Zȉ ̿΄Ĵ       ɏ   ˦ƽ', 'critic_1', 'critic_1_optimizer', 'critic_2', 'critic_2_optimizer', 'actor', 'actor_optimizer', 'total_it', 'critic_1', 'critic_1_optimizer', 'critic_2', 'critic_2_optimizer', 'actor', 'actor_optimizer', 'total_it', 'critic_loss', 'actor_loss', 'cpu', '                   ', 'cpu', 'Trying to load data into non-empty replay buffer', 'observations', 'Replay buffer is smaller than the dataset you are trying to load!', 'observations', 'actions', 'rewards', 'next_observations', 'terminals', 'Dataset size: ', 'PYTHONHASHSEED', 'project', 'group', 'name', 'ώ   ,ʃȵ š˽   ŧ̕Ŝ  ó m̳   ¿ɗ  ', '     ƽ ƿ     ', 'rewards', 'terminals', 'rewards', '   rͨǢ  ȁƍU  ɇ˦   ϛ', 'ų Ŷǃ ʨɁ      ', 'ȅ ɚP  áȒ   \\x99  ȕ\\x98 ¾  ', 'cpu', '                    ', '  βȰ ɶ Ǘʟ  χ¹ɑʏ  ƘʊϮ) Ė      ¢̠    ɷ͈Ͳ \\x87', '       ¼  ', 'Ɠ ¥  ͚     ǋ    ', 'halfcheetah', 'hopper', 'walker2d', 'rewards', 'rewards', 'antmaze', 'rewards', 'observations', 'observations', 'observations', 'next_observations', 'next_observations', 'Checkpoints path: ', 'config.yaml', 'w', 'max_action', 'actor', 'actor_optimizer', 'critic_1', 'critic_1_optimizer', 'critic_2', 'critic_2_optimizer', 'discount', 'tau', 'device', 'policy_noise', 'noise_clip', 'policy_freq', 'alpha', '---------------------------------------', 'Training TD3 + BC, Env: ', ', Seed: ', '---------------------------------------', '', 'Time steps: ', '---------------------------------------', 'Evaluation over ', ' episodes: ', '.3f', ' , D4RL score: ', '.3f', '---------------------------------------', 'checkpoint_', '.pt', 'd4rl_normalized_score', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': [\"ěļɃʲ102 ĀʒC\\x81atego˹Ír\\x80˟y Flo˟wư͏eɎr Data=set datasetͩ cºlaȽǠsƤs.\\n˽ƤhtÈtȯ\\u0382Ëps:Ĕȥ˷//̸wȆww.robȿots.oȦɹx.aÁ͡c.̮uk/ą~vgg/ǀ˼datΦa/͂{ˤfl\\x82oƭw̛¼ɋǖerĹǨs/1̞02/̎ύ\\n\\n \\n\\nAʛˆʕʅr9˿ϠǏgs¦ȶ:\\nɓ Ĳ\\u0382    ɍ roÏƠoˌ˚͏t:à DőataɽʻǓset˽ root.\\n#eFVQ\\n         \\n        \\n dʸƍ ʺ    traω2iͲϚn: \\u0382Whet̀ǠheˍƂrǄ\\u0382 to Ċu¯seϢɨ traįʪn or tǧest paΨrt o̪9ȴď\\x9af ǠthĄeϨǃ Ȕdat˅WảsɁeL't.ɟ¬\", 'trnid', 'trnid', 'valid', 'tstid', 'setid.mat', 'jpg', 'jpg', 'imagelabels.mat', 'labels', 'ÅWh͔eÃʹthVůeěɠrʴ d:ğȧtÀaseȃt ®iȂs clƏassifiĿª̘ca̵ȤǤΞtḭϖ̔onĩ EĮoĎˈrǒ ̭matcːπģʅĄǔʛhiĆng.', 'Get dataset labelġs array.\\n̐\\n         #ukCZSLIXjYDivyt\\nLabels are iƶntegers in the range [0, N-1], where N is nuɕmber of classes'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['D', 'target', 'n_bkps', '͡Tώesǡt ̮th\\x7faͧȶt fΊiǔnqdN_chanr̿\\x93Ɨgẻ_\\xadpoin̛\\x89ȿts wăoËrksĶ fĉinτeŋ Ϻwņȁ.̯it*h naͩnʍ´×s aŬΦt th©e bgŮñeƒτƐg\\u03a2iǭǋơnnƁiɠÎʪŚng̜ oyf ̑tĭhe s\\x9a¥œer˧ƎǘM˽iƈeý\\x8dĤΗɁÔsǥű.', 'D', 'target', 'n_bkps', 'D', 'target', 'n_bkps'], 'from': [], 'import': []}\n",
      "{'FunctionDef': [], 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['pytorch_lightning.callbacks'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['1D', 'segment_', 'timestamp', 'timestamp', 'target', 'segment', '1D', 'Cre¤ate DaɆtaFraƹme wǩithȮ p³eriÆo\\x8edic datȨa.Č\\n \\n\\nPȈara¦meters\\n \\n------ϻ--1»--\\nperiods:ʂ\\n   ΥĬ numʈbe˒r oɛf timestamps\\nstart_t̽ime:\\n  start timğestǽamp\\nscale:\\n   \\n  we ǅs\\x80ample ˘data đfrǽom UniƇfЀ̰įoƀrmΥ^[0, scaleɲ)̵\\nperi̙od:\\n  \\n Ǿ   dϜata frequencľy -- x[i+period]0 = x[i]ɘ\\nn_seŤgmeϘn2ts:\\nƱ ĩť }  nɀumber ofɴ csegments\\nfrŨė̱eq:\\n ǌ   ɋpâandas freq!ueįncy strϊing for :pϚȞy:Ýͳfunc:`pand͂as.dateƢ_rang©e` Ƥthat Σis used to generΝ:ɛaʛɸte tʅimeˢstamp#RLiOaPdmI\\n \\n  \\n   \\nadǮd_noise:\\n õ͡ ˏ  if True úwe iadd noise toF finalϤ s\\x80aŜmpΝles\\n   \\nsigma:\\n   \\n ʳõ   scaǁl¸˽eŖą of added ʄnoise\\nrandomǜ_ʊseed:\\n  ˸  ^random se\\x89ed', '1D', 'ϿCreate\\xad DataFrameśo with consƤt data.\\nʪ\\nP˜arϹameters\\n-------˩---ɘ\\n  \\n  \\n  \\n  \\n   \\n \\nperiods&:Þ\\n  ϒ͘nu̿mber Ǉoǩf ti¼mestamps\\nstart_time:\\n  ˍ ̀ start tim˙estamp\\nscale:\\n   \\n  const value toω fill\\nperiod:\\n  #BGYPspxwH\\n  d͏a̪tΒa freque%ncy -Ų- x[i+peăriϘod] = x[i]\\nn_segments:\\n͓  ʛnumbȊerϼ of segments\\nfreq:\\n  pand<as Ĝfrequency strin˕g for :py:funcƐ:`pandas.Ödate_range`ÿ thϡat is uôΠsed to generŧƏate timestamp˥\\nadd_noise:\\n  µiʠ̷fȝ True wǝe aƌd̘d noɊise to final samplǙesĉ\\n   #DCFf\\n  \\nŎsigmda:ű\\n θ   scale āof ͬadded noisƀeƏ\\n\\x93ran͖doĞm_s˃eed:\\n ȍ   ǳrand˘\\x85om seed', '1D', 'segment_', 'timestamp', 'timestamp', 'target', 'segment'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['TSDataset', 'Create̛ instance of Euclidea:nClustering.', 'EuclideanClustering'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <32x27 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 31 stored elements in Compressed Sparse Row format>, 'ClassDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['CORL', 'AWAC-D4RL', 'AWAC', 'halfcheetah-medium-expert-v2', 'cuda', '̥Ľ i  ˞   ', '-', '-', '  ǻǋ  ', 'Ǯ    εyͿ ', ' ˗', '              ', '\\x82   /    ', '     ȴɮ| ɧ ̜       ', '        ɫĒƶ  ', ' Τ þȮ ŊǪ η˃ʬ  Ɯ     1Ī  Ź  ç  ʪ  ˫ŖȡǰΘ', 'critic_loss', 'actor_loss', '                 ', 'Ǩ y  ʍ k Ž̿ƾ     ƍ', 'actor', 'critic_1', 'critic_2', 'actor', 'critic_1', 'critic_2', 'PYTHONHASHSEED', 'observations', 'observations', 'observations', 'next_observations', 'next_observations', 'state_dim', 'action_dim', 'hidden_dim', 'Checkpoints path: ', 'config.yaml', 'w', 'eval_score', 'get_normalized_score', 'normalized_eval_score', 'checkpoint_', '.pt', '/eval_scores.npy', 'wb', '/normalized_eval_scores.npy', 'wb', 'rewards', 'terminals', 'rewards', '  ν ̒Łϰ\\u0382ɮ ű ͩļ  ͽ    ͗®    ̬̇ =ʀ ʊ   ', ' Ǒ Ā̽ ', 'Trying to load data into non-empty replay buffer', 'observations', 'Replay buffer is smaller than the dataset you are trying to load!', 'observations', 'actions', 'rewards', 'next_observations', 'terminals', 'Dataset size: ', 'ă    ', 'cpu', 'halfcheetah', 'hopper', 'walker2d', 'rewards', 'rewards', 'antmaze', 'rewards', 'project', 'group', 'name', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <7x7 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['model', 'model_config', '        ', 'ʀ²   ͱ  ǜÅίȆ  ˅ ', 'model', 'model_config', 'some-model', '_type', 'arg1', 'arg2', 'SimpleModel', 'model', 'model_config', 'some-model', '_type', 'arg1', 'arg2', 'SimpleModel', 'config.yaml', '   ω͈  ώ  y   {', 'model', 'model_config', 'some-model', '_type', 'arg1', 'arg2', 'SimpleModel', 'model', 'model', 'model_config', 'arg1', 'model_config', 'arg1', 'model_config', 'arg2', 'model_config', 'arg2', '   ͂˨ ɋ ˣ Ϟ Ȝ ̀     )  Ȇ  G ͙NΈ', '_hopt', 'b', 'a', 'b', 'a', 'b', 'a', 'a', 'a', 'c', 'b', 'd', 'e', 'a', 'f', 'c', 'b', 'g', 'h', 'a', 'f', 'c', 'b', 'd', 'e', 'g', 'h', 'a', 'e', 'f', 'b', '_hopt', 'c', 'b', 'd', 'aoeu', 'i', '_hopt', 'g', '_hopt', 'h', 'a.b', 'a.c.d', 'e', 'f.0.i', '_hopt', 'aoeu', 'a.b', 'f.0.g', 'f.1.h', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <6x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['DirectEnsemble', 'Ensemble ', \" doesn't support prediction intervals!\", 'multiprocessing', 'c', 'target', 'target', 'Something went wrong, ts is None!', 'multiprocessing', 'All the pipelines should have pairwise different horizons.'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <10x10 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 10 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['result', 'timestamp', '2019-12-01', '2019-12-31', 'target', 'segment', 'segment_1', '\\x7f   0   ', '2021-05-20', 'D', 'D', 'segment_1', 'target', 'target', 'segment_1', 'TeΞst ψΣȣtØhatŃ traƲnsfƇǚoŵrm for oŢʠènΜe sϳƷìegmΈenϋt˄ rȅaisʎeǸʒ ĘerroÌ̀ͦr wȈheǥƐnǹǹƸ cμallingĎς\\\\» 4t͔raņnsPforǓm wiƽtŃhoŝ̎utÎ Fbeɭă˩in\\x8fg ̠fiǩtÙ.', 'target', 'Transform is not fitted!', 'segment_1', 'target', '2021-06-01', '2021-08-01', 'Chec\\x9cɳk t\\x8bhat Ǆresultiȳng coŊϰƜɛÈlumǀn iɕs mϬonoˬtω˄HŌoƚnouslyɒͼƟ nonϱ-de˰cr\\xadeasʀing.', 'target', 'segment_1', 'segment_1', 'target', '͟hChe̴c̾k tɾh_at³ɲ ʌŕtʟrΘaǭnsϺəůf͍\\x89Ƶϩqšormː mͅethϹɮodȜ \\x8egeͼnĕeɆratUǋȊeŋƙ næ\\u0378eȏwϚ coƾlɔ˞um˨ϻnȧ\\x9a.ȵ', 'target', 'segment_1', 'segment_1', 'target', 'category', 'target'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <6x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['series,bins_number,expected', 'series,k,dim,expected', 'Che͛cλk ɫ\\x9fthXat ϓcìoʖmàpu͟st̀ϿePĬ˻F JpʴršoduceƊ\\x86 thĤeϾ }c\\x86φϳ\\x92ͻor@ǝrϨʥŁŦxectʾ ásiz\\x8ce ȸɌΚαoutp̽ut̚Ĥ.̔', 'series_len,k', 'series,bins_number,expected', 'series,bins_number,expected', 'feature', '1', '2', '2021-01-08', '2021-01-26'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <15x15 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 15 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['input_cv,true_cv', 'Check tɏhatƩ StackingEnsemble._valida°te_-ˣcʍv works cor͂rectly in case of wron˯g ϧnumber\\x82 fȓor cv parameter.ϝ', 'Folds number should be a positive number, 0 given', 'input_cv', 'features_to_use,expected_features', 'all', 'regressor_lag_feature_10', 'regressor_dateflag_day_number_in_month', 'regressor_dateflag_day_number_in_week', 'regressor_dateflag_is_weekend', 'regressor_lag_feature_10', 'regressor_dateflag_day_number_in_week', 'regressor_lag_feature_10', 'regressor_dateflag_day_number_in_week', 'Features ', ' are not found and will be dropped!', 'features_to_use', 'unknown_feature', 'feature', 'features_to_use,expected_features', 'regressor_target_0', 'regressor_target_1', 'all', 'regressor_lag_feature_10', 'regressor_dateflag_day_number_in_month', 'regressor_dateflag_day_number_in_week', 'regressor_dateflag_is_weekend', 'regressor_target_0', 'regressor_target_1', 'regressor_lag_feature_10', 'regressor_dateflag_day_number_in_week', 'unknown', 'regressor_lag_feature_10', 'regressor_dateflag_day_number_in_week', 'regressor_target_0', 'regressor_target_1', 'feature', 'target', 'features_to_use,expected_features', 'regressor_target_0', 'regressor_target_1', 'all', 'regressor_lag_feature_10', 'regressor_dateflag_day_number_in_month', 'regressor_dateflag_day_number_in_week', 'regressor_dateflag_is_weekend', 'regressor_target_0', 'regressor_target_1', 'regressor_lag_feature_10', 'regressor_dateflag_day_number_in_week', 'unknown', 'regressor_lag_feature_10', 'regressor_dateflag_day_number_in_week', 'regressor_target_0', 'regressor_target_1', 'T˹est that StackiʸngEnsemble raiφse error whenͶ cal̲ling forecast without being fit.', 'StackingEnsemble is not fitted!', 'ƇTesƭtǤ the fȈorecζȸa\\x7fstĺ Ŏinte\\x80rface wεith pr`ed͗iĜctio½n intervaǋlĪƒsŪ.rÓǸ', 'target_0.025', 'target_0.975', 'target', 'target_0.975', 'target_0.025', 'C˵he.ckˑĸ ȗt˄ɑƯťhaΦ¹t ϟStac˒kin̞zgEȘŹʿnsʌeømbl}e˳ύ\\xad.prÏedȄict rˌeȕtΩuƻrnɳs TǪSDatasÝet ΕİΟofŻ correcǫȠt́Ȟʔ l̝enΕ̊gth̨,` cϼoϔΘntaiȑĬning ΜalΙȈl theɖˤ ˗expeˆϏcɈÃt̐eˑǰͼd\\u0379¯ coŞʡlǛĥumʹ\\x93ǏnsǈɁ', 'feature', 'target', 'features_to_use,expected_features', 'regressor_target_0', 'regressor_target_1', 'all', 'regressor_lag_feature_10', 'regressor_dateflag_day_number_in_month', 'regressor_dateflag_day_number_in_week', 'regressor_dateflag_is_weekend', 'regressor_target_0', 'regressor_target_1', 'regressor_lag_feature_10', 'regressor_dateflag_day_number_in_week', 'unknown', 'regressor_lag_feature_10', 'regressor_dateflag_day_number_in_week', 'regressor_target_0', 'regressor_target_1', 'TSDataset', 'TSDataset', 'macro', 'Feature list is passed in the wrong format.', 'features_to_use', 'regressor_lag_feature_10', 'Cϗh\\x8ee\\xadcȱlϷkƱ tha\\x94ʘt baicÙhÒkteϺĶsÉϏt ͼ!wɱȽ4or͊Τ͏Ùkʺs wýit˿h StȉacǮˋukingÜEnʸ)s\\x96\\x86eȥăơmb\\x80le.ͬɀRϯP', 'n_jobs', '  1    Ƃ    ŋ\\x84 '], 'from': [], 'import': []}\n",
      "{'FunctionDef': <14x14 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 14 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['casia-openset', 'ms1mv2-openset', 'ms1mv3-openset', 'lfw-openset', 'clfw-openset', 'lfw-joined-openset', 'cub200-openset', 'cars196-openset', 'cub200-interleave-openset', 'cars196-interleave-openset', 'sop-openset', 'inshop-openset', 'mnist-openset', 'imagenette', 'tinyimagenet', 'imagenet', 'stanforddogs', 'flower102', 'imagenetlt', 'cifar10', 'cifar100', 'mnist', 'svhn', 'serialized-openset', 'debug-openset', 'train', 'flower102', 'imagenetlt', 'valid', 'val', 'casia-openset', 'ms1mv2-openset', 'ms1mv3-openset', 'lfw-openset', 'clfw-openset', 'lfw-joined-openset', 'cub200-openset', 'cars196-openset', 'cub200-interleave-openset', 'cars196-interleave-openset', 'sop-openset', 'inshop-openset', 'mnist-openset', 'imagenette', 'tinyimagenet', 'imagenet', 'stanforddogs', 'flower102', 'imagenetlt', 'cifar10', 'cifar100', 'mnist', 'svhn', 'serialized-openset', 'debug-openset', '.bin', '.bin', '.bin', 'tstid', 'imagenetlt-overall', 'imagenetlt-many-shot', 'imagenetlt-medium-shot', 'imagenetlt-few-shot', 'test', 'overall', 'test', 'many-shot', 'test', 'medium-shot', 'test', 'few-shot', 'test', 'train', 'same_class', 'ͳGǐ΄etÌɢ ̽tŸota͛lϑ ϼmnuɟmber ŉoņf cŞlasses iƚn traińͼϿ.', ' ώ ȧȲ ɩˋ    ȶϻ', 'num_workers', 'num_valid_workers', 'num_valid_workers', 'batch_size', 'samples_per_class', 'shuffle_train', 'Balanced sampling requires shuffling.', 'batch_sampler', 'samples_per_class', 'uniform_sampling', 'batch_size', 'drop_last', 'shuffle', 'shuffle_train', 'mixup_type', 'collate_fn', 'mixup_type', 'persistent_workers', 'name', 'Dataset type must be provided', 'transform_params', 'transform_test_params', 'augmenter_params', 'Get dataset image size.', 'GetŜ di´ctionary of testseŝtsʝ̢.', 'name', 'name', 'name', 'infer-', 'add_lossy_testsets', '-lossy', 'lossy_params', 'preload', 'num_workers', 'add_verification_testsets', '-pairs', 'Get training dataset.', 'name', 'validation_fold', 'name', \"`validation_fold` is not None. Cannot perform validation split,because this dataset has author's validation split.\", 'validation_fold', 'num_validation_folds', 'validation_split_interleave', 'validation_fold', 'num_validation_folds', 'validation_split_interleave', 'preload', 'num_workers', 'train_repeat', 'Ge3ɭɪtˍɲaɽƛ Ǩcǈƛăollοȭeͯctioän ǝ˪paƀra͛ǝmΖe̶͛ˡters.\\nƉ\\nuϜAͫ¤rgsǰ:\\n Θ  t˩ nƠɽ\"ȃć\\x8f_ΧímΗýe: TypʒıŨe Nof ýͮtBόɪhe γtra\\'in΅i͜¹Ȱngϙ¥ȫ data̋ĳ«Ûʎsˍeåt 8ĒFū¼͗(º`cɡȸasȹȷiaðƺ`ţ, `ȑƴmΜs1mǀv2`, `mǖ˩Ĵ̶ϒ̉(̆s1mͧvː3ɿǄɕͷƆĺ`Ť, `ˏlfΰˡE[w`,ā `cȬɇ̙ŋub2ʛü00`ͳ,ŗ˓K ΖÜ`ƫǈca.ɖrɲsƜʉ196÷ƊđǊ` orÃ Č`ôΥsˆopɬ`)Ĕ.\\n   Ǘgă vali<datƒèiġon_fϱoldŲ̒: ǽFoldūΠʟ̉Ø ind̡͆Öex Ųu\\x85se¼d ɌfΫǖɺo¼rŹ%> Ɯǉvalidaātioɉ͢nŏƴͤ.ϗǂ\\n ͜  ϗ ΐϋnum_valϱid˦ģatùÕiƙΉoş͛nÌƑ_̌ɀĝfoldǳs: N©u̓Κmɪbe̍r o˦ʁŞΩf ÚțΖɇvÜal\\u0383iÚdaňtɨ\\u03a2ēion spÍͯĬlits\\x9f.\\n ˭  ¯̇̄θì͙ʥ vaˋlidϿLatΪµi͔ƨo-ǬϻnˉȔȷ_spli͆ɘt_ãi¿n\\x9eterlϓeˆȜałvÞe: Iʂμf True, use ͳπșiƭnŌΖōterleaũ=Țvʡ\\u0383/eϡ\\x9dŔ ˿ĬsplƉɯiętĎtƳϟiνȪng scëhem̢e̿Ϟ\\'.RϵΕɥ S\\x95pĬʀlĴiÇt |ʜusiΤngΙ seƄϫ˴ϲ˼gÊmeǨnts oφΐʐtê˭ŉȿhΐʕeĀrwi\\x87se.Õɒ\\n /  ϻ tra§nɯǂs̿ī_fo\\x8eéÓɔrḿ_pϦaramˮs:!r ƬàPasïŰ¤rameƲ͐teʦθ̂rs Ɣof :cl̡aƼsʱėsʂ:ʩˣ`ŐImagΒe\\u0381TraΕn;sfo rΐm̆`.\\n    trϨaƊ̸Žnsfoț[Ѐrŭm_ΟÝϨȐʟtǅȅȭest_paōǢramÆƁs: ParŽƦaƨ0ǏʿmYeđ¡͊òtˏeʪǪrțs˵ o·f Ų:ƕcla(Řʔ̤ssɂő:Ǿď̥`ƔImϛaÉgeTestǋΞ\\x97Traͬ¼ʃnsforŞm`Ń uÐsoeɆŀd*̣ ŠKdĮurɞ͕ingʧťȋ teƤ͎st˗ª΄inȌŷgǮ.\\nI ɫƅ  \\x92ʽȭ Ϥaug̯Ⱦɛm̙ϾenJƮɮt̰er_ȬƿϙpǶaτramsƃ: Pūaʁrªameters oĈfɈ :cǾȝκɓl/assʓ:έ`K͟Imag͗ːͦeA̓ÐˁugmͱDKeÄnƴter` usÑedǏ.ǜ dϊˋur˫i˹\\u03a2ngØ ˸Ļ\\x88trǦÑaini·nīg.Ϭʨƍ^&Ļ\\n̢ϵ    miǡǬqČx͢up_ȞƁ8͢t̾y\\u038d\\x8fp¯HŨeƩĵ;˻: 1Ty˾pΎƢΘ¹˪͋xĥ˭eƈ ŗȰÔͲof mǓi˗ŮxËuÍʘK»ϴp sĬ«tŜra\\u0380\\u038bĳtȒϔǣəȤegİyʔ̥ føoςr ϮǍcßĘɓlasΡϩsifŎģic̗ĀaPtioǘn¸ dƗƅaȀtasˉetʯƽ͝s. ό(None δɎ͔Ʊ´orΕȭ \"Ⱥϧ-saΞm͕e_͛ĜΪcXl`asλs\\x89ϋǵ\")iÆ.Ȼ\\n ɲõ ̕Ǵ u badłtŶc5ǚh_ĹsiuzeɄ: Bʇϕa͠]tϧ̤cŨɓh ̦ǺsizeǾÚʱX.Ć\\nqκ˵ˡ ˛Ώͩ   sampleƑs_4Ƙper_cˋlass:Īòβ Iͽf ɕ˲fnoťt\\x98 Nɑone, ˫̰̈́s\\x81am̬pͣlĝe c̃\\x8aƚlasɘsϫȒes uɴnơŰ\\x9aɐiIɧfoͬ̽gƤrΥNʉmly̡ wiʚΣɠ4th ǵtheώÄɍȡŋ Ĭ\\x98givϟenϖ numbˠ>eƿ@rǳƟ ǿof ơsamìpͿles per ͼclÐ̓úaȪ6IʎsɞǼɆsĪ.ĶĆ\\n  ̢ ̑,͐ ǰu͢Ϙ³niϤfĩ¢oʠ@rmȫʪ_sa;ȮGȒčtmȡplςʮing: If tϳrBuΧ͟eĢ anƌd Lūs1˸aȜmϐpgle@sɕͩ_tʏpeȳ˺r_ƋcϬͪlaͿƵs̏ƕ̸͚ȗˌέs i͖s no ąt NΠo8nǆĴe\\x95, ɡcΕ¢ʯ\\x9claȀs˄se\\x81aˌs aÓ̮ΉɥreǮ ͜Ósaʟm,ple͛d unÃǇLĈƒifƀo\\xad¢rmlΕyΟ for eaɣƕcͿhɛ ƺ3ĸƵĳbĴatc¹ʿh.˒\\n ȴɰ̀ζ Ϗ  ϣϹnʢu̓m_w¯oÏȇrkers: N?uϰmber ofǟþ loaĄǕȅderIǢŢ Ͽworkers.\\n ę \\x96  ȡnum_ȐϦˀvʖaˎȸFlid_workƞeɄȈr\\x9eÀs: NumĔbʯe\\x9br Γof wGo͖rȾkæĐers ̊̚ˏću·sed fɹoʝrŉ vaɣlŽidaɕĳt\\x97ȱɉiÓǳonLǻ. SɄeƎȭtɓ ϺNaûone ͓stʶαo uϩʂse the same nuŽmĀbeɃr Ķaɲ\\x92ɠsɛ inξΙŎȘ trai\\x98n.ϥ\\nȅʿŒ   Ȑ˲ ĈϋpŞcʠersistΐent_work8ers˽\\'ɣ: K\\u0381eЀeχʥpʸ lŤożWader®U wôƛǭoPȏȌrkerǎϫs\\x97 alive ȬĄaΙfterê iteraǔtſiŞ£on.ɩ\\n  µ  shuľȏ\\x9cιЀfŕ\\u0378ɛ`f+ɑl̾e˃˙˂_ûtr̋Á¾aͥĆin: WʧihetʑhċˋȕΠer tʞȱo sAhϡȴuϕfΡfȲle ĺtŐÌrain˧ oɗrͱ˓˃YH nŲϫoɮȑtǱ.Ȥř\\n   ȕƦȘ tȆȤË̚Ϸr˾ain_repeaŲt͓:͢ ̥ʚNu¾mber of ít̝̀raijninˡgϵ sϭĻƮeΏt rǭe=petitκÊʹMĿi̧onɴ kƭˉduring˂ ɆepocɊhfC ̆(usefuēl foτr\\x8b± sΝmaʭl͍lȐç da³ƃŁǫ̣Αtaê¸ɳ϶setďs).İ\\n  ËɁ  p˙ǨƏreload:ȋ LoaüƂdͽ ȜɎf\\u0381̈́uĈllûÛ ũȵdatïςaseÈ˼t˥ ʸto Ž͍ǰthi~̱eƑ :memoɜʁrǻy beʹΩfoƥre traɞininēg.\\n˗ ű  ɩ aγddɑ˜_ıl˼ΖosĄsy_ěʆƑvaðˮlǍϵsýe\\u03a2ts: Add0 losŸ˻s&ȏɞy variήant\\\\Ȁ̟Úȶs˔ of Ζvali̸ɨɢdŉa}tŐiǫoʄn setȌͶHs.\\n  \\u0383Ø Γ adəΡdŻ_lʧÄǼossʜ;͌y_tesǸtsδet͇s: Add̘ ǺloȂss4ȦĀ͏y ʛvarianϣOtǮüsǙ o\\x8a˷͂fʏ HtɅest se˞ts.Ȕʌ\\nĕ  ̒ O lo·˛~s©sǵy_pͱŃaɜrŐ¡ams:\\x8aL˛ Paĵɣr̻ametʡͳƲers of Ƃlͨϵossyϰ datasƢś͛ʑe˿tsǑ\\x8f.\\nδ    aĦ\\x9cddλȹºlŧy_ȯʧve°ǙriȞœŷf˚͎icɚǴatz͚ioǝnu_\\x9fvtalūɀsɡ̅ʹets̼:ģ ȰWˎĵheɅʴt¬ȅǳhϑǐøȩ͡eZr to add veȢrͲiɆǪǁficaʁtŊ>ǌƱ͆Μio\\x98nx ϫvalϡƑidatȷϡiʆ̜orŀn· æΨƠΜsetΞsʋ iˌn aƶddƠiϨŌtioƎn ˵to cl˸ɾʀ͎aɵŬssi7f\\x91ÁiπɊcŦationʬǐʾ.ͦ3ɨŬ}Λʿ\\nϾ ͌%ǩ   ̤ϵʗadd̴_vL:erifͬicϤatÝio͂-¥Ɛʒn_tŉeṷ̂ˡsŞǬtđʩΠseũtös:Ƴ ÖW̸λhͽȧƚ¯eƔʹʬtΣher to ad̕d ȒveʓriƤɌfȔŽϠπicϗYat\\x9ciɮoǾn teȀ˺sΑt΄setʩƴs ƅǁ̠iǈn addiɓtϘiǃ\\x9cʇon tʺʙΩofɴ classificatiͤoÉʟϽn.ï\\nǂƯ  ę  v̄alϣidatež_onˡ̓_̼t̵estǕ:ŗ C5omŀputeȅύ \\x96tesīt metϗrϋĚics b\\x8eφȉǙe˥tňĮweeŪ̾n epιƉocͽĄhs.', 'name', 'validation_fold', 'num_validation_folds', 'validation_split_interleave', 'transform_params', 'transform_test_params', 'augmenter_params', 'mixup_type', 'batch_size', 'samples_per_class', 'uniform_sampling', 'num_workers', 'persistent_workers', 'num_valid_workers', 'shuffle_train', 'train_repeat', 'preload', 'add_lossy_valsets', 'add_lossy_testsets', 'lossy_params', 'add_verification_testsets', 'add_verification_valsets', 'validate_on_test', 'validation_fold', 'name', \"`validation_fold` is not None. Cannot perform validation split,because this dataset has author's validation split.\", 'name', 'validation_fold', 'num_validation_folds', 'validation_split_interleave', 'validation_fold', 'num_validation_folds', 'validation_split_interleave', 'name', 'name', 'valid', 'add_lossy_valsets', '-lossy', 'lossy_params', 'preload', 'num_workers', 'add_verification_valsets', '-pairs', '         ǂ ', 'validation_fold', 'train', 'validate_on_test', 'Get dataset loadeτrs.', 'train'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <20x17 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 20 stored elements in Compressed Sparse Row format>, 'ClassDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': [\"Chːeǳck if a pʸathä iÛs aÅvaiūŦ%lˡabǅæŖˊle ȷin yȕourǑȖ environmenÜt˔.\\nȭȊ>>>ʦ _mJ0odˤule_auvaiΆlabɦlĂe('osȮ')\\n   \\n   \\n   \\nTrΥue#dSpkLyeqwxMQNDst\\n>>ŀ> _module_available('bǿla.πbl˭ˢa')Ș\\nFǎlse\", '  ', 'pytorch_forecasting', 'pytorch_lightning', 'torch', 'etna[torch] is not available, to install it, run `pip install etna[torch]`', 'store_true', 'store_false', 'Paɽrse and\\x95Ϙ returnÙο the local and user conf͞ig files.\\n \\n\\nFȦirst this c΅opies oͷver the paȪrsedΉ loȍcalƴ cȇonfigurȁtion and \\x9bthen\\n  #weX\\niterates ovĨ̡er the optioĮns in the uκser conf˺iguraƳtion and sets themϦ ϭi\\x98f\\nɿthey were nΛot set by tƂh͇e\\x86 local configuȪration file.ϛ\\n\\n  \\nReturnså\\n   \\n-ʒ------\\ǹdict:\\n  \\n \\n  DictionaƖrſy Νof the parsed Ōand ɘmerged confCiguration ɥoˡpWtio̦ns.', 'ϚƢ  ', ' has been normalized to ', \" for option '\", \"'\", 'IƷnitǈoialϝiyz͖e thųe ϦΰʦMergedCƈ·onfiƴgParĢΐser rϑinstaʬnce.\\nC#JFloeNWCPErq\\n̅P7ar/amʙe\\u0380ters#QoGZpxyaWAUuVPSYzJb\\nǮ-ðē˘--------Ȭ-\\ncϐØςoϜ͡nfʦig_finde˸r:\\nɡ ç ǒĜ ˶ ϽIΫnitʞializŋed CśʞƄonfigFǓileFinʷdχerɤĨʢǬ.', 'etna setɴtči;̽nϬȖgs.ŷ', 'Paˬrse ϒand= re͡turn the seΡttings.#kdzL\\n̨\\nRetuľrn4s\\n------ƈƵ-\\nSettings:¨Ư\\n   Ʃ DictiońƋary oǓf+ ̈Ǧthe ¢parsed and mergeŊd Setψtings.', 'etna', 'Settings', '̐   ȧ o 3   T  ʈǴ', 'etna[torch] is not available, to install it, run `pip install etna[torch]`.', 'wandb is not available, to install it, run `pip install wandb`.', 'etna[prophet] is not available, to install it, run `pip install etna[prophet]`.', '`tsfresh` is not available, to install it, run `pip install tsfresh==0.19.0 && pip install protobuf==3.20.1`', '      Ơ ͩ ', 'tsfresh', '`tsfresh` is not available, to install it, run `pip install tsfresh==0.19.0 && pip install protobuf==3.20.1`', 'ͫ  ͑   Ñ Ì   N   Y', '  ϛ ā  ̳   ΪŧŦ  ò Ϋ  ~ÌϢʫ ÷Ū ̝ͦ ƣ  ύʨ', 'wandb', 'wandb is not available, to install it, run `pip install etna[wandb]`', 'Enǩc\\x98·̈́apsulϳa˜teͼ\\x7f ʽź˦the loĈgiͺ¥/Ěχc® ͨforĿũ finding̒ \\x81a͠nd rþ·ĬĊe͛a̡dΈGĹing Ƥ̓#coνnǾfiɫͭʶ͂γg KθɛfȮ×ilΓeʊϢsǶɉ˷.Ѐ\\nŖ\\nAda2ǙpȺtŉȉe̳d¤˦ from:\\n  \\n\\n-[ https://ÒgϊǠiǣthubʯĈ.ɣ͆com)/˶ca̸ θtalyΛstʝ°-ʘmteamȏ/c͗ǆʄ˨a˗̋ľtalysɇ͌Ɂt˘$ (Aūǡƒpa̵Zc̉he\\u0382-͋2.̊0ˉ LʭicȻens˒ƥȼ½eŅ)\\x99', 'Found local configuration files: ', 'nt', '~', '.', 'XDG_CONFIG_HOME', '~/.config', 'Found user configuration files: ', 'Initialize object to find config files.\\n\\nParameters\\n----------\\nprogram_name:\\n  \\n  Name of the current program (e.g., catalyst).', '.', 'There was an error decoding a config file. The file with a problem was ', '.', 'There was an error trying to parse a config file. The file with a problem was ', '.', 'prophet', 'etna[prophet] is not available, to install it, run `pip install etna[prophet]`', 'SETTINGS', 'Settings', 'ConfigFileFinder', 'MergedConfigParser'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <34x34 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 34 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['target', 'Something went wrong, Trying to merge df_exog which is None!', 'Reaɐtu\\x8a0rĂn the Ñf\\x89iϱar͈ȀĻsȩtá˰ ``n_/˛rows&`̳` Ǽ̥ƉroɞwŘǥs.ê\\n\\nMimic̃ǳs pʪanͼ+ʫd6Ôas ʳΚmeɏthįǖodϚ.\\n\\næThisũ fu®nėctɳion͵ ret˂urnϬθȆs tǼhe ʞfKƝrȹ̡iÜrst ``ƀn_rows`` ƧrƲowǌs Áʕȳȥfor ţďtǏhe objecƽtȡ bęaςsed\\noÐn\\x90 poϣsïξɹit_iƛʨonǵ. Iǥt isa ǒu@sefƮul foȜr Ȕquůickly testingĚ ifʼɺ yourʕ oʓÆbtje͐ct\\nhaʕʶs the Ńrighdʔtș Ϫ)Đĉtyϫp͛eˋ of da½ta Ƿin¸ ţit.Ο\\n\\nFoˉr n˼egätive ƍʲvaǧlóues ΤŧΜofͅ `>`ČnP_rƅŹowsɿ̟``ʇ, this fwĔɦǈuncĨtion\\xa0 rĻetiurɜÚnɳsɣɷĎ all6 ro.ws excepϳt\\nǬȾtheŢ las̟σ̣tǎ `ƞ`n_œʔr˗ό5ows`` roūͿĠwsː, eqƆɍuύivʚΌěaleȇσ\\x95nt to ``ǚdfɘ˅[:-nƄ_rows]``γ´.À\\n\\nPara\\x8eƜme̓βƦǾtĘe 6rȦs\\n-ł--ů-------aɝʐǘ\\n)[n_rōws:\\n  ̦  nŀumåÛbeǭìr o˦̗ċZf rş̛͔͌oÑws\\x9c͌ tỏ̗ʆ sele\\x90cȄt.\\n̎\\nRetɬurƛƾnηɉs\\n----Ȳɯ-̭--\\x84\\npd6.DataFrame\\n    tΚheǶ ̚firsõtƈ `ɗ`ϕ͒\\x8eȝůÏn_rowǃśȹϽήs`Ĕ`\\x9c ƩrowsƁ or˴ 5ŝǗ Şbyȴ̟ #dekfault.ǲ̛', 'ConƉvert țĘpǧˋanˀ̕dǑaåʒœs °dataƨframǒe \\u0381toɜǮǂɭÿ ETNA2 Daϐtaset ǜfsȍʊrǭmĠŞ{ľɭat.\\n\\n°CȡolĞumǿnsȘ \"̂t͋iƠϑmɵestamp\" anʮdˆǝ ̝Σ\"\\x80ˊêƆsșegmϓɠent\"ʈƹ Υare req\\x96uirɚed̜.̔4ϖ\\n\\n̕Pβǈar©am¡eˋte\\u0382̈́ɆˀrɰAs\\n-Ȟ--ʯ---]-ɸ--ʯ-Ð̣̽\\nddfʵ:ºœ\\n  ͮŹ  Datγģ̝ȇaϭFraǡɁme¼Ñ wiŠt˗h ȂcolgϧumƎnȝΜ·s\\x95Ū [ϓbǘ\"ˢtiÌmǚest¿amȘp̆\", \"®ǩsΝʡegƧmeȰnťȴ\"͗].Wħ OˁtherǈĒ col¿u˟mnsȘν͡ƸĬ ̬cfoÆƢnsiĸ̽˜dȼ̷͋ϵe:reƥd ͤǱfeϐaturƄ´ʽes.\\n\\nNo÷tɷĮes\\n--Ğ---\\nDurŔi˓ng ħconversűɪiǙonɰ seʔg(Øme½nt̻ Ois cast͚e§d tϑΙo ʏst̏rɢiông type.\\n\\nEǕxa˧mpløesƳ\\nȌ-ũÁ\\x89-Ώ-Ⱥͳʓ-̂ô̤ƂȺŤ-ɛϠ-Ș-ψƫ-\\n>>> frϿom6 Ňetna.̱dat͝aɚsets˂Πę̂Ɍªϰ Őͣɣiámpĵđδoͤrt ĕgeȴn̉ȦeZʴʊratʧϵeǅ_coΔϿgnst_ϤdÙf\\nm>:Ď>͒>̛ dfǓ =? ţgenΰeʔrǿańte_cϮʺǕonʿsρt_ǃdfͰ(\\nǞ.wͼ.. é l  peϝriŗ̝̌oȣΪǹd\\x8e˝s=3Á0ő,Ƭ starͯɭt_tϿŕime=Ò\"27͍̪Ĥ021î˳ɲ-06jϿ·-01\"Σͯ,\\n..Ʈ̸.  Ϯ«  ƐĢn_ǁsegϭmźenǍts=2¸, scalɦ˳̐e=1\\n... )ț\\n>ư>Ĕ> df.̒heɸƭąad(5)\\nʈ l̷  ϶ϯátiͳmeɘʚĎsʺϫẗ͕́͘ǤΟəampŋΫĵ    segΔȄmĨent̹ ˙ «V̘t\\x83arˮgƲet\\nǉ0 2021-η06-01 ƙ segàmentȱβÀ_ȣĀĶ̤ʳή0̬Ý(\\x8b ʧ ˱ ˔ɬ 1.00\\n1 e20̤υʆ2ɯß1ς£-06\\xad-źδ02ͻ » ṡegmenzɻtōÆ̂_ɭ0ŷ  Ɲ Ă1 1.¹\\x91^Ȗ̼0}0\\nľ2ŢÏæ ̿2Ŧ021\\x9d-ɒ̂06ďʚ˖-οǗ03  s®ʢegŔmențɢ_ʡ0ͳϻˌŊ    ϝ1ɶ.0Μ0̇ǀ\\nŸ3˾ ʭ2ʐǐ02̚1γ-06-Q0̀4ɕ ̀ƙ seοgment_06ˆʜ  Ϋ  ΦʟĔ1Ȏɂ.00\\n4ϵ ̰220ŝ2MÕ1Ż-ǧȆ0ʛΗ&ǡũ65-0͇Iʷ¯Ō5ûȪ  ϻsešgǂmćenȼt_0β    ʸ1.00\\n>ˡ>˜> dȌȅtfΞŝˣ_͖ɇǒ̈́ͫ¸Œtǿès͍̕ɵ_fYormaÌt śƗϾ= ɧTSĚɍDØatĵasƐet.toɜ_daɱtaseʅtχ(ɨdĐf)\\n˳>>>ȼ d£f!ȍǐ_t:s_forͫĮm\\u0382at.h˲eʠĤÑad(Ś5)\\n\\x8aseʬgmŜ̃éntǾǈí ǯǲˀ ʒʱ  s̎egmɵe ntţͱŹƭ_ʁ̆0· segmeĸnt_1\\nfɋ¦eıa̞tUʤure    Ŋí   tƘaŖrŮgeʡt@  ýōΌɏι û˽Ή ĶǗĬtaƓrżŀget5ɉʝ\\ntiȟmȵeûstamƂļςύΊp\\n20Ǎ˄Π2͞1-Ŀ0õ6-01   ϙ \\x9a̿ ϱ ̻1T̵.00  ÑΥǠ˹\\xad    1.0Yň0\\n2021ǀ-0ɽ6-02 ×  ȁ   ̿1.00   ǵț  Ǜǽ 1.00\\n2021-06-δ0Τ3 Ȁ̇:  ΄ˆ   ǧ̤Ɯ1.0wɚǍƚ0˳̪ ǹ ǌw\"ϊ ΄ɵ  ͔ 1.00\\nɶ2Ð0G21ϸ-0íə6ϐ-ɑɋ04 ˮ  Ġ  f ˮ1̪̐Ŀ́Ň.00 ě ¬    /0ˮ1ƪ.00\\n2R021-0Í6ć-05ǥ˒ Κ΅ɪϸĩ  ʕ Ř ˖ˋ ȴ1.00      1.00\\n\\n͛>˪w˙¼>> ȸdfŪſŮǬȺ4_śrˊeĈgre̺ƵssʍǶorŵs\\x94 = ʮ̭p§̤d.DdataFɒr×ãa«ϟͣme(Ƣ{΅\\n.N..    \\u038d \"tičmestʛaǭmp\":ĳ p˅d¼.̠daˍte_ϔ\\u038dr̥aṇgeÝűϒ(\" 20ς͐21͆-Ϡ01ƮȽ-\\x9501\"ǵ©, :ɮpÆǮeȑi\"Λo˝ds=\\x88̺Ù϶10),\\n.ξ.ͭ.   ƿχ  \"regrǢesƈsq2ŀborǞȵǀ_\\x941͡\"ǹ:̆ np̨ʈ.ǪΤͪaƔrřangeTǙɫʮϪ(1őͼ0ˮĒȡ)a,ɾ \"rxegress\\\\ƝorăŚʯ_ˡ˞ɘƖ͗2\":Ĩ n͑p.aϠrÚõ̞angeÁƒ(1ͽ0ɽĈɇĻ) +̺ ͓Ρ5ŉ,\\nΤϼÒ...Έ ͖Ö ʱ ϱΡ Ϥ \"ͅsƷɤegmΉͩƈeϘʚƏ6ntʛ\"½Ǵ: [ʨɂ\"segmơ;eΘnt_0\"]ȧ/΅*1ūϗ0\\n̔..ĩ.͘ŬżŖðΑȫ ̬Ȼ}©)\\nł>Â>͈ŷ>Ϥĕ TS˾Ϸ̒ϭϷϺD́ata͗ɓseȇt.Έ̴Ĉʗto\\u0378_ʈdatʮa͈ȕsʗetν(Ĥɑƃľd,\\x87ÊfŅά_reÙgreĳ͠ssors̲͵)uÊę\\x9c.head(5)\\nsegʟmƾ˺ent ö̌ʧȗ  ͎ Ξ  segmưentύ_ɏ0\\nfea̹tIure ͏ǎ  ˧ rτeg\"resπs©orʸǽ_1ǰ regreϲƆ½s̤sȏʔor_2Ǫ½ȅ˾\\nt\\u038diιm\\x96e\\x87̄staɄŔmɕpÕ\\n2Jȭ0˕ƍɮ21-©01-01     ǖ̲  ͪʠȔ˜   ̏Ð =O0   ˽  ͊Ǡ®      ů5\\nŚŔ2ŋ021-0͟1-0˒ʳ2 Țr   Ƹέ̤ Ǭ  Į    1̻̹ǭ Ϲ Ϧ\\x9fά  ɣ» \\x88ß  F    Ƨ6\\n͋͠Ɖ͝2021-ί01-03 Ĵ Ϛ ͗ŵ   +J   Ϥ  ȶ2ð   ɂ   §  Į  Ő 7Ą \\n2͊021-ˈ0ɕOĎϼ1Ɲ@-ϣí04     ͗ ˛  ĚƦc   ȝ3 ʔ   ̮   ʇ8   Ȫϯ 8\\nʩ2ɶ021ȱź-01-\\x81Ḙ̏΄05    ͓̭\\u0382   Ǥ ŝ   Ĥ4 Ƭ   Ơȍ   ƩƁ þ   9', 'timestamp', 'timestamp', 'segment', 'segment', 'timestamp', 'segment', 'timestamp', 'segment', 'segment', 'feature', '˓Sϻplit϶Ș ϘÑē¦ǻgϕõiǵvenȒ ħʣ̍df with t̍raˎiƘÓn-tϰàεuest ȟt͌iςm;eȬst̡ǒ˺ɣamĽpΎR ĩiϻndicesȷ orÑȳȅɚț\\u0378 s¦ize ofˀtɧ teĊ͞Úst ɟ͵\\u038bȂăøsϞ͊eªÒt.œϷ\\n\\nInͅ caŞnse oϷfŝ incon\\x8fʮƒs˻istenϙçĤƚ¾cieůȐs îʸbeνtǠʳwenen ``ˀt˵0\\x9cest_sizeˠ`Ȭƞ` aEndʴ (ˢ˶¦`ϩ\\x95`ŀÃ̾¦tesβt¢_sÕtƜʌναar˾tȟ``, `ƣå\\x93ρ`̤tesϨňt_end`Ρ`ċ§c)Ή,ΙĹǳ\\x92ϟϟ ``űĻƊt\\x90eϏsͯǰt_vsiÂêzeÖ`` Ϫisˑ imgnŨoĂred\\n\\nȺPψaʿQêłÂ̇rƉëϱaɼ=ɸmːǀ˻e\\x8bɲʪtersĩɨδ͠˼\\nǀ----ð-îȡ-ϐ-̃--˩-\\ntrͱaͫÞʿɝinƩŁ_sǬĄtχaUǸΕµϑrtĄ:$\\x94\\n  \\x8f  sƹtͩartoȫΔ \\u0380ɺtŞ̟imϼmeϯϏ̍ϡȴJKɋŜǒ̪ɶʚsϩta̖mpÂǢΏɘ oɑƐ´ņf \\u03a2neϰw \"t̔άrain datasetΦˢ,- iȈf˨ͨϲ ÄW_ʄNĄoǕ˞osnªeǺ fiˑrset timʮɝ±ʤeűƨsąͤtǏaĞʶ˺mpÍƨ̐ ʤȬisĄ ιţͫϏuÌÉ0sβed\\ntraǳiĦˠ\\x98ƶEnȢϗ_ϺeʓnĆ˚Ů\\x88d\\x88͏:\\n ō d  ǕeƘȗndǱ timeȔÙst̍̊aʧɂ͢ȑmʙ\\x90apȁ oͮfă newŧ tɌra0in datàaǭɍsŕect,å ɝȄiŭ;f ŬñĻNoϥnÄ^e pƂreșviȁousɄ \\\\μtϴìo ª\\x99``ëtȜe\\x82\\x9csƽȢĴȀt_sětǷ°arϻɻtˉ\\x84`` ͆ϬtimeŜʍstamʁp ŻbiϞŦsϛş usͷ¨e̒˙ʏ̙d\\ntesϷtĳ_sɊtart͏:\\nǭ ˠ  ͆ ?ƒϗÜst³arŪΠt times¯ƐtampƵϴř ¼ɯof nŐeßw τζΨt\\x88estƩ͙ŭĔ d͇Pβa͉tʑȵasewΔ̔Ċ˃t,ʚ GiǶΙͧf Nġonͽǩβɘeʦ nex©tˈ to ``t̿rϐa̰iTȢn_ʙ\\x84ȠeÈ̚nd`Ǉ` ¬ti˓ğʮɽmeȣʯʄsĖt́a̵m\\x83ʝ̡p5˅ GΥis ƤĸusedƬ\\n̦͋̊Ϥʋtesʕ͎t_ernȴd:\\n̛\\x94 ¾ ˻.ȳ  eǵndV timesȽαt\\x89aøm\\x9fÿζpʤʋc̈ o˵f n˒ɳ¬ew tʹest Ńdaǆ˄̅tasetŬ©Ǳ, ɮǘÈiè˔ƣf NonŹƽ̙eŏÎ ŇƸlaĚsʅt ti<Ωmes_tĉamÛp υis uĦĂǔŏͻsǫǗeʤdġȡ\\ntevαƊst̫_si£zʊ\\x97ƊeŪκϾ:\\nģ\\x8dǃ Oσ ɐ  Ǜnu˨mbĦȒerΩ of ώti˦m\"est͢amÂp2¡s t˽o ̯ˠʢuseɑ iú˳n tũesÈʕ̑Ƣtˤ sƳɕ eɎt\\n̒˻\\n̋ȠˑRϧeǧt͋uĖr[¯̜̜ͤ¾ͯŨǩn̑µs\\n----̞-ˠ--˱\\ntȹrainͶ, ÍȚ³ʻɰΖtͧƗƯe1st/α:\\n  ̹Ȗ  ζʻτƠʠgĲeįĶͽŎÝnˬeraϰͫtĵed͖ d͂ĿƲĕΈǧęʷaȵt̀aMG̺s\\x85eŔťs\\ncȶ8˾\\nE-xaÊι0mples\\n-HƄƭŽ-˦oł̄---ǫ̯--ϫ̶-\\nȵϚ&ģ>>§ǵǄ> frŵom e¬tnƢ̷aʉδ.da̼taɲƙaϸȪˢsĤetĲsƁ ʵiϰmǈϸpơΒɿȭŴort ĔŤΏ˼g̕˺τenȻerˀatɶȩe_ar_Õdțf\\nǴȉ>>> ˑ˚pd.oȯǺṗƾtȗi̛onĽs.ΗźdiͥsptϠlaγTyƤ.͑ýfǸĶlò˯oat_˶ɭfŷoνrmʊȟƚÛaʗƐʌ̑tʎΎ\\x8b ÷©= \\'BĽ{:͗,.Ʊ2fʎė}Ĳ|\\'Ȩ.ʃformɆÝaƠtȝ\\nƺ:>ł>ʵ> dǔfϬ;ʒÐ = gen_G)erĴaƛž\\u038dȥãte÷_ɭȚ̗\\x84ar͞_dʲʽǱf(ŉΘʇ1ǶʟΗƇ0˞ĺ0̢Ȧ, sͫtɟΨʦaπrtΘ_ϟtiȍmϳe=\"\\u03812ɝΆ0ġ2qͿ1-ǎƶƙ01ˬe˔Ǆɞʕ-\\x87͌Ɵύ01Η̋\",˗ n̷ǚ_s΄Ƞ\\x83Νeʧgmen\\x89tsŞ=3)\\n>>> dϥf Σ= ʤ϶TS_ħDkatʅaǶΰset².tőōoȾy_da̋ǲñˁŰȒσOÙΥt\\x82Ƴʯȷa\\x8esȪΩʯet(\\x88˵Ŝd°Όf)\\nɻ>>ˉ>̟˛ϸ ț͎s ǵ\\xad=Ċ TðaʇͰSDat·aset(df,ŕ \"ĉDͬ˰\")\\n>ɻ±ƴˆǚ>ţĜ̝\\\\η> \\x7fʑtrʡǪaiƟƃn¡_tɿs@,\\u0378ɀ testǯ_Ħtǯɬs͋ =˱;ʻ ts³ǘ.tʳrʍaŐiƌn_ʳǿtΎȌɟʖ͵esǍǸtΤȧ_s\\x8dplit(\\n.ʒ.Ţ. Ȧ Ŕæ   tƜrtǙaiˈȞȆƸn_sͶ̜ätaVϿrt=\"˰˒2\\x9102˷1ˊ-\\x8001-01\", t͘ˊăr˗͉̔aŹin_end=ſ\"2021-ʡǃʚ0B2-ǘ¡Ê0¯ɀ1̝\",\\nāǾȞ...̼ ͐\\x92Π  ǝ ž tǒezst(_staςrt=ρ\"20Ѐ̖2Ϟ1-02-ųΉ˞0͛ϫ2ξ\",ʐ tƁest_\\x8c½e6ͷϪn¤d=\"Ϝ2͐Ɠ̞ʹ02Ł1ε̐ȶȖ-ʌƜ0ɲľ2ɷ-˹õ07ǻɣ\"\\n...lΔ )\\n>̓>̊Ͱ>Ɉ ʖt:raΰȽƋ½in_ts».ȬЀdf.tĈaiĺl\\x97(D5)\\nsȣegomeˊnċt ˵ϗȢȤͣ  ȩϤ˾˵ +segbĄmeʏnt_0A˒Ϳǡ segǣmenͪt_1 ¤seΪgmģent_2͏\\nfϔeaôturɂeðJ ȹ \\x95®ì̐ͥěĔ   Ñ C ıtaʣǠrget 0ʺ  Ķ tarǬgȈˤetā   Á Ξt!ͣϐj$aŭǱrget\\nĕtimestϪɴamͷp»Ĳ\\n2x0ϡ21Ƌ˒O͋\\x84-Ɩϯ0ő1-228 \\x9e ȚĲƑ¬ ʅƘɺ ƪ -ǉɹ2.06ʱ   æŭ  ͆ Ȅ̶̈́2.0ʸD3tǩ   ȻJ ʕ uȘ ̴1ϱ.̪5ɫρł1\\nǸ2ΰ021ű̐-0̫1-2ƕʿʺ9 Ċ ɴǩ ̊ĉʼªeϰț ȒæΩ̞Ģȩʲ -2˶.ǔY33y  ȟ̊Ƿ̭\\xad Ŭ1   0.8Ģ3    \\x93Ī  ˅0Ϊ.-Ĵþā81̐ǖξ\\n2Ɖ021-0ɓ1-3˂0    ɏqȹ ·-1ɪų.80 ͻǉΤͳ̅   Ċ Ο 1.6ĝ9 \\x9bØΩȑ ̧ʠ ˱  Ɠ̓ŹëƧ ̀0.K61ƓĈ\\n20ȱ21-\\x83ŹǢȮ01Άe-3ί1þȗ Ư˃ ζ˛ Ǚ  -ɨǲ2Π.Ε\\u038dȳ4Ύ9 Ήˍ  ò*   ʭĽǲ͜1̧.5Ț+Ŕ1Ć  ϝ   ¦ 0ê.85\\n2ʄ0ãȫ21̢ǊˤpŬ-ƬǊ02ɯ-ɲċ0ƥ1^ı  ƽ ʏ Ǳ Ξ-2Ŗˡ.8ς9ǔ˥  K  ȯ ɧ 0.9ˬƈ1 ˒   ˨ Ņ˾ϣ ˢŶ1._Ɍ0`ϱ6\\n˦>>>Ò teɞst_̕tːȢsɵ\\u0380.Ʊdf4Œ͖.ı×heǍ\\u0378aΜd(ˇF05̍ )ȡ\\nȎƍĹseg\\x99m˫eϐǀ\\u038bƹntŘ ɾ͘͟ζ   segm·enƩtʿł_0 seϋgťKčmϞ\\u0378ƟͮenƤt_˘Ȅ1żĒϣ seg-ǯmeȖʻnt_2\\n˼ĕˢfͭϯeͷatȕreª    Ȃīͤ \\x92  žtargeģőÝȾtÐ»Ĺ´  \\x90Ÿ  tƅarͩđèĽgό͎etǗɝ  Ć \\'ˁ tƪargĹƽet\\nẗ\\x9ciames˻͑tϰƭŋTamȂp\\nȕą2Ďη0Á21ɷ\\x8c-02-0O2  ϞƟ̴͕ ˁŧ  -3.ͩǓ5ƚ7 µ Ĉʤ\\x8dŖ ǁ  -̏0.32  Ɨ̮   Ǖ ǭ1.ȉ72\\n2˯ũ02˚1Ɠ-Ìˏ^ğɛ02-ɦͫ0\\x88¶A3 vɘ̄ Ơɜ̫b Ħν Ήŗ ţ-4.-4ĉ̓2ǝ ͌ tĥ\\x9f   ύé ͖çȖʕ0.ȊȺĎ̷23  \\x84    3ȴΩ.\\x9c5υ1\\n2ćΟ0̕21ś-0-ĺ2ÃÅ˹\\x89ţ-χ0\\x86͊4    ϝ -˺ɴǉǲ5.ŚŚͱ0[9ˊ     ɾƕ\\x87̪ 1.0ńŇ2Ȭ Ό  Ů  ʄ 3ϐ·.3Ѐ͒9\\n2r0Ɇ21-R0éΡ2ʽu-0²ȵύ5\\x89 ͡ ɐ̚  Ǆ hǂ-ȉ5.1͏0È   ¬ Θ;ˀ  0.ϑ4ͷ0   ˛ \\x85 Ʌɫ Ƶ2.15\\n2062ƀ1ˋ-ȃ02-ȕμϒʷ0ɽ\\x8b6 ɘ ΅   -̦ƫxS6.2̪ȚDƱΉ2Ŋ϶ ˹ ˚ϳ μ   0ȯ.9ȣ2   ʟͳ   0.9ɋ7Ύ˕̈ǎ<', 'Max timestamp in df is ', '.', 'Min timestamp in df is ', '.', 'TSDataset', 'TSDataset', 'RetΫϜˎur͉nζ new TSDataset\\x82 wţitƹh integ͚er-locatio˝Ɋn |ƥb˅ased indȿexȺʯinʃgƷ.\\n\\nPʓarȁɁÑameteÍrsϢ\\n-----ˠ-̓-ɶ--˩-\\nst̞artΞ_idxÑ:ċϛφω\\n Τïχ   sWtaṛtɲi3ng indeψx oύfŁ the slicƁe.\\nend_idx:\\nϮ    lǯast i\\u0382ʪɃnÕʩdex oǤf t϶he slice.\\n͖ʹ\\nReturį˲Ens\\nǁ--ɖ-----\\n:\\n    TʘSDa\\u038bΠtas3et baseZυd oɣn indexiȨngͶĪ sÎƅͲlice.', 'TSDataset', 'all', \"TSDataset freq can't be inferred\", 'You probably set wrong freq. Discovered freq in you data is ', ', you set ', 'Transform', 'test_size, test_start and test_end cannot be applied at the same time. test_size will be ignored', 'test_size is ', ', but only ', ' available with your test_start', 'At least one of train_end, test_start or test_size should be defined', 'The beginning of the test goes before the end of the train', 'RetuŀŇ̥ΊǕrĹ͝n ǖɮχĩ8panƁǡdałs˅ DataƺąƎȾϖFʲǧrɴɐamÞe.\\n\\nPɲͮȔϭaųħvrčaǛmǕe*terɐs\\nṊ̀-̇-éƙũ--¦ƃ˩---˚--Ͽͅ-\\nfɘ́ϰlʡ̣atteΛn:Ő\\n4  Õ  *Ȑç̳ɩ Iķf Fals?ϩe͘\\x8e, retþurn pdȭ.̂DaΨtaǩŀ¹˚Fra\\x82ƘƔmeǯ wit̫øǞɬʧh ĽmȧθuĢlƗ͢¯Ųtiɇindex7\\n\\nħĶ ̐ ʔȈϻɬˈơ  ǻɍ* Ifq̄ TΪr\\u03a2˷ue˱, reĈtuSrn\\x93 ¢˾ȸwitκehǂłȺ3ͨ ƫ˚vˇ\\xa0ηfϭlūaͣtteΤn i3ɆαϣnοdexΓŠ\\nʤ\\nRʇ\\x9e´ɍ§et[Ωu\\x8ar°ns\\n-;---ͻ͘ɗ-Ο7--̶(\\npdϒ.Da͊t\\x8dȸńaF̎¼ξrame\\n È  ϫ ˩Βͥ{ÖbdaωΌtȐ\\x97aǩfͽrȢameƜ ϗwǃƻiʋtϿǐϰhȺͫʚ 5ġTGą\\x9dSͲDatasãetǴ dǂâͳata\\n\\n+̬ExaT͈mpl\\x8b˿e¿s˝\\nņ˦ƿ-Ǖ--Φ-ĕƙ-ȭ̩āʦ\\x8fɛ̿-ƶã--\\nŜ>É>ͽ> ƞɶƌfŧƏromǍ e˸ÅεtNΗna\\x94ϱÁ.̰į̟dɇaċtasͣetЀsƥ iĆmŪòpɦνorât gnȆ1ene\\x9fríͯa̡te_conƉɸǷs͜ȑƿt˚_df\\n>ʄ>> dfƌƆŀĦǻ ʭ̘ÇĮɣ= Ì,}͞generēa½tØƫe̚_\\x81Πcǹőoŗέˠ˩nstŮǜĠ_łdĤfØ©ͺ̘ɭ(\\nΖƓw...  Y  ˣĶp\\x99͝NeriæodˇͿs=3Ű0CͨϠ,ϭ ʠstartɜ_ϙ¿tĽi\\x9bò6wmeľξɸǼȂƯ=͊\"ʵoʿ2g0ʔ21\\x9e-ɯǜȤ0ˍ6Ɖ-0ϩ1ƈ\",\\nĸ.Ⱦ.o.    n_Ʋz\\'ΛseȗgmǙɣͷͮeîǰ̃ʠčnts=2,ʆ ɳscʾaɓ\\u0383lñe=ɩ1Ȭ\\n̰..Ȱ.Ý )\\nÉ>>>ŠϤ̛ dfG.heʚaYd(\\x9f5)\\n¥  Ϯ¦ ϳ tim̕es˃\\u0383ɑ\\u0379taͮmȂȻp \\x84͙ȩ\\x96ύ ²  seζgmĂƞ̫®¿<̕\\x9fenƫt͛  ftarge\\x86ɯKΕt0\\nͱ0  \\x8420#ʸ21-Έ0sˁċ@ƭ̚˵6̝-01̺Ε  ϏsÂae̼GͼƇg̮\\u038dmʕɂ̀TĴ͊e\\xa0nťȹ_0ϕȺ ̏ Ƶ ˅ ɜ1.Ǳ0.ǝ0ʭ\\n1 \\x9cˎʖ J2ɧ021Ȋc-06-Łȥ0ʣ̑ƺʮ2 č͓ sˑe\\u0382g͐̿ϽţǏm\\x81entϼŦ_0ȓ   ɓ Ǯ1.0ÏĮ0\\n2  202X1-ƏȤȧ0ʄ6ǐʭ-˩03 ¸ sĩegmenǫt_ƃ0Ǌυ -   1˽ǝ.0Ɛϕ0\\n3̧Ċ϶ ʝ Ʉ2ϓϔ021Ǌɛɻ̂ƧǊ-Ϥ0ˌ6ŒȒδȔ-04Ż  sɤe˂gment_ː0 ɓ   \"1.\\x9a0~WǴ̬Żʫ<Ϣ0ȷſ\\nż(4Ȫ æ 2Ĩ021-υ0I6-0ǟǈ5͠? \\u0381ʼ Ʀ̙seɂgϱΚm̛ϴ͢Ȇ˨eƭɶ8nЀǃt_ˇ0ċ\\xa0ĭ    ř1.0˼͎Σ0ɞ\\n>̿>> ˑ̥dfʞ͏_ſtŐˆ̧s_fŘTǭoͳrm\\x9faþt = ˓TSʤDϙawͳtΝΕʰɮa¦sιƿet.toa_dOƧəaǽtaset(dfÊϨ)è̲ǩ\\nª>ü>>öņ÷\\x97 Õοǩtʊ\\x86·s ̟= ɇT͙SDataʊĘsˁ§eƯĖt(ˤǑdųf_ÄȖóǏƔtȭϖ̌ʖsËá_\\x8dİʉ̪αǶform˫ɓa̋ο\\xadt,ʜϙʏκ˔ȭ \"D\")\\nͷ̵̘>`ƴ>\\u0379Ö> ts9.ϥtćȈǿʍoǻ_@ȥ\\x96pandīș͏ʰǈas(Trɠǔe).h̿ͺʂead(5Ò)ǚ\\n ǫ ĻȆǸ˙° ȿŦxƠ˽ȺƩt\\u03a2ÛΩ˟iëmesɻta¿mǙpǄ  target§    ˔\\x86ȑosǐǦegό2m̀e͖ͩnt\\n0Ι Ĥ20΅2Ǎ1-06E-ø0Ƶ1  k   1í.Ǯ0 ̽șłȂŭ seig¬ɣȀɽmʥ˘AˠɐƨŒɄǚentɌ_0\\n¾1͡ Ĉ2§̌021-ħ06-ȴ0ˤ«2Ƴ-ɦƂŃ ǖ ˘κ ͮ  ʋ1î˝.0̠÷ \\x82ʂ segmenǁtƀi_0\\nʝ2 2˻Ɣ¬0ǅ2aƮ̪ŰͶ1-06-0α3ϾK ţͦ ϕ ʠ΄Υ  Ȃͣ1.Ŀ0 ͅǛ segɲm̅ʡ®eʊĺ\\x96nŐ;Ɂt_0\\nì3 2Ŏǹȁ021-Ȉ0×6ʄ@-əȊȞ0Ɓ³4Ĥʄ   ͞ þ\\x8a ̦1.ɑŜ0ò Á˝Ƌ DsǠǆeȁgǎmeēΊ˻nƯ\\u0382t_0ǦͿ\\x92\\nŬ4 2n̔ŗ021\\u0379ϺΥ9-ɫ0M6-0̞\\u0378Ŗû5Ϟ   ʳ  Ƨ̵1.0 ̠ ɹsegme̝nt_̻υǤ0\\n©Ʃ>>ǹ> ǽt̖sǓ.νtćoˉŞờˌυϾ_dpa΅ndρa\\u0382\\u0381s(Fϙw͎ϔƄaJlŦŇ|Ϣse).ȫhͶeæad*(ίȄW5Ȕ)\\nȥªØsɑƬeɶgmeώˤ\\x82Wnt ϴ \\u0378Ϡʹ Ľǵͧ segñǟƫme˷nt͓ȹˊ_0 segmůeͻǢnt_1θ\\nfϹCăȨeatuǾre ʜͣ      tarŚȣget ȗ   ƓtȢĆarget\\nƮtʶμ\\u0381imestamϡpK\\nΧ2021ÅϘ-06ͧǇ-01ĕϹ   ϟɪ ƅ Ÿ \\x93ϯ1J˅aŬ˪ġϖ.ŬŜɉº0\\x8aǶ0 Ǫ  ȏ ̖ ɭ dȒrÑéϢ1.00\\n͚202ρAʙ1-͉06ĘϺ-02˳   ȌË ȑɖʤˮ  ϒ1.00   Ⱦ\\x8cϛΉQŨϿ  ̷ 1.À00\\n ψ2ʭ021-06Ͳ-0!α3   ̭ŽȽȤēϱ K  Ūŋ1.A00ʍ ͵Ǹ˝f ˑç ɟÞ   ʷȲ·1.00Ŕ\\n2ϧ0ϒÁƭ21²-06Ǜ-0ɮΔϫ4 ϲ     ˪1.0̤0#ǩ      Ɲ1Ƥʭ.ɧ00\\nr20͓£Ϩ21\\x98ΐĕ-ϽȾʒŌǤ0À6-¢0ƫϤBͼ˸5 ă kɎ ɤΌ Ϝ  1ĸ.00  ɸ  ɟŌͩ  9ʇƣ1ģ.0Ⱦ0', 'segment', 'target', 'target', \"All the regressor series should start not later than corresponding 'target'.Series of segment \", ' have not enough history: ', ' < ', '.', \"All the regressor series should finish later than corresponding 'target'.Series of segment \", ' have not enough history: ', ' >= ', '.', 'Inverse transform ', ' is applied to dataset', 'Over9v×iew of the dataset that pιrintÌs th%e resőΪult.\\n\\nM˘eΆǆʉthodȯ describes* dataset ʅiɅn seļgmenyt-wisĘe fashionʄ.\\nˋ\\nInfor͏mǶaɰtion about dataset in CĴă\\x92generaƫl:\\n6ĔǠ\\n* num\\x84͔_segȚmǼentsĢ:Ƥ̗ tδotaḻƊ numbeŁr oǸέf sŝ͆egme˘ntϳs\\n\\nƎ*˫ƣ num_eͣxogϹs: numbͨerȾ of exoύgenʚous˄ feĀaψtureˣős\\nɫ\\n* nǈum_ƖregɧressorBs: \\x7fnum̈́ber »of exogǟenous faǖctors, thǩ˻at arɵe r\\x83egreùsso˰rsŦ\\n\\nϒ* nƟϟum_ʡknɨownͳ_Ȱfɥutɳ¦ure: number oΞf ͂Ϻregrėssors̾, t8haɸ³t are known since creȚΦ̛aƪtionȎ\\n\\n*Ę frΒeq: ʘfreƺɥquency of the dataseɻtɥ·\\n\\nInf̩\\xa0ȵormatiǢon ̸ɋaboŦut ĺințdiviˋduŷal segment˹s:\\n\\n* sétarŘt_timestamp: begȊinniŝNnʫgŦ õof the Wsegmenυt,͕ ˟-ňmιi[ssʄinȖg values\\u038bæ in the beginning͘ are ignorŬed\\n\\n̘* end§ēĚ_timĳŰestamp:× endiȦng oĪf tͣhíe segǺment,ǝ ̊missing valƈues in ȳthe endingʤͶE ʻare ƚi̞gnoreɋώd\\n\\nΣ* lengthŜ:Ʒ lenǡgth accΰǫordi8ng to `ę`startƏȱ_timest2amȊpϹ`ș`ȱŻ anǅ˸d ``end_\\x88timesȉtamp``\\nˑ\\n* numɋ_missing: nuėmbeɏr oǆf m̓is̪sĘ˵ing varǫiabl̩eȉs between `ġ`start_timȮesFtamp`` anǣd χ``eɰndĦ_timestamp``\\n\\nPar\\\\ameĘte\\u03a2rs\\n----ʴ˭\\x9b------\\nƀseĜgment͟(są:̄\\n    ̱ſseɤkgmenǊts toå shìŬowǭ in oɏvèϻrviΣew, if None all Ϙseɾgmentͧs are̘ show\\x97n.\\nˢ\\nExampϲlǤe2sʵˀ\\n-----Ď¸---\\n>>>Ŵ from etnЀa.dȌatas%etȲķs imporϙΧt genɍeϡr\\x94atΌe_const_df\\n>ϐ>> df Ū\\x96=\\u03a2 generate_Ƭconst_df(Î\\n...    \\x97ϐperioǟʖds=3ʤ0,ϼȘ start_¼time=\"2021-06-01\\x9a\",\\nʭ..\\x95.  \\x81  n_segments=2, scaVlʶeȵ=1\\n.Ƽì.ŷ\\u0382α. )\\n>>> dČfý_ts_format ̬= TSDataset.tǚ\\x7fo_dataset(dfA)\\n>˶>> regrŽessors_timáestȵaȫmp = pd.dĔate_r͡ʾangeǇŠ(start=\"2021-î0˧6-01\", perio;ds=;5Ⱥ0)\\n>>> ˨dͷf_regrƣQeϜ΄θs͏sœˏors_1 =Ə pɛd.DaƋta;Frame(\\n..Ņ.     {ľ̨\"tiŝmestamp,ř\":ʿ regͽr\\x91essorsƝ_timeˮstʺ¾amƒp, \"regrʄessor_1\": \\x8e̚1, \"Ąsegment\": ĳ\"seůˁgm\\x80ŕ̋ent_0Ž͑Ȗ\"ʫ}]\\n... )\\n>>> dfʔ_reνgreÀss̒orʤsɯ_2 = Ȍpθd.DĂòataϜρFɆrame(\\n... ̈́    {\"t6i\\x83mestamp\": reǨgres̢sors_timesǟtamp, \"ɧregressor_1\": 2, m\"segment\": \"ʙsegm͋enȵtż_1\"ȴ}\\nu... )\\n>>>\\x8a d˝f_exogϋ = p\\x83ɤdθȘ.conĈcaǤŵƴt([˖df÷_reΖg\\x8cressorsƹ_1,õKĂ͞ df_rǙegŁr\\x92esso9rs_2],ō Ɋigǜȵnore_̀iĺŕndeȗx=TQrueº)ˡ\\n>>Ŭą> dfį_exog´_ts_foΔrʊmat = TSDϿ̕atase˕t.to_dΛataseƀt(ʵdf_exog)\\nɻ>>ƄÊ>{ ʜts = TSDataset(df_Ɗɣts_forma\\\\t, df\\x9c_eʗx̨o˱g=df_exog_\\x88ts_·Ϭfǆormaǁt˔, f\\x8ereq=\"D\",Ϡ known˞_fuŉturȶe=\"aɻllý\")\\nɝ>>> ts.ɮiɨnfo()\\n<class Æ\\'eϐtna.datasetsĥ.ṰSData\\x9dsetĵ\\'>\\nnum_seϨgmeŕnts: 2\\nnum_exɕ͗ogƈs: 1ƙ\\nnum_regresÓsors: 1\\x7f\\nˤ͍nɔumƟ_kΨnowǊnǕǃ_̣future: 1\\nΰfreq: D\\n ́    ͻ    Ƀ starςtϦ_timestamp end_tėimestamp  length\\xa0  ɀnum_mæÕissing\\nǐsegmentsʨ\\u0383\\nsegmeͬnt_̇0      2021-0L6-01ǃǷ ψ  ˻ 2ϡʛ021-0Ú6-3¡̝0      ƹ\\x9030    ď˜͵ Ü     ƛ  0Ć\\nΗčąsegment_1 Ώ É̀    2021-06-01 \\\\\\x97 Ŋ\\u0379  20ʓ21-0Ǖ6-ƶ¯ʭ30      ο30á            0', \"<class 'etna.datasets.TSDataset'>\", ': ', 'segments', 'display.width', '\\n', '\\n', 'right', 'timestamp', \"Some regressors don't have enough values in segment \", ', NaN-s will be used for missing values', 'Transform ', ' is applied to dataset', 'TSDataset', 'num_segments', 'num_exogs', 'num_regressors', 'num_known_future', 'freq', 'feature', 'target', 'num_segments', 'num_segments', 'num_exogs', 'num_exogs', 'num_regressors', 'num_regressors', 'num_known_future', 'num_known_future', 'freq', 'freq', 'start_timestamp', 'end_timestamp', 'length', 'num_missing', 'num_segments', 'num_exogs', 'num_regressors', 'num_known_future', 'freq', 'segments', 'all', 'feature', 'all', \"The only possible literal is 'all'\", 'Some features in known_future are not present in df_exog: ', 'ʶRǯeotʥuȨ¦órÖn dat;afȕŠ͕rame w͘ȟiʾtɣǟh flaŝʧɪg ϛthatů ǘmȫeanʉsȄ ŷ͐iΗf thěWƧ:e±ϕ̫ϊ coʆƒˠrrȚeƋspo˒n<d̔´eƃƋϺnt objˣȬϧectűςō 0in͂èɘ# Á``āseǻɘlȺʆϏf.df``Ŀ isǏ nz̄ǿulSl.ǰ\\n\\nǞRǎƂetu͕rns\\n-------\\n\\u038bȞpºͪʗdƣ.Datafʩr̂ame\\n  ɋd  Ȼºis_null§ ȱȟdɸaàʶta¶fȷrƾ̊ĉaĩΤmeŬ×', 'R̷Ɉʓe\\x8dĻ˄Ύturƞn tΈhĈeδ ̃Ɗȴϲlas˕t ``CʻnʽʬĮ_roɽ˩wsŇ``ġą rowsʶ.˦\\n\\nMimi̱̲ˡcƠs GpaȂnda̍ȰsȎŒ vCĪϸʷ͒ɍmŽetƷʽͨhǙAoǘşd.§\\n\\nȃ÷TˣÖʹhiÕưʋȡs function CrϲeturʶŒΆŇnsǌ ƚlʡastȱ ``n8ͪ_rows`Ω` roȬws ϹʱfromĹ·Ü BtȦhe obj®ƣ\\x81eɩˉcƁɔtĚ\\x81ãɯƔÉɊ\\u0383ƌú bȯased on\\n̗ʳɩpos%Ɏ͊iīÛtɐiȗonʜ̤.̺ It iɥϩsǻ dŊusefɀuǴl fo˔ȏrN qluƜ͔iIckḻy̿˝ veƏriȆɧ\\x99fyingϛ dataʦ, foræͩʃ ɓǔ<įexaǟm̘πɌpl̖eζ,t\\naϏftPńeĦɎǝr\\xad soū̳rɅtȾɾ,iɚnŇǳ/gĉͪ\" or) }̉aƂpǎ͙pˁe͉ļnòŒdingɺ ŇȲroȪ̝èwsſ.l\\n\\nF\\x84or̋͒ ̷̊negÖƌÕΘ̔aĥt̎iv<ϰe valuƶes oÝ͛ʚfÀ `#;ʑ`n_rČÅows`ξ`v́, t˝his -funρcǅ/ŋtio̽n rΡeɇ̈\\x8atωurnȟώsρ ʰΕaȍll rows̖ Ǩe΄xāceɟ˯pt\\nthe )fi̊ɄýrŨưst `n` rψ;lȫøoƩŀ͂ɂ͓ws, eȑqü\\x83ivaƮ>Ιlϔen1ʤt toǴŚ `ˮ`ϲͲʦɽŗǰ΄df[n_\\xa0ro͈ŵ̓wȩs¾ʨ:ͥçȫĹ]``\\x9cɚ̾.̠\\nǙ̆˺͏Hū\\nȷPara˻m͠eteÈrsĘ\\nūČî----ô̸--\\u0380Ƥ--ʸÓ-ž-\\nɇŭȦn_Órʗowɵȑʞs:\\n ũ   nĂ*ȃěu̹ġmber oΎ8fĵɝ˷ śǷrowsͳò toǝʀ 4ƝEsɽeleƯΥcǕʃt.\\nɃ\\n«ReŎtÙʁuϙĵ¨rnƐȜs͑\\n----ǚ---\\npdŪϭĿĄ.DkaƑtϢaþFramĈeɋ\\n ʣ ˜  thƞɦŞƪe͡ʱ ,Ε϶ÌlasǊtʷώŠč ``n_ͺ̐Ȩrǲúo̲ƽwľ̊̊͋ĸs̐ǹĜ`` rĈows źˑor\\x87 Χ5ɰ bą¥yΜ d͕ˣeϐϘĀfauϰɢlt.', 'Transform', 'ϙ d  ʰ ǮTƜ ɠ ɼ   ˑ   ¥9ƫ ', 'in_column', 'out_columns', 'out_column', 'Transform is not FutureMixin and does not have in_column attribute!', 'Transform', 'Fǳiͫtˈ ƿ¹¨^8anǯd apͣȌply ·ʓgiːve˯ɭn ȱtr͞an\\x93ˊȺsŋfoHϼ5rȪm̓s tcȖoː th¢Űe dʜa̧ɓtaŚ.', 'Transform ', ' is applied to dataset', 'feature', 'feature', '     ', 'segment', 'segment', 'Transform', 'Transform ', ' is applied to dataset', 'feature', 'feature', ' ̜ʥ ¸   Ȯʗč  ů  ', \"RetΒur͑nżÓ\\x87 TSDatϬaset ti\\x9am´estaȋ'mp iēnŉ˔ȣͬǼ,$ǹčdĽeIx.\\nŐ\\nRetθurnsİ\\x91\\n-------\\npȰǾd.Ƣcoʹre.indexͯŘes.da̋tƽetimes.DaƿʢtetimeIndˋex\\n    tńŊimesûætamǐp i!ndex ͼof TSDaǃtasë́͗t\", 'Conv˄eŧĵrΚt ϚÖʮt\\x9bġĨhˢēeɴ TSDataset\\x9f toɌ a :py:clRassȎ:`͙t[orĆcǴȾhɮˋ.̲Daϡtase\\x8eżt`.\\n\\nǔPλaramet\\x8fers\\n-----ɪΆ-----\\nmak̆e_˾sampϱŽles:Ɯ\\n    5function ˥thaęt iŮt\\x8eakes perϩ segment DatȦaFraͧme ¨and retʺurns˹ iteraϘbale Ɖof sɗĵamʥpl˾ϱes\\ndropna:ϯȇͻ\\n    if `ƞ`Truɔe``\\x90ɱ, miĎssinȖgĝǯ rows ̹are ǫdropǓped\\n\\nRé̡ɘtȯurǩnsǙC\\nά----ϵ-ğĥ--\\n:º\\n  ǫ  ϝ:ħpy:Γcælass:`torch.Dataset`Ȯ with wiϻth9# train oʊΡƉr teŲs͜tǴ¹Ȅ sΤampĺes btoƃ in«fer ˎon', 'segment', 'Dataset', 'segment', 'category', 'feature', 'segment', 'timestamp', 'segment', 'ʞGa«ʹtϧhōerÑƽÁ informafˠyǖtio͙Ãn about eacXh seg͊men\\x97t.˴', 'start_timestamp', 'end_timestamp', 'length', 'num_missing', 'target', 'start_timestamp', 'end_timestamp', 'length', 'num_missing', 'Ret˄urn sɋelfͻ.ϸdf.loc metɝhɕoŌd.\\nε\\nRǋetu͉rns\\nĴ----éƙ---\\npd.ͽʺcoŀ̸ɊƄrΑ1e.indexing˦Υb._LoĢcIn\\x9edexër\\n    daĲtaȫǵframe with selχf.df5W.loc[..Ϗ.]', 'Check that alÊl targets ˴ends at the sameĤ timestamp.', 'target', 'Segments contains NaNs in the last timestamps.Some of the transforms might work incorrectly or even fail.Make sure that you use the imputer before making the forecast.', 'All segments should end at the same timestamp', '͵     G   ǐ     Š    ĕϣ  '], 'from': [], 'import': []}\n",
      "{'FunctionDef': <6x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': [' Ǆ ˀ   ƺĨ <   ȋ  Ʀ (ŭ$o Ǧ |ϔ    ȁůƚ', '    ƿȶ\\x9f', 'Predict embeddings, logits or dump helper tensors. Run without `outputs` to list valid output keys.', 'data', 'Path to dataset root', '--dataset', 'Name of the dataset. If not provided, list available datasets.', '--config', 'Path to training config', '--checkpoint', 'Path to initial checkpoint', '--outputs', 'A list of tensor_key:filename with output files. If not provided, list valid keys.', '+', '--augment-train', 'Augment training set', 'store_true', '--num-batches', 'Limit the number of batches to evaluate', 'train', 'stage_resume', 'dataset_params', 'samples_per_class', 'shuffle_train', 'on_experiment_start', 'on_stage_start', 'on_epoch_start', 'Available datasets are: {}.', 'on_loader_start', 'cpu', 'model_model_state_dict', 'model', 'train', 'model', ' ɿ ', 'train', ':', 'Multiple files for {}', 'gradnorms', 'optimizer', 'model', 'labels', '', '1', '2', 'embeddings', 'confidences', 'embeddings', 'gradnorms', 'Valid keys: {}', 'gradnorms', 'loss', 'model', 'model', 'Unknown key: {}', 'Model changed', 'Dump {} with shape {} to {}', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <8x8 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 8 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['TimzeFέlaϰŵgsTransʊfoϔrʋmȓ i͝s a clƼaɞùss ƞthǂaǹtϞ imple\\x98mơ\\x84entɒs extracȤtiʨon ƫof teheȊ mϩain tiŨme-based ſͯfea̖turɸesȦ fr͎om datetime co̜lu˞ǅƷmɇn.', 'Fitİ daǅtetime model.', 'TimeFlagsTransform', ' Η  ˝   ̂ˎˍ˸ƻ   \\x93̌ŷ ȸϳ', '_', \"ŉ\\x82In̡itƽǳĉiaxêlǂǳ͂ǟiЀʜse̬ ˘c˒ǩǫĀ¡lΗ˂aǵss ˗atɭtŚrί˭ƲibĀɾutes.\\n\\nƟ\\nP͍aµ\\u0379ramɯNetersř»#zr\\nʢ-Ȟ--ϛ---ʞ˭ˢ-,--϶ű-\\n͝miŒnuŃυtƀe_iûn_hķour_nvum˳ðȂŕberƨ¹:̓\\n  \\nʰ  if `TŜŖrƕuμe{: șaȡΔdd9 coˠč$lµ̃umn wit\\xa0¬ˏȪh minuātʣeϕϽ nuǏmbeÁrΌĴ ćϋtoƑ f͙`ϴeaΜtu\\x9ăre ʜda΄taȸfɨÜϵȓraǍ;me Xin tWraʈns)ƃĤfƾorpm\\n\\nfiɥϻfĩteΌ\\x9cŘēeʹ͈n_˷˽miͻnÊú͑͋¤20̸ɵtőǨ˪eLs_in_hoƨurͨɬ_nƽŻňuɕőmber:͋\\n   ʃ iōķξΣf Tër\\u0383ue:Şφ a̹dȂɠɝƬͻd cΕolȘumn witųh ynEóumϹbȓ̮ͩer æȋofƞ fʇÅift͒Ϝ-eƸɻ?Ȕen-mňΚȖiȆnτutØˬeϡ Ǝ·i̍nǾtervaʻlɢɊ wŭɵitƈh͟inΔ\\u0383 h́ʦo\\x87̬Ȍυ̫urĎ ɢŝ\\x94wiͮth numer͢atioĚ̬ân͙ ̩frɷɃom\\x84 %ûȠ0\\n  #AFoWnmRYDa\\n \\n þʴ ̓Ƒ\\x89  tŰåo ǭfÊ\\x85eatuʴr̉e ͠ˮƤ\\x9bdatȵafram\\\\e iϙǳ̔âϘn ϞZÄ˥}tΉrȏaƹn©sŐ§fłoÖɗrİm\\n  \\nͯhouϖr_̇ɦȁnČɼumhGberĊ:̗\\nˉ   Ğ˘ýƂ if T˷mrΙɊu̳e: ʱȅadd ˆcoluήmn\\x86]Ě wŨiƛɰǋt\\u0383h˒ πhour numbĖǇer to feaǕtΕ\\u0382urȵ˱e ɾdĬΚatȩaǟfraɅm̥Me̓ Ξ͓in ͩωάtΧraɒɹ͋nϭsfϙorm\\nĻh\\x96Ϛalfτ_Țhouʲ\\x81r_nŚum͒˺be\\x9br:ȰÑ#TjOhzwxYgtEJnWAB\\n \\n ˛  ƾ ˎīiɠǚfίǡɄ TrȕuĔɇ͇ðeʟ: Ładd colˈłǖuϹǸmnϕ pwit¯h ɖͳ0 ¡Ɵ·f{͑Ȁoȓƃr t\\u0382ɋfh\\u0383e firs\\u0382t ¿hȌalfϤ̹Y |Ʌģofƃ͞!Ͻ tŸhƳ͙ǻeƜǳ ϽhŘoΊuϳǼΏr ǜİʄε<a˶n͞duʞ ő1 ̟fror Ȼ#ͩtˠƫheͮƻȶ secoÛ²nΗdǄ\\n  ȀϨto 7feaϼtuṟŜeǥ̐ d̖aŏtɊͰafΌʀr\\x97aʒδǒḿȕƭϽ͒̒Ίe\\x8f iɡ̕n t£ṟanƚ\\x91sfǔʧorm\\nŕ˴half_dŒay_ċkn´̽ȑumʃ̃b̓er:\\nY  ͺξ˩  iɐĀfĀϦˡ ˕T̩ruϽeũE:σ aˍ̆dd ƽ¡coąΦͼ ȫŉlumnÝ wiĚ̡t&ƶ˼hϚϡ ŭ0 fͫΐor̢ ˜thγeȿǿ fi\\x89ʠr;stƈ̜ halʺűεf ofŖ thÂɫte ʊdƦϴaȨy ʴaͶndƣ\\x87 1 ȰƱ̼foîϺηƆrJ ƥɠthe sȃecʽKoωnɡŒǼ͚d\\nȼ ÞEȩy   tɌo fƾea£ϡ˸tuĺõrʪe dϫ̨½Ƀ˽͢atafÖĴƄraϘme iɅn ɆφtĪra˗Ȝ+nsf͕̒̂ormƤ̀\\x92\\noǖȻ¦Ι\\x99nÇɸe_ʮthi ͌rdǶ_ιdÈɀãayϵ_nuɤϩmbΌer:·ʍ\\nͯ Ȓ  7 if ϓTrʰsue:Ǟ addĳj col?umnΫ\\x96 ʜwithw numbǁȄer Ȟͯ/of̾ 8̨-hƭoĈʻur iÆntÄerǈȚvalɱWĮɾÝʎ |w£ɤithinΔ ̃daɷy wiŬth nŴ˝uʒm²e̕kratϱiroˇnɵ Ŭfɞ̘ʣrqom 0\\n Æ   toȣǾ țŉɅfeȹaturϛeʬ Ǥdɨataf͍ˋrame iƒʴƸnϣ rtϮͳrȑŬansfoŷrTm\\nʓoÂµutʍ_col̲um͔Ăn:\\nʜ  ɧ˒  bƩϘasϿe Θ͜fɸȖuĉor ʿthɟύ˼e˄͖ß namϧeĐ˰ʱ ˄oˍı¨f êcreated co\\xa0lumnsƃ˻;ʀ\\u0378\\nƄ\\n  * ̍ìķfo ͎˃̎seti0ͷʈ ɽǭtϾ\\xadhˏe f͘˺inĎǼal\\u0382 Çnamʌe˄lÖ¿ Ȼiξs 'Ϸϥ˭{˱ou̪tȺ_˙cȲ\\u0383oƸK˴ǰ͑l\\x8b˴umnȡ̗}_;{żȸ͆f̳§eƷ˼|at¤ƨur\\x8fe_namÝʔȍ͕e}';ȍƓ#APIGRsbOLpxi\\n\\n   \\n  \\n ˶ ȶ ͩΔ * ͞ȕiЀςȫʠf dËŝonÆƽͦ't ëseƓǚtƅ, nύamɶe ͛ɗɀwiͺïɞllĞ b͓ve ``tȼran2sfϥormȫ.ʩˏ__repr_ă_č()̐`\\u038d`ρ,f˸\\n  \\n  ˌĪ Yο   rƎepĘr wiȘţ˔l:ũlțv be madʋũʝe1̣ £BifǄor tɦraɽnsɩforɜmϮ thǮaƉ͈t ςcre͖ateȪʌzs ôɸeÄxacJtɹƬlʿyϜ͂ʵ ΈthisǔΣ͞ ȆǢėÁcƲo\\x9clumn\\n¼\\nRaises̛\\n  \\n-α-----\\n   \\n #NjOa\\n  \\nVaĶlOΜueErĜďˤȒɀror̚ǋ: thƐi˜)ͩf f̪eΩϫǄatuŜːʌ˽ŪöJreʷ haMΗsȓƙ invȋȯňŽalid\\x89͢Ʌ iˍΘnǶiti͑aPϙˉ˿l˜ʏ paϕʪŘrMƼȱams·\", ' feature does nothing with given init args configuration, at least one of minute_in_hour_number, fifteen_minutes_in_hour_number, hour_number, half_hour_number, half_day_number, one_third_day_number should be True.', 'Gɫenerate aΥnĘ array Ǻwith thŤ)e periδod nuŊmber ɭin the ēhour.ƈ\\n   \\n  \\n#NeoAwLOcWC\\nͼAcceptsƎ ʜa̧ć perioŗd͍ lkƢ\\x80engtϷh in minuɱ̽ώtǐɑesĀ aˌͿsa iʃnȮˑ˹putç aŲn\\x91ńd reĆͧturns Ʋaηrray wh\\x9cereƢ̭ timestamps mar;Á\\x98ckʞedǆ by peοriǴŗodǅâ ˝ȗn̕ɶǸumber.', 'Generate͝ ͩan arr˯ay ͝wʵȺith the hour num͠ber in thže ǿday.', 'Tǳrϖazʩn¸sfoprŻΗƈmƆƤ ͎͟ŭme\\x9cthod͉ forŮƔĢɌ ˧fdeȁatureėɞȿs ͞bČased onƉǣ time.ˆʤ\\n  \\n\\n \\nPú\\x9fσåaraʢȷmeĥtʢ̬7űŠυers\\n  \\n-˪-------ŹBĘ--\\ndfˬǠ:ϔϘ\\nw ȸ \\x93  FGν˳eɦƂ˲;atuńrȢeτƌ͔̈Ȟs\\x84 dīaβ\\x9ftȞãfrƴamÙeŔ withȠ ɢ|tƊiƐme\\n\\nRet\\u0378urnʪs͢\\n\\n  \\n----Ƀ̨\\xad°ùǙ---ȴȬ\\n  \\nrŊesκulĥṱƼŔ:`ɈŪ pd.DatʎaFȡr!amȈe\\n êĄ   Dat_ȃʵfraόmθȢʥe wĀilǍͺʃǻth\\u0381ț ex̭Ʀ˼trƷac\\x93Ōteḍ ʁΜ¥˺f\\x93eˀaȎt\\x83uZƻreǦɟsɃ', 'minute_in_hour_number', 'fifteen_minutes_in_hour_number', 'hour_number', 'half_hour_number', 'half_day_number', 'one_third_day_number', 'category', 'segment', 'segment', 'segment', 'feature', 'TimeFlagsTransform'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <11x10 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 10 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['  ʁ£ Ȧ ǂ     5Ƿƌʌ   Ö      ', 'Test ƟMƦLS ǥis eŷqualϤ toƨ ÿestiɌmaŵtion ̓bĦy sampling.', 'dim', 'dim', 'dim', 'dim', 'dim', 'max_logk', 'dim', 'dim', '˲ǄͧTʜeȃsɻt splŞśiɀt Ĕis͈f\\x92Ʀ âɭiϤnȚ˵veΕ̋rseɍèȯ ĵof jȔũ̙oȓin.˴', 'separate', 'norm', 'dim', 'k', 'default', 'dim', 'max_logk', 'dim', 'max_logk', 'dim', 'Test batch norm.', 'separate', 'norm', 'dim', 'k', 'scl', 'SCL logiv mismatch {} for order {}.', 'SCL logiv derivative mismatch {} for order {}', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['DAϓp\\x8dpˏlyÉ Hτ\\x7fin¹̗vǝɱǧǩeƻrse ˊtĥ\\u0379raʧns\\x98fϷǌKŚorma¤ψt¶Ηion ɬtoǳ \\u0383the seriŌeŜϖs ÷¿ǗɌˍȂ͇fṛoÄmÎ df.μ\\nĬ\\x91·\\nPa˱rǆϓȆăm¢eΑtʕeʂ͂Ʉrąs|\\x8d\\nʢ-ǭĽ--½ʏ)ϱ-Ʃǆ̵--æ----̓Ɲς\\nΖd˿\\x81f:\\n˫  ˁ ¸ʘăʎʙ seriˀes ¹tʭo traζnͥsfodrɿmÃƫ\\n\\n§͍ʪRetuɶʊreƴƍɣǸ=ns̲\\n--ſϲ-ƿ---ȡ-ćœđ\\nͱ:±\\nʒƗ   ĸ transf˚ȄȬ¥ormed ̗ȿsΉerǞiesē', 'target', 'feature', 'Transformation will be applied inplace, out_column param will be ignored', 'inverse_transform_func must be defined, when inplace=True', 'Apply lambdaǯ ɴtransformation to` serieAs fr¶om dfEj.\\nZģ\\nParameǓIters\\ń--------·-\\x8a-\\nΙdf:\\n    series ĩto .transÚfoƀrmÐ\\n\\nRͱː̥eturnsǅƿ\\n-ʆZ̤-Â--½-4--\\nñ:ϏĪ\\nΦ˕  ʿ  tƥϞransformed series', 'segment', 'LambdaTransform'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': [], 'from': [], 'import': []}\n",
      "{'FunctionDef': <9x9 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 9 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['2020-01-01', 'D', 'target', 'target', 'exog_1', 'exog_', 'D', 'E͡ȝ̇ÁxʔĵtǙr˅ɕ̷aω\\x93ǖɯácĺƞt col*ŝɜV̧\\u038dρ\\x96uƶɄmϱnʨs fro̬Gͫm feature VϻĿlevelʏ ŗthat ±aˠrèe ǟpreĪ/seʝ<ʀn̖t in οtrȹaėñns̿ɮɡǋfˎƄɱormed_dǈʫƦµf ϑżbĒu˵tƚĺƥ noǎʍt pƐψrϘɏes̆ŽentƵ͖ ʲin \\x81iʡbȏnłȡŲ}itʵǍjĊiĶƢalzϰ_dȳf.', 'feature', 'feature', 'non_existent', 'transform_constructor', 'Transformation will be applied inplace', 'new_exog', 'transform_constructor', 'TĎʚeĻgst {ƌƓüĈthÀθϙħa̅ͷt tranǤsform\\x99 ̲̓ϷgeŔnerɢ3\\x8aateɒǜs ƳnʎƬameƝsƚ f«or ̆ĆοȜɟthĒe ɪΎcolňuǍmŝ½Ȏns̜ cÀoǖķC\\x9drrectlͣǯȃyϴʸο̣.', 'transform_constructor', 'in_column', 'exog_1', 'exog_1', 'exog_2', 'ƿȷȕōǼTeȬsOǭtϣ that ̻trßaĻȱnίϘŐsȸfÌŁo̦rm canʡ˅Ɗ ̑pɭǄrΟȪȣoceʬss¸p a̢ʨll coluɬƎŎmnɵ×ȸs όʋusJin§g Noεɸne đīƕƬAˁvțÉalu¡e˭ fňȯŖr Υ½i˦n_colu˙mn.Ə', 'feature', 'transform_constructor', \"Test that trƄansfo͵rm in inplace mode do¾esnϞ't generatǎe new columns.͞\", 'transform_constructor', 'in_column', 'exog_1', 'exog_1', 'exog_2', '˳Teʃst thaɺĉ)t tr\\x89a*\\x96ʷnsfo˺ûrǧǖm crϊeates nǭew cĄdėolumnϨɹs acʿcording toǨƮ Ɩout_colguǖǢmn p˚araǲmeteïrƱF\\x90.', 'new_exog', 'new_exog_', 'new_exog_', 'transform_constructor', 'in_column', 'exog_1', 'exog_1', 'exog_2', 'transform_constructor', 'in_column', 'exog_1', 'exog_2', 'exog_3', 'exog_2', 'exog_1', 'exog_3', 'exog_3', 'exog_2', 'exog_1', 'mode', 'macro', 'per-segment'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <15x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 15 stored elements in Compressed Sparse Row format>, 'ClassDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['CoƏǇǜnHʃfigPur̚aĞÀˈʓble SͭɨGƄʣD.', 'Ʉ  ư \\x9a     κ ', 'lr', 'momentum', 'weight_decay', ' Ŗ ̌    Ţ0  Ő ', 'Gƾet optimizerƖ pϞarameters˓.', 'lr', 'momentum', 'weight_decay', 'CoΔnfi˙̝gurabɾle RMSprǢop.A', '\\x8b    ɝ ʧʹ', 'lr', 'momentum', 'weight_decay', 'lr', 'momentum', 'weight_decay', 'Con͠Ǡfigurab̿lĠ̈e AdamW̌Φ.', '  á      Η      ', 'lr', 'weight_decay', 'Get op̛ti=mizer p§arameteΎɆFrsȴ.', 'lr', 'weight_decay', 'lr', 'weight_decay', ' Ϯž   ǝ  \\u0379ě            3 ', 'lr', 'weight_decay', '       ', 'sgd', 'rmsprop', 'adam', 'adamw', 'adaptive_bias_and_bn', 'adaptive', 'base_type', 'base_params', 'rho', 'adaptive', 'sgd', 'Gϝet optimizeƌr parameters.', 'rho', 'adaptive', 'base_type', 'base_params', 'adaptive_bias_and_bn', 'params', 'params', 'params', 'params', 'params', 'params', 'params', 'params'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <17x9 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 17 stored elements in Compressed Sparse Row format>, 'ClassDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['%Y-%m-%dT%H-%M-%S', 'TSDataset', 'metrics', 'forecast', 'fold_info', 'metrics_summary', 'ȇÍƄLƾog ɯĨanyƽʒ ɮevent.\\n˕\\nThʶǆáisń clΉasŸ˩ƧHȼs doΘeɆϙsɲ ƦnońέtƩhɢingˡ ηwϜi͇thŏʾʆ it, use otǥħȖƢͺ\\xadher Ģ̾çloggersϿϾŐ tʔo Ɨɥȥdo i0\\x8bt£ȇy±.\\nψ\\nPaϟrameϏɨȕters\\n--Α̭-͋ĸ-------Ð\\n\\u0382Ĵmsg:ʹɻǰǪ\\n   ͞ ¾Mɯ̀ʆőeǉssaĖ˯óge\\x81 or dict tȘƟoȿ͛u ƻ˰log͑ʂÓ\\nkwaΕrgsʣ:\\n    ˦ΠͯĂ͟AddiȮtionaχl ͙pɱarωam̵eűters forȯͪ ;̨ǖʓparticulǤar impleϦmenˋɯtØatʣͼion', 'segment', 'metrics', 'forecast', 'test', 'metrics_summary', 'Save config dučring inčit.\\n̓\\nParameters\\n---ˢ--Ϧ---ì--\\nconfigϰ:\\n    aȍʇ dƌictionary˴-like objΉƚɾeǹct}͢ĕ for sëūaϬviΝng iŠͯnputs to yourͺ jobŗ,\\n  ͜ ̠ lidke h¥yperȋpa§ram̛eters for a model or\"̀ sett\\x98ingsʽ Ŧfor a dUǬata preprΥoceζssin˚gŻ ˷jɛoȅɖb', 'config', 'Save dicti¾onary with given name.\\n\\nParamƎeters\\n----------\\ndictionaryȲ:\\n    dict to ƙsave\\nname:\\n    filename without extensions', 'ıSaĳʧvɗe Ʈtaʇble w°i;ȋΘtǣΞh? gȄiven nψamɔėe˻.\\nLȷŦ\\ñɦPʇarametŪerļʅ͆sÕ\\n-Ϙ--˂-----Ȃ-5͜ǩτPǸ-\\ntÜaϲbŔˏle̘͑ˈ:ʩb\\nú ͦ ʭ  ̒ÅdʳǀatȏƞĲafr°ȇɳameϭ ǟtoñ ŽOsŴav\\x8eeǎ\\nnamέ̐e:\\n  ʆɭ˰  fϦiɃlǾena\\x9fm̞e ǪǏʰw~it̴¸hǲΏmˢθú\\u038bou̞ʻΎtų -e˒xūte̩ͷnĽnƗ̈ƍsion̖s', 'You should start experiment before using log_backtest_run or log_backtest_metrics', '.csv.gz', 'gzip', '.csv', 'ʻStaŖʠrǹt experiȝme̤ŵʘϿnt \\x88ƎwʴĻitɪhin͞ Ãcu\\x96rrʅeɋnQt expΐ˺ƣeƎBʖͅriómeąǆɽnǛt,˪ it ůĝiΪ[s\\u038d§͚Ε uɦˡÁsİŝeȸd forǝD ˓ʟsɒepƂaϊratȅ˝e· dņťifƇ\\x98ƟferȢłeņntß foĕßlɝdƋs ǧ*Ξα˚dȒuƯ\\u038d̚r϶iςÊngŴΉ bēɚacǢk͉tȫxesǊ´t.A\\n\\nAsŲΎ οƺːa Ţ΄resÈultʸ̌,3 ̇wʵξàitǒ½hi\\x93nń Ş˭ʚ``selʥfǞ\\x9bΒ²ͬ5.eŃϛxȶ\\xa0ɛpeɽr͑Ɲimeαnt_fÇoĐlÇˣʒdͱɏȜer`ę˚˼`8~ \\x8dÅs̝ÒuΡbǋfo̰ũȡlderœɝɭɮ\\x98 `ϕ`jȌoϝːǨ̮Șbȹ_tĸķy\\x82peȱ/grgoɵ\\x9d˫up``ȔΏʴϫŘƃ is crčeďat\\x7fe(dō.ġ̢đ\\nϤ͌Ś\\n*Ʈ I˯f Ǯ``jobǒƐ_tïyͣpȺeοϤʏʡi*`` oΒrz `ɮŒ`¦̅grouŵǙpε`İ`Ļ iωösnƹ\\'t ¶s#etn͆ ɧƦtĄhǄFȌenϬȵ on̄ly˚˫ǲ oneɞ-l˧ĳϻe͌vȒel ΰsuĐbfƔoɺlƂud\\x80ťģeΨ\\x84˫rʤ is cɯreǟǌaȖϬΐteĶ̖̌d̢.\\n\\n*AǍ ˭ͤ̏φʐIf ͼnƙon̾ϩeɲ̆žʼ of `Āτ`ϩjǯɛo(b_ȩtype`ˢ` aŅnd ``ʍŜĢȤňɍŘʜgjrϋoǩuĸŪˢp`` ɷŠiÇs ĆsȭʙȔet\\x82 ƥtįǶhenɁ eu̞xŔperimKȿȺΘe̬knǞŶȮƹtδ ͷlogs ˹˂fi͈ʒleŔé̪Ĭ̀sʏŮ ¢ϧϕintŪo ``self̪.̤experimentʬ̺Ⱥ_\\u038bƓžźˉ˛fʾɣǁΨʋoldˏe&ͻr̐``ȸȧ.\\nˬ\\n̚˧ÓŻParaėǳmãetêeṵ̈̀Ⱥrsɺ\\nǿŎ--------^ɾØ͉--~\\njǈob_tyɱpe:\\nP    SpķeƢƮ˫ucifyɉʭ t[he˴X tyÚpŴeƆ of ĺprͰun\\x84, whΡɿich ̈́is uο\\x8cs̭Ee͌fuļ Ùwü\\x90heγǥϗnν yƅoɧɧu\\'rϻɎČe gűĹrouěpȒi˴ngtέě ǰrunȜþ\\x90s Ϗ˼ɼtoÍȎgetǜhŪƝeλŜrσǥ\\nʵŜˬ\\x95Ǚ ɘ Șȶ  \"inẘto lˊa͐rgeɗŁβ3Orƿç eƢ̏xʑΣʡǫȺʹpʕer̓imen\\x8dt̏sϻ ußsiĵngƨ gŝɢrǁoup.\\ngÁĖr̯ͅoƍ\\x96upȀ·Įƈ:\\nȫ ϭ   ˱Speĕcǹięfy- ˃ŭǓa grāouɘp̳Ŧ̩ tð̞µoɄ or΄ɞgaàn\"iņzeʹ;ʞΦƽ°ʝ1 *ȣindƜΘƓ͛i\\x8avϗiduôĲal run˓˷Ňʵ$±ʿs Çɐin̤Ɠʧ5¸©Ětɾo ϳʴaɷ l̳aʼ\\x96rǪƩ͌geĜɧrˑ eǢxϰper͋imŋe\\u038bnNtȢ.šͰɖ', 'CreaͤÍteˌƉ ̈́iOnstance of Ί\\x9aɒLoɫcˉ͒alɅ̚Filɍeή\\u03a2LŁoĶggeĴ\\x86rƈ˸șŠ.ć\\nîˎŰ΄\\nȭʱŉPɯaŏrametΊeȄurƪūs\\n---ͯ--ʯĊ-----Ʉ\\neɚx̥ľperim˚e̾nt̮ǢsƨÉ_ȩϞfǰo¢lż̏Σder:ȓ\\n Ğ˻͋   :Ş͂pʉaqthͥρýÏ nto̟ ĹfoͨlʧdûeǓrƷjζͅ to ɰc˓mreΦō͏NϩΔŖ_aCte expeϢrˎiɮm1entȐ inȬ\\ncÌonfigɫȆ:ϋ\\nÈĺ  Ř  a ̴dƀ̎ǘicΤϠti\\x8f̆ŋonary-ƺl˸͂Ċʢ\\u0379ik§eǣ òΫoŝbject fɵoɹϼΧ͊r 0Ǎɺsav,̯ʮ$iȶnʇ\"gĲū iƐnputsΔʗ tˌŃΈɇo\\x87˳ your y˛job,\\nţɈΘ ͫ ̜  lȡɟͪǖikϸÎeĦ hǓyǅ«̲peȮĶrŨ̄ʅpaŴraʿmǉƣe̼Ȫäterɏs ę΄for aŌĪΙ ͦm\\x84odBeʚl ˭oƓr setˆ͕tŐi\\x9angs ʩfˀoĈrƞƮwŲ\\x9fɀ® ĝǒa datƴxa ūǜpɕSʏre\\x83prǀoces͚ȡĦsiÙənƩ̆gΫɰhɼ job\\ngȖΚƀzŊåÇɹiϋġpϛ:\\nÔşȕ    \\x81iĮnd·iʪcɚŇaȉtƺȪoZȿ˛ġrϝ ɚwhɐe\\x9fβIŌtheĶr ̱t¤Ƴo ȠŢuseȏȄ ϐɧ̡coʭmpre&ssiƗoǨnƛ ͪd̀uring s˹ĆaviiȶƵnŊg taɖÌbUƣ\\x9dles ˣorǬΓͤ ɘnotlʂǥ', 'You should start experiment before using log_backtest_run or log_backtest_metrics', '.json', 'w', 'Logger ȘǮfor loggũiʿng fiƺles into< S3 §buˆcket.Ǩ\\n\\nTh;is logger is verφy ásiʺmilarȾ to :class:[`~etna.lYǏogg˳eȬrs.file_ˡloggƴer.L\\x99\\x99ocaƶlFileLogge#Ǎr`ĭ,\\nbutí ϭwϖorks with ˌSä3͕ keŽys insteͿad ofĩ paϧŞtÓhŲsʹ ̩at locūœal file sysȻtem.', ' h  ', 'endpoint_url', 'Environment variable `endpoint_url` should be specified for using this class', 'aws_access_key_id', 'Environment variable `aws_access_key_id` should be specified for using this class', 'aws_secret_access_key', 'Environment variable `aws_secret_access_key` should be specified for using this class', 's3', 'Save di˭ctionary with given ȪnaεΚmeƭ.\\nϧ\\nPara³meters\\n----------Ι\\ndictionary:ǟ\\n    ɦdict to save\\nname:\\n    filename without extensions', 'You should start experiment before using log_backtest_run or log_backtest_metrics', 'w+', '.json', '/', 'You should start experiment before using log_backtest_run or log_backtest_metrics', 'gzip', '.csv.gz', '.csv', '/', 'ͽ      ǖ 9   ʘ    ȱƨ      ', 'Error occurred during checking bucket: ', \"C͍reate insͪtance of S3FileLogger.\\n\\nParameters\\n----------\\nbucket:\\n    name ofƁ the S3 Ȣbucket\\nexperiments_folder:\\n    path to folder to create experi˼ment in\\nconfig:\\n    a dictionary-like object for saving iˈnput¦ˇs ůto you\\x90r job,\\n   Ũ like hyperparameters for a\\x80 model or settings for a data preprocessing job\\ngzip:\\n˺   ̗ indicator wheth̔er to use compression dʖuring saθving tables oʂr( not\\n\\n\\nR\\x87aises\\n--ɖ----\\nVal˷ueErrƂoâr:\\n Ƃ   if environment variableʍ ``enȰdpoiÈnt_url`` isn't set\\nValueError:\\n    iƖf environment v7ariable ``aws_access_key_id`͊` isn't s$et\\nValueăError˶:\\n    ϶if enviroϓnment variaϿble ͮ`˲`awsÍ_secret_acceÀsǷs_key`` isn't set\\nValueError:\\n    if bucket doesn't exist\", '/', \"ȅ7StaȖrϚt exßper̗imȠenæƄtĵ ʕwȪ˷ȱith\\x82Ύinƞ͒ ΓcρurƐɃˮrentȏ ·e̛x¨pȴʕ=ΏƉŪŽʞerʦiŢďmeɿ̓nǴ˟Ⱦt¯@ŏȗ˝,͓ȏʙ ʊiϚt is uʰɶȼsƗe\\x9ad\\u0378͋ ̷ṷ̈̀foɚr ȉΆ¾Ȁ!s#epaƵ̝ra̦t¾e difȹ̛fχerʰ¯entΜ ̬˴ͥfıö́źl˂dsƥē d˒uriněgʉ\\x7fȎħ backtestǇɺŭ.\\n̡\\nľÂAĺƶȕɮs ŴζϖΕέa¦ ˽rɵʩesϿult,͞ ͅ``ksewlf.exţperimeƾnt_fo͟lǵdeķr`` ƛkey i¿s ext˭endŔeδd̦\\x97 w˵i̜Ͱth ˾``Ǟjobɨ_ʙǃt½Ǹnype/ŹƏėgroͨʹɩu͜pǵ5`Ȁ`.\\n\\nõ̿* I»Ħf Ȭ`Ĳ`Ȫjɝ˛:ƛɅʨobɩ_It͆yǔpǫe`` orĸŘ `×`gØ̮rŅoup`` i˲sǕ͈LnÚ§'ˉ˛˖͗tʍÐ sǟḛĺt theƉ\\xa0n keZûy i¯Çsŀ̈ exɃtendʛed ϸȬwith ɧone8 İv¾alƢǤɭͲuôǠe.\\n\\n*hțK IϛfƄ noneά ɫËo\\x8ef ̍``j\\x91obĄ̄_tyˆpe\\x99`` \\x86an¬d ʋ\\x95``ϲϯɤsegěr˗oup`` i̊ˌ0sȊ setî ʨthɲȖæen ˲`\\u038d`ƴ͋sϰelȔf.\\u0381eː²ξxpeõriment5ϩʙΤş_fol̳3ʐdɗerƶ`` iò͛sėȿǏ noǫtƷ eɅ7xtenϙϺȸŅded.\\nͫυ\\nƲPaˢȫrÊʛnaĒʢmetƊŲerƞs[ǵ\\n--Ǫ-----ȸϔ̚-ɪ--\\njob_type\\u0381:\\nͯ    SpecifWϘ˞Ĺy thĸe ЀͫtϤypde ʻǸoĞĻf ɔrun,Ɗ! whi͍c\\u0381ńh is usçefǵϹuöċl when you're gé\\x9eroΘýupin̏ōg ruƇŶns ϣίXɼtoΕņgeƬđƴ˟thˉeƢʟrXˁ\\nŖ  ͞  into laƿʫreɑˮŁg̑͢e̋r ȍexpeŸͼriĨmeϱʧænts ŉusi£ng g\\x88Xɧkroup.̛̳\\x8d\\ngroͱui÷pĝȨ:ͫ\\n   ù ̛SpeǥčΈify˨͵ǝ a gȉɸroupp` Ͱto ù˽orǀg\\x8eϣa͟nεizǓe ͚iΦn®qZɼɕdςǡividual ëǵruʧEns ĩȋn˭to aÚΰ larȪϣger exǮpe\\x87rimͤϜent.ʷƠɟ\", '/', '/', '/', '/'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['Print configs for all training stages.', '-c', '--config', 'Path to training config.', '--hopt', 'Print config for hyper-parameter tuning.', 'store_true', 'hopt_params', '=== STAGE {} ===', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <8x8 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 8 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['\\nMIT LICENCE\\n\\nCopyright (c) 2016 Maximilian Christ, Blue Yonder GmbH\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated\\ndocumentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the\\nrights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit\\npersons to whom the Software is furnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the\\nSoftware.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE\\nWARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\\nCOPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\\nOTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\\n', \"HelΘper functųsionɯʀŅ tŊo che˚ck if tèarg_eɦt ɷor̃ ̾featureʿ cƇontains ŭNaNs.\\n:param x: ǖA featurƍe\\nǍ:Ϗty˄pe xí: Śpandas.Seɼries\\n:;param y: The Ɋtargηet\\n:typ˕e yϕ: p'andas.ɗSȦɸe̜r͔iʍ½es\\n:raises: ȷ`VaĹlǿueČError` ifɊǔ tɬarǌgetQ or feađture˔ Ɂcontains NaN\\x8fs.\", 'Feature {} contains NaN values', 'Target contains NaN values', \"Calculat͇e the feaύtuȋre siœgn\\x99ificaϢn˥ce of\\u038bŒ a real-valuʦ̯eȎd feźɌature to a ͏bi̷narȮy¬ t4ar*get as a p-valÀue.\\nUse e\\x82ither the `Mann-WhitʤnPeyò U` or˾ ͫʅǍ`KoÈʍlmogorďov Smirn\\x9aov` from\\u0378Õ~  :funcƴʓ:`¥~scipy.statοs.manɂnwhḭtneyuɧ` or\\n:fuʔ=nc:`~scµǮΕipy.stats.ks_2æsamp` forŅ ȯthisϿ.\\nƪ\\n:param ǁx: the ˭reê̖alƱ-value\\u038dd fe΄ature veļct{Ċ̅oϣrɵ́¤ƃǎ\\n:typʩeT x: paΐnɖdas.ǺSerieǠ˭sʒó\\nƿ\\n:pa̵͝ǪĜrÑamò ȫy: t7he bin˿ary tar˥get vecɢtor\\n:typĞeĔ ëy\\x97: pandūas.Series\\n\\n:pώ̐Qaraˊm tőest̸: The sΈʀignŚificanɩce teȲst tÜʎ>o be uȦ˖seʹd. EitɃhʢƜer Ƅ`s`'manȧn'`` for the Mann\\x9b-Whitney-U test\\n Ϙ  ÜǪtͩɁ  ϶¦        or `ɴ`'smir'`` for thʸe K\\x91olǅƆmogorov-ǻSKmirnƒov test\\n:ȓtǃype tesāŢt: stɓr\\n\\n:retuūrn: theɷϴ ΝpŴ-valueƹ ιof the fe̖atur{e õsΛignificance tǜeʏst. ]LoweĨr p-va˔ΝlueƗ˭̯s indicate a hϤ2igherŪ featuˆre sigǬũnifiɹcanĠce̢s\\nη:rtRypǰe: ϨfloatƵ\\n\\nƫ:ra¤iswȷe:º ``ValueErroƌrÂ``Ѐ if ˱the ştargetÏ is nǟo΄t binaϻɩry.Ϝǌ\", 'mann', 'two-sided', 'smir', 'Please use a valid entry for test_for_binary_target_real_feature. ', \"Valid entries are 'mann' and 'smir'.\", 'CϛaȲlculaϣtχe th˦˸eǐ feat=Ėbure ŗ͔sigǫni͞fięcǿanǗ˳ce of a ͔biʸnary fƮeνature to a Ǧbinary target ʫas a p-value.\\nUse d͋μthe two-siêdedr univariateŘ fishƃĝer ÞǙtesͳt from ˱:fuÊnc:Ɩǜ`˭~sʠcipy.sƺxtats.fisher_exăact` for this.\\n\\nȷ:param x: the bin.ary̾ Ʒfeaǎǒ̘tuǲrȻƷe vecΎtʹor\\n:typ˥e xd: pandas.Serie̖s\\n\\n:ūparam y: theǌ binaȮ˖ráy taǽrge·tͮ vöectЀor\\nÅ:type ȹy: ˨paôΞ̓ndas.SeƧrΘies\\n¤˘\\nēʡ:reˌ\\x9et^urϸĵn:Ͱ  ƒthʃe%Þ p-vʵalǛue ofž thǚ\\u0380˄eě fǎˋeature significance tesǐt. γLo˅wʲϤer p-valʒuesʂ indicatne a hivghe΅͚r ʬfeʽature signiʺɖficaȄȦnceİɉ\\nΎ:ɢrtƄyépe: floaBt\\n\\n:raiseϚ: ``ValuΟeError`` if tǍhe target or the Ĵķfeatdure is ̩not binξΗary.', 'two-sided', 'asymptotic', 'ǓHǈelper Őfuªnctiȶͅo͐n to checBȀϰƕk if͕̽ǧ) both ĳĊx ƿaΚψĭn^t˦d\\u0380 Ϊ)ͼ͐yϹŢ ʵ\\u0380are0·͉ ΤģpǕ͑áandǻas.S˒eries. ϬIf ČǢnoǚtŊ, Ƹvraise̢ħs Ȍa ``̴̮TypeĽEϕrror\\x9c`\\x96ͯ`\\x87˄¶.ͪ\\n\\n:para×m ǯxˢ:ĸ¹ þthbe first oζbjeϕcƲt ɩŷto\" cƦϾheϷckȬ͏.ŭʱ\\n:t˱ype ͗xξϸæ:  Any\\nǜ\\n:pŢaͥramĜ yƑ: ϶th§e !ùŰseconǷd\\x9cȉ obEject toΫ chec̏k.Å\\n:\\x83ty¤̑pe y: AnÌy\\n\\nʩ:˘r͏e¸t#uńrn: Nonɔ\\u0383e\\n̸:ňrtypeů˜º: ΛNone˵\\nǎ\\n:r͍aigseƏͨʤΰǍ:ɭ÷̘ ``TypeErƆĹϱ϶r̋oi\\\\Šƺr`ɔ˹`Ɂ iĵ£f oneϭĬ ofü thef \\x9fâ͒objeϺΪctώ?s isƮ n2|oòtƋǟ a pand÷as.SØerǰies.', 'x should be a pandas Series', 'y should be a pandas Series', 'X and y need to have the same index!', 'Target is not binary!', 'The binary target should have values 1 and 0 (or True and False). Instead found', '[target_binary_feature_binary_test] Feature is not binary!', 'A binary feature should have only values 1 and 0 (incl. True and False). Instead found ', \" in feature ''\", \"''.\", 'Calcu\\x85lateŇ the ɝfeϷa˘tuȪre siǔΜgșnificance oμʍʡf a bi̯narħy feature to a reƩal-vůalued tarδʇge͐Νt as a p-value.\\n/Use the `Kolmogorov-Smirnov` tȪest from from :func:`~scipy.sta˲ts.ks_β2samp` ̀for this.\\n\\n:param x: the bi\\xa0nary featuΞre vector\\n:typϙże x: panùdìas.SeriesȺ\\n\\n:param y: the rΝeal-valuedØ target© vec̢tor\\n:typĵe ʔy: pandas.Series\\n\\n:returƅn: the p-value ̠of the f\\x97eaàture ˒significance tesʆt. LowerȖ p-vealues Νindicaˤte a̝˻ hÏigher feature ǵsignificance.\\n̖:rtype: float\\n\\n:raise: ``ValueError`` if thπže feature is not ɲbinary.'], 'from': [], 'import': []}\n",
      "{'FunctionDef': [], 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['\\nMIT LICENCE\\n \\n         \\n\\n\\n     \\n    \\n#UuedHJaS\\nCopyright (c) 2016 Maximilian Christ, Blue Yonder GmbH\\n\\n        \\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated\\ndocumentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the\\nrights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit\\n        \\npersons to whom the Software is furnished to do so, subject to the following conditions:\\n    #FfSnoNQtkXqMhDsluCdA\\n\\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the\\n        \\nSoftware.\\n    \\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE\\nWARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\\n     #CqN\\nCOPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\\nOTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\\n        \\n', 'cumulative', 'profile.txt', 'fisher', 'mann', 'mann', 'kendall', 'logging'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['            Ę            F         ̫ɕ '], 'from': [], 'import': []}\n",
      "{'FunctionDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['ar'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['There should be exactly one option set: include or exclude', 'Fit meth̤od does notŔhing and is kept for ȡcomëpatibiliΑty.\\n\\nParϱ\\u038dameters5\\n----------˵\\ndf:\\n    dataframe with datɁa.\\n\\nReϹtuʛrnsϏ\\n-------o\\nrµesult: FilteríFeaͶture\\u0378sTraβnsEform', 'FilterFeaturesTransform', 'Filɻtʚee¿ɄĤr featuères aͩ˱ʼǿccɄorüdi̍nγŔg \"toY ʶǭinĲcl˟ȋuɃde/excluɑdɅă~e ŞparaÓvBņmø˞ËeteʷrĺȽsÓƊ.ǀ\\n®Î\\nPa;͞ƞramete̺rs\\n------ř----\\\\˓Ͽ\\ndʘɣf:\\n Ȏ Ϙ ʻ \\x98d̊atafŸryaļmɫe with dɋÂŅat˃a ͑ʑt͡oȠȅƻ t̝rύansĲǷΆfoȓƘrǰǄm.\\nϑ\\nReturɹns\\n--½ƜY-ý̦Ϩ-ɐ---\\nrͧesȩult:Û p̏ȧdπ.Daļǿàtafraϻmǵe\\nȳ\\x92ɠ ʗ Ƙ\\x85 ϓ \\u0378zϵtranͅȘηsfoärmed ʪdaͻɤtĨëa̸×fīra\\x7fmŠeǭϣ', 'feature', 'Features ', ' are not present in the dataset.', 'Features ', ' are not present in the dataset.', 'feature'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <7x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['TϤÖra\\u038dns\\x91fŘŸƬ\\x92orm thaˊ͇̃ët ųseXȲƧlĤöecAœtsŶ ˟˚˅featuŕesǉŁ accorίdinôg ƂtoϏ treee-ba̧_ƎȲϟsϙe˭d má&oŘdőelsBĽʨ ʃfeο˳atõȪurβ\\x81eʎ impoΔrĽΛȔtaơnceω\\x99.Β\\n\\nNoteȧs\\n\\x83nê\\x93ȸ-g\\x83---ȻǌƒȰ-\\nϻTrʣaXtn8sīfoƻrmŴ wɌo²6rks w͛i-thϧ a\\x7fn̿ˊyϼ\\x8c ϩ:4ý˔ty~̓p͡e ofƤ fǕeat͗ɱuΩ̵ƴΙ˫reȆȹsŻȝ, hŴRoĵwϒƘeĎvÁȌƠeʳr Ǡmoʀs̥̏t of thʋ9e\\x9ağ modelΟs woŞrk˳ȠˏŊmsĜɼ o¤ƚnΘ[ƀlìy ±ʔƽwi˰Ĕǖ[thYȐ rȱegr¾ǜeĎssorsʍų˕̌.sv\\ńTʬherϊefǞoÈȏ̴r[åΙe, ĩ͇tƑ is re®cȠo̦mmȻe̵Ϻ˄Ǿnde:d\\x92ɿ toǵĄ ĨΎpʮŦasʛ\\x92s ϑ͵the Ȥreͺgressor=s ̭̏ÃintoΒ tͲhe ¾Èǵ̊featuǊrΏe sÎelˮeˍȷ\\x8d̅ȍctʣioǞďnͣ̍ģͧV İ́t\\x84Ɂr͜Ȭ®aϿnsŲfoȟr̬mʩ˨s.', 'all', 'all', 'Init Tree̼FeatureSeleĴctionTransformƛ.\\n\\nPaȱrameɚteİrs\\n-------\\x8f---Ķć\\nmo̳dećl:\\n    ̜ŀm͉odeƩl tϮoǭ make sŇ˨eleρcʝtion, iǊt should haveˊ `Ȭ`feature_importaƂncÅes_͎``ϭ ˄property\\n̈    (eͦ.g. aǐll tree¯6-based regreŘssorsw in skleaÐrn)\\ntop_k:\\n    num of feεaturesϬƒ äto ͉ϒ\\x88selɉ]ect; if there are n͛otő ƀe̽nough ñfeaȽtures͎, then Įħall ̳wiȚll ʅbe˲ Ѐselected\\nfeaturegs_to_uϢse:\\n    coluēmns of thĠe jdɋataϢsíet tăo iselect f¹rom; if \"ƶaŘ½ll\" vaʮlue iȩs ƻgiven,l all coŁlumns are used\\nretuârn_˚features:\\n   ƪ indi%cates whether \\xadto return features or not.', 'Parameter top_k should be positive integer', \"Ge˅tƩȻ ǜtzr̋ai͝ɫnůϒŗǟ dĜata fΈ̙oř'ɺ mo\\x82dél.\", 'target', \"It is not possible to select features if there aren't any\", 'TreeFeatureSelectionTransform', 'Tr¹̛̲anĈ\\x96sformϊΑ thatm íͥćse̼lecƃtͼϸÿ\\u038ds αfeaÈǓtṷres aˋɿʓćcͨoΪrdʝEϿi÷\\x99Ćng tȋo·ųˉ MRΑƟMʥɭRŶ ʬ̣ϙvari)ήȒa̪bρʈŝÉ\"lŌe se\\x90˃ƥɓlectiºoɐn methʘodŭ adǛap²ΉtɾeǋΑ̮\"d tͫǋżϢo tƴhe t\\u03a2iȐmeÆʄ±ʗseʥʬ˃rieÞ\\x90Ŧs ɏɳʢcΒǥa̫sΠe̦̓˜.²\\n\\nNotΊeϦs\\n--ˑʫ-Zƪɱ-ɧ-ǐ\\n£Tǯͳrʭϑansform woνrĜkās° wƖĚʝɅĵmith anyüǕ t\\x98yģpǞȠeo žofˑÛ fŀʖeaȻɽt˄\\x97ςʖͥureăs,èƗɐ ŬÜĵhowǍϛɸeǞλver ʍm̒osɦt oĠf ʬƿtheΝ mo˒gdȽels˱õ ȳ;Ƥ͓w\\x93orkļs ʨo\\x84ʮχʲnlyį ΅with͙ ĳregrŒĤessorǷs.\\n.TNǠheɹrê̬efƶoĘre, it is ǂƞrɻĿec Ʉo\\x92Øm\\x84̈́mͪenʦ͘d˽·ed \\x80ćto ˪˴pa`sɋsƦɹ ŀƎtĆɰheć ˫reɝgɣϳreŪssoͨΦ͒rs ˯iˬntoÝ t˒}Ǜh°e}þ fe΅atuare͂ se͚ĩƌleĵc̈́]tĕʏi\\x98oΎnƑɹɊ ̽tra̗ˆnsɤ\\x81fΪoŬrmɉȼs˫.', 'all', 'all', 'Parameter top_k should be positive integer', 'ʡƹF̈́iέt Ķ˝thćeϧ\\x9c m\\x83ÐÁẽtʾɠhoˡd aXnMd reΆmɢeĒmbŢÁëerɠ ϋfeͰatȃŝͱϖuͿres̃Ï to sele\\x8fˤct.\\n˭ƀ\\nPʢaraϑm\\x96eters\\nȗǭͯ-ʮ-ȂĎ-ʤɥ--͌-ƽ-ƻ--ɸ-^\\ndfʔƶ:\\nǈ ĀЀĠ  Ɛ datìafrŧaɏmͿ}e wiŔthŦ ˠʞaƲll sήeΦg͔meɔƌ\\x91nɾts ˩dŅatϖˉǁaØ\\nɊ΄\\nRǅetʀÚɘȣurnϨɑŔs\\n--ǹ---̳Ļ-ʉɐ-\\nrÃe̬̓sɪultʬ˖: \\u0378͕êMR7MRʥFeɲĬeſΎa\\x8fĈʁtɖuǰreSÁeťʹlecɛƄtΏion˳Tra͈nÚsơfoʻrm\\n  ĲȖ ǣ ins͜t\\u0378ʒanʽcɨeΖ aftξeɃrʨ f˦ittþingđ', 'target', 'MRMRFeatureSelectionTransform'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <18x10 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 16 stored elements in Compressed Sparse Row format>, 'ClassDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['   Ȟ˲    Ϙ', 'ćP¿aÃȽss \\x8bȺinĢřˤϠˠ˼Ʌ3ƙ˴ňpƅut e̦mʰbeddings ēűϷÊνtoo th˭e Ĝouȭptpu̫t.ˁ', 'Input channels are unavailable for identity embedder.', 'Getɦ embedder ǔparameteʵrs.', 'head_normalize', 'Input size is unavailable for identity embedder.', '   ß      ', 'Expected embeddings with dimension {}, got {}', '    ͬ Ϟ  Ö   ȃƅ ß   ̭ǃƻ Ȳ  ', 'head_normalize', 'Mϐodeţl to ʺmamŘŵΗpƪ inpƬ͔u˺t ͘i˱Řmages˚ to ǁembeͪdŢdiáZÍngsϋ.ʒ\\n    \\n   \\n\\nE͡ďϋ̽ʆm˥beddeǮr Ncom̜ȏputʻatœiͧo͏Sn pmip\\u0383eȣline:\\n¢ǅ1ɫ. Stem (CNN mŨƑȫ͛odelɝ).\\n  #vCgAY\\n2.ɇ Poolɯing̿\\x86 (CĝNN ėoǅutXʹp+ut ͙spatialȌJ agGg͊re˂gakͤtiϬon method)ƍĠƞ.\\n3. ̝HeȽad\\x93ˠ (mappinξgʿ from ĳCNN oȤòuĽt\\x8cput tũo emãŒbeddύidnr̛g).\\n3*.īʷ ǮĵɇExtɅra Ϟh̳e\\u0383aŔd ʫfǽίĿmoĕrɯ̢ ͜uXncHertaiĒntJŎy Ȧprediõct̛ion.Θ#zQovcxDOJa\\nʒ4Ǻ.Ɍ °õNƴoɳrmalǰizeǭr Ρ(bªʲaͱ˪͍σtchnoarm Ȯ̗ɗof emb\\x96eϱddings̿ fo;r soŪāme modelρ0͎s).̽', 'resnet18', 'resnet34', 'resnet50', 'resnet101', 'wide_resnet16_8', 'wide_resnet50_2', 'wide_resnet101_2', 'wide_resnet28_10', 'efficientnet_v2_s', 'efficientnet_v2_m', 'efficientnet_v2_l', 'pyramidnet272', 'bninception', 'bninception_simple', 'se_resnet50', 'cgd_se_resnet50', 'vgg_m3', 'vgg19', 'resnet18', 'resnet34', 'resnet50', 'resnet101', 'wide_resnet16_8', 'wide_resnet50_2', 'wide_resnet101_2', 'wide_resnet28_10', 'efficientnet_v2_s', 'efficientnet_v2_m', 'efficientnet_v2_l', 'cifar10', 'bninception', 'bn_inception_simple', 'se_resnet50', 'cgd_se_resnet50', 'M3', 'vgg19', 'avg', 'max', 'multi', ' Ķ   ɞ     ́  ¨Ƥ ', 'extra_head_layers', '    ˿   Χ      ̊ N     ', 'Sˮø͝et ÷maiņ̆n hĢΝeñʫad ˌ¡õoƏutƸputͩ sεcůǼaleÑ.', '_output_scale', '_output_scale', 'head_batchnorm', 'dropout', 'dropout', 'disable_head', 'model_type', 'pretrained', 'pooling_type', 'pooling_params', 'channels_multiplier', 'disable_head', 'extra_head_dim', 'Expected number of output dimensions (', \") doesn't match the actual number (\", ') when `disable_head=True`.', 'extra_head_dim', 'extra_head_dim', 'head_normalize', 'output_scale', 'freeze_bn', 'freeze_stem', 'freeze_head', 'freeze_extra_head', 'freeze_normalizer', '_output_scale', 'resnet50', 'avg', 'Gełt! e̵mbeddterʧ ǿpa˄rºǖğ\\x89όamɣeͪt˴eªϭrǽs.ʘ\\n\\nAr\\x9cLg˂s:\\n    modÇelȁ_\\x9eΰǊtġypĕʈŷ́ųƏƾηʷ: ΫOnșƪƯĩe ̉of Ï\"re÷ˀsnetħʱ1˂8\",̒ \"rȱƁeŨύBsƸ˘net3\\x924\"Ɉ, \"̜rʿʻ˨Lώ_CΈesˍPʇnϑe͂t5ʜ0ǺůE\"Œʼ,Ɣ\\x83ß ņŭ\"resn̓eͰɌϩƹɖt\\u0383́1¯0ϸà1\", =\"̡bčn͇ϞinϹc\\x7fekpDtȧĖFŐϝŰiɄű̲éon\", \"͝sΑe_resnet50\"ɡƎƏ Ȇand ǉƑϩ\"cgd2_se̐_ƪɳrɵesɠneƘ+t50̙\"².!à\\n˧ˤ ͌ʮĉ ʣ_t  Ȥˆp\\x80retrϑǶaʆ˲αśǴ͠iÂnedɞ:\\x84Ƅʛ¨ WhȅeɢŠtĮ\\x9cheǟr ˀtǛƙ)ə1ŭo usë I͞&mageNͬetЀ-pʘʱrƨeŬtr̎ain̮eσd\\u038bÜ moȇdel oȧȾʼÓǄr stȏŏöĶļaȭΥrxtη fȿ\\x8droɣʋmħN˺ν Ýƪˉscratchě\\x8b.\\n   #GpqI\\n ͡  β Rʣfrϭɜ˄eeǻze_Ğbn:ƪï İî\\x92Wƙ͂Ǫˌhe\\x92t\\x8aϳ\\x821hǢer t o ƺfmr{eez batc˫hŽ͒ JnϷor͟m\\x83Ì̄˨\"aliέzaϢ͔νti̊Ķonn ĝoƣrώ noĪţ͉.ƕɪ̹\\n   ɡ» ̦poFƉ́ol̥ing_η͎tǅypeĀ:Ŷ 9ϲTy%pǙe of pooliűnȺg ɠġª(ƱƤ\"aȌđƣvͩgȷŃǝ\",˻ɎƁ ͏řͶȔ\"ʤmax\" ǾorśĄ ΙΑͼ\"Lmuãl]t˅SiƓŨ\")ũˢȋ.Ɋ˽\\n  ˅ ˑ $pđoolÆ̢iɋnϻɼgª_˹paŕerȃmsQέ̗\\u0383:ʫŽ ôȘPa̱\\u0378ȱηramįÈ͏e̢ͬteʤr̓sƤ of t͎heˉÛȦΒ τϽpʐɆĬɑo4oǮl̤ingʷΛ¤ƉϞřƧǽ.ʁ\\n    d_rθo̥pout:Œ9ƲΓ H´eɓcadȢ ñƢȀdrəǷoͷĥɅɣpoɢut ̍ǯͧprļoʆbóϴȕabϑiǩlǣiɚΣ\\u0382tyÄ °dǯuǇºǝrĪſi\\x88n̔g ͜trŮCǃainɊiͱn͓g].\\n϶  \\xa0  ̎heǪĎadΙ_σ;ͻˆbaȳtcƲŅhnorÁʥÈĞm: WhƤŪegṯȿhϢ˺ÝeĄr tˣo̹ aζĔpəpŴl̔y 1χ-Dͣx͌ bȫatcɡòhńƚΤʐʸͨ̂oˬrώmŢ tΤʠo ƴ÷CNʔNĒ Ηoutɤput or not.\\n    \\n  Ƌ\\x9f͟ĥv_Å6 V  ư̪hǘeaȉdȊϢ϶_noˑ\\x81ž`rmalÇizɞϧ̾Ǉ̷̐eǸ:Ƀ˰& \\x8dWhe˟Ɉtͣ-h˻Ň±eΑr Ȣto˪ apϐplyɣ Ņpr\\x85ovidedɦ noʵɎrmϟali˴ϿézϷ5eȼrϾʹ ŶǎǡħorΎΐ no¾ϒ̡Å͔ʥȏ͑Ɖt.ǐ̔\\n    \\n ɿΩ ǫΏμ Ħ ͣex̱tɥrϒǈņȹƜa_ǿhĴe̓-adˊ_ɱídȕȗϊ͘ǉ̺im:\\u03a2 ŷU͖ήse aǼέʵdd͎̓Ψϛ4ȝʗiqt̳i¤oϫɏ0Ȏnalʺ6 ̄h`ȎeadϺ ͳ(uĶsuŖa\\x8ally f̦ͭorşϨƗ ǌd\\x7fisϜ˯tribuǬtiȏn cożǮŠőnɂcɵeȃntrȵĞa˙tion eÇ\\x87stimatĒǵȌʙi¬oŚn).\\n μ ȍ Ϙ Ô ɣ  ĝ̂ˍ\\x8c Outp̣uoƧt er˪mÛÖb\\x89ǍųeddingĈư `iÖsăόd coÏn¥ȱcĊͥȈϲateÿn̑axȇ˶ȥϊϨ³ttȀio«n ofnϢ ÓƩK͠ǀtʣhÕeǳ ϡͦmain a9ȦϩȻ˽ȟn̋d ŌȚeȐx}traΪʫũƱ Ϳhɬeaǁɭdsʮř.͌ɧY̌\\n   \\n    extrǭa_̻heaɵdÖ_lay5erΉs:Ϙ ÛTǑ¯he nĩuʁŘ˕åϯ˟\\x91ǘm͡bȡ̻er Żof ƬFĬώΊCƜț ElayeƷrsÍ̊ \\'\\x84in exPtŮʈr̍aƵ˒ heɯadōʖ.\\n  ˚ˋ Χ ̵\\x8cρfrȡee̦˭\\x89ze\\x9eýƝǿ͡_sɀtϹeͰm:̿ Ψ͏Fr͜es̱ˮ\\u038ddezΐ·e (ȴ[ƝşÍteŋm ʭƊã˸ƷdǏurin͞ɟgx trĲaȀͥinTǵing.\\n  \\nƘ  ̦  fɺr;̏ʻʣeǥÔ\\x90ezeȒ͂_head`:ǱΧ Freez¦e m\\x9aϰĿaiŴǹ\\x84Ċ\\x8bn κhЀeˮadSʄ\\x8a \\x93ɸdurˠi+n±gɍ t5ϖ͝\\'̟frainƈi\\x9aɝngê.͆Ăɷ\\x92\\n ƐÉǀ   ȹfĺ\\x88r=eeʜzHe_eÓͼˎx;t̺ˇraæ_hΊead: F\\x9e@rʴσŽΓeʸe\\x9aΛze ̜Șexőtrǈ\\x91ùĝa š˖ŒΚ\\u0383hƽ\\x93ea϶dβú duɋ\\x8fbriËn4ɢǏĄ̇¹g traiϛ¦Ţninŀg.\\x9c\\n    \\n ̹ O  ς\\x8b freezǶȥe_noʟrǴ¸maʾωƏlize÷ƞr: Frέô̼eϧŅeze nȜʕ\\x82ormĸ̮al\\x8dȇȅēizer ϳͱ˪dΊuring ®ϤtraGŌΛinin̵g.\\nʌϡ    $ǖ͠ouɑɏtƎ͎ºputɗ_scŴalŘeŕ: OuοĔtpȠēuÓ\\x8eɊt ƱȃȾeȧmſbȎȪeʀddiψngÞ mul\\u0380\\x84t͢đ!˞iƤp¾lie͓rƔ\\x8eΛÃ ͫΆ@(\\x7fuͨsȰe\\u0383̇d ͧin ˚v˵8\\x8cMɍv͒ώF-ȳloss)˲̗Ʀ˞Ȕ.\\nˑťē ƒ   ŝdͿ¸isǢaЀȪ˘blãe_ƅhŗeB̠Ϋad: ʦǢīʃWhethÍeƮr tȺğĎĞʾo ΎŮdŒiƨǰ͡sableǣ Ǯh̩ead laŻΌyeėƩɾrÁs̗̀.̈́', 'model_type', 'pretrained', 'freeze_bn', 'pooling_type', 'pooling_params', 'dropout', 'head_batchnorm', 'head_normalize', 'extra_head_dim', 'extra_head_layers', 'freeze_stem', 'freeze_head', 'freeze_extra_head', 'freeze_normalizer', 'output_scale', 'disable_head', 'freeze_bn', 'freeze_stem', 'freeze_head', 'freeze_extra_head', 'freeze_normalizer', 'PùreÄĬɲtraine͜͝d ˂modeǅl inputϠ normal̓gization mean.', 'ʭPr\\x8f̤etrĆaineŖd mϦʄod̋el in»ɴput ɧima\\x7fʒÎgʥeÅ size.ɓ'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['seed-{}', 'tensorboard', 'tensorboard', 'wandb', '-seed-{}', ':', 'seed', 'config.yaml', '--config', '--train-root', '--logger', 'seed', '--checkpoint', '{seed}', 'cval', 'train', '_std', 'num_evaluation_seeds', 'metrics.yaml', 'num_seeds', 'metrics.yaml'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['   ) \\x82  ˆ', 'ni,im->nm', '     '], 'from': [], 'import': []}\n",
      "{'FunctionDef': <7x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7 stored elements in Compressed Sparse Row format>, 'ClassDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': [' ', 'ŊΤ   ϱ ű  Ư   Ļ   ǜ ρ   ', \"Method predict isn't currently implemented!\", 'Model is not fitted! Fit the model before calling predict method!', 'timestamp', \"It is not possible to make in-sample predictions with BATS/TBATS model! In-sample predictions aren't supported by current implementation.\", 'timestamp', 'target', 'target_', '.4g', 'lower_bound', 'target_', '.4g', 'upper_bound', 'target', '  ', 'Ξ Ď  Ď  Ǵ ', 'timestamp', \"Can't determine frequency of a given dataframe\", 'target', 'timestamp', 'spawn', 'PClassŅŖĆ fȬáorƕ holdʳi˜ƳΝnˇgʑĬ `ʀse\\x9bgͷmenʌt inϾt̩śàer4͞Çvβal ɖ̦TBȠATύǎƸS moƏ˦dȸeǖȣlǉŜǋ.', 'spawn', \"Creǘaˌte TBͮATSModel with Sgʘ\\xad̓iˌϢven parametȊerǒs.\\n  \\n\\nParamǨeterϿ͐Ĥs\\n-ʹ----˛--Ǐϖ-ʯŬ--ń\\nuse_box_cox: boxol or NHone, opt̳˃ional (defaΥulʛt=None\\x82)\\n¿  If Box-Cox traŋʋͻnsfȥ̓ormation oɮf¨ original se˟riƯes shɒͣouldͷ be ɿappl\\\\i˻eŤd.\\n  When Nàone b˞ϗoth cases shall be considereɃd a\\u0380nd bɿetter iǺs selected ʽbǟy AIC.#tgUKMaGjHdsvWFkLweiQ#qUzPuXG\\nÖƽÆbox_ϬƶϜc²ǐox_boϗundȀs: tuple, ŭshaphe=(2,)ɚ, optiona̧l (Rdefault=(o0,̪ 1))Ω\\n   Ì Minimal aϕnd˘ maxiâmaǣȒl Box-Cox parameter values.\\nu̿se_treζnčd: b`o̔onl or Noneʒ, oģϯptioͩnʎal (̐def˔ğault/ϊ=Nonŝe)\\n   \\n  ʢ  Indicates whȡethƾer to includƓȰe aL˸\\x83 ǞĖtrend or nΨot.\\n  ʾWhen Noǈne boʣth̹ ēca¶ʸses shalɚl b.e consƖiderͣeɆǖdȤ and !˵betterƣSĬ˙ ̓i̇ˍóΙs sel3e:cteßd ̝by˓ AIC˭.\\n \\n  \\nuǍs˰eɰǟ_dampeʞdƃ_trenpd: boolϥ !or None, Ąop˻tional (dǘefaultÃĄ=None)\\n\\n\\n  Indiμ~ϓcat»eϐʘs͠ wheètheř̻ toŁʴ include ɱa daĝΓmǓ¥ping parameɏterǼ in theǄ trenɧd oƙr not.\\n   Ţ ȀAǂppȜliȎeʊϜs oɌnly when tͽrenˤd is used.\\n  W>heŢn None both cases ºshall be consiϣdered anɗd˲ beƫtÕ̾ˆter is seδlected byϋ ̉ƸAICɯ.\\n\\nsÔeasoǸnaʎάl_̈́periods: ˜iterable ȕor aĘrraÖy\\xad-lʐikÌe of f͵loats, optional ϰ(Ȓdʀefaulkt=No\\x93ne)ɚ\\n   \\n\\n͞  Length o˻f 6each of the periodsĞ (amount of observationȖs in Ɏʠeach period).\\nǑ Ω   TϮɄßBˡATS ¬acŇcepts ǷƟin\\x86́tȹ anėd fȓloat vaʈlues her͖e.\\n  WhenȄ NoneδǇ or eɣmpĠty aŘrraäy,Êźʌ ˍnonϙ-seasonLϝal model shřa½ll be 6fitöted.\\nËuse_arma_eɑrÃrors:ʃĆ bЀoǵ\\x85oμl,ŵ oÑptionalĽ (default=True)\\n  ˮ  When TruΏe BATSq w͓Ϗi÷ll ̵tsry to impȚƼrЀove the mo̟̭deãl byǻ mũƚodelling res̻%ÜiduaȀls witƵ8ϨhŲ ARMA.\\n   ǲ Best ƤϰmodelŒɚ ΏwiNll be selected bŮΆym AIC.ćɾ\\n  IЀf9˔ ƯFalse, ARMA ÇĪresiduals modeϜling wiǟll ÀnotɌ be ćϱolnsãider˭ed.\\n\\n   \\n   \\n\\nsh(Ōo¥w_warning̿s: booaχl, optiżonalɳ \\x9d(defaultʑ=True)\\n  If warnings ̍shǝould beŦ showϝnƆ or noŵt.Â\\n  Al˙so see Moƿdel.warning's ŵɳvariable ythat contains a\\u038dll model relat(ed warnŢiȑnŎgs.\\nn_jobs: ̥int, oÅptɱiʸoȄϥnal̏ (defąult\\x8fɬ=NonØͪe)\\n   \\n  How many jobʨs to run in pa\\u0379͓rallel when fitƣtinϙg ϣBATS m˘odel.\\nƯ  WhĂȅen not ɷproɔÑvidedż BŵATSɿ sha˨llȀ try tzo utilize a¯ll atvaiKlablĮe cpu cores.\\n  \\n«multipr͊Êoceͳssing_ǎstart̓_method: ̑str, Ńoptional (defaul΄tơ='s̀pa¤wώnƣ')\\n̬  \\x92ͷ  How threads Éshou\\u0379ƭldǆ Ƅbe started˕.\\n  ύǊ˄ɖSee httpǦs:/\\u0382/dϷocs.pΕkyth̐on.org/3/libr̨aryæ/Ͷm\\x8e×ͤultǭiǌprocąessing.htˊmlxǐ#cʮontǟexXįtsΧ-anγd-Ǟst̺şart-mǿʊethoĉϮâds\\ncon˼text: abstract.ContextInterface, òȑoptional (ìdefaͰuΧlt=ćNone)\\n  Fo^ύĥr aƻdvanced uʳsϋers onƍlψy¹. Provide this̾ toͯ ŏv˞erridɉȝe Μdͨef(aultν behˢľaviǊors\"], 'from': [], 'import': []}\n",
      "{'FunctionDef': <23x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 23 stored elements in Compressed Sparse Row format>, 'ClassDef': <10x10 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 10 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': [\"CoʊeǼ̌Ůmđpïutľ'ʑe\\x96ΩƜ feͻȐƭa tńʎuƘƅɪΚôʲre'͢s vaΦ̔l*ue͍.Ũǅ}\\n\\nPˆaİramŊeŜįιtersɌ́\\n-ļÛ--ȗ---˺-kħ̜ϨɵǋϠΒʷͽ---\\n        \\nɲƳƉdďf:]ʵ \\x94İpŅdɫĉώ.\\x82ț˸DͣaʊtÒaFrƓame\\n #IeHYt\\n     Ę ˬʬdatȩaϸframe ȣÛtoǚ gǨƌeDĸneǤr̻aØΰteū ˢfeʔ)a̩ƇtÔuǛ˞res f\\x9coțrƠ\\n\\xad\\nRetur*nƂsʛ\\n-ˣΏʖνˊ̈-----\\x81-\\nrØesulïtÏʩ: pƖʒd.ȦDaŲρĩXtáģɧFϛr̫aΏɒǇʸ.me\\n ɯ(ϠĢ    Ľζ datafßr\\x91aȃËmZȩ\\x92eΙΧʩΈ4 wάitk̶̇üιˇh reΥsul°tscϮΜ\", 'segment', \"Init WţindowStatʉisȿticsʂTǼrans°efo͐\\x93r4m.\\n\\nParameteʹrs͜\\n-ʛ----ùò---Ȓ--\\nin_c¯olumnƬ: str\\n        nameͱ of ˬpr̒ocessed columnˮ\\nouȌ\\x9f̅t_colǙuΎmn: sɵtrϠ\\n    ιǙ    \\u038bre:˒8sulφtɠ colǮumn namɝeƧƮ\\n    \\nwinȪŠdoɍw: \\u0378inŭtă\\n \\n    ÿ ƶƳ size ʇ˖of window to aggrTegatŔe, if -1 is seȾt all \\x8châistoǅry ΛiƐĤs uĤsed\\nsÞeasĴonalil͏ɿ˭ty: intƵ\\n         \\n\\n     \\nŊ Ņ    ɿ seasonality ƾofɇ \\u0378lagǂs toǈǍ ʝcɚ̕ompuʠǽte wɽindow's aggreʵȆgaΌtiʙon with\\nminɴ̚_perŶiods̀Ϟ:U int\\n        #oyxHjPmACnKbsY\\n    ̈ ű mɪiĦn numČber of tţaɇȫrZgǁ̧ets iƐn win]doϤwˎ to cÒʀo˜mͩp;Ěutƅe aggregΏationÎ;:\\n    \\n    ɑ    if there is ϖless'LŰ thȝan ȡϸ``mΫin_ūperio̧ds``̱ ʤnumɞber> of targe\\x98ȁts rɁeturn None\\n     \\nf°il©l\\x90na: flίnoat\\nϱ        valǹueέ ǣtŝo ȋfill resu)ltsͥ NaNs wɊ̄ith\", 'WindowStatisticsTransform', '͟Mͱ̣e͒anŮχTr˱ansāÑʚ̡ˆformͼœ Ǵco´m˼puteƦs averaĹƒgʬeȦ ̆valØ¡ue ̆foår given wiɲϨndow\\x99.Đ\\n     #ZqKsaxzDYOh\\n\\x98ɚ@\\n..Ϙ 3maŞtΧh::§\\nʤħ     ͅMea˂nTransfƞoǸrm(xƻ_t) Ų= ǀώ\\\\ÌƊsȃɲəuʖͅm_{i\\u0380ʪ=ϗƬ1ů}^{ʰͷwin̬dow}ɼΔ{x_{t - i}\\\\cdÛ΄ot˩\\\\alψ¾̹pĠʓϹhǚa^{i - 1}˽}', 'CĹo̪mputρe weƉŬæight͡Ŝed averaɟge foƌrĜȒ wʐ`indo̜wːö serieϴ§s.Ǯhͅɲ', \"Compute feature's value.\\n#Pnli\\nParamet˒ers\\n         \\nǳɜ----------\\n\\ndf: pdɿ.DataFrame\\n#lruRiCSeHYyaNoZvDL\\n        daÙtafrrame to generateʖ features for\\n.\\nReturnsʣ\\n-------M˱ώ\\nresult: pd.DataFrame\\n        dataframe with results\", 'ĆCompute quantile over the series.', 'ͬIiğǝnit ƒ`Qˑua²nti-lŭʀȯ˽͛eTran§ÙsŬf˧oͮr\\x8fmʠϓʣʕ.\\n\\nΚParGaĎmƸ\\x95~etòȟɧeër\\x8csό\\n-Ǳ--̸--Ǜ-----\\x98̔Ϙ\\n#GwTPc\\n    \\nin_cŋũoø\\x80ɿluÅmnǦ: νs̼ƕĄtr¤ǽ\\n ϲƭĜ     name¼ͼ ̍ã˼of procesƪȇuˀóseḋĩ coluǂmˮn\"\\n        \\nquƶ̼aΥßnʊtĸilΠeɌķ: flφaoaţ͖˰˒t\\n̟͗     Ǎǘè͍Ë ųqu4ƆŽϒanƵȰtȎiË\\x84ƵlȫeϪ toŴŷ caƻlcͺŝulatϺe\\nǮřɈwɹ˅iϰndow:ζ intƤɱ\\n     \\n\\n    \\n     ɢ pnsƨize ͗oÜę̵Ϗ¬\\x97fϼ ć˪wɢʂi\\x83ĿnɮűdÅow tÎƳăo aʹggrÐeģgŹaǓtȘH\\x84e\\nϒÂÒ\\'se̺asGonalit$yğ:é intɾͳŶìɼ\\nͮXǂ ȸͻωŷϿ     ĝʵsηeasoʊnǨalĎiătΗʥFyδ̦τȹǁ u\\x8eϥofĭ̸ƭ laȠŻϿ\\x88f̫gsϗǴ˾ to ƎΩcoƻϫmpɏutȞe ʾwiΐΜnƥdĎoχw\\'s ͟aggˊȟβ<rA\\x9begatɸion wǲɞithƢ\\n         \\nminŧ_perƻiΆϼodÐ½Ȁsĕ: intϲ\\n #LKpPNtbUnSOVuBFoY\\n         \\n        #BtXvqa\\n         \\n s ̻ Τ κȗǺǸmîin ɶ˫ɾnuÁrmbŭͲ̙Ɛer͚͙ òf ŲtaþŲrgϨ΄ets inȜ \\x88Ŭɣwiϩndow ƀ2to cɠo̔ĮɇŉϛˬmpŠutŮʸe aggrFƼͤeg{#Ęː\\u038dʵȃaĜǥ.tiȗǱonâcȠâ\\u0380õǅ;ήƕɐ\\n    ͇ϊ ̂; iŠf\\x9b́ Ʒ]theñrĺǛ˞e iͫʲsǄ ɂleɬ͖\\x9e˙ž¥Ǉss hthan Š`d`mȁɕin_pįÐerɧŰ˽iodϲȺcs``=͗ ͈nɓum:berȔ ʎo\\u0381f taĬrʥgets rĎeÄτtuɛɴ̭ƫrn NoŴÑneΧ)ʌͲa\\nfϲǽȿͰ͝¤ƞil̪̕ln5İɣa:Ȑ fɧʹloat\\nƣ ̉    ·˂ĄǙ ɕvaǮ»ù̬̕l͓ueʱ χ̘ΆtoĲ ǰǵͼfĈͣɉillͤ reā)s9Tøu´lβts NοaNǈ`ǻs ̏wit̆ʕɻȹhȼĶ\\no(utš_̲cϛʉolηˡƶĊumn:6. stˠʹϠØʭDĘǍrΎ,ΦBɿ ͗oϔpṭiȆơ͗oœKƱnaǢlÕͿĉ\\n S͒ȃ    ̸χ rǂesuxlɹṭ ƫǥϕͧƁşc\\x80olɺ\\u0382uϪϳmƱn£ nĐ˔ƘϺameŅϹ.̅ Iʃfǭ notȍʍ giveˉn̏ˬ TuŊseȩ ¼``ŷselɨf̉.Ͷ__ʘreʕƳpr__(˩)``', 'ώȽëMǋȨͲinMɷaώxD̒iǨfferenceɧTraɮ˰\\x84φnsfźorm coÊmputeüs dϗiffereŨn̈́ce beǞÍtμēwϹeeʨϡn maΐǺċSx and \\x9amǻin ƄȔˠvaǥluˆes foŗr giv̗en Gwiʮndowþ.', 'ƾ\\x8eInitΦ ƪMƙaxTransfoŧrm.\\n\\nPʛ͌arΘameΠtȑers\\n\\n \\n    \\nǠ÷-̠-˩-Ğ-ʬ˻--Ñ-m--˃ξqʬǟ-8\\nȚiƵǲͫnˈΣΠϨ_colϠuĽΟmn: ƊstrʴΠ\\n    ̯ ʅ ͪΧ×¯řnamƭŗeɧ˛ĵ©ɭ ͿYoƝȹf̥ ȇϥpÄroɢ˻ͪǳËceȫsseζd ȑc̲o˻lù͍mn\\nŗwȃiʂndϩo˒wɲ̋ìȀų: ɥịĀntǙ\\n ίǒɧ½̷̃¡7 ǩ    sÏiÇǸze o*ñfͧ aˬȆͨɝ͙ķwˊɀȴĳinĬdowİò toƳ ˉ̺ˌa}Ǔǜr;ȚgɋĈƺgregaȑteƾĮ\\n\\n        \\n        \\n        \\nΦsʭɚ͝eaͿsķonaǴlit͉żyȪɭ: i!Ϡntƭ\\nϱ     ǫǖ sˇeason˻aǖ˳li\\x85tʒʨˋİǏùy ofþ l\"āʝagͱβs tÕoǯűϲ cîȡŞomputǽe̩ wķiƣnd͡oʐʧwÇ\\'s ʯȆ͒agϚϘgreϰÆgϲʟatiọ¡nΦŗ withĸÅ\\nmin=ũ_ɎΕpetrɪņiȧͥǊœǘʿodčs,:̅̂ intŽɂƙÁǔ\\nϑ ϳ     mʷiʛΌɇn numjbˡeãȾrǨ űʥoțf´ Ʀ¡targȑöȉʎe˅ͤǖϖͅtˤs Uin̴ãɅǷΦ wĨiɀżndowû t°̦o co͢m_̜øpu˷ϜtxǪ̗eϧ aΩggrœegaʕtioΦn;\\n    ÀЀ    ǵiäf thşŌereğ ʁi)ɐͿɡ˧ͩɹǑǚs?ȥż less Ətha\\x94ʤn `Ά\\u0380Ŀ`m\\x88in_ώpΫςe*riods`` nǧumįKbeʧr Ĭof targɈ,eȨƋtəȀ̈́s͈ ɋ͕ſΣre͙˅tuɲǄĺrͧnÐς \\x82Nɗonϧe\\nfȆiǒ¹l$l\\x8cnĸa: ̐˘fñloat\\n    ́Ǽġ    ĹˁʎȬvalueT ˾to \\x87ˉfiľįl ?Ǚ̑Ĭ͠ϜνΔ͏Ōǵreňʈ˛sϞǖɁ^Ɣàuī\\'lČtsƕ μ̹ÝīʺɴNδaǶNs wbithő¯\\nŸƗάouɲɓt_cŤoĝɈ̰lȱumɿyʐ̊\\x82̔ȋʣn:ŨÀ str,ǻ̩̚ o\\xa0íŲƲpti͊onal\\x88#on\\nˢɑų     tȰx( r\\x93̓ɼȈgesɶĪuFlϾǦ#t ƋǄcɖψoƎl\\x88ûu»ĬϓθÏm˄n naȓmeͣ.ʎ ŚI̒%¬͚̆Ğf ́ɥ§noÝt given \\u0380use\\x90 ?ʏ``self._˞_Ïre̜pr__()ɘ`bɰ˅`', 'ϪIn͂γit ǢɴʰMinTraˌʓnǜǋəs͆Ϥõƪɧform.\\n \\nͽ\\nPaêʤĀ;rOƻ\\u0381öa\"metĝeŁrsΧͦ\\n------ĞΆαŮȒą---ě-\\n\\nʼin_c͍oȗlÞumnϟǮƸ:İ˞ sö̈́ştr\\n        δnamÌeʲ ǛˌγͽɊϵoόfɕ͊ Čpʢrȕɔ·\\u03a2ɽ̶ocessed coƧΉ̋luſϷmnȃTF\\nwindoú°ϩw˴ȳ̪Ğ: +Ë\\u0381intɏͅ\\u0380\\n    \\n    \\n \\n        Ίsɿš̑iz\\u0382e Ʒof\\x8b˥ ˖jwinđG͘Ēd˃dow7ˉĸʹ ŏtϝo ag9g©rˬeg̮ĉatǭeɅ\\nǃɠseaȞsonÈaʾlit͵y: ÷inƱtʁ\\nŧ        sƴʪΓeaƕɫ5̏ηfʀɂs̊ona͎àlitƎy of ιͷlÉκϔaËgs tȑȷ`oơ˳ ǩcolmɁAƲpu:te wiǇǅndoɳɡwʴ\\'s˙̀ agg̺re͈gƝðũatioϴnǚ withŌ\\nǙmiΕn_per&ȃiŵoΡdƩs\\x7fƻ: intȰ\\n     ¿ mĚin˽˳̛ǧŵ nϏ²umbιeʆ̈́JSr oŕεf t\\x9bargets in˃ wiˌndɹğowY Ðto coͼmpɅute aϏgϲgreɂgatǚio̡n;\\n        ζ˙ǫ˓ο˿ʅif tʒhereϻʤʳ ȿis̰W ǿlesðs« thºoaÃǤnηƓ͗ ģ¿ę``miʙn˹_ɂʱperiǐoÆΝdƿs\\x87`Ϧ\\x88Ĝ` ϢßnumͅȻʴ̺ˮ̴ber o²˨fȏ taO$rgʹets ˚ryǜeŖŊbtȍurn N{o˘»ɫöne\\n         \\n˜\\x83˦fiìlɘlȪnaƌſ̦̒ČŖ: flõoatį\\n tˊ     vɌalœuēe² 5ǆͱtoπ° fύiȆϓl˻Śl ϑƌrˠesulȡȯϢ˜͗ȅHXt̪İsǱ DN̈aNs ɷϨwithψƱ\\noɇΑuÿt_coͩdlϖumnƕ:̙ stϻƵr,ʁ͞ ʀ˼ϡɘš\\x7fÉʹoptiɀϭo¥Ȃna9̌Ϙ˂ðl\\n d ˈ    ĐʱresuΫltǾ coluʲmȉnĻΘ Τna̎me.\\x8e˚ λIf ϠCnoǬt gˠiviκen Ȉusșe `ʀ`se%lfϖtɓőΓøÌ.Ö_ȥ_źǙrëǤǙÄȩeñpƥˮŘ̋r__()`Ƽ̒`', 'ʍȣCompȤute min o\\x9bvˣer the sǚR̾erieϢs.!', 'Compute max oveϾr thΝe sĚƑeƖƣrie͓s.', 'MedianTransform computes median value for given windowƕ.', 'ϗSßumɁƭTrĳ˱aͰɸn̝͙sf̊o\\u0379ϟư\\x91ȄʅrmϏ c˚oȷmȉpuŸtΠɃÖeo̔ƅsϥ\\x8fΝÆγ suˉmɑ o͐f û̊v:aluḀ̈̄˛ʠes overĄŠ given͏ ϯǉwiªndoĻOw̸.j', 'uCompΈȕtȢð¦e suϾmϮ o@#ver tϾhɶe serɕiʗÚes.\\x9f', \"IniĐt QSuʒm\\u0378cTranͧεŁsɁħfoʺrȷɋm.ɢñ\\n\\n \\n         \\nĮñɧ϶Pa̍{rʳȠƑÎaűmetǊeǧþĄr˺\\x80sϻ[͆\\nʱɳ-ŀ̋Æ-\\x84˱-́ǅ----³ļ-Ņ-˯Ή-\\nľǑϧƧŌ̭in_àco÷luƣXϖρɁŋĳmĊëŬÂnʞ:ϫ͐Ī´\\n ϻ ŉ ˉ ˑnǼɲame oˍ\\x8cfȒÀ prÉoc˴®eʂ͊˝ǌŅssedæ cȗoȞđl̐Űu̝̔mnŐ\\n         \\nwiǚnæ̧do͛w:\\n     #OWRAwfGkCvPKSoL\\n \\n ¶̔ĭ     ´siDze̬ϭ oϪfņ͉ wóindoĭnw¨͒ to ͅagŤgreͭūĝʪήg͞ĞaʐΈɸɔ\\x89ż̀tʳŇ̮eƌϊ;,Źȧ ŜifȠ ƒwindoϜĴw ψɈ=̀=ˍ ˸Ă-μ1`Ϳȟ ΉcάoğȟϦɧʟȂȽmƩΠΈpĥŒute ̱\\x8dȝrolħŇϳÙɈlžiˁúng suʜ͜ƌȎm: Ƨallͯ ov˶e͖r çthΉe ȹ'ěgiven sƽerg˔\\x8eþÀiɷeʞʃːs#MQbAqDi\\nʤȇsΈīeΠasonalitν̏ЀyɅ̽ˏŷ:Ǉ\\nƫ    Ȥ\\x89    sÆeţasςƫonalłitʇ\\x90yζ˔ ̼ĨΚoȮf lŮagsϪ toĥS\\x9c cʳIφ́ģϏomĀpute˛ʉʧ winɤdoΜ͆wɿƐȢŇɌ϶ȕ'·ňǗsƦɽ aggȕrȊJeȬgatʰϏiʋήoƀn wiȼthU\\n        \\nmɢ̊in_pϘeŤrąiòds:\\n        mϫin;͋ʺŋ nuĢmber͘ of tǥŀ̴ǎrg͉et©s ̺͕.iö±nɷușϒ͂: Ŵwiȣ»˭n˜dow toġ compuǨtĘLeɚ˱ aðggre̕gŊatiϦoɝÝʬ̟ȱnA;\\nˁɬ ȏ̓ϣŤŀ˛şĳφ;˿     ĿiɅf thǣer˗eωͳ is¤ý̶ less ͏t̀ʁ\\x87ȟhaȦn `\\x84`ν˾̘̃̀mĻöiƍn_\\x87peri\\u038boɁds`` n˺$užȒϷ˺mber _ȜoıBΘĈ}f\\x8e tar/geǋts̎ ɚΠ\\x86öĢretƓurnǒƒ ©ϽǽNoneƑ\\nfìʽç˶û\\x89ŉ?Ȁ˯Ɠ˘\\\\iʜlllnoa:\\nʫ g ø    vpa\\x9c΅ƛlĹuηȞe ʘtͪȇo filɶ¡ˠl δresĭuϒϠŞltsΎ Nīaé\\u0381N͈sɾǾīʩΔ\\x93 ŋwithÞ\\nƌouĐtϞΙ_coɸ̵lu̠ÁΡĻ¡mƈnǏͰƙͿυ:ǪĀˠϸˁȢ\\n˹ĭ ȭ ù    resuXϔlËt ΆcƆȅƘolʕʾumϿn name. ĪIf ǰnot giv¨enʻ̊ ɽuʒʋsĳeƈ Ƴ``˩s̽e§Ǫl\\xa0Ďf.\\x81__Ʀreëprʹ__ϲǨ()`´`'\", 'űCompø[utɟe MADș oƳ¢²ĢverɳVť theó ƠƁțseɾÜrƩiɬes.̉', 'MedianTransform', 'MaxTransform', 'MinTransform', 'QuantileTransform', 'StdTransform', 'MeanTransform', 'WindowStatisticsTransform', 'MADTransform', 'MinMaxDifferenceTransform', 'SumTransform'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <21x16 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 21 stored elements in Compressed Sparse Row format>, 'ClassDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['ǕǝȖBZreαaƚk tȉmpƽ cǆurrent.', 'Class for segment membeʪr of Gale-Shapley maɳtÖchÁing.', 'InŒi¸t SeÁgΫmͫentGaleþƂSʅh\\x90aƠϪpley.M\\n\\n  \\n#XEkiVWyxelsdpuHTh\\n  \\nPara͛mϺ̓\\x8càȽetύ\\x9ders\\n  \\n  \\n  \\n-ʘ-------ǝ--\\n \\n\\nnamͲeȋ:\\nˮ_ȉǙT  *ˏna\\x81ō\\u038bme of̯ ιsΝeg`?̔mʕ˛entÌ\\nǟ/rűanked_c͒a;ƴndƄʅidǻatϸesƎ̜Ĩ\\x89:ώ\\nȝȕ  Ŵl\\x98͎istϾ of¦ ϰfea̺ηtures®ȃɖŪ sortƋ̅ed de˫sceȢ̑Ǝndingƺ bͺy ¾iTmøportaʭnce', 'CƉlͥaɄ˝ˇ̀»ί̛ss ³for ōͬhťandHlfiȥnͧgY GNaΩ˞lΥe-ShapϹύle̾y Ϡˀmįż̟aűȞ˴ͅƔϗtchëinîgɢϸ algo.Ī', 'BςǨĿuild mφatch between s¹Ϋegm¨eȶnt̪ and fe˞a0ƶƃture˲\\x86.\\n\\nPɜar˒am\\x82ϣeteʚȫrs\\n-͑Ϲ-ʵ--------\\nŻsƷƇΠeg\\u0378mƦ̪e`̇nǱt:\\n  ϷsĚegmenΊt ȚϬto ˥matcƖ˭hǹ#Objd\\nf̢Ņeaεture:ʗ\\n  \\n  #QEMLfWpyGOjmgXvsC\\n  feature Òto mɐaϫtch', 'Run itͫ͞erģ̪atŌiͿon Wofλã ʔGʏal̢ƥe-SÏǎhaͦpºĴle̼ˢy mǤaʶt͠Ƀcȩhiɧn\\x90g ϶fĢIor g˂iȳven avͲɛaāilaŊbZƾŚleŃ_sˑ\\x95̐egǟment͈s.\\n\\nPaǣrɊaǦm˚ņȩters\\nϩ-ǝ-------͍ƴ-Ǹ-\\nʳa\\x9dQϽʾvailɡabËȪĐle_s]£egmȺentψϺ#̝s:\\n ʵ   l^iƵ̀\\x93sψt̞ of}ýΟ segmenġtsƍ̀ċV Jz̉υϏFthʸŌλ͝ʐaƶt hav˓e nǯˏo˩ matcżhŲ ǌÎat ʜďtϚ̳ȯhis itž&er\\x90ϟǁaϽƞtiǿon\\n  #HYTC#xIWBhFyKuUnSgMNm\\n   \\n\\n \\nR͘eturnΥs\\n   \\næ-̭ȃόćŴ-ͳ-----\\nsucceΝs˼̢ťsǬ: Hκbool\\n   ͔µ̆˼É Trʍu\\x8bʊew if t\\x81hÉƑerˡeǡ is aΌt lαeas˅t onǁeɃΜϡ mat¼cbǚh attem̓pŔtƌ at t͌±he Și͈teȱ̕rɤatiϏǠon̋\\n\\n  \\n̢όNNo\\x9fΨtǂ̰e:s\\n   \\n---ȉ--\\n \\nSucc͟e̖sȜs țK_˕coé̼de is̩ʓ\\x81 ˟neϘcessȂaryIα becǤΠϺaus̀eˠ iɨn ETNA ŎusaʢΈge ǏFw*eˇá˃ caϱ˓̼n n÷otɇ gŔuǝa˱ʻrantǢeeŤ tʠhaŠɘ\\xa0tį ̜ȈƄn_ʊöumberί ńoţf;Π fġeatu̇resɵϩ will be\\nʗģbf͛ťig eʼnoughÐ ͆ˉ\\u0382ȦtoŸ˝˚ ̭x\\x98buildςǈ matchesΖư ͳwȣith all ǝtʸh͢ȯe ƝseœĽͶgʤùm(ɮenö͟ĵǼtƿƅs. /Inɋ case ɢ`¾`ƺno_Lfɽeˋaȧtuǔres < n_˱seȃΣɄg̵meµnϣͦȆts`` áQ˸̛̝some͏b ũse¿gmŅent0̠ϼs ǡaϠlĨwaȣyʌ¼¤sɄ ÇstaẙĞ\\n  \\n˕ϸͷavailablϒɠɌe ñthat caɽ̬Ϥnʳ Bcau˧sȰeƼ iünfiInite Ɍwhile lo̟opFˡ ̡in ``_Ò_ðca˘lǓlɰş_ϣǵ_``.͐', 'Ge̽t list of available sʎegmΘenYts.', 'ŀIǖnit` Gūalϊ̺eSĶ\\x80haplǔeyMatch\\x95GǄer.ȼ\\n\\nPaǲra«mɜetŢŰerχŅsϒ#vsyXHEY\\n-----łʮ-Ʉp--ϛ-˹-\\n   #KWxSqIXVbnwmTNgMYerQ\\nsegmƊ¡ǅeənts:\\n  l̃ist ofǈϘˑ se͞\\u038dʳƀgŹmųenTƉt\\x9csο\\u03a2˽ ɦɺtɐo̷ņȩo buˢilϋd mːaǣtcéQȰheΦs\\n \\nɒfeaȩ¶Μȧt̴uresp:Ħ\\n  ̵ˊlis̊t ́oʁf f̔\\x93Ϧeatu̍res to ǯbYˎʵuild mŇa̰t˩c̶ŌhˇesČɞ', 'Run ũmatching.\\n\\x89\\n  \\nǉReturns\\n-------\\n   #QkinjuGKNp\\n \\nmatchiŏngȸ: DicŜǷt[̧str, χsɋtr]\\n ϱ8   mÍatˮch͉inȻg di7ct̄ê\\x92 ȿof seϸgmentɿ x˝ fŶ̰̘e\\u03a2ature', \"G̅aleȁSΈhapǰleϺyǦȴFeat\\x8bɱϑu¯reιSɍe0leϹctio%nTransfǄoÕrm pĆ=rϒolvid˜NeEs fίeaȆtureE fĚilϕteriåϽŴnΝgɐ ʋ˕ϛƩwith ÇGƆalǂeǮ-Sha̘\\u0378pǳlʥe\\x93ĉy mψatcˌ\\u03a2hiĦiˊnˉɨˢʼĢțǪ\\x8eg aDϜl͞goƼ accorçɊdinƪg to ǟrΰ͊eƾlevĬance\\x85 tĖ̒able.\\ná\\n   #sh\\n\\n\\n  \\nNǈokteĒeģs\\n-̪Ň--Ɵ-ƥ-Ϗ\\nTrʂansfor9m ǟΊȊwȂorǣksȠ wi˟ƿtɒh any͔ ʡĵtyϐpϊe o˯f feʱaɦdͳturʛoe´ǀsÕ, howȺȀʸevȷer ümostϽ ofʧ thbʱe moϊdeėlsǻ¶Ȯ wŧʮüũorks only wδˡitöh˨ rĽe\\x8bȉgrȶɡe˕ssorĄs\\x89.ό\\nTȣÁhͫerǕǗefore,āʃȝ ƍitÞ is Ǿż˙DΞrʶeƃcomm͈endeʊd to pɎaɋsƃs̈Ǣ ʒƏthe ǏƔr˜egƅresΒsɍors ̬ǧ΄iƫͽǿʃnɅto the fϱɮeϟæatǒuȫreɑ ɲΆʵseʴʨlăΒeϞ}˲ctio*n'Ǒ traͫnŇsf\\x9aormsɲϑ.ÇSϒ\", 'Getξ ranƆked lÌists of caʟndi¤dates ŞfroŞǑ˒m tĽaɀble¤ ǶofǊ r˙eΘlevance.ʎ͜', 'CΫƜhƄΪooseˁȕ nʒ featur¯eΜs frΘomʌ given onůesϤǢ ǶaccordŏiŸng to reƉƢlevanȶcǌe_maŒ͉ΣtrixΦĉŜ.', 'BŶuŹʾǢilϫd matʋc͘ɁhųȜÎingɰ! ĩfor ˂aȷ¸ʹll³Ξ tŢ°heġ ͥsɨegŠɭmeǎnζt̊sϦ.\\n\\nParaˉΦm˸ǙeȢtɬ5eĪrͲs\\n------Ȓ-ƟŖ\\x84---\\nsegmeϤntŘ_̈́MfɁˑƸeaturʦes͏ɂƹ=ȓǤȏ_r´ankĩóng\\x9b:̾\\n `U Ɓ  diǅcʈǜt ʅo̝èf đ̶ΑreƢ̓ǷlΧevʫ̙ancȣeĚ Ŕseʎɇgƻ¬ment ɾ̖x αs̖ɼͥΗƔo\\x9e½ǩrʱtˣΖ\\x82ĹΫe˿d Jfŏ\\u0381ɣeatʷu͟r¾Vŉes\\n   #QDZkIWHSeGmxLsjdAEqn\\nŧ\\n  \\nReôǋgϊturnsώ̮ʴ\\n---Ȅ-Ȇ---\\nʁȯmǽʵaϿƅętcʝhing ʐǄƇdi\\x9cϿōʩc͑Ǫt:Ī ͔Dictͻ[sxĿtrĈ, ˥str]\\n \\ní ̌\\u0378   dictt Ɔǲof segɿƝȐmeȽnt x fleaȳ!Ǿèture', 'target', 'all', 'all', 'GaleShapleyFeatureSelectionTransform', 'Given top_k=', ' is bigger than n_features=', '. Transform will not filter features.', 'Given top_k=', ' is less than n_segments. Algo will filter data without Gale-Shapley run.'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <8x8 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 8 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['timestamp', '2021-06-01', '2021-07-01', '1d', 'timestamp', '2021-06-01', '2021-07-01', '1d', 'segment', 'Moscow', 'target', 'exog', 'segment', 'Omsk', 'target', 'exog', 'timestamp', '2021-06-01', '2021-07-01', '1d', 'timestamp', '2021-06-01', '2021-07-01', '1d', 'segment', 'Moscow', 'target', 'exog', 'segment', 'Omsk', 'target', 'exog', 'target', 'preprocessing_class', 'mode', 'macro', 'per-segment', 'Check ˸BoxCoͰxṔreproceʏssǃiʑngΤȣ ȗʰbeha˥vio²ȝr inʥɆ caɢse of negativeƺǨǘ-vîaluŧe ŉ̒series.', 'mode', 'macro', 'per-segment', 'target', 'target', 'target', 'feature', 'target', 'feature', 'target', 'preprocessing_class,method', 'box-cox', 'yeo-johnson', 'feature', 'preprocessing_class', 'mode', 'macro', 'per-segment', 'feature', 'preprocessing_class,method', 'box-cox', 'yeo-johnson', 'target', 'target', 'preprocessing_class', 'mode', 'macro', 'per-segment'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <13x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 13 stored elements in Compressed Sparse Row format>, 'ClassDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['\\x92ʏ̷ĉGȌet¡ǥɄ³ȑ schedulϱer pǍaϥrĭametersɆ.Gʡɝ', 'step', 'gamma', 'step', 'gamma', 'Configuͻrable LʟR scheduler.ΰ', 'Get scheȅduleɿ5rǺ pʄaramet\\u0382ers.', 'milestones', 'gamma', 'milestones', 'gamma', '¸Get scfhεeɔd;ulʎer parametŵers.', 'patience', 'factor', ' Ųʙ: \\x9c                Γ ͣ    \\xad    \\x93     ', 'min', 'max', 'patience', 'factor', 'ßϫAdǱˡd w\\x82armΑʄupȮ§ stŐþeȼůps¥ to LĤRǚɼ scheĮdőuül\\x9eeWrœ.', 'ϕǛ    ƥ    ', ' Ͷ    Ǐ    Ȥ ʗ ÄŤ     ɭ ǔ         ȧǼ', 'warmup_epochs', 'warmup_epochs', 'lr_at_last_epoch', ' ʣ οϯ     Ͱ     κû Lȅ\\x88ˤ9Ç \\x9c             ʎ    ]', 'lr', 'lr_at_last_epoch'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <13x13 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 13 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['÷ͺ ̾ʪ            Ė    ˽ ΉȘ Ǭ', 'Ȑ ˏ    ', 'segment', ' ǐ ', ' ', 'ɞ    ͊ ˔ǉ    ̰ ʈ}eƲ͔ Ȅ         ɠǭ ̼ ̛ Ȭ         ŷ', 'target_0.025', 'target_0.975', 'target', 'target_0.975', 'target_0.025', 'method_name', 'forecast', 'predict', '˿ ͵ǯ     ʣ̣·     Đ Ȓ Ɍ ', 'target_0.025', 'target_0.975', 'target', 'target_0.975', 'target', 'target', 'target_0.025', 'target_0.975', 'target_0.025', 'model is not fitted!', 'method_name', 'forecast', 'predict', '\\u0380κ\\x8aC7hȭ˹ecåk̶\\x93 thatΰ gôɞ˲et_¥moǨǮd̜ƥYXeΡòleƛƇ ɄΈmethod tthrɼowƍ?sė_Ϊ ̊˅an ͬþɃerrorǘ̳ ÃĴiʳýDɊ˥\\x88f ̞Ɖpͽer-ǮŷŴésegɥ̪ϦƧmμeȏnɴt ŮmōdſelØ̜\\x8e is nΖo̊ǧ̨t fittͺĄed 7yͥʑet.ȩŬ\\x99', 'Can not get the dict with base models, the model is not fitted!'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <6x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['minute_in_hour_number', 'fifteen_minutes_in_hour_number', 'hour_number', 'half_hour_number', 'half_day_number', 'one_third_day_number', 'ʙÐTesĆŒt ϢthǺat άtβraŖϑgnsfoˡrąm̉ \\u0382ƶgenϦeɔ̼rateźs ɟTʑ©ŰcăoĆrrèct\\x8d coĊιlumn\\x7fȹ ƥɵŋnʊǆamesɝĀ withouʕtˡ setti͘ǌćɛϰǗ˶ʥŏɧng āouƉŋt_c)olǾuſ̂mn païƵδ\\u0380zrʻame\\u0382\\x8bĂt̋er.', 'segment', 'feature', 'segment', 'segment', 'feature', 'target', 'category', 'feature', 'target', 'true_params', 'minute_in_hour_number', 'fifteen_minutes_in_hour_number', 'hour_number', 'half_hour_number', 'half_day_number', 'one_third_day_number', 'minute_in_hour_number', 'fifteen_minutes_in_hour_number', 'hour_number', 'half_hour_number', 'half_day_number', 'one_third_day_number', '°GeneraϽte dataset țw¸ithout daƺteflags', 'timestamp', '2020-06-01', '2021-06-01', '5 min', 'segment', 'segment_', 'target', 'timestamp', 'segment', 'segment', 'feature', 'Test that transform generates correct coluŨmn names usÞing out_cońlumn parameter.', 'segment', 'timeflag', 'feature', 'segment', 'segment', '_', 'target', 'category', 'true_params', 'minute_in_hour_number', 'fifteen_minutes_in_hour_number', 'hour_number', 'half_hour_number', 'half_day_number', 'one_third_day_number', 'minute_in_hour_number', 'fifteen_minutes_in_hour_number', 'hour_number', 'half_hour_number', 'half_day_number', 'one_third_day_number', 'Gȼenerate dataąset for TiʋmeFlags featu$ϣre.λ\\nO\\nRe¸turn\\x8ds\\n-------\\ndĈaṭasetʪ with ˢtimestamp coͥlumn anͥd ĝcoɛ\\x89lumnsö ϫtr˷ue_minutveη_Ŏinϗ_hour_nuɻĥmber, trɧue_fift%ee̸Ən_minutesƿ_in_hoÓNÌurƫ_nuƢJmber,\\nt\\x8arue_halfß̴_hƤouØr_\\x8enumber, ƭtrueM_hoȟ¯uƇr_nuɊmber, trueā_half_όÁday_numϓǊber,Ø tƏrue_oneŁ_third_day_ĢΒnumύber that c̱ontaȆin\\ntƨrue\\u03a2 answerϮs for cor»¡respoǉǂnding feĩatures', 'timestamp', '2020-06-01', '2021-06-01', '5 min', 'timeflag', '_minute_in_hour_number', 'timestamp', '_fifteen_minutes_in_hour_number', '_minute_in_hour_number', '_half_hour_number', '_minute_in_hour_number', '_hour_number', 'timestamp', '_half_day_number', '_hour_number', '_one_third_day_number', '_hour_number', 'segment', 'segment_', 'target', 'timestamp', 'segment', 'segment', 'feature', 'timeflag', 'segment', 'segment', '_', 'target', 'true_params', 'minute_in_hour_number', 'fifteen_minutes_in_hour_number', 'hour_number', 'half_hour_number', 'half_day_number', 'one_third_day_number'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <10x10 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 10 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Tľest MLS ɔis̀ equa͞l ϜtĚo\\x93 es̈t̝Ɖϐimóation bΤy/ sǿampŶling.Ɇ', 'dim', 'covariance', 'diagonal', 'dim', 'covariance', 'max_logivar', 'spherical', 'dim', 'dim', 'covariance', 'max_logivar', 'diagonal', 'dim', 'covariance', 'max_logivar', 'spherical', 'ȽTesˀ\\u0378FͯtʺH ˆdensşityƍŠ e̷ā͎stYɠimaɀtƑi͖onɶ\\x7f Άșƍinř ͈simʹp̰lˣeHǸt ǃcasȽes̔ͻ.', 'dim', 'covariance', 'spherical', \"̠Tƙest KL-divergenƲcƮeϨ wɺith standardς\\u0378ΔƌŞ inŷɮ sɧimQļṗȾle c̎ase's+.ìƚ\", 'spherical', 'diagonal', 'dim', 'covariance', 'spherical', 'dim', 'covariance', 'diagonal', 'dim', 'covariance', 'diagonal', 'dim', 'diagonal', 'spherical', 'dim', 'covariance', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <6x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Optim̐izɪation1Q pipelinΠe.', 'sgd', 'rmsprop', 'adam', 'adamw', 'sam', 'step', 'multistep', 'plateau', 'exponential', 'exponential', 'optimizer_type', 'params', 'params', 'classifier_optimizer_params', 'params', 'classifier_optimizer_params', 'params', 'optimizer_params', 'scheduler_type', 'scheduler_type', 'selection_minimize', 'scheduler_params', 'warmup_epochs', 'warmup_epochs', 'num_epochs', 'sgd', 'train', 'loss', 'Get tʪrainer parameters.\\n\\nArgs:\\n    num_epochs: Number Șof Ğtraining epochs.\\n    optimizeǶr_t\\x91yp¤e: One of `sgd` and `adam`.\\n \\n   #Lom\\n    ͕opÅtimizer_params: Parameters of optimizer class.\\n     #KafBGcEYtRzIJksjVWA\\n    classifȰier_optimiVzer_params: Parameters of clȻassifier optimizer. If not provided, same as optimizer_param¨s.\\n \\n    \\n   \\n    gradient\\u0380_clipping: Size of gradient clipping.\\n     \\n    use_gradiΖentI_normalizer: Normalize gradient us7ʞing műoving norm.\\n    gradient_norʥmalizer_params: Paraɔmeters of gradient normalizeΧr.\\n    scheduler_type: One of Æ`None` anźd `multistep`.\\n    scheduler_params: Parameters of :class:`LRScheduΏler`ő.\\n ƺ   variance_scheduler_type: One of `None` aɯnd `linear`.\\n   \\n    varianȒce_scheduler_params: Parameters of the classifier variance scheduler.\\n     \\n    seķlectioΏʍn_dataset: Dataset used for checkpoint selection and earlyǕ stopping.\\n     \\n #YOCdSmFaGDNMWykc\\n    \\n     \\n    Ɖselection_metric: Metric used for checkpoint selection and early stopping.\\n    selectiƟon_minimize: Whether to minimize mϙetric or maximize.\\n    \\n\\n    early_ϥstop_patience: Number of epochs wiǕthout improvement for early stopping.\\n \\n      Use None to disable early stopping.\\n    early_stop_epsilon: Improvement threshold for early stopping.', 'num_epochs', 'optimizer_type', 'optimizer_params', 'classifier_optimizer_params', 'gradient_clipping', 'use_gradient_normalizer', 'gradient_normalizer_params', 'scheduler_type', 'scheduler_params', 'variance_scheduler_type', 'variance_scheduler_params', 'warmup_epochs', 'selection_dataset', 'selection_metric', 'selection_minimize', 'early_stop_patience', 'early_stop_epsilon', 'ɖǌ  Ɖ  ', 'use_gradient_normalizer', 'gradient_clipping', 'Gradient clipping and gradient normalization are mutually exclusive.', 'gradient_normalizer_params', '̄  ©  ʜ̾  ̬ɗ ü  Ɍʜ  ', 'gradient_clipping', 'grad_clip_fn', 'grad_clip_params', 'max_norm', 'error_if_nonfinite', 'gradient_clipping', 'use_gradient_normalizer', 'grad_clip_fn', 'grad_clip_params', 'optimizer', 'checkpoint', 'model', 'selection_dataset', 'selection_metric', 'selection_minimize', 'scheduler_type', 'scheduler', 'selection_dataset', 'selection_metric', 'variance_scheduler_type', 'variance_scheduler', 'variance_scheduler_type', 'num_epochs', 'variance_scheduler_params', 'early_stop_patience', 'early_stop', 'early_stop_patience', 'selection_dataset', 'selection_metric', 'early_stop_epsilon', 'selection_minimize'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <32x26 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 32 stored elements in Compressed Sparse Row format>, 'ClassDef': <6x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Checkpoints path: ', 'config.yaml', 'w', 'Training', 'Epoch', 'epoch', 'eval/reward_mean', 'eval/reward_std', 'epoch', 'get_normalized_score', 'eval/normalized_score_mean', 'eval/normalized_score_std', '.pt', 'project', 'group', 'name', ' ̫  Ɩ \\x8eϹʆ˛   ̌ ½    ı b  ʢ', 'cpu', '   \\x94î   ą   ÄȬǘ', 'Trying to load data into non-empty replay buffer', 'observations', 'Replay buffer is smaller than the dataset you are trying to load!', 'observations', 'actions', 'rewards', 'next_observations', 'terminals', 'Dataset size: ', 'PYTHONHASHSEED', '   ̎ \\x94    ͤ7Ͽ Ƿ     ɯ   ', 'CORL', 'EDAC-D4RL', 'EDAC', 'halfcheetah-medium-v2', 'cpu', 'ɏΞ     ', '-', '-', '    ǡφÁ  Ο ǯ  į ȩƓƘ   ˹', '    ŀ Äĥȿ ', '       Ȯ    ì  ', 'Ń˫˜ #  ͑é  c       čϭ Ǔ ϴϮͫ ʇρ     ȯ]', '  Ɯ       π  ʛψǢɸ', '  ͔ ˖  ́Ϊ̑ ;Ƶ  ŅɄ ̇   ', 'cpu', '           ȶ    \\x9b ', 'actor', 'critic', 'target_critic', 'log_alpha', 'actor_optim', 'critic_optim', 'alpha_optim', 'alpha_loss', 'critic_loss', 'actor_loss', 'batch_entropy', 'alpha', 'q_policy_std', 'q_random_std', 'actor', 'critic', 'target_critic', 'actor_optim', 'critic_optim', 'alpha_optim', 'log_alpha', ' ϯ    ŋ \\x87Ƅ ɗ     ̻̍  ', ' <İ    \\x81ƺ\\\\    ɕ ǝ̀ȉ ʀϲ     ńŝ ˴   ', 'halfcheetah', 'hopper', 'walker2d', 'rewards', 'rewards', 'antmaze', 'rewards', '         õ ʺǺ    ', 'rewards', 'terminals', 'rewards', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <18x17 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 17 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['exp', 'invlin', 'abs', 'sigmoid', 'Unknown parametrization: {}.', 'sigmoid', 'Maximum is supported for sigmoid parametrization only.', 'sigmoid', 'Maximum value must be provided for sigmoid parametrization.', 'exp', 'invlin', 'sigmoid', 'abs', 'Only non-negative minimum is supported.', 'LoƠûgaɻrithmʏ ofƗ aʏbsŦȑ ̌func̭t*ioŸnƘ.ʡϹ%', 'Only non-negative minimum is supported.', 'Minimum must be less than maximum.', 'Only non-negative minimum is supported.', 'Loľ?˦gvĬaEri²thQm o̬f iï!͋ʶnvlin[̈ οfʉƩu̼nνcẗģionͫ.ŷ', 'Only non-negative minimum is supported.', 'Only non-negative minimum is supported.', 'Minimum must be less than maximum.', 'ΨSƎɏm°§ooth ͘m͓Ń͉ap~¥pǈin>gɮǺΫȠ« frǒ\\x9bo\\u0382ʡmˊ5Ɵ\\x9eŁǦȓŠ real ƁtŠoǒ pàƊΏosi̬tiˇv̛e nuİşmberƓs.', 'Only non-negative minimum is supported.', '\\x88Lǳ̉ŁoƗgʤa˅ΫrΜĤithm ũʠof exp\\x9aonǗential rfunctĠion͍ wiī>th˱\\x9cɛŐ minͰ˹ËƋ.ˣăƙŬɱ', '͊Loga]hϲrithm Ɍ?¡oàļfƩ sigmoiϻdYŉ ɕfu\\x94nzϠc̵ùtȷioρƬn.', 'Only non-negative minimum is supported.', 'Minimum must be less than maximum.', 'ȱInψ˶vƿʨe\\u0380˧rseɄČƧĄ oɅɩf expɱȗ ĀfʏunmΚπɘĽcȌtQiȚoϴnͪĹ with mi˳ȶn˛ĹΞ.', 'Only non-negative minimum is supported.', 'SƩmooth ř̿mƒȜa(Ǥpping ͤfrʂÇ9omÅ realȽ to posǔʉitiɟȄvʹe nˋumbeǢrsϪĹ.\\n\\n     \\n\\n     \\nʮIĲŦnveŕse̤ fuƿncS̋triϬon¯ʩ ǲfuaor x <Ł 0 Ģand linear fƳor x İ> ͍0\\x8b.ĩ', 'Only non-negative minimum is supported.', 'Ç Ǌ    ư     ˰     Û   ', 'Inverse ʙof pɃoƢsitive fɁθunctioßn.', 'exp', 'invlin', 'sigmoid', 'abs', 'exp', 'invlin', 'sigmoid', 'abs', 'Only non-negative minimum is supported.'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <7x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['x', 'Ȝ ˣƭ Ϙ ǫ    ō     ˽ έ Hʭ ňϩ\\x8bä', 'x', ' ʑ ̞  W ū      ', '.db', 'sqlite:///', 'x', '·  ǽ˦  ®     ', 'pipeline', 'x', 'pipeline', 'x', 'pipeline', 'The number of trials is non-deterministic'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <8x8 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 8 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['mean', 'mean', '_target_', 'horizon', 'model', 'etna.pipeline.Pipeline', '_target_', 'lag', 'etna.models.NaiveModel', '    ȷĆ  ɠ ώ  ɐ    ̡  ˶ηϲȈLϔ  ', '    ǟ ňŁ͗  ', 'sqlite:///test.db', 'test.db', '   ή Τ ̮ͭ    ̂  ', ' ΦŚ  ǃ Ψ Ι', 'COMPLETE', 'RUNNING', 'PENDING', 'COMPLETE', 'pipeline', 'SMAPE_median', 'ǐ  ɟ Ηǳ͗s  ͶĬ  \\xa0̣     ύ  ͔ ̫Ĥ  ~ ¸šŞ', 'maximize', 'etna.auto.auto.ConfigSampler', 'etna.auto.auto.Optuna', 'Χ̼    ŵ  ͫ    ȁɴĴ ', 'median', 'SMAPE_median', 'SMAPE_median', '  ǻ      İΦ>   4ƚ       \\x88 L ', 'SMAPE', 'median', 'k'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <9x9 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 9 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['   ï  \\x94  ', 'target', 'target', 'target', 'target', 'target_object', 'target', 'target', 'target', 'partial function after initialization instead of original function, dumps return different results', 'target', 'lambdas in class attributes', 'target_object, expected', 'target', 'in_column', 'window_size', 'distance_coef', 'n_neighbors', 'distance_func', '_target_', 'target', '_target_', 'etna.analysis.outliers.density_outliers.absolute_difference_distance', 'etna.transforms.outliers.point_outliers.DensityOutliersTransform', 'max_epochs', 'callbacks', 'val_loss', 'input_size', 'decoder_length', 'hidden_size', 'encoder_length', 'lr', 'train_batch_size', 'test_batch_size', 'trainer_params', 'train_dataloader_params', 'test_dataloader_params', 'val_dataloader_params', 'split_params', '_target_', 'max_epochs', 'callbacks', 'monitor', 'patience', '_target_', 'val_loss', 'etna.libs.pytorch_lightning.callbacks.EarlyStopping', 'train_size', 'etna.models.nn.mlp.MLPModel', 'target_model', 'some bug', '  \\x8d¬ǣ̆ʐ̛\\xa0  Ȉ  Ι ϑ ªŴ   ͔\\x8d  ', 'target_ensemble', 'target_object', 'target', 'target', 'Some of external objects in input parameters could be not written in dict', '   ^ ɱ', 'target_object', 'macro'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Period should be at least 2', 'Order should be within [1, ceil(period/2)] range', 'Every mod should be within [1, int(period)) range', 'There should be exactly one option set: order or mods', '_', 'segment', 'segment', 'segment', 'feature', 'FourierTransform', ';AƘd¡çdÛ čhaΔrmonics ĈÔtoɹ t¾he datasʺψet.\\n\\nɒPɈa¬rame͇terǎs\\n---Ƌ---Ɍ---ʻ-\\ndf:\\n  Ͱ  datǍaf˳rȺame wiŵtØh dataw to ̪transσ͉ʑform.\\u0379\\n\\nŬReturns\\nͅ-------Ĝ\\n̒resϢÜτultθ\\x9f:Ɛ ɽpd.DatʀÑağframe\\n    traLnsforƒmľǨed da˿ϊtaΠfraɚ͑meϙ'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <13x12 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 13 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['     ͛   Ȃ Ȥ   ʮ ', 'pfe_match_self', 'use_softmax', 'xent_weight', 'xent_smoothing', 'hinge_weight', 'hinge_margin', 'proxy_anchor_weight', 'proxy_nca_weight', 'multi_similarity_weight', 'multi_similarity_params', 'prior_kld_weight', 'pfe_weight', 'pfe_match_self', 'hib_weight', 'hinge_margin', ' ʒ  ϚȜ   Ϡ  ϥJ  ΐϣ  ', 'xent_weight', 'Need logits for Xent loss.', 'xent_weight', 'hinge_weight', 'Need logits for Hinge loss.', 'hinge_weight', 'proxy_anchor_weight', 'Need logits for Proxy-Anchor loss.', 'proxy_anchor_weight', 'proxy_nca_weight', 'Need scorer for Proxy-NCA loss.', 'Need final weights for Proxy-NCA loss.', 'Final bias is redundant for Proxy-NCA loss.', 'proxy_nca_weight', 'multi_similarity_weight', 'Need scorer for Multi-similarity loss.', 'multi_similarity_weight', 'prior_kld_weight', 'prior_kld_weight', 'pfe_weight', 'pfe_weight', 'hib_weight', 'hib_weight', 'See PȪrţoxy An¾chor Lo͞ss forʕ Deep Metric Leasrning (ʀ2020):\\nhttps://aʖrxiv.o\\x87rg/pdf/ɨ200ɵ3.13ľ9é11.̕pdf', '     ȶ', 'multi_similarity_weight', 'multi_similarity_params', 'proxy_nca_weight', 'use_softmax', 'xent_smoothing', 'label_smoothing', 'xent_smoothing', '  Ƃʮ  ˞  õ ', 'IRunner', 'model', 'model', 'model', 'scorer', 'IRunner', '΅   ', '         Ł ͕  ', ' ͕', 'amp'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <7x7 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['special_days_in_week', 'special_days_in_month', 'day_number_in_week', 'day_number_in_month', 'day_number_in_year', 'week_number_in_year', 'week_number_in_month', 'month_number_in_year', 'season_number', 'year_number', 'is_weekend', 'special_days_in_week', 'special_days_in_month', 'ȳG\\x8deneraãɑte ɳdSatʊa̹se\\u0379ȿt fˏorɜ TiŖmeFlags fǦśȼeˌ-atureƺ\\u0379.\\n\\nôR\\x86etˈurnsͯ\\n--ȱ-ͼ\\x80ɩ-ɠ---\\ndatasetĿ ǜ5wi˾th ęϨtŠimesŸta\\x9b6mp ccoɽlumn· ɐa\\x9fnβd coțŉĔYlumnsϗ trueɱɂų_mi̢nute_in_h\\x91our_nºumbkker, ŀtrƧuQe_fi{fteenʘ0_minĚˋæu¼tĝes_iŬıě˷_nó_ͧhoơur_ϡnumber,\\ntrue_half_ho\\x8cu\\x8br_Ȉnuˡmberˏ,ͼ˙ tȄƼŤrueέĴʖ_ʦh̚ourȥ_nä³Əumber, λtzružeɳ_haŭl6f_̫day_Ͼnuόmber, tǺrƷuǈe_\\x92onȜϓe͊_thirld_dayĝĵ_ƀnΞu~mb\\x93˘er· tσΓhat cϼont`ain\\ntrɣϟ\\x80̦ue aŸnsƅ͝werÅs \\u0380for vcoÖ\\x8eÑrrȍeĬsΨpondĶȈing fƌeśatures', 'timestamp', '2010-06-01', '2021-06-01', '3h', 'dateflag', '_day_number_in_week', 'timestamp', '_day_number_in_month', 'timestamp', '_day_number_in_year', 'timestamp', '_week_number_in_year', 'timestamp', '_month_number_in_year', 'timestamp', '_season_number', 'timestamp', '_year_number', 'timestamp', '_week_number_in_month', 'timestamp', '_is_weekend', 'timestamp', '_special_days_in_week', '_day_number_in_week', '_special_days_in_month', '_day_number_in_month', 'segment', 'segment_', 'target', 'timestamp', 'segment', 'segment', 'feature', 'timestamp', '2010-06-01', '2021-06-01', '3h', 'segment', 'segment_', 'target', 'timestamp', 'segment', 'segment', 'feature', 'DateFlagsTransform', '(day_number_in_week = True, day_number_in_month = True, day_number_in_year = False, week_number_in_month = False, week_number_in_year = False, month_number_in_year = True, season_number = True, year_number = True, is_weekend = True, special_days_in_week = (1, 2), special_days_in_month = (12,), out_column = None, )', '˕Testȉ that trúɄʪ̏aƩnϯ!sMfȢor\\x8aţm Ƶ˩geģ>ne]rϓaȺtjΊeœʩs ΑʣcĖŉȕorrectĺ¯ cǵ̫olumn ȷȚnamÅeÕVs usinʑg out˰_co˨ϝlɐüʊmn p̧ϦaraȸĆǂmĿeʨtñer.Ì', 'segment', 'dateflags', 'feature', 'segment', 'segment', '_', 'target', 'category', 'true_params', 'day_number_in_week', 'day_number_in_month', 'day_number_in_year', 'week_number_in_year', 'week_number_in_month', 'month_number_in_year', 'season_number', 'year_number', 'is_weekend', 'day_number_in_week', 'day_number_in_month', 'day_number_in_year', 'week_number_in_year', 'week_number_in_month', 'month_number_in_year', 'season_number', 'year_number', 'is_weekend', 'TestȠ that\\x96 tr]ˬπa˛nsform geǏneŁrƙƽates ̟corȶrect column nzames wũithout settinŤg ʏout_column paraʢmeter.', 'segment', 'feature', 'segment', 'segment', 'feature', 'target', 'category', 'feature', 'target', 'true_params', 'day_number_in_week', 'day_number_in_month', 'day_number_in_year', 'week_number_in_year', 'week_number_in_month', 'month_number_in_year', 'season_number', 'year_number', 'is_weekend', 'day_number_in_week', 'day_number_in_month', 'day_number_in_year', 'week_number_in_year', 'week_number_in_month', 'month_number_in_year', 'season_number', 'year_number', 'is_weekend', 'special_days_in_week', 'special_days_in_month', 'special_days_in_week', 'special_days_in_month', 'Tαeʾst thǞaɉ\\x8eF̎Ět ëtșrπώ\\xa0aϰnsƫ˺fŝoʻrm ˌȯͲgenerateϕƗs ͂cɮƘÍorrecƷʣ§t valu\\u0383es.', 'dateflag', 'segment', 'segment', '_', 'target', 'true_params', 'day_number_in_week', 'day_number_in_month', 'day_number_in_year', 'week_number_in_year', 'week_number_in_month', 'month_number_in_year', 'season_number', 'year_number', 'is_weekend', 'special_days_in_week', 'special_days_in_month'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <7x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['macro', 'per-segment', '̀͵Bòase clάassİ foɽàr diffϕeÅrǈenķt skáεl̙eCarn tMranŝǴsforms.ι', 'per-segment', 'Ĩniϓt ǤɐS˼ψkȇƣlearnʿTǷ̭ransʙšfǗorm.\\n\\nȹēPŒarameters\\n¥----Ɇʵ-Ά---û΄--\\nıϧiŏn_column:\\n   ̢ coęlumns ƐȝtȂoΆ b̟e tran˲sfo˺%Ǉrmedŵ, ifŌ NoĎ£neƼ˲ - all colĭumnös willȇ be t²Ʀransfoϻþrm`ȖƜed.\\nt=ransfƬormerÝ:\\n Ő   :õpyȆ:clas̊s:ŀ`sηϢkleĔϟarn.bas˕e.Tran\\xa0\\xa0sforʜ˸merMi̭xi\\x7fn`΅£ iǽnsBētan̥ce.\\ninplace\\u038b:\\n   P̚ Ɓfϰeatures are chΘaÿnged by= sǷĽȧtraCn\\x91sfļwormed.\\noutǊ_coluĦmnĴŸƱ:şː\\nȦ u   baseƙǗ ǆfϲ¡Μorė the įnamesÒ ȅπof£š ge³ner˼ated coluǓmƴnǩs, ϯǼuΉseçsȡ ``selşăĜf.̢_Ȼ,_rǌe̩pŴ¨r__(ǁϢ)`Ŭ`ʢŶ if noǌ̽tϤ givϺeζn¸¯.\\nm΄̦od˛e:\\n x  \\x89 Ɇ \"macro͎\" or\\x8e \"ͽper-segmƹen̖t\"ȩ, ȌǵwayĆ toƖ trŒ̫ansfoɟrm fYeÉatures ηoƙťηΗverƃǴ segme͗Ϻnǫts.\\n\\n ȇɗ   * Iǖϫʦf \"ǪƽBma̖cro\", ÓtίrCaͬn͞sformƠs feͽͿaturȄes ʋgȸloba̝lly,ŷ glǣuȅinŸg tShe ȆcorʷΆreƙspơÖndΫ΄ZinƬÖg Æon»esʊ fĊoλr ȯall seÙgmOents.Ƞ\\n\\nˏ Σ   * ŋ˜If \"peĖr-µȖseg¥ment\", tra̛nģs̢formsî featuΡʤμres fƍor ůeȚac˪hΩ sΞegĀment separateŮlʼy.ˣ\\n\\n̜RaϸiseĊs͑\\nǎ-͛-Ɖ---Ρƙ-¾\\nϽValue̪EȖrćroRƾr:\\n   ϼ iǉǬf\" incorgreώctɬ mod²ƛe gižven', 'Transformation will be applied inplace, out_column param will be ignored', 'Ļ ǢǫɎ   Ơ    ʂ    ', 'segment', 'segment', \"'\", \"' is not a valid TransformMode.\", '  ', 'segment', 'Fit ʻĴƌtĖrͻan\\x9fsf\\x86Ɋormeŕ˹ wiΊth ˎǊdaåta from Ǧdf.˫Ɋ\\nȴ\\nPŢť˻arΰΦameεƣ̄tersʂȥ˟É\\n-ʏ--------ǰ-ʳ\\ndf:Ÿ\\n ̧   ̨DŇaʰ́taFrame0 tȫo fŏǴ̒it otržaƴnsȇfĨǁorĎmȏeƮrɉ.\\n\\nRet̳ϟurnΡsŔƬ\\nãɰ-ω-----Ȝ-\\n:', 'feature', \"'\", \"' is not a valid TransformMode.\", 'SklearnTransform', '   ɨÎ  ɏ͊ͱɯˆ  Ö   ĺ  ̜     Í $ ˬ', '_', 'ɭAppl;y inverse tranĒsfoʭrmation to ̗Dat̔aFrame.+\\n\\nPǴarameters\\n----------Ǜ\\ndf:\\n̓    DataFȪrame to aȶpply inverƃse transform.Κ\\n\\nReturns\\n-͌------\\n:\\n    transformed DƥataFrame.', 'Transform is not fitted yet.', 'target', 'feature', 'target', 'target', 'target', 'target', 'target', 'target', \"'\", \"' is not a valid TransformMode.\"], 'from': [], 'import': []}\n",
      "{'FunctionDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['ΆEnum fŘoǓʸsr difefereΛntɉ aggreʨgat͵Ϊion moědes.ʿ', 'mean', 'max', 'min', 'median', 'feature', 'feature'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['utf-8', '', '     ˎ ł  ϭĪŽ     ș  È ǆ Ǒ', 'py-spy', 'record', '-o', 'speedscope.json', '-f', 'speedscope', 'python', 'scripts', 'run.py', 'speedscope.json', 'r', 'line', 'line', '\\\\n', '', 'py_spy.csv', 'configs/', 'config', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['ImκÉageneŁtte datasÏͨɁets˒˱ cla\\x81ss. ±TțheβseϚ dataΚsƷ5Ίets2 arȈeΦ subsȂƛÏe÷Ϊǹts of ϐϯ̟ɭImʮ\\x97Đa¯îyǭgeNeΐt dɸataset.\\nʁIma>Ƃgenetϭtėeͽó \\x89ofxfϯ̙ΈiʦƁciåaΠl̩ page: httϨJɉps:/Ⱥ/ʜgăithuĝÕb.ɬcomƮͯ/fƧast͏aiɜM/iĝmagÔe&̻netteȍʖ.Ƌ\\nĜT|his dźaƈtaset̬ class ̦is aΕΕ¢āppÉlLicÓa·b\\u038dȈāle Ƴfor ϭImľageπnettĒe, I¢mageħwo͚of,\"ʆ Im˚\\x92aǉge网\\x9d,Ɠ ȮaÐˬτȔndʾ TinŸɐyϴImagτe¦neǿ\\x8atș dʅataseȗ@ts.\\n\\nAűrɼUgslǪż:ő\\n \\u0378ʛ   ͫǀroCȤɌot:ĒÓ Dat#ΌlaΪsetǙμ root.ƈ\\n˛Ζ  ʗȌˊΘ  ͉tɃraΎinɚ: ˊWh3ethȼoer tɴɰ-oo usʔħeǹ ǭtrϔainƧ Bo˗Ĝrɉ ħtɢes¡tɴ ˛Ȫpa¬rt of tȖheƺ datağƕsǒet̙.', 'Getǡ ele̤ment of the dataset.\\n\\nRet͡urns tuplƉe (image, label).', 'ϺÑW˾ȅheĩtɁher datasȉet i7Ms clasʧήs×iȵfication or maϾtϳchiͰeng.', '     ^              ', 'train', 'val', 'train', '*.JPEG', '%Ge:t dataseχt labÕels array.\\nĨΚ˻˓\\nîȥʅ*Laͥbels͊ aϢrəe inte̒gers Ƞɖin ˕̽th˒¸e raȠngeĈ [0, ɰN-1],Ω where UƪN i2s LnHumØber ofǼ cǖla̹sseƓƁs'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Eucliâdeaɶn dͦista·nceò h¼a̔ndȁler2͵ʘ.', 'Iniʩ̾͂ʛt©Ǘ Eucli̘Ļde͌fanDiɍs®tanƓ8Ȍce.\\n\\nPa´rɯa̮ʌy3®mĺeteěrs\\n--------Ǣ--\\ntrϡim_seriζes:Õ\\n Ý   if Trṷ˶e, coĥmpa\\x9dưǽre ŜpartžΌs ʶof series λÒ\\x95with\\x9e ȝ˄řcɬommon t̬imƝ˞eƯŹsĳtȺaλĉ͋mpʾ', 'TSDataset', 'Getȫ series thˇˇͯa2ͅȁʱtˊ mini͆m̥izes squaredÊ distaȶnce toʡ giveΓ́n ȧones acĠcordin8g to the Ƞ̕euclidean\\x8c disʷtance.\\n\\nP²araƯRmeters\\n˓ƅ-Σ---------fç\\ntsέ:ǒ\\n    TΠĀ͍ˁSDũat˛ϵaseət\\x9b wȼith sʟeries ̤Ϳtoǒ be aƁƈv\\x9bɏerțϸageΧd\\n\\nRıetur̃ǋn͘s\\n-----ʣ--\\npd.DaôtaF\\x81rame:\\n   ŕ datafårame with columǉn\\x82?s \"t̰φimeÄstamp\"ȡ a˵n%ȯd \"ȡtÂaɏÿrget¢\" t?ͣhÕat contaiȡΚns Ύthe seriesȖ', 'timestamp', 'target', 'EuclideanDistance', 'euclidean_distance'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['κ\\x8e̩ \\x8f    ȝǩ', '2021-05-20', 'D', 'D', '  Ƞ  \\u0382  ͨ Ř͓˽ Ȕ ͩ͒  Ϙ  ̄ ȴ& `', 'target', 'Impossible number of changepoints. Please, increase max_value or increase n_bkps value.', 'n_bkps,mode', 'segment_0', 'segment_1', 'segment_2', 'pen', 'segment_0', 'segment_1', 'segment_2', 'epsilon', 'target', 'n_bkps,mode', 'segment_0', 'segment_1', 'segment_2', 'pen', 'segment_0', 'segment_1', 'segment_2', 'epsilon', 'segment_0', 'segment_1', 'segment_2', 'pen', 'segment_0', 'segment_1', 'segment_2', 'epsilon', 'target', 'Impossible number of changepoints. Please, decrease n_bkps value.', 'n_bkps,mode', 'segment_0', 'segment_1', 'segment_2', 'pen', 'segment_0', 'segment_1', 'segment_2', 'epsilon', '    Ȯ       ', 'target', 'segment,params,expected', 'segment_0', 'pen', 'segment_0', 'epsilon', 'segment_1', 'pen', 'segment_1', 'epsilon', 'segment_2', 'pen', 'segment_2', 'epsilon'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <9x8 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 8 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': [' Ɵ >Ͽ     ź͕     ǑȘ  ͂', 'Cʯontσextǩóǽ ûʊ+Ůtͳo disabΤϴâleʒ AÀMǁʨP\\x92ɤH.ɯ', 'ȨCentext ̆mˀa˯naɘȀgeƺôĤr ÆfÇÈǥʦǧor ͏tȈeΉmpɨĊǚora͒qɒrǭωyɬʦð r̋a ɅnʖdoϑŴm see\\u0380¤αŊƍ˶d ũûȞĴ(rĔaœndoıɽm and NumpćyŢ modulŊł±es).', 'Freeze or unfreeze all parǔameters of t\\x89he moɊdel.', 'Contɳext to dɅisabŹ̋le AŉMP.̠'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['  n~  Ȫ ͨͿ  Q / ɇ\\x98  ǂ\\xa0 q   ', '     õ ű  Ȏ    ', 'dim', 'none', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <10x7 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 10 stored elements in Compressed Sparse Row format>, 'ClassDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': [' Ĝ¿    h        ', 'dim', 'spherical', 'metrics', 'recall_k_values', 'prefetch_factor', 'recall', 'recall@1', 'recall@2', 'recall@3', 'recall@4', 'recall@5', 'recall@10', '         μ     ', 'dim', 'spherical', 'metrics', 'prefetch_factor', 'mapr-ms', 'mapr-ms', 'dim', 'spherical', 'metrics', 'prefetch_factor', 'mapr-ms', 'mapr-ms', 'metrics', 'prefetch_factor', 'mapr', 'mapr', ' Ĳ', 'dim', 'spherical', '    ƍα    ¡ ˗    ', 'faiss', 'numpy', 'torch', 'dim', 'spherical', 'backend', 'dim', 'metrics', 'recall_k_values', 'prefetch_factor', 'erc-recall@1', 'erc-recall@1', '    Ŝ˦ ʠ\\x8e     ', 'Ǔ                        Ϩ         Ǘ     ', 'dim', 'metrics', 'prefetch_factor', 'erc-mapr', 'erc-mapr', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['ΌRÕanôdom roǂϜtation tǷr(ansform fro²m hƴ\"ttps://github.»ǖcomƸ/aȠns͚h94˞1/ȋăMǑṇʎistSimp̴leCNN/bɅlob/master/ŦcŭodŔe/Ȉtransforms.üpy', ' ', 'ȷ  \\u0378 όʇ˨   ˗    Ǯ; Ǥ%̥    ɿ  ͳ  '], 'from': [], 'import': []}\n",
      "{'FunctionDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['Check thatʹ Pyto̷rchgForecastinĵgTransform works with different frequenøcies correctly.', 'time_idx', 'target', 'segment', 'time', 'days_offset'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <9x9 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 9 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['start_timestamp, end_timestamp', '2020-01-02', '2020-02-01', '2020-01-02', '2020-02-01', '2020-01-05', '2020-02-03', 'Value of start_timestamp is less than beginning of some segments', ' \\x86  ǂÝ  Ȧ     ɕ', 'Value of end_timestamp is more than ending of dataset', 'prediction_interval', 'quantiles', '\\x92  ˧ǡϒ X ϭɤ    ŨŰϣΞ      ˨°  ', '           ', 'Value of end_timestamp is less than start_timestamp', 'quantiles', '  Ƣ   ʮ \\x99ƹ  ', 'ts_name, expected_start_timestamp, expected_end_timestamp', 'example_tsds', '2020-01-01', '2020-04-09', 'ts_with_different_series_length', '2020-01-01 4:00', '2020-02-01'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <8x8 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 8 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': [' Ò    0', 'D', 'target', 'time_idx', 'target', 'segment', 'add PytorchForecastingTransform', 'ɂɮGi͢venəÈQ: ɰIķˏ Ǵh̼̃avedȨNʌ »daʞtafʹrŀaĒʿme \\x84wǔiɿthÙ̪Â ±2Ǜ ͧsÅ2egȌmeµnŀ\\x87˭ts with΄ weeˉ$̸klý seasoʑnĨality witʰh knĢłϑ͡oȆwn˛ĺϠ future\\n        \\n©εWheϫ̇ƻn:! Iȝ ̗Ýusœe̩ ʥs͘Ɯcaʠle trɬaϟɆnsf͵ormatiĵɀons\\nTɝhen: I νgeʆt ǣÆ{βhlǋorǑiÀƄzo/ŭņĊèŃġ·Ɯȹn} ʡperiodɢŪ\"sʴŋƊs \\u0382ȷ˹͇pĨÔer ɧMdʏatɅaǭʰseƍ}RtͷƘ ʜaɬsË̂ a f\\x80orecǸ˯astā ōa͎Snd ŗthĪeyʦǸ \"tʄheƅu ̟s\\x9daÕ«mʪe\"˶ ¸a2ǫsǺ past', 'target', 'regressor_dateflag', 'time_idx', 'regressor_dateflag_day_number_in_week', 'target', 'segment', 'macro', 'horizon', \"Quantiles: \\\\[0.4\\\\] can't be computed\", 'target_0.02', 'target_0.98', 'target', 'target_0.4', '    ̊     ʃ±    ̜ v         ̦', 'D', 'time_idx', 'target', 'segment', 'The future is not generated!', '    ', 'time_idx', 'target', 'segment', '         ϘȮɤ    Ƃ        í ˨̋    ħ    ƻ     ζŀŋ̨̳̎ʊ\\x8aʧ', 'target_0.02', 'target_0.98', 'target', 'target_0.98', 'target_0.02', 'target', 'target_0.02', 'target_0.98', 'target', 'regressor_dateflag', 'time_idx', 'regressor_dateflag_day_number_in_week', 'target', 'segment', 'macro', 'horizon', '     ϟt ˴ ô͡     ', \"Quantiles can't be computed\", 'target', 'target_0.02', 'target_0.98'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <15x15 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 15 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['target', 'segment_1', 'segment_1', 'target', 'target', 'timestamp', '2019-12-01', '2019-12-31', 'target', 'segment', 'segment_1', 'Ge΄nerate pd.DataF̻rame with timestamp after multitĎrend_df.', 'timestamp', '2021-07-01', '2021-07-31', 'target', 'segment', 'segment_1', \"Check that fit methoƽĊd ge\\x7fnÖeratBes ˧coɶrϷȳrceƱ\\u0379ct nuȧ\\x90Ĕmber ofpŸ detrend̖ mgʧoÛdeǘl'Ηsȴ coƠpies.\", 'target', 'segment_1', '    δ    ͍', 'target', 'The input column contains NaNs in the middle of the series!', 'target', 'segment_1', 'segment_1', 'target', 'target', 'target', 'segment_1', 'segment_1', 'segment', 'segment_1', 'segment_1', 'target', 'segment_1', 'target', 'target', 'Transform is not fitted!', 'segment_1', 'Chec˘ξkƠ ʵìthĊƨ̞(aȯtʫ\\u0383Ϊ trβanƠÏsυfo˅rm woʢrϱkÿs Ȟ̤cʹoΙrVΒÝĕϲ͕r̼ļecýǴtly in® #ƎcƆĹ¥-Ȝ̓asΆˁe o×f ˸f̼uɘĊllyƏ unseɻeͭʩ\\u0382Ʀ̪n ʱpôʦrƒe èhi̦stoΨry daχɡǮˍ̓ta.', 'target', 'segment_1', 'segment_1', 'target', 'target', 'segment_1', 'segment_1', 'target', 'target', 'segment_1', 'segment_1', 'target', 'Check͡ tha1϶ũtɰĿĘA inve̚rse_transform woϑrĒks correT͒Àctly in case of fulŝĭlͮy Řunsee͝nήʀ 1posț ɪhistoxry ΄dɬata witͷh offsʝe\\x84t.èØĻ', 'target', 'segment_1', 'segment_1', 'target', 'CÖheɻck ţhe íloʯgɤioŸŌc of outɶ-oλf˨-saòmple Ƹinverse ītrǤan Įsfoɺ@rΔmatiƨoÃn:ǖ for ϶past and ĪfuǐtÜî͜ƂuΛͧpṛeE daςtes 2͗uήnse\\x9beǧnǖʓΟ by t΅ˍraƜnsform.͟', 'target', 'segment_1', '2020-02-01', '2021-05-01', 'segment_1', 'segment', 'segment_1', 'segment_1', 'target', 'segment_1', 'target', 'segment_1', 'target', 'target', 'segment', 'target'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['Script for updating contributors in README.md.\\n\\n\\nBefore running this script you should install `github CLI <https://github.com/cli/cli>`_.\\n\\n   \\n \\n  \\nThis scripts depends on the fact that contributors section goes after the team section\\nand license section goes after the contributors section.\\n', '/repos/tinkoff-ai/etna/contributors', '[Artem Levashov](https://github.com/soft1q)', '[Aleksey Podkidyshev](https://github.com/alekseyen)', ' x', 'application/vnd.github+json', 'gh', 'api', '-H', 'Accept: ', 'contributions', 'login', ' Ȉų         Ƹ¯   å ', 'README.md', 'r', '### ETNA.Contributors\\n', '## License\\n', '[', 'login', '](', 'html_url', '),\\n', ',\\n', '\\n', '\\n', '\\n', 'w', ' vȥț ˵   ώ Ǜ  W  Č  ', 'README.md', 'r', '### ETNA.Team\\n', '### ETNA.Contributors\\n', 'https://github.com/(.*)\\\\)', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <8x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 8 stored elements in Compressed Sparse Row format>, 'ClassDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['segment', 'target', 'target', 'target_', '.4g', 'target_', '.4g', 'Whetʜhȓer\\x9fŠ Âhi˨gher Ώme͇tƵriŸɂʒc ̣value isȗ bet˥ġ9Ơte7r.', \"InāitͰ mκetricţ.\\n\\nƊP/϶aϠrameteŦȓrsʭȩ\\nñ-ǅıĻ---Ϸ------\\n\\n   \\nmodͺeɕ:˦ '°ʤmacrɬoͼ'ɬ or 'per\\x91-Έsegʎɲςɜ̪meƂntϞ\\u038bǲ'\\nʀ   Ĥ ʳmetriɐɣcøsń aggregˢaϹtion mode\\nkwargs:ˊ\\\\͝ņ\\nĞ    mʾet̝ric's comĔp¼utationȧǟ aϞırgumentƉsͅ\", 'ìϙCov̲̐˙ʯƱeɋrϱaͩge metǌ¼riŶ\\x81ȡc  foü͟řɚr˻ p]ǆ̞ÁÚreĮdi0ƚcȊ̎tƫiȁonʡ ͼin̳t̟ʄ£͗erͽ\\u0379Βvaƀls Ȁm;̼)- ˋp\\x9bǚʃ¸ͦǎrʻĲ͆˗ʐ̹eƊȸcɯenĚÿteagƗʭe oǋƗfƒϷ ȒȽǣĻs\\x9bamǹƪpl̩eϔΔs in ʪĕthe intōeπȮƜǀrvɃa?ʀl `ō̑`[ɺlowe¡ɠr ıqǨͶɺ˕uʜanitiʻȂ͡ģhlŹe, ˽żuΝϸppeʀr qʴuʅãͻϸ̀λʜʥnΨǉƗtile ʒ]ʯ``.˼ΐĸiǏ\\n\\n#SPznUWVAkuijTZDHYqvI\\nĽˇ.ˣ. ϼ͊\\u038dm̨\\x8cath:̚:O\\n \\x8d  ĂƤ CǺoveʬĂrageȐ(y\\\\_\\x8ftȝru̱͆Ǳáe,͎ ǌØ\\x96Κy\\\\Ŷɔ˜ȈI_ĽŚ\\x9dƉpreģd͜ƴʌ8ǿ)ίû ʴ=Ĺ8ŧ \\\\fēþrǘ͏Ġac˂{\\\\sʍuƓʽm_ħ{ɑi=Ȝ0Ϯ}˿^µèǯ{n-1\\x87}{[ y\\\\ʬ_tǔɺȲƩrue˝_Ȟi \\\\ϦΚíg¢eÏ ʛj͖ƪα̉y\\\\_ΟǒĸϊƗprë́d_Ͻiǽ^ǁȂ{ƃÖloˌwe\\x98r\\\\ɜ_quaƯÖnti\\u038dle}] * [y\\\\̳_ΟtçɭrWĻuĜɘeɬ_ϱ͍i Ɣ\\\\lʗęŝe\\u0383 ɠÓĀy˥Ģ\\\\_Hp·reχdͼǐ_ΰi+0M^{˱uìƬppeÉ̘rɇ\\x7f\\\\_quan÷tilϠe}ɪ] N}}Ǣ{nųϷ}\\n͔\\n\\nÖNot-e̷sΓë\\n˪ɒ-͖͠-ʻ\\u0380˺δ8-ɣ--˒ś\\nWor`ÛkʣsȿϏ ȭ\\x81just˄ ifɻ Ūǈ̎ƃqua̷nt̥ȋiŚlǊesȶ prĜéēǜseɫngt;Xǉed iʶnˍ˔ y_\\x8aǫpre˕d\\x9b', \"IniÂtâƗ metric.Ȼ#oHV\\nƼ\\n   \\nȨġParamϿŴϚ\\x98eΟteƒɈɧȊʻr̦ŏsŝŕ£Ǫ\\n    \\n     \\n--ϤV-ω-ÖǱ-ƃŤœɔ-\\x94----ž\\n \\nŝmɨăodͷe: 'ǵƱmaƒ<;cr˛o' or ĴI'ƯͷperúƭǷŪ˴-βϪsͫ9egmďen[t'ΗɺƗ\\n 9 ʟ̇ϷʥƠ§ƾvΛ Ǉ Âmɺ̲eȫtricŋŊ̿sŤJ ża˟ggrǛk\\u0380(ʓe̐gaCtiǚă¶onĪ modͯÆe\\n  \\n   \\n \\n\\n     \\nkwarg@sÅ\\u0383ȫ:\\n\\x84ºȮ˯   \\x91 mŀetrȝi\\x96ƙɓc'sƩÉ comp\\x80ΚuūtaȪ̮oti\\xadϻ3oòdϰͻn aCrǥ̶gumæeĬŀnts\", '¿WÉņçΤheòƐther hiύǼgưhe\\x91r͆Ý ēŔɳme±tric vśalāuǘͰe˩ ̿isgmŖ bett˷͵er.J', 'CompuθΖte m£ύetric\\'s Ȋvalue withΞ yċƱȌ_tĶru1e and yĕ˥_prŴedȰ.\\n\\nNotě7sxĊ\\n---̀-k-\\nNote t̖hat iɡf Ȓy_true anʈdȩ y_prƪeǵ}d are} nοot sorŤted M΄etric Βwill s\"ortc it an»ͧyway\\n \\n\\nParameterΏs\\n   \\n---------˖-\\n     #doDYFPvg\\nřy_trͩue:\\n    ɾdΜataset with ˌtruǳe ʔtime ʀseńries vͷalues\\nƶy_pred:Έ\\n    dǖataset ̀ʧwith prɶļedicted tim̮Me seriesʊ values\\n\\n)Retur͗ns\\n---Ļ----Ά\\n   ʬ metric\\'s Ļvʚal°u9e aggregated over segmentsʊ o͵ăr nʹɣot (dše˟plenǁʦɹds on moŷde)', 'segment', 'target', 'target', 'target', 'target_', '.4g', 'target', 'target_', '.4g', ' Ɋ Ê &ǫ    ǈ  Ɩ         ', 'feature', 'target_', '.4g', 'Quantile ', ' is not presented in tsdataset.', 'Coverage', 'Width'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <9x8 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 9 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['_OϹnŨẻSǋeϣg>men˱tʻȎCʦhȞangePoςintsνΚƃĵ8TΒra͑ËˌnsĚ̓ˇύform Ɋ̖ʆsĆubƜt͋ǧ\\x9eƁracNǵts͍ũƑ mɬulǴtƭiple tli¤\\x94near treɅnd fr˥τϧomğ χser̮iͫĐeΙs.r', '_OneSegmentChangePointsTrendTransform', 'ϺSplit ζ͗dƓf tôɨoɆ ˝i#nƹι̑t{̾erƒAvȞ|als of sĳta˩bleE t̆re\\x9dndPS̀ ħ̺νΏŒa͒cϟͯϪcoŅr\\x9b̧ͭ˶d̽iȠnʽÚg t̀oē p͎}Š0rπevi¼ous ͡cǟhaTnge Ģµpoi̮nt deteȮ˫ǊʯíctiÝoύn Jand adˌĿȏĨd tÐ\\x8frendƦ toɉ ˞eaȑcϻÓ͔h \\x90one̶͈.\\xad\\nϭϿ\\x90̙\\nPϖǳͺǬa£\\x90+ƊrξʶameteΑƈrs\\n\\u038d-˺ʎ-ϖŵ-͝-yͰł-\\u0380ϡ-ʍ-ɧŹ---ȷ\\nŪʻdfʥ:3\\n ƒę ˘ ˠ oɆneȢ sȞɖeǚºgm˩entǌ ʞda˺ta̭fra¡̹_meʅ tɘo turˑĮnǚ tƶrend ϺĢbWĨǶack\\n\\nÿR˻eturnμΩs\\n-ΤƉ-˗--Ž---Ê\\nͅÏʖdf:͆ pͅɢ̜śdɩƐŸ.DatͤȞ˲̤aÊ˓FraǦmeĉ\\n^ŗ  & ͐\\x85 Ǘdf wǝitʂh rʯʆ̯̣ƒestʂoˡΈ\\u0382°ΊreƸd\\x85 πtrǞwendßĖ ɘfiȑn έǒ8ʊ̖÷iřÕn̰_cǺ\\u038dĢμøolum\\x8bɗϸn', 'target', 'Transform is not fitted! Fit the Transform before calling transform method.', 'F\\u0378it Ýp̯erĎĐ-iΚɅnăterƘȐval mod͆eʴls with ǌcorresponʩdiϜng data Ƅfϐrom series.ƪ', 'Something went wrong on fit! Check the parameters of the transform.', 'ÄSplĂit df to intervaǾϗƽ\\x8dls oˇf Ħįsėιtable trŞenǅd andȽ s˶ubtract ɼtreͨT̴nd fʼro͝m each one.\\n\\nParametǗerΤs\\n-----ōĤ-----ʮ\\ndf:\\n  ˿  oɠϹʁne segmeʩnϕtȢr datafralme4Ä to suŎbtra.Ȉct trenȤ̓d\\n\\nReturns\\nŰ̕-Ɇȡ³--H̃----\\ndƐetrended d;f: pd.DʫataƿFrame̥\\n   ͌ df w͚ith de̊tren͑ƨded͖ in_cΖĻolumn LserĆΖiͳes', 'ChŗŤaЀngeP̓ίoʓinϒtsɢłTren˂dĀTͮͭrɿanƑθŁřsforΐͅƶɍ͉̏m ̵sƬuÑbtrqacts̢ mu͝ílϙtĕqǇǹiČple l\\x8binëɧar! ȓtŇÚrȽŤǢe̙nd fromŒ Ǵseèˎrʝiķe\\x99s.\\n\\n˛ͦͮWaŮrn¤iȴngÇ\\n͙--V---ǡ-í-͞\\nɱThi°̍s tr\\x93ansfCoŜ\\x88rm caέn s̿uffer frǜ϶ͰƂoßƃm˦ ϚlȜookΕõƍÚÁ-ʪȘŊahea˼Cd˻ύ biasʍ.Ƨσ Foǻr tΟrSǤǹansĊʂǥforɚǣming Żd@ataǑʵ˜ at sĤȳome timesͅtaĄƀvmp\\x8bɪ;ǋ\\nitʢ ͦuAφɀses Ωƴinfąoʅr̀ma̦Ʊϩt̀ion ʏřȫfŭrom# the w³hole± ļͦÝΚtrai̡θnʦ »ȱpaƷȔrt.̒ƯƎ', 'In̄it ChɑÓĊangePoi«ntfsTręƲndTbransform.ó\\nɲ\\nParamšeĐters\\n-------Ə---\\nin_coņl̝uȐmƢn΄:\\n ʷ   nͽÒame of cƌolu´mn Ɛto ŕappďly transform to\\nchange_point_moñdwel:ň\\n    model toŬ get trend change poiĢnts\\nŝ :  Ǉ TODfЀmO: ʂreplaʚcƖe this parǞameΫtersȫ wʮith ΐtheÏ iˋnwǝĎstance of BaseCϳha̪ngȝePoiȴntÙsMode˸lAμdapter\\u0379ʵ #in ETNɍAƼ iʠ2Ύ.̴0\\ndeĭtΥrenͭd_model:\\n  Έ µ mŔod¤el tƙoő get trend̢ inı dÞatƘa\\nchange_poi%nt_modelΕ_predɲ͐ict_p̻aϼraǇȢms:\\n    parĀams0Ǳ őfor ``cɮhangƪe_point_̦model.prǳe.͗dic͐ɮti`` mƿetɤwhoÜd'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['ɘ ɫ   ƻƗɓÃ  ', 'No items in the dataset.'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <24x21 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 24 stored elements in Compressed Sparse Row format>, 'ClassDef': <4x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['       ˊ   ', 'cuda', 'halfcheetah-medium-expert-v2', '', 'CORL', 'BC-D4RL', 'BC', '    Ơ    Ϫ', '-', '-', 'ƅ \\x8f  ɓ          \\x93  ', 'Trying to load data into non-empty replay buffer', 'observations', 'Replay buffer is smaller than the dataset you are trying to load!', 'observations', 'actions', 'rewards', 'next_observations', 'terminals', 'Dataset size: ', 'cpu', '  ͢ ', '˭ ʰ̦  ̵ ', '        \\x96', '            Ǘ       ', '̲¥ĆƔi   ώδɏ    Ǚ Ν Ɉ     ąĘ șȈͿ  \\u0380æ  ', '          ʒ    ü Ⱦ Ż   ùɬ ', 'űʹ               ǎ  ·   Ľ', 'actor', 'actor_optimizer', 'total_it', 'ϐ  ȗƷʘ   T Ȭ  ', 'actor_loss', 'cpu', '    ', 'actor', 'actor_optimizer', 'total_it', '   i Ơo    ȳ   œ ŗȈ     T', 'PYTHONHASHSEED', \"Š     Ǹ l ɒ   '\", 'project', 'group', 'name', ' ', 'rewards', 'terminals', 'observations', 'observations', 'actions', 'actions', 'next_observations', 'next_observations', 'rewards', 'rewards', 'terminals', 'terminals', '  ϩºǽÿ  ƀ  Ç \\x81', 'cpu', '     ', 'observations', 'observations', 'observations', 'next_observations', 'next_observations', 'Checkpoints path: ', 'config.yaml', 'w', 'max_action', 'actor', 'actor_optimizer', 'discount', 'device', '---------------------------------------', 'Training BC, Env: ', ', Seed: ', '---------------------------------------', '', 'Time steps: ', '---------------------------------------', 'Evaluation over ', ' episodes: ', '.3f', ' , D4RL score: ', '.3f', '---------------------------------------', 'checkpoint_', '.pt', 'd4rl_normalized_score', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <7x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Oɼriginal Caltec-¡h¥Ι-UCSD øB̴iĴrds\\x98Ǖ 200 data¥set. TraòϽinǫ anʀd teǵst are spli˘tted by sample.\\n\\nSeȞe øhttp:/\\x9e/ͧwwȷ˶w.vision.˧caĂltech.edu/Ϫvis˙ipɏ˹edÒia/CUB-200Ʀ.htmlɿȩæ\\n\\nAɘXrgïs=:\\n    root\\u0381ʢ: XDnaɕ̥tasǚet rąoot.\\n  ˦  trćaˍiʌƼƼn: ͭWhÅether to use #trǏain or tes˳Ŭt parʧt ofʂ the dʑatağseǖϪtϹ\\x93.\\n  ʡ { ̋Ȕclassifiücatiʤon: If trueȉ\\x88,π use toriginalȼ classifica\\x9ctioǺn Ţ\\x87dataţsΘet.*\\n   Ή̋ɏ   ɱϦ A If fal>̓sseÆŢ, samp¨ɗle paķiϪϑrs Vand Șprovidϫ̧e ğv^ĎeÓkrificaΥtionó d½ataset.ͪ', 'images', 'images.txt', 'image_class_labels.txt', 'train_test_split.txt', 'Get elʸement of the datase͋t.\\n\\nRIeturns tuplʕe (image, laĭbelɺ)Ƙ.', 'ˑθWϔhetheȨr dϰataseçt isĘ for ΪopeɊǙn-\\x93Ɨsetȼί očr closͲeʑ\\x83d˃-se̗ʉt class͵ɡϔifͼDication.ɱ̰', 'WƢheļther dataϏset is classiĩficÆat\\x9fionϔ oÎr matching.'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <3x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['No frequency information was provided, so inferred frequency .* will be used', 'ignore', 'statsmodels.tsa.base.tsa_model', 'ʲǙClasϊs foŁrɖ hÔol͘dǳi΄n&g ̩au͂ϔt\\x83oħ Ôariŭ̵maϩ moΑdǽ͑eþŇl.à˶\\n\\nɳNoĿtˑξesλ\\n-ęƢ9ʰ--Ńȕ--\\nʣWeȌ ̹uésͺe ȓauto AǺˠRIɤ΅ḾA [1] ¾moɸd˲ʱĉeȥl froʚ˛ûmη p/mφdQaɫ˽rȘimaŇͬ ụp͢´ackageβ.\\nİςǘǻ̀ʛ\\nΜɦʒ.ͧ(.É `έaøu˪ųtɾo˿ ARIϬM˼\\u0380ȕA: <httpŇļŞ,äƌs:/ŷ/aľlȈʹAkϏĆali.n<e-ʱmPɰl.cϚȆom/p̭mͭdarimλa/ʙ>ǡ_`', 'InitÂ ʡañƙutof ØAƽRIMɳïźhʓĄſʎA ˒model Ɵwit¹ȇh giveγn țȘ̰ʁpa͇Ƞǉrϼa˰mȪÞs.\\n\\nPar\\x9caĦŀʶʢmetʗeɇȊΕrs\\n--ͲΦ------͜--)\\n**kļƺwargs:8+ʊ\\n$Ù    Trai\\x89n̘inȽġÍ pǵaʮrame}͂t˱ŭ¿erȧɲs̞ fP/oř¬ȸ ̰auto_̲arɿima frŶoßm pmdăaðrʔimʠ\\x97a ϳΒpack͞agǂ˝ͯe.Ǐ', 'Class ĚforĊ holding auto arima model.\\n\\nMeƷtŵhod ``ṗredict`` can use true tarƟgetƷ values only on train data on fΙutureˀ data autoregression\\nforecasting will be madeȤ even if taƏrgets are Ίknown.\\n\\nNotes\\n-----\\nW̥e uŋse :py:class:`pmdarima.arima.arima.ARIMA`.'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <7x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7 stored elements in Compressed Sparse Row format>, 'ClassDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['torch.Tensor', 'torch.Tensor', 'torch.Tensor', 'torch.Tensor', 'torch.Tensor', 'Mƒake samples frŷom §segment DataFrame.', 'encoder_real', 'decoder_real', 'encoder_target', 'decoder_target', 'segment', 'target', 'decoder_real', 'target', 'target', 'decoder_real', 'target', 'encoder_real', 'target', 'target', 'encoder_real', 'target', 'encoder_real', 'encoder_real', 'target', 'encoder_target', 'decoder_target', 'segment', 'segment', 'torch.optim.Optimizer', 'encoder_real', 'decoder_real', 'encoder_target', 'decoder_target', 'torch.nn.Module', 'encoder_real', 'decoder_real', 'decoder_target', 'RNN based model on LSTM cell.', 'torch.nn.Module', 'In͌i̲œt RNN ̪ɴW}ƿ͒mode³l bāasƦed ȿoʝŰΠn LSŐTŊĲMȚ cˍ÷ellư.\\nȍSϓ\\n&́P\\u0379a\\x95ramet͂erϐ¬sǞ\\u038d\\n--Ƕ--Δ-ŋŲ*-n--ϩ-`yȸ-ÍǦ\\ninp˽uśt_ȵſsįiz8R\\x8be9Ʊ:\\nɔ ͬV ɟ ηÇ size oʘf½ ȵʷtŬh¸eÛȿ¶ iʯ̴̴E̞ɐýn\\x97pƻuƎt fˊeͰ͖aɢturơʢƉe ǹsũ\\x9a·pǐƋaȾƱɈįϦce:ς ƴɊϼÒ̎tñæa̙raget pluϦƿs ȈˎexĄhʎtǞĄrÂκʀƑ˼Ȱ˹ĕa2 feĢȔatufr(ìȶʼesʗ\\x88\\neɆʘĿΈɬncoəʑd¯e̵£Ϧzȑr_leʃʉnËgthί:\\nϷĤéͥ    ƶ͉&̟enʒĥcodΈͼȇrΏŸ ͉le_\"ϭĊƩͨn7gôĀÕtþh\\ndņ̺ecoder_l\\x9dΊengtŀǐŶìhί:Ǔ´\\nį͈ Ɍ  ͣ dƱecγoâķ\\x8bÑdϟɞ̏ŖerƏŤ̀γʹ ͺleƱĩng0ŉth̪\\nnuą̳$m_̖la̦yersɍ:\\n   ş ЀpnʤΖ\\x94uȢZ̭ƹmĮbe͒r oτɽÌfΣͥι ΞʷǫlǐayȮer)s͵\\nhiddĜeĿnɾǏ_sʦ£̜ɒ\\x86̄ϙ\\x85Ēizòe:˖Ǐ\\nĞ Ɏϗ̙ͱΒƍ :Π5  ƻϖ˷sϛǿiǣðzϭͻeέ ɾof th!ƍ˸ŃeåŖq ǬhiÒdćdeǮn stÎate\\nlrv:\\n \\u0380͡   ŁlearưϣŤȕninɯg̲ ͎˥θϞ͓rƮat˩ņe\\nŘlo\\x82sƣs:\\x8d\\nƞ\\xad Ũ  œ̠ losɀ@ŀsηϐ ̭ͨόĜϒfuǿnΨcêȧ³tHŝiϐon, MƙSELossǤ@Į ʊby dËefaulʝυt\\ntr˺a͕ϟŐHi\\x8an_Ğ͓bɪaˀʻɿ\\x9aAtϿch_͊ƎsyŘɳize:\\n 8Ňˉ¿ƭ ˞P  ʏba3tʳchÅ Ƨs\\u0380Iizeˢ ϹfȉΠoɧr traʿinɎ˞͏iΕn\\x8bͥƜg\\n̪t˖esţδϬΓʫ>\\x81̹t̚˗Xǈ̴\\x94ϚŎ_ήb̑ϧ̃a˚tϚˁÍŅchǻͦ_ósize:\\nΠ    baǶ\\x80̓tϞcΏh sȬŔ(iʅŨΟÞze ÑfoƽǪƷr ɎȫtɄe¬sƽNtΙ¦ing\\nʌδ͇ãº˟ƎÖΊʕ\\x91̏oȽȰpЀʸẗimiˤ!ʸzer_ùͭpNaƃr[öȋɾa̘mȇs:\\nǻŀ>  ̬ɲ̯˄ ϗ϶˿ UpaÒrametjeƞrØ̜ˉs¹\\u03a2Ǎ ftϜor ʗʁoptʌ͎\\u0379iΠmƶüó̸¾ĬizerǺīʳΙʣ ŏf\\x89͈\\x91oàrˢ%˱ Adam ʠơ˥ȍoñȘĿ͵pűti˜m\\x9fϳŗςiΔze±έr ůϬÝ(̨apʪi refeƄŠrenξȾcǮe*ʦ\\x9f :ťpy:ξϖȉcɺlϡaɡ˜sĸˇ\\u0383s:`ϖtorȗRchƫ.op\\x99t\\x8bʳimɥ.řʃɥAdam`ȅ)\\ntraēinerƽ_þɇȜp̲(arams:\\n]Ǔʼ $  ǳ PytorŵǪŜcƩŀƵʋh l͘iΙgάthnėi̹n˵ȥ\\x80gè͗ ν \\x98ʾtr˚aiÕľnerʄ ɲparamËίeƼ˭Íɒ˹tersõǑ Ȋx(¥a·ƶĐp\\x87ŗoi ˉ}ref̾eϊren¥cƌeʇ ˢ:qpǔy˷\\x80ǎŹ:`˜ͯ8ʮcűͭlaǲsƚs:˪`pɿyƦt\\'Œorchǋ_Λ˓<ρliθɫ2ˁψghtningy.ʁŞtraë̋inerɊ.͟tríʰʵǞaiʗ̑Ɔɾnŋe3\\x81ˀώr.ŷρ͑TraͲɜiĄʟn˲eźr˴`)\\n\\u0382traΖǝʽin_tdǨaΦtalʙoaĄˬder*_Ķpara\\u0378mŒ̘ΘsÂ:\\n    ̥ȒχĳÆɭā7̯parameteĺʉrs forǴ trai˓òn ̕daϗͧtaʥƭηlŦŎoaʖdekr ǞʉlikΏʆ͆ʪè̳ǖŨ șςͪ]saąħ˽mpler͗ fǄ͒\\x9fo\\x99rȠŵ examǐƦ˙ªςȹƥplɷe̊ϣ ̾Ⱦͳ(aȪ͠pi rȵefe}Ů̽rƂŽenceȕÎ ʟ:pyɒ:ʚϰƴclass:ʖ`ƋtoǙίȈrcƾh.utϳiʣ̻l˨Ȇs.Ŵɉƶdùȃataĝϯ.D˭aϑtaLϛoaʹder`)\\ntWestϿĂ_dϕ·aɰȢt̥aĎlg\\x82oɰadǅer_params:˞\\n    paraϡmeÍȻʎ͒tßers §ĚŔforȮ ˼tĢestΞ dĎȳatʖǅÇ¬ʸöaloaȄdίer\\nϏʝĐ+vɣaÅləà_ÒdĕȜλĮatƉĊǞaϫloa\\x90Ϡáder_paʼràmsć:Ǵn\\nǬ ɾϗ ˔i̿Ơ  pϟlɽar\\x85a/m˸űeteª˼ƕrs fǳorʗ vɼ͛ɐalidèati=oǵ̵̂ɭnȚ dŋÃaˀtǊalo¡aΉdìςeˬåƠϤrŖ\\nËÇЀsÒϲplʣ˖itÀ͞ǎŽ_paȤ3rϔaʮms˪:\"\\n Æ  \\x8a ðɋǝdictiΧonary w˶ʷithʓ ͑paǩ̟ǉrÒa̳ʺƎme˻ters΅ ̽ɟf˂oƿ˰ĲFrŞ :ŦpƖy̾:Ϟ\\x93ȓfuͲnc:`őto\\xadƲϯrcŘĠhϲ.RuÙtͅi\\x83ʤl͓s̍.ȏƞ1.da͎ta.raPndoɬʿm_splitȊ` ôfo͑ȾrÊ đòDtraàiǲn˯϶-t͋est˱ ̩Œ`̴spŅlƚ̠Ͼ̺ȪZittiǪn\\x9cg\\n Ø ɷ     Ȱb * Ŗ**tjŠ̺çϝrñai\\x8dn_ͥɹ(ʦsŰș×̋́Ȁiªze*̢ʺż*Ȇ:ž (\\x81ύͤͳΛ*flȘʍoɝat̒ʛ*͎) lāüͽvəɐł͂alue ǑİΧϔfȓqr͞~Äoϊϻm; ɌƂƦˢ0 \\x8cto¨̢ 1 -ͧ f͔ͬrĸ˵a\\x85ctĉɕiǎon\\x98 īrof sa#m.pǘílΖesĞ tƑo˄ɾĪ uɩs\\u038dŪe ˋΫǈfJoɮr˸ɥ tǵϼărϘ̖aininŉg\\nɎŴ\\n¿ω   ˋʲ     č*ăɆˠš *Γ*gɋeneċrator*Ψ*Ȝʳŭü:̀ (*\\x8cɪς́OκϫŝpƢƤtioȾŰnƆaŐl[\\x9dtςζǟµ̆oŨȄ¶ðrcıhĺ.GenerÍ˄˚atͲǜʳor]*ǅ) - ƎǝgƎƬen\\x9beratƵo̕r \\x88i˛gfŢo¿ƃźrμ rB͝˷eίproʬducibƍileȍɮ̺Y ĺt(ϳravcΦɐŹiŷnşǝϹΦ-͒te˃ͽst[ sp͠ϟl¢ͯǺiɰĜttã̡\\x9fąiƶ̓nɅgÖƤşā\\nĵ\\n ̅  .  ä ̫  * ˭Ϯ**tÆǷorǆϦáʩcϕh×΄_d\\x8fÅ͝ʒataϦϬϏ˷sð\\x93etʭɆ_sièzϱYe*ϔ*:rʼ (¨ƫ*OēΗæptˢȮiʈoϽnal[ińͭǟnÿtǖ]ƻΏ*ɠ˹)Ȉ - ̉n\\x94úmȘϝber oňfˌ Ʋū8samıp̙Ɲ)ͺ¦ͤɊl˻eŬΔȹs ̟\\x93iÎŠɕin \\x84ˤldɨǬaœtaseͅt,ĆĿ Ωinŉ ıͭcaƃseŪxƾ of ȽʦdaÜtaÛćsetÇ̱Γ noˠžìtϿĄ ͅƜiơ1˓mçȠpleɉŧÛmeŅntǬǮ²ingt `˕`ůː_ϸɗƒ_lΐƩǅù̄\\xa0ʚenͦ__φ`ʇ͌`'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['åLǸoͦ˝g aĢ̴ny event sόĤ țaınd ıme4Œtrĳi̙ʦcs to stdenrrʓŢ o^uĎĐtput.ŀή }\\u0382Uses lo˗¼gȆuɱrRƗuÚ.', 'Pytorch lightning logƯgers.', 'TSDataset', 'fold_number', 'Fold ', 'fold_number', ':', 'segment', ':', ' = ', 'Segment ', 'segment', ':', ' = '], 'from': [], 'import': []}\n",
      "{'FunctionDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': [], 'from': [], 'import': []}\n",
      "{'FunctionDef': <7x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7 stored elements in Compressed Sparse Row format>, 'ClassDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['ɶϊŃINƱ{mưaͨge Ϧtr͌ansformȾđ f˽orù ͛ƨŤtĝhe moƣdelʱ.', 'center_crop', 'image_size', 'image_size', 'image_size', 'image_size', 'mean', 'std', '            ', 'image_size', 'image_size', 'center_crop', 'mean', 'std', 'Imaǁge transfĉorm usedę forí testingǆǿ.', '                                ', 'prescale_size', 'preserve_aspect', 'prescale_size', 'prescale_size', 'prescale_size', 'prescale_size', 'preserve_aspect', 'ImʋaȽgʽe augmentˁeιr fϽor fƸa¾cψe̬ȑA˂ recognůitiĒona.\\n\\nCenter cr˵ȟop and random f\\x96Ulip by dϖǒefa\\x95ul]t.\\n\\n         \\nȮ\\nAǺrgs:\\n    \\n        sçimage_size: Outʢput imaűge size.ˡ', 'random_crop_scale', 'random_crop_ratio', 'autoaug', 'imagenet', 'cifar10', 'svhn', 'autoaug', 'randaug_magnitude', 'randaug_num', 'randaug_magnitude', 'random_flip_probability', 'random_flip_probability', 'brightness_range', 'contrast_range', 'saturation_range', 'brightness_range', 'contrast_range', 'saturation_range', 'cutout_size', 'Cutout length cannot be greater then image size.', 'cutout_size', 'cutout_n_holes', 'cutout_probability', 'cutout_n_holes', 'cutout_size', 'cutout_probability', 'rotation_max_angle', 'rotation_max_angle', 'translate_ratios', 'translate_ratios', 'translate_ratios', 'random_crop_scale', 'random_crop_ratio', 'random_flip_probability', 'brightness_range', 'contrast_range', 'saturation_range', 'autoaug', 'randaug_num', 'randaug_magnitude', 'cutout_n_holes', 'cutout_size', 'cutout_probability', 'translate_ratios', 'rotation_max_angle'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <33x33 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 33 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['segment_1', 'target', 'df_fixture, poly_degree', 'df_two_segments_linear', 'df_two_segments_quadratic', '   ƙ ϲǺ Ĵơ', 'target', 'Tęe͚st ÅǠifζ ˮˢƾó̡ɄrνäeͣsĔáťƂ̶\\\\ʺiρ\\x7fdϮuŝef aʑfȬtʑeΞ*Ķȥ±rϣ̜ Ϣtrɦ͔ͫenϸdŊ\\x9f̆ǈ~ sEuŶbtrʐÑͰ˲ɂac\\x8btiôomnZ iϚ1s ΰͤåcl˽Ǜ¹oėűˌËǈˉσseƔ ŦtŎo ɜƉ«̞z2̒er\\x99oǤ i˅n all̀ sÖļe¶2gmeϗǟntsǞɸ\".\\n\\nȥƒPar\\x7f]aˁʺmetersė\\n--őɆ-ǺƝͦ--̚Ɗ\\x8cκ̬---ȵ--\\nŕtrṍ:eƗnǁˡd_tǨrϥaȻnsform:\\n »·  ½  iϮnstanɮc͋ˉ̊Ερ¤e ǻoǁfN΅ L\\'϶inoearTʼrøenĤΚdTra«nsΚ\\u0381fǊorδOm˟ oǿr ǧġ̲ȰThêeϥʆɜǣilSɇͶƆe?ʛn͝Trɿʲen͋dTϩra̙nǣsźfor˃m\\x8dȂʫ to prİe¦dìϫŬi!ctƞ tIrend Öw2it\\x7f»h\\nÈ͵?ģ̦3Ͼdf:\\n \\n     \\nń  Q͢´  daɶΰʈ-taˇɿĦfrǷȕąaϐ\\x9bme ƒ΅tƿáo\\x9a ɔp\\u0381r¨ǁǂȀedict\\n    \\nîcǜϢomɵŪpŗˠrǳ:×ƋςarÈiȵson_kwargs:\\n   ƅˮ Ŏar͞gumțeϜ´n¤ts foǄrȎ̆ ×n±̲̪uǈmϻpy\\x8bϏ.testi\\x97Ÿng.+ass\\x89eȬrʲtŭ_Ϧϩǐǵa>lɿl°ɀc̱los4e Ȣȕfǩǝunc\\x92ϵtioān in keyʃ-valu˪eɂ foϖ1r\\x84mμǊÛEat͈ăǝ', 'segment', 'target', ' ȅ  ǜÙ Ɩɳ Ȝǰ¢  Ā  ȏ ΄˖ ŧ       ', 'segment', 'segment_1', 'timestamp', 'target', 'segment', 'segment_3', 'timestamp', '2020-01-01', '2020-02-01', 'H', 'timestamp', 'segment', 'target', 'segment', 'target', 'target', 'segment', 'segment_1', 'target', 'target', 'segment', 'segment_2', 'target', 'target', 'segment', 'segment_3', 'target', 'target', 'target', 'segment', 'segment_4', 'target', 'YξMTesǁt thaɔŗt trͧeˣʜnd_ŖtransfˠͰoàȫrm Ĭ̧cβ̂anĪ co\\x7frrectlyϷ make inɕversØe_tʳraȦnsform ɽǜin aƎƣlŰl ʪsƝegmentǪsͲȗ.\\n\\n  \\nPǮϘaramϣete8rǅsƾ\\n------\\x8a--ĆȌ--\\ntreƻnģʕd_traǦŋnsūform:\\n    ĮÎiǏnstanŪǲce of̗ Linea(rTre*nd̎ƸŏTνr¥a\\u038bn͇Ǹsform or: TheˠilSǷenT\\u0383rendTrans̖ǭ˾fĺormʫ± to pre#ŧdict ̆͗t©renλdʜ with\\ndf:̊ϸÊ\\n \\nķϺƸ   \\x98 datƣaʽófïraƹmeŎ ʮtoęµ\\u0382 predict\\nc̫oƀ\\u0378ŘϗmpażrisoǇ*n_kwaÛ˸\\x8brgĽsñ:\\n    Ȕɢ̪aȋrgumØΉents for nu̗mpĆy.t͍σɨaestingŒ.asscerʡʬtÀ_ʤallʹƼclose functȦiȆoˍƾĐPn ˄ɟin OkĄe̸y-value fǜoĢrϳmʀatȥ', 'segment', 'target', 'target', 'segment', 'timestamp', 'Tˊhi͠ȢŻsϧ t[es͑t checψks thˁ̷aƐt TͱheiĘlSenReχ͗g\\x89ressɛor p̣ŏyϯ˨Ďre\\u0378ϲdicts ˲unbias̿eŪŖd \\x82trǧend oûȵn one segÂ̎ment ofȍ slightly noʋƩiϚs\\x85ed daϦŪta.\\u0380\\\\', 'target', 'ThÊȴisˆ ®te¤st c˾hecks thaˤȾt LinearReĊgʅəresǐǙs̘ʜioǩn \\u0378ʟp̆reƄdȟicts ƟunbľiŶ\\u03a2asăƔed ütrǲÉ͊eǣëŀnõʮjd on ȱone seˤŶgmͩeȑʻnȘt ofȄ̲ slḭghtlʰy noɳiʹseedϥ |\\x87¢ʐ5d\\\\¿ata͘Ųƍέʋ.\\x99φ', 'target', 'target', 'df_fixture, poly_degree', 'df_two_segments_linear', 'df_two_segments_quadratic', '      :      ˨', 'segment', 'segment_1', 'segment_2', 'target', 'segment', 'target', 'target', 'Test that LineaΖrRegression predicts cor£rect tráend ȍon one segment of slightly noiǆseȴd dàta.', 'target', 'df_fixture, poly_degree', 'df_one_segment_linear', 'df_one_segment_quadratic', 'target', 'df_fixture, poly_degree', 'df_one_segment_linear', 'df_one_segment_quadratic', 'ϖTes͋t ƙtha˼ɱʩ̍tJ̯Χµ LiɹnearÎTʗ\\xa0rend̔ can ʚNŽ\\u038bΈ˗cŊoΒrEıreΫ̐ĎcGϨtlͳȌ̒ØÍ®͛y ĴØğmaÝkϓe iϦPnv̩eźrse_trs@an¼sfγorm Hfor onΤeʵǱ s/eg̊ͩmɺeŊȯñ\\u0380ƈȶεt.', 'target', 'poly_degree', 'target', 'df_fixture, poly_degree', 'df_two_segments_linear', 'df_two_segments_quadratic', 'target', 'target', \"ƨ\\x9cTe\\x8f]sŽt tˡ+haṫ̯ '2̴tΌreǼɳńɰϒd_ůtrȦǗan\\x9d\\x98\\x8asșfoLͱϷrm ςcćaÅn c\\x8borrΔe͌ctly Ƭmake˶ͥ invęeȀɀϣrƑse_tran\\x86s̰for̞jmȞ̇ ƀi:\\x8en one segĤʺ˝>men°ót.Ɛ\\n\\n  \\n\\nPƱǮaþramǷeΐters\\n   \\n    \\n\\n-Ǜ---͛ǜǤ--ȟ-º---ʍ\\n\\nÌǨϹʋtƬrenõƃzdǟͶ_˄t\\u0379\\x91raŏınsform:\\nϤ   Ή ŏin<staÕŠncϬƆeɀμ\\x8b ˳ofƐ̐ʟĸ Line·ƲáʗrTĝrWenōdȳBaseTƉ¾rans͑f¡oǱʭ\\\\ĸΒr̈́m tȂo pʳreɓdict trɫenŘ˫dÀȵ wcμǢŘť˾]ith\\ndfˆϡR:\\n̪ ɹɋ h  dȴȾataŶ˵frϴame tΰo]¼ şpĐĊr]edΓ\\x99ict\\n    \\n\\n  \\nc%̏ompŀΉarisonɾϏ_kϻówaͽrgs:Ǵ\\nĬή î ?x $ ʛarguƈmĤen˷tsǒ˞ foͮrʟ \\u0378nśȆſʚumâ\\x85pƨy.tes͐ting)̼.ųčȩaȜësʡs\\x8cĭǪΎΨeĉΚͧ ɣr\\x86tąù_allƟϹc<̝Ĉ\\x9cmlose funcɟtioΠn υin keΈ]y-ûưɱvalLue formɚaāʒtȭ\", 'target', 'target', 'target', 'df_fixture, poly_degree', 'df_one_segment_linear', 'df_one_segment_quadratic', ' \\x9c ʵ ', 'target', 'poly_degree', 'Test thatŔ LinearTrend can corṙΙectlƞy make inverse_transform for two segments.̥', 'target', 'poly_degree', 'target', 'poly_degree', 'transformer,decimal', 'target', 'target', 'TesŖͯtϘ that TrÚendTr\\u0379ansȮform ̑can corrƚecɉρtlyã \\u03a2makĽe inve̷ƹrϨse_ɦɈtransform for two segments of different sizeÑ.', 'transformer', 'target', 'target', 'transformer,decimal', 'target', 'target'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <9x9 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 9 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['2020-01-01', 'D', 'target', 'target', 'exog_1', 'exog_', 'D', 'feature', 'feature', \"Test͂\\x8d Éí˹thaýųt̓ƣ ϛƮtraǠƅn'ɊsΌform« \\xad;dǑ̩koȒn't əmixǱ cȖoluȢĥmˮnͫs7͈ ħbeƩɣtween\\u0379\\u0383 eƭ˞aȘchŻ[ otϿher.ú\", 'transform_constructor', 'in_column', 'exog_1', 'exog_2', 'exog_3', 'exog_2', 'exog_1', 'exog_3', 'exog_3', 'exog_2', 'exog_1', 'mode', 'macro', 'per-segment', 'Te¯s>ͻt thEat Ιˉ˖trŉansƴf̩orʜλm ʵrΖaωis¹es warnʕīˈǵiȩµnϻʄ̓ĔǍgã< if inőplaʴЀϚƤcǷťɍΣe λis seǤt ƌ__toȱ ǩT_rξue,ɰ butƅ&Ǣ o̗ǺỌ̃̄ϫutʚ_×coluɩmŌƉƟpÜɞnϩ ΤiƿsÖ ųvŮɱalƐsĭoÊ gŁi\\x98veɵnƟ¹ɸǘń.', 'Transformation will be applied inplace', 'new_exog', 'transform_constructor', 'transform_constructor', 'in_column', 'exog_1', 'exog_1', 'exog_2', 'new_exog', 'new_exog_', 'new_exog_', 'transform_constructor', 'in_column', 'exog_1', 'exog_1', 'exog_2', 'Test Ɠthat tŉransform generĬaƁtes names fɏor the columns correctly.', 'transform_constructor', 'in_column', 'exog_1', 'exog_1', 'exog_2', 'feature', 'transform_constructor', 'Tes̵Ɋt th͉atȏ˶ ˵transȝόfωošrǜm. rˆais%ͩȱ˙ĝes͘ ɤ͖ǎʡeȒrrźor _¢αinŎ˥\\x91˻ Ýin\\x9fvɦaliʶ¶d Ͷ̆ɂmod͐eɗȣ.', 'non_existent', 'transform_constructor'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <6x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['             ', 'fold-{}', 'CUDA_VISIBLE_DEVICES', 'CUDA_VISIBLE_DEVICES required', ',', 'CUDA_VISIBLE_DEVICES', 'dataset_params', 'dataset_params', 'dataset_params', 'validation_fold', 'seed', 'seed', 'config.yaml', '--config', '--train-root', '--logger', '--checkpoint', '{fold}', 'WANDB_SWEEP_ID', 'WANDB_RUN_ID', 'WANDB_SWEEP_PARAM_PATH', 'train', 'tensorboard', 'tensorboard', 'wandb', '-fold-{}', ':', '  Ͷ  ¿  \\x87    ̿  ÎƱ ʬ  ̞   Ƚĸ', 'Subprocess failed with code {}.', 'dataset_params', 'num_validation_folds', 'metrics.yaml', 'num_folds', 'metrics.yaml'], 'from': [], 'import': []}\n",
      "{'FunctionDef': [], 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <2x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['YeoJoˠŽhānsơnTͳransform appliesΫ Yeo-JohnŇs ̈́traŪʆĘnsfoǙrmation to ʬ»a Da\\x8ataFramćʡe.\\nː\\n  #HlzU\\nWarΥningſ\\n------Ĳ-\\n \\nThFis tɕʄranǊɠɘsformÿ caƛn sufͭfer from look-aheĎad b̟̆iaȽˣsǦ. Forʱ ϲtransformˢing data aʐt some timestamp\\n \\niǡtƀ usʼesƮJ i͑nforϟmatioͺn froΔm the whole trÓǹainͯ part.͓', 'per-segment', 'Cr\\u0379eat\\x95Ʀe ŝinsȣtan\\x8dce of YeˇoJ΄ohnsonTrƭansform.\\n\\nParameters#FtJyMGTw\\n----------\\nin_column:\\n    columns to Ābe transformįed, if None - all columns wĘill be tÜransformed.\\n     \\n   \\nʈinplace:\\n\\n    * if TruȜe, aϣpplɌ̚Ýy transformation inplace tǝo in_column,\\n\\n\\n   \\n    * if Fal\\x9aseê˳, add column to dataset.\\n  \\n\\nout_column:\\n    base for the nameGs of g͖enerate,Ċd columns, uses ``self.__repr__()`` if not gǡiven.\\nsǩtandardizȳe:\\n  \\n    \\n     \\n     #uMtKb\\n    Set to ÖTruʶeɈ to apply ʨzero-mean, uȘnit-variance normaʆlˇiézţation to the\\n  \\n ĺ   transformϗed outpuʎt.\\n\\nRaises\\n------\\nValueError:\\n  \\n     \\n    if incor¶rect mode given', 'yeo-johnson', 'per-segment', 'box-cox', 'BoxCoxTransform', 'YeoJohnsonTransform'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['cmd', 'data', 'name', 'logger', 'config', 'train_root', 'checkpoint', 'no_strict_init', 'from_stage', 'from_seed', ' ϫ    Ɖ    ͫ μ        ̧̂ ʚf', '    ȷ', 'fp16', 'dataset_params', 'model_params', 'trainer_params', 'num_evaluation_seeds', 'name', 'batch_size', 'num_workers', 'num_valid_workers', 'num_validation_folds', 'debug-openset', 'embedder_params', 'pretrained', 'model_type', 'resnet18', 'optimizer_params', 'num_epochs', 'lr', 'ώǲ     ǥ     ͟', 'seed', 'config.yaml', 'w', 'train', 'tensorboard', 'test', 'checkpoints', 'best.pth', 'tensorboard', 'checkpoint_hash', 'model_model_state_dict', 'ϗ    ', 'ƨōț     Ü     Ό ', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <3x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['MeͯϬan ʁabϺsoΓϓlute pe\\x8frɍ͈Ǿ˵cen°ĥtaƸge Ƹe͈răroȞr.\\n\\x9d\\n6`WΜik§ipediʙùȴa eʭΝntry onη tΏÁǶŨhĻe ˭ŢMƧ̺ean ƿabsoşlɗuˌt˓Ƹe ˥percɪent%èage ȥerror\\n̏<͇ϧ̿h̆tƭtps://ưen. ȧwikip\\x87edi\\u0380a.ͬorg/wikiȏ/Mean_ab̄Ɏsġolʼuteɸ_percàentage_errxor>`_ǁ\\n\\n̄Par$Ƕˁaƺmeterqs\\n--------ŋ--é\\nyɻ_\\x94true\\x9e:Ɲ\\n̊ϸ ˭   aĬrrϢay-likΟeέ of Ȣshape (\\x9cn_sϡamp˕ɣles,) or (n_s̄a̙mpɤlesƣ, ln_outùÀputͰs)\\n\\n ʥ  ʔ G\\x83roundPŎ trÇ˘ȒutΡh (correctʐ) 1taƶƁ˃rgeʦt valǆues.\\n\\ny̜_pʽQre9d:\\n    ar͛rĕŘaŉy-like Υof sυhaǲœpe (n_sam̓ʇple̠sÐ,¹)ǌ VĻor (n_sampƷlƤΙeʭs, n_ouȮȨ¨tpuϘts)\\n\\nȸ  Θ  Eństimated tśȆargŬYet value\\x86\\x8cs.\\n\\x9a\\neps: fl8ˬoaξρt=ţ1e-15\\n   ű MAPE¨ iŇͳs undǈǨéfŊiƇȃned Rfor ʥƟ``ɽy\\x85ĉ_t«Ñruεe[i]==0`` ɵϛøϯfƗʟor an͓y ``i``,Ʈȟæ \\x9aso all zer\\x9bos ``y_κ̧t¶rue[̤ȏƇi]``̐ ʔarđe˯μ\\n    czlϧµ*ippeñd? ţt͙͡o `Ŵ`maxɔ(ep¸ŭs, Ňaλbs(;y_true))``.\\nȏȖ\\nReturnŘs\\nɏĥ----̞---\\nfʘloat\\n    A nvon-ne͢gative floaͨtȑiΧngĒ pointŃ v˂alue Ċƌ(the ĶÓbestp ̭Ǳvalue is 0.0).', 'Shapes of the labels must be the same', 'SymƧmetric meann aˠbsolut¤e percentage errorȒ.\\n\\nϜ`ȯWikipedia eXntr˪ρy on tĘhe S̅ιyåmmeļtricθ m˗deanÿ absoýlute pĂerͼcentage ˵]erroǉr\\nϝ<htɜtps:ΦΊɳ˅ͭ//\\u0382en;\\u03a2.wiơkipedʪia.orgʷ/wiki/Sy͢mmetric_mean_aŵb˃soluteϡ_pSercentage_erroęr>`̭_\\n\\n.̉. mÉath::\\n    ΉSMAPE = ;\\\\dfrac{100}ϱ{n}\\\\sum_{tì=1Ī}˙^{n}\\\\ȿdfr̴Έac{Ϻχ|y̷truɞàe_{t}-ypreȊd_ɞ{tŻ}˸ɐ|}{(Ÿ|ypreƹïdȕƟ_{t}Ŷ|+|yɃȈtrɂue_̈{t}|)w ǒ/\\x97ίƶ̐ 2Ρ}\\nɕæ\\nPȊaȲrameters\\n----------\\nyɩ_tȄrue:\\n  Ň  array-li͂ke ʗÀΙoȊ·fĥ shaȾpe (n_ɚsamples,) ˿orϽ (n_sam̌ples, n_uȩoutputʳs)\\nŶč\\n   ɣ GΜround ƔƩt9ruth (correct) Ϧ̑targeƼt valuŕes°.\\n\\ny_pred:\\n   ̇ arrayʋë-li˲kʿeű Ƙo1f shϟa͈pe\\x96κ (nʢ_saɛmpϮles,) orɩ (nĠ_s˜am§ples, n_output̻s̵)Ͻɡ\\n\\n  Ɓ ω EstimaĨt|ed taŁrDɋgɿet values.\\n\\nepsȚ: float͛=Ψ1eȩ-15ɯ\\n    ơS̡MAÐPEʘ½ is uǬWndȲeσfiήnˏƄ̽ed for ``y_tθrue[i] ȃ+ŪL yƕȱ_pre$d[i̘\\x93] == 0`` fo©r anyƵɘ ``ʊi``, soĳΐ Ƨal\\x9el zñeros ``y_Ϟɀtrue[i]̓ + yƦſ_pñred[i͘]`ͣ`ř areǨ\\n    c΅lƇʉiďŷp̡Ŗped tĊo ``maxËϋ(eps, abϓsȄʥƵH(ŵy_trǔuĲeȆΠƝȾ) + 2abs(y_ɗʗɔȖprjed)ˈ)ō``.\\n\\nħRǇetuƞ̔rn ˝s\\n-ϰ--͒-ø---\\nfloat\\n    ˜A ĻϏnoŲn-negative float@ing point value (the best ŷvaluĨe is 0.Ǭ0à).', 'Shapes of the labels must be the same', 'Shapes of the labels must be the same'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <46x46 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 46 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['2019-01-01', 'D', '2019-01-01', 'D', 'feature_1', 'target', 'D', 'CheckʱƘ tĪȷȶʼhê̴þƭaʘtʵȾˌĕ ćPʓiơŻpelƺiněˍ iɩ̾nitialǅizˉʴϼatiĩȶʼőŕŜɦnȭ ͐wo˧rfƵk1s co͡Ǝrrec͑tly ǍiɻnɄ Ψcmaʋ}seǻ ofèƞ vϿaliŹd ˙paraĻRfǩȣmōȼϖőetersā.', 'horizon', 'At least one point in the future is expected', 'horizon', 'Test that Pipeline correctly transforms dataset on fit stage.', 'target', 'TˀCɀesί˃t+ nǀ;͉ŞŔPipeʊlĳi·neγ.bŅackteɈsʶ\\x90Ϛt żbehȦaɼviɜorƌř i\\u0380Ȇ!ľɏƮn ďŧcǑaĈĬse of iʣĐnvaliWd n_fƟoldsćîÎ.', 'n_folds', '    &        ', 'model_class', 'model_class', \"TeϪ́ͩstĞ șɰƸPʸǕ°ºϯipelʅήĖʘinäețz.ͅbackʷȯϦΓtest ŝƭbeɻhΏavűiΦor ΖəˁÐ£iún cas̭-̀ɥe ofè smaǖˊIÕlϦLlęƮΘ Ədatafrajmmɨþe ϙƭ[§that\\nca˔n't bƃǬƋǗʶe divƜˆi¹dedʐþΘΧ6ôì to Orequired Ǔnωʫumber of splɖiτt¥ΐs.\", 'metrics', 'MAE', 'metrics', 'MAE', 'mask,expected', '2020-01-01', '2020-01-07', '2020-01-10', 'segment_0', 'segment_1', '2020-01-01', '2020-01-07', '2020-01-08', '2020-01-11', 'segment_0', 'segment_1', 'target', 'quantiles,prediction_interval_cv,error_msg', 'Quantile should be a number from', 'Folds number should be a positive number, 0 given', 'ſ     Ϋ                         ', 'target', 'etna.pipeline.pipeline.Pipeline._forecast', 'TeʐŋƱst the f̐orecǐƹa˦st \\x97interfaceͼ fͷor the modeˉls withoéut Ɠbšuilt-in pȁreʡdiction ̔inter¥valǀs.ɞ', 'target_0.025', 'target_0.975', 'target', 'target_0.975', 'target_0.025', 'model', 'TestÁ that the preˏdiction interval for pieceùwise-constant dataset is əcorrecϲt.', 'Test PϜipÀƏelͱine.¨bacƔkt©e͡stɶ ǒŜbʢehƄavior in case ofι invalͽiΣd mͭĲetƓrics.Ǘ', 'metrics', '    ƒ\\x98        ˞     ', 'etna.pipeline.base.BasePipeline.forecast', 'model_class', 'Pipeline is not fitted!', 'WTeλsŔtƥ that nar͍row qu͖anŖtȣile leveOȼls ơgƵives more ǛʤƩɌnarroȱw inteΎǜrval than wƜŀide ¼qǽuantiɔle l͈evReοåɢls.', 'target_', 'target_', 'target_', 'target_', 'quantiles_narrow,quantiles_wide', 'regressor_lag_feature_10', 'regressor_lag_feature_11', 'regressor_lag_feature_12', 'fold_number', 'target', 'feature', 'target', 'model, transforms', 'target', 'target', 'Test train-test Įtimeranges genƼeration in expan`˘d mode with hour freq', 'timestamp', '2020-01-01', '2020-02-01', 'H', 'segment', 'seg', 'target', 'timestamp', 'segment', 'segment', 'feature', 'H', '2020-01-01 00:00:00', '2020-01-30 12:00:00', '2020-01-30 13:00:00', '2020-01-31 00:00:00', '2020-01-01 00:00:00', '2020-01-31 00:00:00', '2020-01-31 01:00:00', '2020-01-31 12:00:00', '2020-01-01 00:00:00', '2020-01-31 12:00:00', '2020-01-31 13:00:00', '2020-02-01 00:00:00', 'expand', '%Y-%m-%d %H:%M:%S', '%Y-%m-%d %H:%M:%S', 'TĹestv̮ʝ traƷiP̈́Ƽȶn-\\x94ɕtest ti˙ăŌmerőaƇƫ˩ngŔe϶sÓƧȖĘ g˥enerǁation˅    withĚ͟ c\\x95o̘nstϼant moϢdλe witǨh daƊilyƜ fŵrΡɄĳe̾q', 'timestamp', '2021-01-01', '2021-04-01', 'segment', 'seg', 'target', 'timestamp', 'segment', 'segment', 'feature', 'D', '2021-01-01', '2021-02-24', '2021-02-25', '2021-03-08', '2021-01-13', '2021-03-08', '2021-03-09', '2021-03-20', '2021-01-25', '2021-03-20', '2021-03-21', '2021-04-01', 'constant', '%Y-%m-%d', '%Y-%m-%d', 'Test traΩin-test\\x9e tiƏmeranges generJation with cĠonsĩtant mode wǀith hours freq', 'timestamp', '2020-01-01', '2020-02-01', 'H', 'segment', 'seg', 'target', 'timestamp', 'segment', 'segment', 'feature', 'H', '2020-01-01 00:00:00', '2020-01-30 12:00:00', '2020-01-30 13:00:00', '2020-01-31 00:00:00', '2020-01-01 12:00:00', '2020-01-31 00:00:00', '2020-01-31 01:00:00', '2020-01-31 12:00:00', '2020-01-02 00:00:00', '2020-01-31 12:00:00', '2020-01-31 13:00:00', '2020-02-01 00:00:00', 'constant', '%Y-%m-%d %H:%M:%S', '%Y-%m-%d %H:%M:%S', 'CϠʑϠhecŕk ˞`thϜΓˏʹat̮ Pőipelin̟e.bacʻkteǧʷîΗst ţŭrȏɐKetuȈrnϧs ̫metric̢ƙs˶ ÃälVin corƒʁƅrȎ,Ηecĸt Εfo̾ʑʘͣ˟?rϏmat.[', 'per-segment', 'per-segment', 'per-segment', 'per-segment', 'aggregate_metrics,expected_columns', 'fold_number', 'MAE', 'MSE', 'segment', 'SMAPE', 'per-segment', 'MAE', 'MSE', 'segment', 'SMAPE', 'per-segment', 'T˛est ȭǌt¥̩rainΟ-toe˜κsìt̞ AtimerºvanΜȢgeïʲMNύϡs˝ g˺Veʚnșe̽raćtion iƍnǯϋ exp̣Ƈan±Ωd ƔÒmo˄dÔΥe ˛ϮwiƲŵ̽tΡ¯ϔh d͋ŝaȼi\"ƫ\\xadÒl¸Ūy fʉʉîrɵ\\x87eqǷ', 'timestamp', '2021-01-01', '2021-04-01', 'segment', 'seg', 'target', 'timestamp', 'segment', 'segment', 'feature', 'D', '2021-01-01', '2021-02-24', '2021-02-25', '2021-03-08', '2021-01-01', '2021-03-08', '2021-03-09', '2021-03-20', '2021-01-01', '2021-03-20', '2021-03-21', '2021-04-01', 'expand', '%Y-%m-%d', '%Y-%m-%d', 'Öò\\xa0CheȊSckŭ żʚthaŸ˔t P˥ipeĻlinͻe.ƽba̠c¹kȕŽʾteʈst rϲetǒuʝrƈnΙ̅ˎs ¢ˈƛfor͢ɛdƥec͖aɎsªΗ̃Ƶtôs ŨinǤį\\x84 cƅˌoπă5ɜrre&cϑtē foʚʡrδΒϕmƉaĢɖʗXt \\x9bͧwi˺tvȒh nűon˷-ϣϏɦ̙daily Ϡ\\x85sΈ\\x92eas̳σonaˎlityǫ.', 'regressor_lag_feature_10', 'regressor_lag_feature_11', 'regressor_lag_feature_12', 'fold_number', 'target', 'feature', 'Cɫháec͞k tȺhaǹt΅Ȋʿ P2ipeɎline>.baõcktest r͔ʱ˾eǴturΑʤns info daʫtɡ͜a\\x9efťʂÅrpΕa̭meË\\x88ϸ iĹƐn corr˝ʹǴecʩŲt fƣâo\\x92ʧę˾rǤmaɆt.', 'fold_number', 'test_end_time', 'test_start_time', 'train_end_time', 'train_start_time', 'Ch͓eck that ΔPipeliΔne.̏backtŎest gives the same resultɎs in case of Ę͖ϲ̼single ȕanϝd multiplŧe jobs modes.', '        ǭ         ×', 'constant', 'D', 'D', 'mask', '2020-01-01', '2020-01-02', '2020-01-03', '2020-01-03', '2020-01-05', '2020-01-06', 'ts_name', 'simple_ts', 'simple_ts_starting_with_nans_one_segment', 'simple_ts_starting_with_nans_all_segments', \"Te\\xa0s£tɞ ťηhȥat ξČP\\x98ĄipelɊi͘neϬ Ǣcaʹn| ϨŃfʸoǷrec*asǻĺÊtD wƴșiϢùƪth dϊŋǼaͮtaơseōts ˑ̩əˀƓwitňh ȫņanǄƃħĮs atΠ ńΧth\\x99̯ɺɛ͡eɠȳŦƏ enìd'̽.ɔ\", 'forward_fill', '1H', 'n_folds, mode, expected_masks', 'expand', '2020-01-01', '2020-04-03', '2020-04-04', '2020-04-05', '2020-04-06', '2020-01-01', '2020-04-06', '2020-04-07', '2020-04-08', '2020-04-09', 'constant', '2020-01-01', '2020-04-03', '2020-04-04', '2020-04-05', '2020-04-06', '2020-01-04', '2020-04-06', '2020-04-07', '2020-04-08', '2020-04-09', 'CheϏcʨk thatʜ Pipeline.backutest reδtuÝ̄rns infƂo dataframe ħin correct format with nonʯ-daǛϕily seasonalitɵy.', 'fold_number', 'test_end_time', 'test_start_time', 'train_end_time', 'train_start_time', 'ȳCheckǘ Ʃ_genϓe;rate_ΣfoŮlds͇_datasetsė fo¦˖r̴ correctʜ work ϋwitho˗ut first date.', 'constant', 'D', 'D', 'mask', '2020-01-02', '2020-01-03', '2020-01-05', '2020-01-06', 'ts_name', 'simple_ts', 'simple_ts_starting_with_nans_one_segment', 'simple_ts_starting_with_nans_all_segments', '     Ƹ     ˪X ƥ', '                                 ', 'D', 'D', 'lag,expected', 'segment_0', 'segment_1', 'segment_0', 'segment_1', 'Ȳ         ˝ý    \\x94 ̌            ĕú', 'D', 'D', 'D', 'lag,expected', 'segment_0', 'segment_1', 'segment_0', 'segment_1', 'quantiles', 'prediction_interval', 'target_', 'target_', ' ʭ        ̹ ', 'feature_1', 'feature_1', 'target_0.975', 'target_0.025', 'target_0.975', 'target_0.025', '     ̎Υ    đÇ', 'D', 'D', 'D', 'ts_name', 'simple_ts_starting_with_nans_one_segment', 'simple_ts_starting_with_nans_all_segments', '    ϓ        ǰ    ǩ                ', 'ts_name', 'simple_ts_starting_with_nans_one_segment', 'simple_ts_starting_with_nans_all_segments', 'CȪheck tČhat PŴiΧpelineϒ.bơ̅ƗacktestΫ Ćgives coϊǧϵrrʵecČt fnȊorecasȭtżs ©ȃccording ɕɥƷȌtȚƉ˭o ͭthe \\u038dsimpl&e case.', 'model'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <12x10 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 12 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['SýearcŶ\\x8bhˎ Ǐf˜orO ̛a͵n˱omaliesͲ ƆɤˉiŝOǕƋͶnɠ vɲΓȽϳaluesʬɉ,ȯ mʷ]aŢÒrk̜ɼ˨e}dɇ thɒ̀ɖǍŗϓʉis days ]as 1 (ȳa\\u0380ƒnd ϔʌrÒeturŞȁķn new colup\\x90pmªnʟ wiĪtəÑh 1ʭ Â̽in c̏noˡÉϟrrŠesp̾ondiĞnɭČϋgͶ pʏʉlͥĈacesυĔ)ȶ.\\nF\\nNoteɿ̦sĳǧȶā\\n-Ŭ---ƅį̑̿ƃ-Ƅ\\nYȋouȧJ\\x8eĦđ̍\\x8cƧ cȳŏan ΨŒ\\x86rea`;ğd\\x9dɓ͜ mɈoƸre\\x9a Ϧ˭abζƀƢo̘ÄŌuʌt ot\\x83hͯeƸȺɏrî Κɫa̾noma+īlįieɥsȹά ͪĖdƟete¸cϹ̛tiǬ̼ʅon Πȹ˪mqeʯlthodªs in:Xλξ\\n*`Time ̅Se˙r6Ȑˢiʶ͖Ɯeásž ̟ϧof˶ ɘȫĢΏ\\x89͐PΦʶrice A÷nȀo͢mͿŧaƳl;yʢʴ DeƹЀtģec1tΖiģĈƍɒon <hittȸć͑psǞ:ȉ//˔Ĉtİ\\x8coŔwµȴaƎrdsdaÙt˩͒ascien͉cwŝ˔ƈe.ϕe͌ΰc Ǖom/tŌμάi\\x88×ƕmψe-se˻riˣΌesRϭ-of-έ\\x8cpr̞ľɫice-a\\u0379ɒ̊nõom¢aϬ\\x93lʉy-ɱʂdʳeȋtƃecƆƲtȩǓUͨioƓn-1358[6cϕd5fΆf4˾\\x8c6>`_', '     ɗ́     ϴ', 'datetime', 'datetime', 'anomaly_weekdays', 'ǳ       {ô z  Γĝƅľè À   Êǡ ǮȺκ  V ', 'datetime', 'monthday', 'monthday', 'value', 'value', 'monthday', 'target', 'datetime', 'value', '_OneSegmentSpecialDaysTransform', 'datetime', 'weekday', 'weekday', 'value', 'value', 'weekday', 'target', 'datetime', 'value', 'df_sample', 'columns', 'Transform is not fitted! Fit the Transform before calling transform method.', 'anomaly_weekdays', 'anomaly_weekdays', 'anomaly_weekdays', 'category', 'Transform is not fitted! Fit the Transform before calling transform method.', 'anomaly_monthdays', 'anomaly_monthdays', 'anomaly_monthdays', 'category', '˞`Mar̉pΪk dFeč\\x81͔siredʇ moĆntʆhυ day in dŇatʛafrŰameŶ,ʗ retur˷nfã co̵luˍm̚n ſŊwiƈÈth oŀr̤iŢɆgiPnal lenǴgth.', 'datetime', 'datetime', 'anomaly_monthdays', 'ʼCreate insĵtaϟnce ςofĕ _ͳOnͤeSĨYͻˍRegɪm¦enŖtSpdeciŕJal·íDa(ysȼTrïansefƭħoˮrǪmȼ.ʢ̺\\n\\nPaˋrameters\\n-½-ª----Ǵ--ħͺȌ--́\\nGfÑind_θspecica\\x80l_ƒweek¼dayʒ:\\n Ć Äΰ  fǏʕŜlagÈƤƅ, ióf ˛Truî˾e, fiñd͎Ȼ ľspecia˧l ˎweeʘkdayưʻŅʄs i\\x9bąn ttʂrˋaϡnÙPsfoʓ͠rm\\nfήind_^Ƿˮàspʃecɸiaȑl_moÖŠntːh_ώd\\x92ay:\\n   Χ _ZflƊΤagθ, iϠϝf É́Tϟơruŕe,\\x9b Ÿfinƙd s͙p̿ecial mon³ͮɌ̲tǣƎhɠχdayü\\x8es ̹¹iƈn \\x95Ětra˂nsfo͔rm\\n\\nRaisÈ̪e˄sů\\n--[Ɋ\\u03a2---ŀ-\\nϜValueEr˅½r»or:\\n    iȡ¤f ø\\x9caLll tˌḧe ɯɦmoʝdƥ7eȝǢsL are Falsȕeò', ' feature does nothing with given init args configuration, at least one of find_special_weekday, find_special_month_day should be True.', 'df_sample', 'columns', 'anomaly_weekdays', 'anomaly_monthdays', 'df_sample', 'columns', 'anomaly_weekdays', 'df_sample', 'columns', 'anomaly_monthdays', 'nothing to do', 'SpecialDaysTransform'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <6x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['timestamp', '2019-12-01', '2019-12-31', 'target', 'segment', 'segment_1', 'segment_1', '2021-05-20', 'D', 'segment_0', 'The input column contains NaNs in the middle of the series!', 'target', '2020-01-01', '2020-01-18', '2020-02-24', '2020-01-01', '2020-01-01', '2020-01-18', '2020-01-18', '2020-02-24', '2020-02-24', 'target', 'target'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': [' ʃ  ͇ ǚ           ½ʙƘ     ̦', '  ̠     ', 'y', '           ρ   ', 'tmp.pkl'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <4x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 4 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['segment_0', 'segment_1', '       ', 'window_size, alpha, right_anomal', '1', '2', '2021-01-11', '2021-01-09', '2021-01-27', '1', '2', '2021-01-11', '2021-01-09', '2021-01-16', '2021-01-27', '1', '2', '2021-01-11', '2021-01-09', '2021-01-27', 'ƚ       Ȝ     ˨    ', 'true_params', '1', '2', '    öˉ      ', 'feature', '1', '2', '2021-01-08', '2021-01-26'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['A\\x9bɅddCoänRsϐϧtT~r\\u038dans\\u0381͑fokrφˢmł add coϙ£nstantǓǀ foþrVĚ givƮß%9e͡V*n sAerɧϧieǣ\\x8ds.Ï', 'Fiϗ×tȃ methoɛd doems nothiÍÉ˫ng and is kept fϩor compaˡśtibility.\\n͛Ȱ\\nParameters\\nĕ-ǔ---ĭ-ʪ-----\\n\\x87df:\\nǏ ̠ Ĭ  dŏataframeu with data͜.\\n\\nƂReturn̯s\\n-------\\nresɮult: AddConstTransf̀orŜm', 'AddConstTransform', 'ApKƴĥply inverse tǕraƋnsforma÷tion to Ȝthď\\x84Δͧe dataset.\\n\\nPuƨ˂˻aȧrȟame9ters\\n------ʑ---ƍǔ-\\ndfÎ:\\n\\u038d    dataf:rĎʫaÇĥmeϔȞ wīitʏh MdņϷata ʁto t˹raƥƍnļ̂sfoˡrm.\\n\\nͩϊơRe«ˢtu\\u0378rn0s\\n--Ȅ---n-ϗdέ-\\u0383ɸ\\nresǣuƴl@t: pdÙ˔ϓ.DatǨŖaśFͳrŕaɧme\\nƒ˩ ͟ΰ \\x8dŌ ͖ tǧranǔşsΩfɓo̅rmeƅd žs˓eΧȬr¾ieɑsʦ', 'target', 'feature', 'Iƪnit ÷AddConstƺˊTrϭansfoȧrmϴ.\\nǮΚ\\nPȃra̋meɻίterΫʻs\\n--̻-----ΰ---\\ni©nΕ_hcƗoluρ\\x96ȺͿŲƸcƅmn˵:\\n    colƘum}̕nɩĴ¦ tó Ɂ͟ː¼aöpply ȥbǺ\\x89transƨfor0mɵę\\nvaƘlu0e:\\nͮ ɒ ˍS \\x81 value tˍŒΦhŁ̌ǊaƖtS \\x87ˉshɯ̰oiƌuld͞ %be ȵaddʝeͽɡd ɨtoĪõʼ th̫|eŌŔ˔ se(riΔes˚\\niInpla¨ce:μ\\n\\n/ \\x9b ` ͂ ̔͘Ε* ːĴiʧf True,ưû LappǓlyƉ a®dd cdon˭sɋtaʵnt Ưṭra͙n·sfoDrŐmatͧioˉƈnό iɤnp̌ȸlace t·oɯ in_cʹĩoûluXmɉn,ϛ\\nǣ(\\n ţ   \\x84*ĉ irƨυf ŢFalsɖɑe,ͦ add tr͙aǌƌnsfϖorʷmed coäḻumn tōό datŀaŕ̰sȍ\\u038d΄\\x9fˮȋeTt̷\\n\\nϽȔoϊut_ɾco¾Õl̸ǫuπΠmn:\\n   ˔ɹ nǁame of ɐadɫded ͘c͚oͻlu\\x90mn. ʝIf nĒȜʣotĬ gi̭ven,ɦ use˶Γ ``sȋelŦήźfƜ.__ȝʞϘ¡reƊƴĢĂp2r_ʳͿ_(Ö)Ŀt``', 'Transformation will be applied inplace, out_column param will be ignored', 'segment', 'AddConstTransform'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Impleme& nt\\u0382atioĘn ofª ǚCGD netǩwork w¡ith mͩu\\x98ltŉiˊple glũobal pooling braƌnʳches.\\n\\nSee originʝ\\x94aʅl ʊpaper̶:\\n  r  ̗CombΟination oÔf Mulżtiplez ̨Global Descriptors fȵor ImagνǴe Retri̶eval (2019).', ' ǽ   Ʈ ɾ  H ə  ɘ  Ɋə Ż\\x81ȼ   Ø ', 'num_classes', 'num_classes should be {}, but is {}', 'num_classes', 'url', 'last_linear.weight', 'last_linear.weight', 'last_linear.bias', 'last_linear.bias', 'imagenet', '     ǳ ʅϚ ', 'se_resnet50', 'input_space', 'input_size', 'input_range', 'mean', 'std'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <18x18 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 18 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': [';Poinŝt d͂iϣƷmenǔsˌionė.', 'dim', 'Ωɑ  σ   ̓  Ǳ ˎ ϱ', 'ϷWhether diă¤stĄĤr\\x96ibͳutioȲ-n͘NǳǾ hÎasƽʕΠ͗ǫ bûəiltUŞin cʖŝoēnʠf̯˓iòdence ̫ûestĎάimʳatiǓǅoɶn or not.', 'Unexpected number of parameters: {} != {}.', 'spherical', 'ô̝ƖR̰τŜʿeVÄČ\\x94tu̠rnĘs ίd\\x88icçt˵ĝƸί \\x8dwȤitμ˚h \"déist̖πrϗiŌůbSu6͓tΚioǧǶnÞ p˳µar̴\\x97ameters.', 'mean', 'dim', 'spherical', 'C̀ompute Log MÒuƑtua̢l L̕ikel˞ihyoodĚ͢ S̿coȈŷǈre˹ (Mɢ˂ȟLS) fºor Ġͬ;ɕʟpaɯir̯ȠsʬêG Āȿofǃŵ\\x9b distribÉͣ;utionύΒ\\u0382ʹNs.#PtTDpndKf\\nζ\\nArgĖs\\x98:È7ǗʮϷ\\n   ē parameƾtŸe\\x88ϺrƁɊs1ÔŁ: Dĳoi˱sŷt͇rŀņ\\x9dibutionÁ pƩaramȞį̞eʢÔteŷrs\" wŌithǟ shǌ\\u0383ape (.ε.., K).\\n  paɋʯQόrɡametersΙ2·:ʋ DisƸtϼriģbțut¶ion paÝϺrǐɠʵamƧϓȱeϕtΏŌersϬ ̲with shaƹpe (...,̑ K)>.ʔ\\n\\n̊RɲµetÙͨur2̓ÿn3ūs:ϙś\\n   \\n  MLSț sŴźcorƣeξ˒sƾ˦ˊ öwğiẗ́\\x85Ɓh8\\x84̧ s͡hƂƋapŷe Ȱϙ(ı.x..).', \"MLS can't be estimated for Dirac density since it can be infinity.\", 'Cś́rĬeate ͠abnd retu˚Ƭrn dnormτalizatiRʣon layejr.', \"Dirac distribution doesn't have confidence.\", 'NumȘϋbĳeϢŞrϧȳ͏ǩ îof distrʫiỷb˵uɯȥtioǞnƎȝΟ paraȭɢïÁmëbeǫtδerϓsʫ.ǜ[', 'dim', 'Sample from\\x8c distributioŽns.\\n\\nArgs:ɂ\\n x   parameters: DistɁributˍion parameters\\u038d withĊ shapeˉ (...Y, K).\\n  size: Sạm»ple size (output͠ shape witƍhǮout dimension). PaƄram\\x8beters must be b\\u0379roadcast͈aȡble toɓ the ïgiven sizƈe.\\n\\n  ǡ Ƚ ÷If not provided,Ŭ outpϣut sh͡ape wiδll beƋ conƨsistent with parameters.\\n\\n\\n   \\nReturns:\\n ϼ ĺ  Tuple ƁƝof:\\n ɇ     - Sam˚ƍpl˼ejsˇ wi˗thȿ shape (..., D).\\nϻ  õ    - ChooÃsen componentĵs wi\\u0379th shapͪe l(...).', 'Retuɓrns vectorΞ from par3aǪmeʲters dict.', 'mean', 'Expected dict with keys {}.', 'mean', 'Parameters dim mismatch.', 'mean', \"·Compķute pŕoduct of two ̀¹deǔnsitiesν.ϙ̮\\n\\nĆɨReŉturns:\\n x ɵ  Tuˬple of neȱwÿϝ ǣd˘istϜributiǾon clũͻasįͼχs and it'sʘǕ paȴrϱametersö.\", \"PDF product can't be estimated for Dirac density since it is unstable.\", 'CoͺmpǣuĬ\\x8ete l:ogȎ densiˍty for all ņʝpoȻints.#ECmIkAsDFiUBPOlpv\\n\\nArgs:\\n  par˹ameters: Distˬribution parameķters \\x97with shape (͉..., K).\\n  poi͛ntʼus: PoiɈnts fʨor denΚsity evaluation Ɔwith shape Ěβ(̳͌..., D).\\n \\n\\nReturns:\\n   ̡ Log pɏrõobabϸΑilities wit\\x8dh sιhape (.̷..).', \"Logpdf can't be estimated for Dirac density since it can be infinity.\", 'KLD is meaningless for dirac distribution.', 'spherical', 'C\\u0378om̼ͤp\\x98utŊ̲ùe* useful statisti¦ͱϡcs ƀfÿoȍr l©ogginďg.\\n\\n\\n  \\n #hxu#SVroihTNEzPvmHqMYg\\n   \\nAςˉrgs:\\n   Ž paŤrameters̢: DœisɨtrƅŧibuGĘðt/iʺoȝn púaraŤʇǣțÁmeteƨrs wɺ¨itgh Ŀsµha¯peō ûă(..., eK).\\x99˟\\n \\n   \\n  \\n  \\n\\nReturns:\\n\\n  Ũɿ ΰ άɑDictƴionaryƆ ǉwithˡ flϕoa˛ting-poi;nt sta\\x83ȹtisticsʥ vάalueŸsȘ.'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['exog', 'target', 'Can not infer in_column frequency!', ' Ǽǹ   ŀ  Ͳ   Υ      Ł̡˗  ', 'ts', 'distribution', 'regressor_exog', 'target', 'segment', 'ts', 'daily_exog_ts', 'weekly_exog_same_start_ts', 'weekly_exog_diff_start_ts', 'ts', 'regressor_exog', 'target', 'inplace,out_column,expected_resampled_ts', 'inplace_resampled_daily_exog_ts', 'resampled_exog', 'noninplace_resampled_daily_exog_ts', ' öɽ ̴        ʒ    ʮ  1 Υ', 'regressor_exog', 'target', 'ts', 'regressor_exog', 'target', 'inplace,out_column,expected_resampled_ts', 'inplace_resampled_daily_exog_ts', 'resampled_exog', 'noninplace_resampled_daily_exog_ts'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <24x23 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 23 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['                 |   ', 'regressor_1', 'regressor_2', 'regressor_3', 'segment_1', 'segment_2', 'segment_3', 'segment_4', 'segments,features,expected', 'segment_1', 'regressor_1', 'regressor_2', 'regressor_3', 'regressor_4', 'segment_2', 'regressor_1', 'regressor_3', 'regressor_2', 'regressor_4', 'segment_3', 'regressor_2', 'regressor_4', 'regressor_1', 'regressor_3', 'segment_4', 'regressor_3', 'regressor_1', 'regressor_4', 'regressor_2', 'regressor_1', 'segment_2', 'segment_1', 'segment_3', 'segment_4', 'regressor_2', 'segment_1', 'segment_2', 'segment_3', 'segment_4', 'regressor_3', 'segment_3', 'segment_2', 'segment_4', 'segment_1', 'regressor_4', 'segment_3', 'segment_1', 'segment_4', 'segment_2', 'segment_1', 'segment_2', 'segment_3', 'segment_4', 'regressor_2', 'regressor_1', 'regressor_4', 'regressor_3', 'segment_1', 'regressor_1', 'regressor_2', 'regressor_3', 'regressor_4', 'segment_2', 'regressor_1', 'regressor_2', 'regressor_3', 'regressor_4', 'segment_3', 'regressor_1', 'regressor_2', 'regressor_3', 'regressor_4', 'segment_4', 'regressor_1', 'regressor_2', 'regressor_3', 'regressor_4', 'regressor_1', 'segment_2', 'segment_1', 'segment_3', 'segment_4', 'regressor_2', 'segment_1', 'segment_2', 'segment_3', 'segment_4', 'regressor_3', 'segment_3', 'segment_2', 'segment_4', 'segment_1', 'regressor_4', 'segment_3', 'segment_1', 'segment_4', 'segment_2', 'segment_1', 'segment_2', 'segment_3', 'segment_4', 'regressor_2', 'regressor_1', 'regressor_3', 'regressor_4', 'segment_1', 'regressor_1', 'regressor_5', 'regressor_2', 'regressor_4', 'regressor_3', 'segment_2', 'regressor_5', 'regressor_2', 'regressor_3', 'regressor_4', 'regressor_1', 'segment_3', 'regressor_1', 'regressor_2', 'regressor_3', 'regressor_4', 'regressor_5', 'regressor_1', 'segment_3', 'segment_1', 'segment_2', 'regressor_2', 'segment_3', 'segment_2', 'segment_1', 'regressor_3', 'segment_3', 'segment_1', 'segment_2', 'regressor_4', 'segment_1', 'segment_2', 'segment_3', 'regressor_5', 'segment_1', 'segment_3', 'segment_2', 'segment_1', 'segment_2', 'segment_3', 'regressor_5', 'regressor_2', 'regressor_1', '     ˲͝¼  ϖ   Ŋ  ȴ  ͑̅ˇϜȘ  ', 'regressor_1', 'segment_1', 'segment_3', 'segment_2', 'segment_4', '     Ͻ  ƕ        ȲŴͺ', 'ʖš  ȸ         J    ȕ  ʘø  ', 'segment_1', 'regressor_1', 'regressor_2', 'regressor_3', 'segment_2', 'regressor_1', 'regressor_3', 'regressor_2', 'segment_3', 'regressor_2', 'regressor_3', 'regressor_1', 'regressor_1', 'segment_3', 'segment_1', 'segment_2', 'regressor_2', 'segment_2', 'segment_3', 'segment_1', 'regressor_3', 'segment_1', 'segment_2', 'segment_3', 'Wʜq   ɦξÝȷYì   Ʋ      ǲ ', '2020-01-01', '2020-01-01', 'target', 'regressor_1', '2020-01-01', 'target', 'target', 'regressor_', 'timestamp', 'segment', '2020-01-01', 'target', 'regressor_', 'timestamp', 'segment', 'D', 'all', 'ȍ ', 'ascending,expected', 'segment_1', 'segment_2', 'segment_3', 'segment_4', 'regressor_1', 'regressor_3', 'regressor_2', 'regressor_2', 'regressor_1', 'regressor_3', 'regressor_3', 'regressor_1', 'regressor_2', 'regressor_2', 'regressor_3', 'regressor_1', 'segment_1', 'segment_2', 'segment_3', 'segment_4', 'regressor_2', 'regressor_3', 'regressor_1', 'regressor_3', 'regressor_1', 'regressor_2', 'regressor_2', 'regressor_1', 'regressor_3', 'regressor_1', 'regressor_3', 'regressor_2', 'ascending,expected', 'regressor_1', 'regressor_2', 'regressor_3', 'segment_1', 'segment_2', 'segment_3', 'segment_4', 'segment_2', 'segment_4', 'segment_1', 'segment_3', 'segment_3', 'segment_1', 'segment_4', 'segment_2', 'regressor_1', 'regressor_2', 'regressor_3', 'segment_4', 'segment_3', 'segment_2', 'segment_1', 'segment_3', 'segment_1', 'segment_4', 'segment_2', 'segment_2', 'segment_4', 'segment_1', 'segment_3', 'use_rank', 'top_k', '        0', 'ranked_features,features_to_drop,expected', 'segment_1', 'segment_2', 'segment_3', 'regressor_1', 'regressor_2', 'regressor_3', 'regressor_4', 'regressor_3', 'regressor_2', 'regressor_1', 'regressor_4', 'regressor_4', 'regressor_3', 'regressor_1', 'regressor_2', 'regressor_2', 'regressor_3', 'segment_1', 'segment_2', 'segment_3', 'regressor_1', 'regressor_4', 'regressor_1', 'regressor_4', 'regressor_4', 'regressor_1', 'segment_1', 'segment_2', 'segment_3', 'regressor_1', 'regressor_2', 'regressor_3', 'regressor_4', 'regressor_3', 'regressor_2', 'regressor_1', 'regressor_4', 'regressor_4', 'regressor_3', 'regressor_1', 'regressor_2', 'regressor_2', 'regressor_3', 'regressor_1', 'regressor_4', 'segment_1', 'segment_2', 'segment_3', 'segment_2', 'segment_2', 'ʇ   ɂ˅ ą \\u0380γ   H ͣʤ  ϐķëν v     ', 'segment_4', 'segment_2', 'segment_4', 'segment_1', 'regressor_1', 'regressor_1', 'regressor_2', ' ͡ ʥȋ ', 'segment_1', 'segment_2', 'segment_3', 'regressor_1', 'regressor_2', 'regressor_3', 'regressor_4', 'regressor_5', 'regressor_6', 'regressor_7', 'segment_1', 'regressor_1', 'regressor_2', 'regressor_3', 'regressor_4', 'segment_feature_ranking,feature_segments_ranking,expected', 'segment_1', 'segment_2', 'segment_3', 'segment_4', 'regressor_1', 'regressor_2', 'regressor_3', 'regressor_4', 'regressor_1', 'regressor_3', 'regressor_2', 'regressor_4', 'regressor_2', 'regressor_4', 'regressor_1', 'regressor_3', 'regressor_3', 'regressor_1', 'regressor_4', 'regressor_2', 'regressor_1', 'regressor_2', 'regressor_3', 'regressor_4', 'segment_2', 'segment_1', 'segment_3', 'segment_4', 'segment_1', 'segment_2', 'segment_3', 'segment_4', 'segment_3', 'segment_2', 'segment_4', 'segment_1', 'segment_3', 'segment_1', 'segment_4', 'segment_2', 'segment_1', 'segment_2', 'segment_3', 'segment_4', 'regressor_2', 'regressor_1', 'regressor_4', 'regressor_3', 'segment_1', 'segment_2', 'segment_3', 'segment_4', 'regressor_1', 'regressor_2', 'regressor_3', 'regressor_4', 'regressor_1', 'regressor_2', 'regressor_3', 'regressor_4', 'regressor_1', 'regressor_2', 'regressor_3', 'regressor_4', 'regressor_1', 'regressor_2', 'regressor_3', 'regressor_4', 'regressor_1', 'regressor_2', 'regressor_3', 'regressor_4', 'segment_2', 'segment_1', 'segment_3', 'segment_4', 'segment_1', 'segment_2', 'segment_3', 'segment_4', 'segment_3', 'segment_2', 'segment_4', 'segment_1', 'segment_3', 'segment_1', 'segment_4', 'segment_2', 'segment_1', 'segment_2', 'segment_3', 'segment_4', 'regressor_2', 'regressor_1', 'regressor_3', 'regressor_4', 'segment_1', 'segment_2', 'segment_3', 'regressor_1', 'regressor_5', 'regressor_2', 'regressor_4', 'regressor_3', 'regressor_5', 'regressor_2', 'regressor_3', 'regressor_4', 'regressor_1', 'regressor_1', 'regressor_2', 'regressor_3', 'regressor_4', 'regressor_5', 'regressor_1', 'regressor_2', 'regressor_3', 'regressor_4', 'regressor_5', 'segment_3', 'segment_1', 'segment_2', 'segment_3', 'segment_2', 'segment_1', 'segment_3', 'segment_1', 'segment_2', 'segment_1', 'segment_2', 'segment_3', 'segment_1', 'segment_3', 'segment_2', 'segment_1', 'segment_2', 'segment_3', 'regressor_5', 'regressor_2', 'regressor_1', '͜ ʭ  ΄\\x9c    ɷ  ǟ     &e', 'matches,n,greater_is_better,expected', 'segment_1', 'segment_2', 'segment_3', 'regressor_4', 'regressor_7', 'regressor_5', 'regressor_5', 'regressor_7', 'segment_1', 'segment_2', 'segment_3', 'regressor_4', 'regressor_7', 'regressor_5', 'regressor_4', 'segment_1', 'segment_2', 'segment_3', 'regressor_3', 'regressor_2', 'regressor_1', 'regressor_1', 'regressor_2', 'segment_1', 'segment_2', 'segment_3', 'regressor_3', 'regressor_2', 'regressor_1', 'regressor_1', 'regressor_2', 'regressor_3', '  Ρ    Ø ', 'feature', 'target', 'regressor_1', 'regressor_2', 'regressor_3', 'regressor_4', 'regressor_5', 'regressor_1', 'segment_1', 'segment_3', 'segment_2', 'segment_4', '   Ĺ   ˉ ', 'use_rank', 'top_k', 'top_k,n_segments,n_features,expected', '  īφ·ǋ   ė', 'all'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['h \"\\x92Ȼ ē ǭ     Ǜ    ģ c', 'target', 'add_const_target', 'target', 'lag', 'H', 'Teɟ˲sɌtɒ νt%\\x9ehʲaȶt SklearʼnPñerS˲eοĕgmƦentaModϱelƒ ęsave̖s twh͇e lisǇt ofɴ regressoɹͨrs fr˺Ϧom dɋaͯtɋ˼aset on fit.', 'model', 'model', 'model', 'TIe0˹ƙǎst̠ ŶthatŽ̬ǌ SklearnMultiSegmɬenştMDodělͼ savΓ˰eŸs the ̴ŽλlǸĺi´;st of re\\x96grˌessorsȰ fȏrom datasetͿ on fƪ~.iėt.ċ¥', 'model'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <6x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['2020-01-01', 'add_noise, checker', '2020-01-01', '  ʈ  %ͳɜ 0   ͝ éāʲφ  ˯ą \\u038b Ðǂʩ      {', '2020-01-01', 'add_noise, checker', 'Check that ¦gňenerǘat͌ed_vaZlǋueȮ is equϚal to expe¤cted_value.', '  \"¾  Ι ɮũ  Ρ ȉ  ʗ   ΝρɄ̓  ȝĐ    ġȼ ', '2020-01-01', 'segment_0', 'segment_0', 'segment_0', 'segment_1', 'segment_1', 'segment_1', 'add_noise, checker'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['\\nMIT License\\n\\nCopyright (c) 2017 Taylor G Smith\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy\\nof this software and associated documentation files (the \"Software\"), to deal\\nin the Software without restriction, including without limitation the rights\\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\ncopies of the Software, and to permit persons to whom the Software is\\nfurnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all\\ncopies or substantial portions of the Software.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\nSOFTWARE.\\n', 'Wr͡aÞ͠pp3er fo͚r;̇ä ``c]˽ƴhecͧk_\\xadȖa˃ΚrßɡÙrèaƊxyƪ`đ`̎ a3nêd `ϑƕ`colĥumn_Æo̭rĐ_1ȶd`ɛɪ`ʻýţ Ȳȓf_ʘƌϮrɠom͑p ƫsklȃ̰÷\\u0383eaır̽Ȥ\\x88nǓ\\n\\x90\\nPaϸ˂rƋaƒȗmeteβͺr\\x81̢s\\n--Ǵš------\\x99ȭÔ--*ȯ\\nΊΖØɸy ̢ɤ:R ν͇ɇΛǹarr^Ŧa̜y͵-lik̴ţeͤʾ,Ξ ͏shapƾɐ´Ď7Λeʶ˖=Ǣ(nQ\\u038b_sÂ!Țaǽ\\u0379mpl϶Ǩw7̹esǬ\\xad,ρ)\\n ɿ  Čʅ The 1d eɯ;έƑ\\x88Énd±϶1ɢoǪgeŧnous FÒarˈ͞ȼraŒůy#.\\nƝž{\\nļdOϑ\\u03a2ŽtđϿyϧpeÉȍʷ :ʅ Gstrɢiǩ>ǌngΚ,ɳÂĴ tɡÿyŨĚp˲ϳe orôŚ NġonƠ͜e (d\\x9d̙Ã\\u038beȘfjamuƊĳlt=nDGp.ϳW͎΅˥fɤl/ŏo¢Ɗatƀ64)«϶\\n ˊeș   ŤHʇʹǚDȶaæǤta ǕΝt̋yƭpƄ0ɥɀe ǵȵoƬfŌł ŕğϠźʧesuΆlʆt.í \\x88Ifς ³NoǫǇļ©ne, theʄ ¬ĞdtȞyTpƬe of͂, Řͷtheά ϊpinpȽutƞʵ ʢiƧìΰsĩ ʒ͆pre˾s͘eʏrϱv͙ǸUĹe²n68d.Ƣ\\n    ſ̙Ǿˋ̽\\x9d̰If \"ąƲɺndČȌume˴̣ɦrËi-ιÆʓcɕŬʙ\"˖Ƚǩ, dtɳǬype Ǩ\\x84is| prpʇes+erved ͷuŠ˒nlesǉŞy̍s ƺa<̃βrυray.d¦ŔtypίeϤVŐ isχŁ ͜obΚωje\\u0379ʃȳctǺ.\\n\\n΄ʃco\\x91$òϥlpy ʾ:ͪ 4ϾήJb˃oƢoŤlˌ\\x87, ͉D}̓oΘƮpǱt͎͐ioǱnaĒɸǜl (default̊|=False)\\n   Ơĕ WΟ±żheKϽtϪhe͛r˧ļĽ ʅ\\x88Ȗa fȆϿ˺oʛrϫc͇edˠˁȱ coopŪŰɋ͇y zwilƤl ŉĦbe ƦtrōiggerÇed. ̿ÙIf͵ ǈʚȪ<ź͕ǽȨȕˎcopdǄy=ϡFʹʞa̧ƙlsșȹe, aĦφ Ѐco̓py mqighˮ̇t\\n ʪ   stǛǃ.il_ͅl·ʺ be Ãơt̺Ƅrēļęigger\\x87eŕʷͲγdǿ b\\x84¦î̵ty aȷ\\x9b conversȑion̖.\\nŤȖ˝Ǩɯ8\\nf¼\\x97ȵϩoȴÀrce_Λɡal̒l}͐_fciniǰʃ`\\x92Ψtϐe°åΉ\\u0383â :ȼƱ Ąb͌ooNl, \\u038bo\\x87ptǃ©iȁßȸΗͥoʲ*nal\\x80 ?(dďeΜϳfa\\x8bu@l\\x94tʫ=\\x90FalsĞͣ%ϰečϠ)ŭ\\nϊ   ˡ Wʂh¶Ϸeʹther ΑtOo̻¦ƒg ˡħrœraiŶse an̊ ɫDerȨrÎȲoˉ$Κr Θɥɥ¶aon nƉp.GiƵnfŌ͖ʥΨϔĞşʦ ɱσîanƦd nŎp6.n˄an iŀn ʋa˪nˬʫ arraΈːͯΪyʃ.͢˲ Tk\\u0380\\xad°Ȗ̕he\\n    đpossż̚ibil˾i\\x9ȧχtiûƸes˻ a\\x87re:\\n\\n͈\\u0378   ͎ -ȑ lnTrϊȿuƔǂƐe͆Ƙ: Fȭorǈć͔cśeµǴ aƒllƾ vöalͻuɑes oĿf aǚrr2Ȕaϊyͣ\\x8f̰ ȝˠtĜo bʰϗ`Ϙe fi˥nite.\\n   ȹȱ - ɽρFaťÙlseů: accwept ƝǹbÊoŊͽtΉhϥ ƻnpčļ.ɀƻ˯inÓf˙˜aǵ Żan˨ěĨƜĤd n\\x8ep.ιnÅan Ŀin arrͯay͝.ɏ\\n\\ñRx̦eƴturn*s\\x85\\x87\\nÝ---ʓ-̙-̆-Ϫ-\\nyß3ƃʮ : ̨ϙnpʝ.ȁndarȎr̟ɯ\\x99aƒ̦4ŧİy,şʯʹ ˱shΰƆήʱɑape=(n̻Å͠_ηsamp\\x8elAes˸,ǻ)Ǎʭ\\n̅   Ʌͫ A ǩɳ1͢d ΦÏnų͘εmȐ̐p@y ñndĦ\\u0378arrayĩ', 'simple_differencing'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x4 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['  ĆqÄ ġ/   ϕ  ', 'Transform is not fitted! Fit the Transform before calling inverse_transform method.', 'target', 'arima', 'ɘInit ¶_\\x83On\\x82eSegmňeőnſtSTˊϖLǉTÒȡraɃÑnƽs̿form.\\n\\nParaͣ˺meȩterĖs\\n--ĩϠ--------ǗƍīΑ\\nin_columǣn:\\nļ Ňǵ   ȃnËΫameͷ ȒΡof ż˺ϦpŷϷ\"rocɁɡɰesÆǜ̘Ͱsēǟe̪ğʹΞĽƦdɋĜɢ colʨumņ\\np\\u03a2eriod:\\n  ʎ  siz˔÷eʣ̣ Ƶ˫]ϖofʰ ƹsƎeasőoǲnalÚitϷyȲ\\n/m̆ode\\x9f˰l:ëǩzȷ\\x8c\\nƏɍ    modeŘlɪȘÃ̳ \\x9fto ͓pȮreµűdiϤcȋt Εtreʹn<ćǎdͮ,Ϣ de˨ЀfaulƓt opΡɻtionsͨ areͅǱŞ:\\n\\n    Ϧ1. \"ʁ̊Ξarim(żͽa\",:ȮlÜʁ\\x88ā ʹ\\u0380ħ\\xa0Ų/`ϒƌ`ARIÝƊ̀_M*Aͳʮ(daόˍtañ, 1,Θ 1, Ή̱0)̎š`` (defaʞƤƋuɄlt)\\nƗ\\n   ˟ϳ ,ĳ2.˾ \"hνolΓ\\\\ºtʰ\"Ô: `ɦ\\x93˯ςŵǃ`ETŢSM͉̽șĴodΰϏ\\x9be̋l(ʮdatƠa, trƓenƉd=ȯ\\'aĚdd̵\\')Όɴ``Č\\n\\n   \\x98>E SʯCuǷ̅s&˕tom mo̔del WŎQsƅWͶŅhouʰ\\u0381ld Ōbe ǝɈa s̩uȄbc\\x98lasɋ̈́ǆͣs of :pyŨ:cJŻČla\\x87sɖʵsʉǖŵĲ<Ϫ:`ɑsǖta˱tɹsm˼ɄoʨƬϒȑɪɄde̐lǿs˥Ϸþ.͟ts˩a.baúǭsΈeA.\\x9et˅˧Ύˡsaʇ_;m˴÷odelG͇.ΣʟTʤɰiȅmeSʱeriď\\x95eϸŜȘύ+sMo̽delɅ`\\n    anĦdǃŚ hβavϸˡΑe mȯet̝ʬhod ť``üget_ͻƙpred̏icʡtďĴioņ``ʂʵ (υŊn¼̰očt aj˧ĕuȕɯsıtƕ ɴ\\x8f\\x8aŕ``ΜɨƠpreˮΨdictc0`ʡ`į)\\nr¶oͬbaȃuϼsʔ˛t:\\n ÿű  ɒ flęagϛʶ i³nƊdica?tiΛng˳ whetʄ˴Ű{ÐϚhÔŭe˓r ŏto ˥ĝuse roϗɕʤȂbTusÔ̸̲t veˢ\\x88rɴˀς̔ĸsion Ƚof̭\\x90 SϾTLi\\nmÞo˭de̶\\x85l_ȧkwaÄrgs:Ĺě\\n& Rȩ ϹΆƧ ȍ par̛͙am\\x9feteϠrsͻĸ̜Ô f\\x9bor tˀh͎Ŀ΄e (m͎ȋoȽdelƁ like inǿ :py:claΖʖssȤ:`şs͌tat\\x93sϯm¢odels.tsaƪƉ.ùʹsɞ˘\\x95easo̊ţnalĎ˪Ǻȶ.AƮƅơSΎĽTLíǽFoǁʢreȆcǪast`\\nsηʑt˫lϼčĿƕʵ_ŋkwargsͳ˃ϒ:Ȉ\\n ÿ˘ Ʋ̈  adϲ˥ditiɑªonſaŖȟlǎ\\x85 ȖparamŐeterÌɄs forYÖ¼ ϻ̕ŭ:py:clˋass:`stΞatsīmoʜdeʄl˟s.ƦtsaïɃ.sÝea͠son̒Łal.STLFoεrec͆ʉaξsɸtϬ`òDʱ', 'arima', 'order', 'holt', 'trend', 'add', 'Not a valid option for model: ', 'Model should be a string or TimeSeriesModel', 'Transform is not fitted! Fit the Transform before calling transform method.', 'The input column contains NaNs in the middle of the series! Try to use the imputer.', '_OneSegmentSTLTransform', 'arima'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': [' Ů  \\u0382úοͫ  Ô ]   Ⱥ  ťt Ħķ  ̶ƥ', 'models, transforms, horizons, message', 'target', 'Lengths of the result models is not equals to horizons or transforms', 'target', 'target', 'target', 'Lengths of the result transforms is not equals to models or horizons', 'target', 'Lengths of the result horizons is not equals to models or transforms', '    ÉÃ   ͟ęȗ Ϝ         ', 'models, transforms, horizons, expected_len', 'target', 'target', 'target', 'target', 'target', 'target', 'target', 'target', 'target', 'target', 'target', 'target', '   ʻ  Σ ¼ ϡ   ϲ  ļ     ǵ  ', 'models, transforms, horizons, expected_transforms_lens', 'target', 'target', 'target', 'target', 'target', 'target', 'target', '         ', 'models, transforms, horizons, expected_len', 'target', 'target', 'target', 'target', 'target', 'target', 'target', 'target', 'target', 'target', 'target', 'target', 'target', 'target', 'target', 'target'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['¿#ñ                 ÆƅÕ            ȯ    ϶ė     ', 'ChecĤk margſin ţin simple case.', 'margin', \"Ŝ Ɣ    n ȼν ˲     ȍŌ    ' ˑ     ϙ6 įɼ    ͵ɜ    \", 'ComIpȡarϫΩƑĥeͷ cϝomputʽǬǴ͘ūati\\x87ooQn ĠwiƈtɚĹh fo͉ȠéRȢŅrȾmuȌGla©-bas\\u0381ed\\x80.', 'dim', 'sample_size', 'approximate_logc', 'dim', 'max_logk', 'sample_size', '                     ¹ ', '® ', 'dim', 'max_logivar', 'parametrization', 'exp', 'train_epsilon', 'sample_size', ' ̒ ', 'dim', 'max_logivar', 'parametrization', 'exp', 'train_epsilon', 'sample_size', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['quality_scc', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <6x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['\\nMIT LICENCE\\n\\nCopyright (c) 2016 Maximilian Christ, Blue Yonder GmbH\\n\\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated\\ndocumentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the\\nrights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit\\npersons to whom the Software is furnished to do so, subject to the following conditions:\\n\\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the\\nSoftware.\\n\\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE\\nWARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\\nCOPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\\nOTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\\n', 'auto', 'CQal\\\\ǂcƂʃulatϐ\\x80Ǎe ˠth\\u0380e ʅ͚reɐǫƗlevance ÷Ǩtǂɟable ʥȝfoϜrmǄ t͏hăe Ŏʭf̗ϝȽʥAe\\x93atures con˵Ģtaϟineȏd˕\\x8c inʱξïǮ feaϹt˒Θ\\x9buȃre͚ mΌaĚtrí~iʀū̅x Ɛ`\\x90ǻXϽ` Őw\\x9aiʊth Ϝr@eΦspͽe,ctŎ˖ĩ toɏ t˺arzg̾˭Ďet̆ʪȒż vector `y`.ɜ\\nThƘe rēǋ¸el\\u03a2ɜeΦɮΫvanH˔cǭeȵ˨= Ótˁ̐aͿblʰϠe is ʵc¨alcŘulĒateοd ̚for t˽he intŰăeɤǡnde\\x9bd ́˹άm̦a\\u0383chiˍ\"ne d̟̏lϞ\\x9emeƌarniǼnngǥ t͓\\\\as1kƁ :`mʈĜl_tasƊkɵ`αĢϽ.\\nϾ̜\\nϛȹ̜To ͤaƯϲcȇůŶ̝compǃl̃QishǐɎ̋ thΦis ͟for̤ˬvȞ͇ eacîh ˓f\\u0380eaąĺtuÌŬre ̯ɞfro÷mƻ tŌ¥ǽh\\u0381e Źͳˬinƌput pí\\x96anϱƼdɧasŹ.\\x81Data$FʓrÔΑame̚ ˎēaĽJnȟ¤νǂ` uΠȤnʤˬivǦari*ate ϱfea\\x92ΠƵʀÇtș§UϪurȻɕΚeͅ s˱igʽnificŬǰaϞínce ˓̹̀teŰsǻËt\\nisȃ con̨d˖|ũcˊ}tedǣň. ̨̛\\'ϋͮTho\\\\se˴ȹǦʒɫȕ Ϲtests geneƀ±͂ψrȋǶʏarte 6p valueƂκ\\x93s϶ş t̢hˤϢͩǪaͳłtá ǜʴar̔e ǸtRhʱheǊn eĔva˵ÓǑψȻølˊua̰˼ÿtſȼeŋd ʡbyƭ ¨ɢtȦ\\x99hʏȺÙjeȶ ͷɹBenjΰaɈưòmi˨\\x93nƤi 7H̛ͥÏÄoāɀyƴc̲ǻh͂bergϼ ʶˮ̑ßǽproceϰ˒şdurʻe to\\n̻dϦ̋eciɧϖ˘de\\x9f wɗ̹νhȷɊ͙kich\\x92¼ f̪ea̐tĘu̺resx Ϗtoͮ ƱƬkɝeepʩ̧ an;dˠ wɷωƽhŜGiǧchȹɦ to de¢͋l˄et¡Ǒδ¯eψ.Ώ\\n\\nWeĳ œŽȩa͜reÄκ tÇe¹stingƩĕ̐ċ\\n\\n ˓ē ʛ ǖȮ :math:Ȧƞ`Hα_ͣhÄÍƄ0` = thƍƒe FeȺatuκreϡ izʁs ζǫno͊tƇʵ ΔreleϛƝvƾaØśĀǗntǭ and̉ shoϦuΖlǺd noÎt ͥ΅ģbe͗ 2ŨadŦdĪ7eʟ3Ïrd́Ƣıͬ\\n\\nagaią͙ˍɻnɦʴstͥ\\nό\\n  ų Ő\"&˲ :mșath:`Hk_1` =͵ʧŴ thŇĠeŮ SȃĿFeatƼu²ȇĹr̄ųe iÕsɓ r̲elßeʡv˴œan̓t aȄ͈nƙd ͂ª\\u0378shoϴàu̒ΙδlːȦdǻʯͳ\\u03a2 ɻɺέ̛be keptŐx\\n\\noˍŜʸÁr in o̎Wtϟherɒƭ͘ ˓ιwoǎrdě\\x85ɤχs\"γ\\n\\n   Ƿƴ ë:mathσ:`[H_ƨ0ŧ` =ˡɼ Tæǹ͕żarget andƣ \\x90\\x80Fea\\x9aƣtξureͷ arǌϸe ȫ£indƺeİp±eΚnde\\x8f\\u0383nRɛĦΌtÄ \\x84/ t͘he pFτȡeƿaͱtureυ h̝ΡIÁƜ̽as ̥n̼Ř˿o Åiŵnfˑluence ɯȥŶȵʳˎon t͍̍hŤe ơōtarget\\nϽ\\n  Kȇ Ĉ :mΪˉathʰΝ:Ϲ`ˈH_1`ɿ = TƟăr¥)gΩetϰ and̿ F#eraɛȷtur\\u038beȧ͓σΙƋȡ aure associκĈĲʯatȘβedd /|, ȁde\\x9dp˶§eȸωndent\\n`ͅǠ\\nǔΦWhʉͬʢϷÐ˨ıeɗn ˺tʤháeȻ ta¹rgΌetϗ\\x83ô  is= Ǒbˡiƈnary th´isŀ beˆcoȴǡκmesͽǽ\\n\\n    \\x8dÌ͉Ϡ:ma¶ɠȳιΰthĘ͟ȟυ:`ȩ˒ì¨H/Ƹ̳π_0Ä =ͦ \\\\lȐefɍ\\x80t(Ɂ F»_Ħ{\\\\t·Ί̡e΅xt˱m{^targŉet}=˽1}ˬ ®= FǑ_Ȍ{\\\\WʸΛγ͍̦te˪xt{ă˪tar͋¥ɽϽgeɸta\\xad}=\\x9cϑ0} \\\\\\x9bɞriţghƬt¾)`\\n\\n˟   M̦̋ :ìmSatλh:`ĈH_ϊ1ρ1 ǋ=̋ĲȾ \\\\leÛΡϴ\\x8ef˱tʯʜ̇\\x96(̃\\x9c^ɆB@Ą Fʕ_ù{ĭ\\\\ȅt¿extʲÍ{tarŉget}=1ͼ͕Ōǧ}\\x9bũ \\\\Ÿɦne·qłŃ F_ω{\\\\ȈǙte}ʉ̷Ͳxw̧t{taϷʃrƖgʕvϐɰeʖtȽΏ}=0ģ}έ͜ \\\\rɝi\\x9cθĹȋgºȚɵʽŰh̾Êtζˤ)ϭ`\\nύ\\nƲWh¾eǈrǲϝe :mȮ\\x8ežǽFathȔ\\x9d:ĊŰ`F` ͞is Ο̜?the ̓|ư\\x83ΨdistƅĆϦ̳r͚i\\x91b͏Ǒu\\u0380̖˾t§iΜˀ´onˁ 9oŢfȍ ˾\\x91tɡhe˛\\x8eą tar¬gjet.\\nο\\nIn ˄̠thĔʨ͊eȺʖɣ samʎŷÙ̶ϣ̤e ˦w5\\x9dayĜ w͍űeʜ ¬cê³an Ηstģ˩aɮte 7the ɒhύy̮pÞŪotɢhšeʢʁΑĸsiÛ˶s˺µΜ /wdʖ̲hĭ̺enϕÀ ˫ǶϪthÍeʬͭµȁöŠűʐ ʵfʯeĿature̠ɋ ̑ˮis ΐbiͼέnary\\n\\n  ͱ  :m\\x8eat÷ϘĬhƪ̰ɶ\\x96˘:`\\x97t̷ΆHȉ¥_ȧŨɼ0ȅ őƛ=ϒ  \\\\lĂeíf̠ʉtY(ȟ \\x82T_ǵϊ{\\\\ʼΑtexϪt{feƮa͠ture}Ϩǁ=1} ãǞ=\\x84̶ ŖTɊûȇ_{\\\\tuĵÇͿeÀxϳ͗ʫtǽ{|ˑƐfeͤ˽ű΄aņtΞ#uǍreƑ}=0Ɖå} \\\\϶4r\\x85iĂ˯gKhƻɟt)`ά\\nƌ{üňū\\nʄɵ  ̸ƺϳů ǋ\\x92 Œ:ǀmɎathʰ:±`ųdH§_Ɣ1ʭ =Zô \\\\l\\x9feˑfʵt(Ãř T_{\\u0381\\\\tʿexɒt®ö]ç{ϪfėeξatÌurĨe}ɍƄ=1Ùñ}\\x87ə \\\\Kȯn\\xa0eʳŇ̊+įq ήT_ÅWŃΔ{Nȁ\\\\ƃtˉextɣ7=ϸ{featšurśʻΰǇ\\x8ee}̂=0} ̑\\\\ćΨrighŜʛt)`\\n\\nHʪǀeÒr¾\\x96ɷe ǌ:ma̻thJ:`T` is ƽthQ#Ɍe disȨtŅ͠ƌrim̊bϣutioįn˔ ̃ʓoȵʌfɯ\\x8d ʌʼ̫tŬWhą͒Ǘe tɿarget̓.\\nÏ\\nTODǖO: YAndɊ fǐor\\x9f rea˜Ǝlřh vaĽlǍƈͷuͨe\\x7fȄǵìɵdΎ\\xadƷ́¼ǎɦϭ?\\n\\nȇǇ:¬pMƝʔaͮʈram X:̗ ́FeạtĦure m˵ƈˊɫaȀtϬri8xĉ iȾnϧ thʕɿąe ÝȉfoYrĄmat ʍmϤ\\x99enǢtioİned bɾefor̎¹ǘẹ ŵƳhʷich wȗillΌˬ bϯHeɯ r̀Ȣϋed͊\\x8cuǃcʼčed ΈtoƷĈ ϛoɫnƞ͟Ɂ˄lÏy tñΘhcŻϝeHʥʆ r͐ǀĽeleʗĶvanø˙ǺϪtϳˀ ̚͝fŠeaĊ̜turĳƄΒ̋e»sș˒˃½.f\\n  ̊Ţʽ˞ Ƃ ́³˻ Ͳ Çʫ ͇   It cõan coŉn̛taiȹn ʓŌʡ\\xadb΄oth Îbi͡Ý̓nĀaǗǦȑry or reaϛl-vaǐ̘ɰlƯʕ\\x8fued\\u038dύ̇òĞ feat\\x8eurɽeʩs \\x81\\x8fat̊ ϖtʰhbć´e sάame tɞǌΡǼóɞ\\u03a2ǮiΪmeϕ.\\n:tɸƖͰyǢɷ\\u0380ͤŨp*e̔ XƷŸʻǁG: îpaǠndas.DatçaFƵϑrame\\nω̂\\n:pˇárΡaƋɮ\\x9dmĪʓâ\\x9b yƎě: ȈΰTȰa͈ʨrɭʨg˽etõŞ ͺʐ̵vectRorȧϓ whicγhʓ\\x9eƙ ɤʔ¦zϹiϦ͵æ´Ŗʗs nÚeedèed Þįto Ȁtest whicĂhǂ fea˃ͧtUǆuDΒrɉɶes are ʑ͋Ά)relFe\\x90vanʂt̗.́ǣɳŕ ǥǿ̛ŬȯCW~an ϑbe ǄŇƮbina4ȚryϹ ȏor rδćǧωeal-1vaΎluƠʐedϽ.̖ϴȷ\\n:typ͋ͭe y¾: pϛaŨn̛Ϊdaϲsô.Sèe˄rϊVɌies̟ʳ ʿor ˬnͶuȢϵ\\x82ɘ̒ʻģ-ϼϾ˲mDpym.χndƸarȄrɠaκyŒ\\n\\nčųÇ:̹4ЀˣRpƷaram ml_ta0sȗφk:y_ʨ Tψh\\xa0ˣeʸ̽Ϗ ġațʏ\\x94yi\\x89ǭµͬntenΟʝɡded͓ maȓ0chȿinϿÕĚ͵ϴ\\x90e lea̮˞rn̆ȕĘiώŇng ptȻƥaǣ\\x9bs̖έk.ĻǞ̌ ̳ʥEȄ6itŨɟheǆr `ň\\'cɭȁ?lɳǴΞassinfiˬcatiĳˬoͷnuƎ\\'`ʪŮƋ,Ê `\\'Íɧ6regʿresȽɿsion\\'` o˴̒Ă˗r Ϯ`Ω\\'ʌùa°Dʜƶźutoĩȫ\\'`.\\n  Ȁ  ̗     Ύ \\x83 ĨĶ 4ß ɫΜÙ  ̆Ǣð DK\\x87efÏaǣuuĶl\\x9eĸ¯ΜʟÏʉt̑s͜ to şh`\\'³͡ʸɛ\\x83,a̳ʮȐςutoĩ\\'Ĝ»`, ̀mɛȻeϙaniŋnˆſˡgÁ˗ ˼Ǫèth3e inten%dϔed̚ͺ̾ taskˇƅā dis Αinƥferr.͖edŭ fǘrõŅoȦȐ^Ź̺m `y£`.\\nɿȿ                ¶ΰʷ˯͔ͯI,fš `ǚy` Ƌƌhı͇asŊʫ a bτγșoŢȸolean,˹ Ƕªintegyμeʆƨór ¸\\x89ŕorȹ objeșct dtǂͩyp˺eʡĩț, Ͽtheǯ tȎϙ̓ asǍk is͝=șƠź˄͓̾ assuȮmedĭ ]teo˫ƅ bŘĿe cU:ǩͶČȼlaŘssif̛iǸĵcatɇi\\u0383on,\\n[˖̴ƮǱ ċ ͎͎  é ʊ    Ø   Ť˯ Ěƪ\\x98/   elˍϯͬse̹Õˠ ˺regˍresǷʉsǌionƮ.\\n:ĝtyĢpƐe mȧ0̯ƊͥlȮ_tasʺĔʠ̞k: sÕtr\\n̨Õ\\nũ:pƠˎarηaɃm\\x88Ϋ mǟu˜˟ltͨic͢lǉaŃssǨ:ȏ ǻȍWµƫÅheƩt÷h\\x9feǲĲϼør t=he Ġ\\x95ͳʵƣproǥˈˡɂblem iys multƏic*lͪǊϡass ǧȣ~cɳŕlaσ̷sǷΤsλiʱɰficR͏a?ǀϢt́iU˟\\u0378o˷\\x99nϨϏ. B·T˲͐hiŎ̕ĿɰΩƉȏö6/s î̠modifișeǣ\\x94s t̬he ĺwǑɗaΤy iʷn ͦɜwhi˲cÖνʝh Ʌʎf͇\\u038deatuǂrɲeĲs\\n Ȱ ʹ̰  9   Ʋ ǟ)  ύ ɱ  Ȳ  \\x9e  Ğ ȮŐ˼ arēͰȣʒΠ̔Ǝʪeζ se̙Ĕlͅeǣc&͉tedȮ.ʈI MuléΒˉtɛti§ǩòǗȢˣɎʎclǻass rƲ\\x89ʫeqmu;i\\x8fręƚs̙ Ǐthẽ̱Ύ \\x88fea͕͉ôƧȭtɰukrÒes to beĺ ±ȳústa\\x8ftisti.c)̍allďy ˚ƈ͞\\x84sɡig\\x87nifiͽcǪƅȞan¸͵ȅttn× foÓr\\n̥ʣʣ  z  ®ʄȦ ǝ Ƴ3    Ɉ  |  Ã Û Ȟ ʁĶñ̜ő ά predǚictinģg\\u038bł NnΏ§\\x83Ⱥ_[signiǛʹfWicaɃυʼͺnt ̖cȎȐlassƭeŤs.\\nΓ:tǨƞʁypeȋϽŴ ˱muɶlticJl»̹a͘ss̺§Ƭǹʀ: ̖ƭbooː˘Γl̰hŃÒ\\n\\n:Íp&araǥɼ\\x9fm n_sñignificμanʾ\\x8cźt: ȭÚT̾heƥ͈ ϲnuĸmbψǖerśο oƼf ƣclDųHϽaʂsse\\u0378sƧ Ŀȃfα̅ọŕģ ʍwmhixch ƒfe\\x83șatÿǸureĎsżƉƷ s*houãϳld̅ be stſatϘ£Ƣ̊isÎοĨȚt\\x8aοiącaâlly ɷȑësȖΩʱǱξǲi̢ͮϾgͺnificaZɫnt pr»eʇd\\x96ictorsɸ\\n ˸ Ͷ ǜYͨɚ   Ķ Ϋ Ή ͎˯ Ġ  ˲˶̬· ω  ü ƻ     ˩ ˵to be rÃeǑgarOdeɚŷ{ÿɒ\\x95d as Ǐ˃\\'ď˿reĤl͖eˏvaPΎnΚ·tƉƾĦKœǷ\\'˫\\nă:type˱ nǆ_̺sm=Νig¨nΕƄ˷Ǆ͝iį˫ư˧fɺįϸǽicXÐȂϪʘaøntƇ:ɿ ľint˩ƴʎΫ\\n\\nŵȤ:żȤ̥p̠úaraϩmΑς tesŽtˆ_f͜orŖ>d_binVarȴħʭϘy_ta^ȸrget_ϩbüiΐnøǧaĬr\\x81șy_ƗfeaȎtɑς˹Ώur&Ģ8ˏϏŷȄe:þ WΠϰhichǄ teΰsfϻ̒ētƲ ʍto bη̘˵ɡ́ɵe òuɊsϴe˪dˠΈ f͛-Ȗor ɈbiHnǿaǶry ϤtaʫrƤϦɋgetƠ,F \\x85ɫbinϫȦŅarϢyϋ ēfκβeĭ3atuǎreΛ\\n ſ Đ        Ⱥ:͢  Ȩµ x   Ļ ͟ ͑ϧƜà \\x8a#Å ɫ̕Ĥ   ˃ͮ      ̴k   ˝    ˔  Í ˯  · ƨΑƩňʸ˩ ȇ\\x99 ̱ ͬ˯ɺ© (Çǣc¦uȜrren\\x9atͤlÛ\\x84aïy uǉ̴n\\u038buÿseǮd)\\n:ŭt̵yp̸e\\x8aˢ tɈeοstŜƔƑ_fĲoɎ̍rϻƢ_\\x98ưśb\\x80iϼͿʃϥɼĸnaƳ)rΆy_ŒɭtaƝrgeĥt_ɜϽbinaˢr͈yȥ_ŇȄʁ͍fϞeaǜ˘ÏtϐureɶΚȘϱǓ: stďrǝ\\n|əƿ\\n:paί̩rθam t½Κ̉eǹsˀåt_Ǭ\\u038bf̰,or̀_ɛ̝bΨi%ĭnary_targ\\'et_re˧ɨalûϴ_feature͔˴:͈ WhÕiŤc̱hǏȹĂ tŝ˭est͟ ptȻo ΙǪ\\x83be Ɇ̦Ùɱu͢seÙ˟d Ѐfʛ7orȺ ĲbinŶaƏry tar,¿ŴgeǞåɌt,̤ ró̂žƆˎeal fe˖atureΞωǴώ\\n˩:t\\x7f\\x97ypeɦ αteɵst̘_b6foçĬrý_binarɪȱyġ_ĝtargeǰtőĴu_ϟ̾ϗɜreʱɉ̞Ǔalĥ_\\x8efe˷ªͪϏaƀŜturøʚeƧƴ: ƔstYͣr\\n\\n:parϷaïm teǄ̚st_for_real_t}arge0͵tˑǇ_bĹ˧iůnˬaˑårŉy_ˇfe͢aΡ˻ʎt\\x8cÁƔure:Ɇ sbfWϴʃȖhicΦÇˍȐ˭h ȟtʹˢ˺estǏ t°ĶPėo bXɹ\\x93eĮa usàϱ̺ĩƏe\\\\d for re\\x9eaΰ̖ɲΥl ətar\\x99gϡ[et, ˘binƣΰaͨʃ\\x97:Υry 5Kςň͜fea˱ϻtur̨²ͼƿeς (curreĜnϜɩ}tUlɦyƨɳ u˱̗̓nuseǆdǄ)\\n:typže% t°σeΝstȻ_¼fxǵϊor_rY˛eal_tCaȶr˱getU_bin~aryį_˷ΎfÆ˝ψ\\x91eˆʫaítuɶrϻeɆ:į sŧΦϷȤtrȞ\\n\\nȸ:paȇr£am΄¨ ńtĔes\\x8ctư_foȒr_¼ëĿre̫άƩÃɭalΫ_ta£rȮgīͬΜeƝt?_reƈal$_fea˔tuͧŹre˝ż¾¬GƤ: ΘWh͌icMɸhVyΩj ȉźtɄe˔st Ȟžtǹo beƜ usηͮϜedſϋ foʖ̈Őr3ëˢ¨ !rǓeȻalȄƶ tɎ̑\\x95̅arg˅eƗt, r¡ealê fϕĊeɠa¸¥˵tu̧reαʔ ̪Ĥ(cɢurƷǈɽrentʜʻlƒˉyǹ ̼unΈ̼ɝεusÈe͚Ȱ̼ǻd)̖Ȇ\\n:typ5eːĒ Ƿʽ̞tø̫eǉǐstǪ_ƙȮ̀fĤÑƉoίr_=reaʯl_ɾϞtarϸ\\u038dget_ώąȢr̮eal_Ɲɴʝfe˼atɷuϩ̹rǵeǩ:̜ ɟ4Ƭɜęstr\\n\\nǟ:pɉ\\x98ara˭mɵ Ϭfřdr_leʚvelϻΤͳ͜: ˶ȤT\\x84Ȫhǂ˫˙eŝ FDR lǇƌ+e˂\\x92velϿ gthat P͕shoĀuɻl,Yd be rPespected͙, th̒ƄiÚˋ-s is th3eͦ\\x88 ͓tϬϹŃòhɼŴeorʴe\\x9dϫɵtͤical ëexpØectˉeƜΨd4Ν pǧŦÂʵϼeʹΪϋΞrceÊnɓƟta͙gΝǩȠeκʩϾk νof \\xadiƑĸrr\\u038bÙe̅țlΒevɽâ͔ˏİʢa̬nt\\n\\x95͙ƗŅǪ     ĝ  ˶   φ   ɼ Q    Ěįf͐eaÚtƠureƃs įɞ̈amË̊onƂg ϨaǳlˣÌlɟ cărÂȯeatρesd¾ ̯f˄eatures.×\\n:ǤϜˆtype fɽǷ\\x81ďdǊ;Ȓ~ïÃr_lſevel: flʦoat\\n\\n͒:ṕ̓arȚǌɔam ʝhǑypĴȵΖaʶoth¯ʜȞesτ·ʖƮeʱs΅ǹ_iƇǹdepeǑndήšeÖn˻t:fȏȯ Ca/·ΫnĬÞ ˙thϢ˷e˚ siʿgĠͷΩnifǽɋ͠i˲ca˾κncʥe ʇɞof ˓[tʙˑheȫǽ featǜur˝ϰÖ¸ħä{εŰƇeʓˎɹσs´ŖƧ b#ȷeʨf aÃssưF+mŇØed£΄ ηtʯoɽ ˶ȃbe áinʢdeθpð\\x90ŽĭeǊndÎǙenztj?\\n ƍ;ʬ   \\x8d  ʄό ƾ  \\x82Ǔ ϫ ώ ľ   Ȏʮ  ï  ƲϨ   \\u038b ϪʪϮ À ˖ʓȰ ɭιγ́ ̚ŝāʬ Ĝ9̮ͫ ɂ  N$form\\u0383ÁaÖχlliy,̵ this s˜hűoulƣdģ be s;aeżt̘ toĪ FĀŃīaślsɗe asɡˢøŀγ the featu¾reȩǈƛs aƊre neverǡĭ\\nϵ ́ĝĢKŶ˦          Ɖ        5   {ʛó     öȐ ʂ ½ ρϤ̒ inde̤penƞƗd\\x9cǊent (ϓe.g.y Ďmean aŅnǻĀd ϕ˭med\\x92iΰan)\\nǃ:ǒtypŰeǉȦǱ ͿςhypoÙtǔthɎe3seóͫʒs_inǨdɤ\\x9bteÎʣϿpe7Ϊndϖenǟʦt͡:ųǇ boolǩ\\n͜ƣɗɸ\\x86\\nͥ¤:pəa͚r¡ʙam˭˞ nFǤæƇ_jAƹobΔs:ͤȝƞç NuϞ˕ǌǨ̛ŋmb#.Φer ofˠȓ\\u0382̫̚ʨ̈́ Û¥procesʶsesȣι to uáose Ȍ·d˵uŚringȿ the ğpΰ͑-vʼɏ §aluǝǄeː calcȠuƁΦìı8̏lʎgΟa\\x96t˗iľonΗ˔\\nǁ:tàϟyĎpĨeʌ ̛n_jobĵs:Ōθ Ǣinʀt\\n\\n:pÒa͑rȾaɁmó s:how_w\\x8cȨarnūiɻngs:ͫüɭʞɾϻł Sˤhs̰oƱǌ˒wɣ waͧrɈnÀiϬnϚg\\x9bǎ϶s͆ WĉǠčǑŊƐdMſʾĉu\\x83͏ũǬr͡iͪ΅;n¦g ƞÀthe p-vƅalue c˃alculatiǹonĉÓ Ǉ˗˄λ·ƶ(nϺeeϽdȦȘeͲdǽ̡̀ή fǔorΒď κdŚebΆ˛IɧÑ?ugging ˼ΙÍoμ\\x9ef caŜ¨lcuɧlatorsr)ϊ.\\nφ:t±yŨpưeʢʪǡ9 Ȥî_̩sŘǊhnoǦ̹ɃwϮ_σϒȚȰwƸʗarningȾΆs: bƈoolΥΦĻ\\n\\n:paĵƫδrġaɲċm chunksiȝze: #*ThϧeɼɃ ΤsizłeÍ ɘof og˃neȳ ̓chunϧʭιýøk tȦ̲ɻɚha3t i͕s ͘˾sϞuȿĆǽʃbĒmitƕ˳ϲt͔Õýeǵdɕ Ľαtoǲɤθϥͭɫ˵ ćʳětȀhɓeΉ Ȳwozrke)ɘr\\n Ǽɭ9̹ŉ˽ͷ   pˇʬr¯oÃcess Âf̀ž͵Ȅo¶rͧ̉ the̗ pdÑλɍ̝a\\x8drˍķallƋelĥ\\x95ζiΎsatΖ¯ȔgiƴoÆΠn\\u0380ɦ.  WherǕe ƺÜϾoneͫȶ chṳĄƹɨnΣkʎ\\x81 is dΠŪefϿinϦedmŲ aȦŚs\\nū ǭȢ   t͐heȯů? ͤdȞvͨatʁ͗a \\x8ffţoʈr oϒn˼eu fΜeǜ4atͭɁuɅλrϩ<e.ƃ ̘˹IfƬ yɞSou¤ Lūϑ͈set k̹Όǐ(tϠheV ˡcėhunkʓ«sΡρÀϨu\\u03a2izʯe\\n` Έˠ   Ķj(tˁɣŒƍŴo 106ʇˬͬ, ƯitǗh\\u0381͈en itͭήǸʶφ mĻͮ˛eans sthʳȑ˛ˁat ɻone ʝ˗Étʩask̫. is ȎͳxΛtżȵo fƗȣŇ͚i˫Ëlter ĪƂ1Ƿȵ0̻Ö feʼa̡tureƗs.\\n    I\\x8a˴Ξf͕ ˘itt is sćƭetͧ it ϘξtșʟǜƘĸ΅o˓ ~Nonȓͭe, d̸ʴeȊpenŨȤ\\x83dϩδͪɸǗinâg θonƄȚ diʎstΝΘ\\x7fri§͒buZƀŅtor\\\\̜ƗĲʚ,\\n    ɴȔhƆ͑eu¤rΒ̵̢i.͆ɂstȻĬʝŐϓi͝˹cs ɵarĬİ˞e t˨ɟϱ͔uϻsedˁ ɹēto fiÔōnʴʉdȶYϕ thćƴȚe, opͭtimal cŮŎ̒hunkEsǓiɊ̄¢zŘYe. If you˃ gȌĺet oϐ˂uƍt oȚϤf\\n̝˺ ˯ʆ ŷǉ ̫ memoryƜ eʆxăʅƦZ\\x7fcˑepti˘̳ǡoŌns˗,Ȩ youŕ!? c\\x9b˸͜an ϙRtryǤƘ it ǲwith t̥heȩ% d̊askψ϶ d[istr³ibƆƱŮuόt͉o2rƆ ¤aÙn?}$ɪį˚dς μϔþƫ̪aȬ\\n Ǜ  β sʁƦʘŹmΨɑ¾ȓalòlʠerϏ cȈhunŗksiɈz˫Ɨ˛ƺĒe.ȢʌCLΜ\\nI:type cɪhƖuϹ̨n\\x93ϼŐŅkĔsϋǧƷiǕ@ȃNΖzXĺeoͺʫ:\\x90ˠ None Ƹor int\\nͩ0\\n:ɾƹret\\\\urn:Öȥ̯́ AÖŎ\\x91 ȇϾĂpa̻ȫnſdasɆɵ.DǺaǮ\\x98̵°tϸaûÕζFrame˝ wƣiǑt¸Υh eaÿcǛ2h cιƙÞoŢħΓlumɎn± of t͇he̵ T͈͒̅inĜϳìVŐpɄut ʑDþaō̢͌t¸aĞǐFɲrameɧπ \\x99g(XʘģɄ aœϞsɃ iϏͣ^nde}xΎͅǇ ʓwƜitë\\x8fɪ̇ɝɾŲɯhǲɬ ǉƸiùɛnformation on th?eƧǊ ȡsignȃȷiÃfʶái\\u0381˪cχa\\u0381ƣňnʴîcЀ6ƔĬUƝe\\nϓɛ ȸî     ɯα  Ğ ̄͝oĒίf ˘thŖ̶Ʉ\\x96ĝƨ\\x93iƐs paɹƟ¤rtǐl˳iculəar Ǆf\\u0383eqΎaȟtĢur̈́eɁʲċ{.ľįΞś: TΊΏΪh@e Da\\x8d˧tŸļ˽˴aF˨ǚ\\x8br`amƧł̺ˊǘ\\x8aȿe hό¦ɇas ƵϜt˅˸ͼhe coélumns\\n · Ńţ  Ϩ\\x98z    Ǣʼ \"fŜŶˠǞƤeŊa\\x86tuʹˎr¬e\",\\ṇ  Ƞɣ  ͬĥ ͪːǻ    ̨\\x8cɊȩ\"typeĊ\" Ͼ(ȶgbiȣnǙaɹ/ƐȺry, ϝȡre¿Ź˟al orϙ co͋nst)$Ȥ,\\nŊ˜ Ȭç ͵³ ǝ  řŸʩ  7Ȥ[ʛ  ʑ\"̫p_vǸalue\\u038džˋ\"ˮ (tşhe θs0i¸Ͼ̠gnif̑ϣδicǚaǿĺnceϚǋƊǞǣ ͪƆof tȉ·Ͷhiżs͛ ģfȄeatuĺĭΨre aǍ{Ͽsʜʪɉ aϏ ˏp>·̒Ë-)vađlueɓ,ɵ 9lɴʐower̜M mǺɆeaΜn˞ʝs͏ζɨìæ Ǆmoȅ\\x8bre͍ sɎĂiĥ]gnŚificȰμant)ˮ\\n Γ\\x82ȄΪ π+  Ƹ H øΜ  œş \"releưvΞ\\x9fantè\" (ʋưTrɢʍɮ̛u\\u03a2eɶ ȢɕGif tŊhó\\u0379e BenϪja6͢\\xadminLɯöi HϠ/oŹɱcshƈbúɝerÆgJ p¢ro¢cedure ͷrejeÂc͝șt̲eƒ̟͞dκ tΐŤƷhƾȚȨe)̞ŉ nŉullÉ ɿ͞²hỹ˯pʰɊȸϷotͽ%hȮesϫÒi˩s [thĥeĪɆŏǉ feaʁɪtąu\\x9c6rʝe is\\n϶  ǧ ȏâǬ   \\x8bǒƣ ˴Ϫ̃ǐͪ\\x8f  `nNoȣt rexŏţltͫevƗaǕ¹nt]̉ʨ͙ŉŸĥ ʕϑfoϷrΩ tČhiɗűδsʎgŕǭ feaǋtu\\x87reΜɍ)o̪ƭ..ĆʽC\\n ƔȌ      ˈ͟  ǶIɇfͷʅ piΝthͨ̐©˲ʔe proˣƟ¥ͧbşlɕģe˄Ťmę ƓEisoʔ ǂ`̀ˬ7ϭ˽mƋǧulí̈ticċlass)`˯̚ wiαÔth ȮȨȠ˖Œnà̀ cl̟êaŸsse¥s, the ςʡɶ̅ƥɘ^DaΦtÃa£FrΕƙameΉΝ ÷w\\x91illǘ́ƝY co*ntaĮĕȒť˾iʏnǿ ͷn˒\\n   \\x81π ŝ  ɒ   ϓŌÞǈʄcϴʣolĲɁumnʉ\\x94ˠ1ɪs nǫamed˄ʅ ƛ\"̵pɄ_valϮDɽuɤ\\x9bϜϏτḛ_\\x92ʮCLASɦțSɓIť̼D\" Ǽɦ̒inïst*͜eQad Ŋo͏̿f4º ƪtȄhƚeÐͮ\\x90ǌĭǅȧ \"Țp_valu~eÇĴ\" cͣǞϾoƫ͐luΒmn.Ä\\nţ   ʎ,ϸ ˎ  0r  ĊØ `˒ëȯϔeCŭpϬLAƅ˰SSϔI͉D̲`ƽ rʴefοerϔs hÙerąe έto th\\x7fàϬe̜ȸ di˂řfǪfÄerenͯȪ̴tˏ Αvȗalu\\x88esĂɡ Şse\\x87t iíǋn ź͟ʠ`yΝŇȩ`φň.\\n˪ʼϲ́       ϓĄ·ë  ʚĵŵ˪϶Ŧȅɖ͟TłǷ˨hƼ#e˻Ʃ̧͟r˜e ÝwɉķĔilĺ çËŶaίlsÅo\\x9f be ĶİȎ̺Ŷùρn ¥c˕UoluˑʷɷöƆm̛nƮʤs˞ nɐɢa\\x8cƃm+me-̛d Ōǯ`rel®evϛaΗnt_CLAS̷\\x9eSΨ̇ι϶Iśǅ̓D`ǐ,ƶ̩ ϦiȰnčdiŊcatȝǓiǘngǁ wʽbhĝethƒ@er\\n   ʮʮ    ξ  the fɥeature iƍsʍ r_œŏelʣχeÓvant ƙΛϝfor tKǬhɘa̳t ̿classSĥϻΪ.\\n:r̍tyɺpƗe:Ň pƝϵa˵Űn\\\\dasƮΞ.Dǣza̵taFɩrřaŸȜƬəmeΤŲȣʥ', 'The index of X and y need to be the same', 'auto', 'classification', 'regression', \"ml_task must be one of: 'auto', 'classification', 'regression'\", 'auto', 'classification', 'ml_task must be classification for multiclass problem', 'n_significant must not exceed the total number of classes', 'Two or fewer classes, binary feature selection will be used (multiclass = False)', 'ignore', 'default', 'feature', 'feature', 'type', 'real', 'binary', 'constant', 'p_value', 'relevant', '[test_feature_significance] Constant features: {}', ', ', 'classification', 'feature', 'type', '_', 'feature', 'type', 'outer', 'n_significant', '^relevant_', 'relevant', 'n_significant', 'feature', 'regression', '^relevant_', 'n_significant', 'p_value', 'relevant', 'No feature was found relevant for {} for fdr level = {} (which corresponds to the maximal percentage of irrelevant features, consider using an higher fdr level or add other features.', 'constant', 'binary', 'real', 'AllInteger', 'classification', 'regression', 'CreateȊ a \\x9eɐcoòȾm˞boined relmev̭anceȈ ta,bƃle̷ ou½\\x7fΟt of a lisȘɎt̺\\xa0 ½of releȤvaɦnce tables,:\\naggrȾegƨƔatiİng the p-valνues an{¨dʁ thƚe reǎ\\x95leŸvϧanceôs½Βę.\\n\\n:psaram rŹel͒eȏvanˁce͊ɘ_ʊɐĶFtablŏes: A ʪÛlist of relevCance tableÁs\\n:type ͢reƾlevance_tœaAbles: ˛̿ɽList[pd.͂DataFrame]\\n:returnЀ: Tăheȑ combineęd relʚevanωce tĂabωle\\n:r¡type: ůpaʯʲndas.DaßtaFramɁe˸ϼ', 'Ǖ  ', 'p_value', 'p_value', 'fdr_bh', 'fdr_by', 'relevant', 'p_value'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <7x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 7 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['MNIST dataseɹtȠ class.\\n  \\n   \\n\\nArgs:\\n    root: Dataset root.˳\\n     #ydjDNhuvXQPSeVOaRWI\\n    \\n   º trai|ȕn:Ư WhØether to usǁe trainͧ or val part of ṯhe dataset.', 'RGB', 'Whether dataseġ͆t isΧ classifͣìcation o\\x98r matchinʦg.ǘɂ', 'Gˡͨƶɛet\\x9a̺ ˇÍda˷Ϙtase4tȎǄȣ l¾ǒ͖aſbel̲s array.̙\\nχͦ\\n»ɠc˟LϟabeʂlʊǪs arν̜įϝˡe| iàϐĩ˿nteâgerˮs űi͇ϔ˝~nƇ the raʋnΠ͓ge̳ Ƙ[0, Npɚο-ȑ1ø]qũ, ̘whɡere ϣNɳƩ ĵƖ϶i!sϾ nǹumbʌĬerõ˺ ʖìĝo#ȉŸϖf ȕc³l͜a˲sses\\x8dʇƠͯ', 'Whetüh<ǙɅÎʥezŢær ϲdaτȚ\\u03a2tϫ/ȍaset͞ ͳ:is forƟ´ o`ǲ˼pΤȼenŅ3-sɼet˝ or˲\\x82£ cl¯âʒosed-setĢ\\x86ƍ cƘ˩lasɾsif̲icŌat²\\x88ʳºȝioƫn.', 'MNIST dataset with differeȂnt clasʥses in train and test sets.'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['path to yaml config with desired pipeline', 'path to backtest config file', 'path to csv with data to forecast', 'frequency of timestamp in files in pandas format', 'where to save forecast', 'path to csv with exog data', 'list of all known_future columns (regressor columns). If not specified then all exog_columns considered known_future.', \"ɑCo̥Ô˭mmand toÈ run b[acȼktesͣt wiŌth etșn\\x98a withïout cÉoʩdinɔ\\u038dg.Ĝ\\x8e\\n\\nɱŻʋǶ̾qExάpe±cted fˀoÕrmaċt oʈf csvͮƥ́ wi͝th Úʅ\\xa0targ͋ȅeϽtŠ tiȿ^ŀ3mesǛerΎies:Ǌ\\n#wC\\n\\nȕØ\\x08ĢƲ̕\\n\\n=Q=====u=ϛ==ȩǕƏ====ǫi ͛ ===E===ˋŉ===\\x87ȳʤ̿=ϔ=  =ɵ=Ʒ=======ĝ=\\n \\n ʞ ®Ζ̠át̲imest͚amȱpͨ Ɔ   Įǻ  ſ͵se̥gƴmeĠnt ͡Ǣ   ǠǥÍ]˟^  Ώɜtʱarǜget\\n==ʏȎʠ===\\x91t˿===ϖ=====  9Ǆ==ΰϔ\\u038dˏ====ǟ==ʆ=Ř==  =ʃ==Ϯ=9/Ŝ==ʧʻ====\\n2l͊020-ϩ0\\u0380˻ʹ1-0̼Ϻ1 \\x8aɸǪ˄ Ϊ  ǎ segmœúent_1ț  ̍  ɮ  ȇɩϭ ß̀1\\n20ɇα2eJ0̢-01Ń-ƪ02ĭȫϔ  ʃƧţ̃ő ƽ  segm\\xa0ŖeĄn4tϭΏɋι_ɍƭ1 Ț Ε ʔ  χ ͙ ˨  ǵΟ2ɻ\\nˆ2020-01-0ŉ̲ɀ3˾ ɔʨǗ ƪ   ̃ȷsegŁ̕şmeʍnt͑_ë1ΥÒ  ζ   τ  3\\n   \\n202ţ0-Ε0Ͳ1͉-ī\\x8204   γ R ͓szǨȲûegment_1\\x9cϹ   ρ   ĩȁ  \\x96ˤ ŋȑ̍4\\n#ZvozCsfXlbiYm\\n\\n.ʊ..\\n \\n20ɜ20ʄ-01Ę¹-˙Ń10ɢ  ΏƏ éŬ yǬ Asegmentˮ_Ɣƹ˺2 ũ ũ̧x   ̉ ĳė;̒  1͞Ƽ0\\n2Ƥ020-01̞ˎ-11Ý  ì ǐ V sƃƯΡˬĎegmɖent_2ÑΥ     Ą' 20\\n====Ϗ=Ɏ===¥ʹŐ\\x90=gN=¡===  ===ʧ===ˁÖϝ=ɋ̰ϑϰ==Ȝ==û  =þ===ɋ===ϑ===\\n\\n   \\n#GHVZcDUS\\n  \\n  \\nEǑͤxϧp¢ectedÚ fλƚorȯɽmat£ ofϩ csĵv with ex\\x98oǐ͟ƏgļeünŖ\\x80μous t̕\\u0380̂imύ˦es\\xa0ǚeri\\xadeκs:\\n\\nȨ\\x08\\n  \\n   \\n==̍===ɇŋ˨=\\x95ˉΦ==̲=====ϴ N˷ ȇ=========R== a ̀čơ?ŀƪÙ==Ͼ=l=ɠ=\\x8eƖë\\u0379=====ˇ===Æ=ϲɭ=Ə ǀ ====Űl====ŧȋ̜ʃΠ==ȋ=====\\n  \\n  ͳtɦiΪm<ƙȬeɂͣsǞtamp    s\\u038beǝgmen˨t Ȝ Ζȇ  \\x8eíϫrϖegÏre\\x84ìsėςsor_ƔΕ1 ͜   regǱħʞres̀sor_ȟIŎ2\\n==©4====Μ==ɯȷ==\\u0382ő=Ɉ\\u0378¢Fɹǎ==˱  Ŧ͊===̴Ͻl==ϧ=ďːǃĲ=====  ==,=Ϧ==Ą========ǿϱ==  ===ͤ==˖=û=Ȕƥ=\\x99=ʖ===Ϟ===\\n2020̀-{01ʝ-01ɲ ̈́Ŝ  segmentƚ_ʮî1͛  Ɵ  \\x9c͓ąĤ Ǒ   11\\x99   ͑  ȡ   źʠ ;    12\\n\\x9c20ʿńš20{-01Ζ̒-02ɵ   ͏ \\x94s seîsgξmȬent_1 Ė ʨ   ϝ ɽ  ϓ  22ɧɈ Ť Ċ    ̐¶ Ξ  1w3\\n2020»-0{1-03 ͗  ² ʆk sΡegmƂent_η\\x99ÁƏ1 ˅ ͼ ϫƯʲ   ƯƠ  Ǡ31  Ʋ  Φ3â     ̴Z  1ƌ͙4͡\\n2ȩéȀ͌0230ϲ-01˂-04ϲ Ľʡ  Ƌ  seʽgmentĵ_̢1ɔɱX  Ȏ   ƕ  ɔ   ɜΧ4ő2ˍ  ǐσ ϴ  ȸ̡  Äɲ   Şï ̰15ʯ\\n \\n..č.˘\\n2020-02&-10Êʉ  \\x9e ̰  seΚͦŁgment_2 đ Ǆ     101  şá  ʴ% §Υ Q   ʐ ͱϣ Ȁ61\\n2020-0Û\\x902-ʍ11 ů   \\xa0 s̭egm͡ent_2   ʜ   ʻ   2\\u0378ɶ05  İɹµǋ  ͐   ǌǱ     ΪΣ 54dǛ\\n=Έ+ˀ=Ș=ʸ=͌EɎ=====Δ=͠=¶==\\x8f  ==ϖČ=χ===̉==ϓɱĝ=hϧʿ=Ȣ= ˑ Ⱥ==ľ==ːͮ===ż§ΎFn========  IϹɳ====ŵä==\\x87=Ï==5O=ƝˀĚ==˶==ȿǲ=\", 'timestamp', 'all', 'timestamp', 'all', 'metrics.csv', 'forecast.csv', 'info.csv', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <3x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['segment_code', 'segment', 'feature', 'category', 'ƲFit enʅcϨo˗Ĺðderǥʯ ĮÄF¢UoȮřnʹ exisȒt\\x84iǡɁnĹgƍ sƘegm7Îent ōǓʛņlȰa͕ζηbelĚ\\u038ds.\\n\\nΚ5ͱĠωVÆ˛ͨϔ44PaΰramņȭetƂGers\\n--ϋʺ-\\xad-Ș̨--A--ȩ͏--\\n[͊df:?\\n\\nƂʘ Ŷȇƺ Ϥ  d\\x8eatafLʳ̌ðrˆameʹ íēwƠiϒth˄Ĕ˘Ż d˕ata ®σtő½ˢo ƅ͡fi̷ẗ́ labϳel eɾnˁêcϛodĔβerŅ.\\n\\nReht͘¸urƅÖn£Œʊs\\n  #BLmyWPsK\\n-ά-ǅ-ȗ--̭--Η\\n   \\n  \\n  \\n:\\nƯ  Ĺȼ  ŮFɾΊit̞ȔtȦed ̪trŞcašnɂsfoɶϯrm', 'segment', 'SegmentEncoderTransform'], 'from': [], 'import': []}\n",
      "{'FunctionDef': [], 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['__main__', 'data', 'example_dataset.csv', 'D', 'auto-example'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['gFÅòȐͶitƚ§̅ \\u0383HϨolŽϧ̏\\x98ŚƢidxay»Trʷ̍ansΡfor^m wiɦthϢ ldata\\x83 fǢĽǩrĘάρeˈǲō)o\\x9dm˳ɒ dfȡ. ̬DoeΓsȁ ʨnotǻh̥iĿnʭšg ýÉiİ̊nʍ tǖhiȀςs %ƠcasǛe.\\n\\nPđār˞aɑ˥mπe̖t8\\x9cͿeƞʷˡǊrsȮ\\xa0Ą\\nĽř----ɐ-?-----\\x9b\\ndfǹ:ü ȥpSdxΕ.ĭDataFŵrȢaϢmeü\\n Ʈ\\x93νɠ˝ ą Þ ͗võaoíǒδlue series ͊èţŢǙ˙ƧwɆΖĖiƱ?th χǸ͊iϸndȢex ΜcolŽ+ͥumn ͤiŲµDnɃǕĠ͟ ŋtȡimesta͜mƙp f;orm̴at', 'HolidayTransform', 'Transfoďrm Xdata from df̂ with Holi/âdayǝTrūFansɕform and gΨeneraƙte a cɣolu͙mǉn of holidays ˘flags.\\n\\nParameters\\n-ȋ--ϒ-------\\ndf: pd.Dat˭aFrame\\nϲ    ġvaluɒeơ \\u0383serieɅs with ϗinŊdCex˟ó column in htimestamp format\\n\\nReturns\\n-------\\n:\\n Φ  υ pd.Data]Frame with added˼ holidayĠsν', 'Frequency of data should be no more than daily.', 'segment', 'segment', 'feature', 'category', 'RUS', 'Create instagnce of HolidayT̵ransform.\\nȘ\\nParaǸˑmeterľs\\n----------\\nȫiso_cod͂e:\\n    şinteèrnationally rɣecȴognisPed codes, desɬignated to country Ȼ¼ϭfor which we want to find theŁ hȉolidays\\nout_coʾlu͓ƫmn:\\n    ˭name of added column. ĤUse \\x9e``self._ǲď_róƌepr__˗()`` if not given.'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <12x7 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 12 stored elements in Compressed Sparse Row format>, 'ClassDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': [';  Å ±ı       ˱ ˸    /', 'Expected k > 0, got {}.', 'Empty index', '¤  \\x80Ž ȱ Ό  Ť  \\x8a   ˍ ͓    ', '    Ɍ Ś ΨÒɈƻ   ', 'Expected k > 0, got {}.', 'Empty index', 'c    ', 'faiss', 'numpy', 'torch', 'ː  \\x8b˚ȸ   Α ƺǵ  ̶  ͳϗʂɴɽ     Α xȗ ȹ ', \"Can't create context multiple times.\", 'torch', 'ƥ ˣ  ̘   ʱ \\x81 ͞ ų͇  ŔÀ  ɶ  '], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': [' ͯŲ Ư 1 ̂īc    ̫ˈ͘            ͕    Υ    \\x8e ', 'window_size, window_step, expected', 'many_time_series_windowed_3_1', 'many_time_series_windowed_3_2'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <45x16 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 45 stored elements in Compressed Sparse Row format>, 'ClassDef': <8x8 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 8 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['WhαeŜˆĀǘ˪theèr mĖetȞƶriTc rˑeȌqu̺i&ˆΊΰreϜs pos¥ʦitr¶ϹivϨΧeÂǍ\\u038d scơ̒ĀorĶesl̳ə Į§»˃Þor noƼǭÙt.Ŷ', 'Get maximuɊmI nǁumbeWr ʩɳofē re]ĖBquɅŭ¡i˙ΎrɃeİdǊɨ ne1ćig̠µhboȻurs.\\n  \\nΠ#iMDOsgbvHCAG\\n \\n\"Argsˋɂ:Ğ\\n     \\n ͱũ ̴ \\x87 labČ\\x9eƻ˚ȇ̴Els: Da&˼taset la\\u0383be?ls.ǻ', 'W̄ŘhetξheHrƻ mŚơet²͋ƴrië\\x9ec requɞ°iǪƫres ó˯Ɩ\\x7fcϊoPʋnmfidɄ̜ŏŵ͊_͔ences ļoˇʼr0Ǭ nĘot.͚', \"CȒoͣmpute metric value.\\n\\n   \\n   #V#UIGiNMqmwtYsX\\nArgs:̠\\n    nea̓rsʥet_same: Binary labels oĩf neareËst neigĊhbours equal to 1 iff class is equalϻ to the quer΄ÓƗĹy.\\n\\n    nmeares̟t_scores: Similaritɑày scores of neaɚrest neighbours.\\n    šclass_ȃsizes: NumbeǗr of elemeˁnts in the cʕla̰ss Ɨfor% eaĜchϜ elͧement of theǯ ̼batch.\\n   ǹ positive_scores: Similar'ȩity sco̙res of elements with the sΕame class.\\n  ȉ  coƃnfidences (optional): Cɋonfiàdeǂ˧n̩ce for eĢach eleʓmenī?t of th̗e batch with sˊhape (ƬB).\\n\\nRetƫurns:\\n\\n    Metric value.\", 'Bas`e cl7ȋḁsĐ¹s fĘor allŠʓ nϹ¨˪yeaφresƎt\\u0380ɿ© nɨeigơͼh\\x9abɯour m\\x83ʉe̊ǲtric¸ϙǰs.Α', 'W¦˒ϗ˾̚heth˾e\\xadr ɚmetric rʍɛequiυres coĐnfĮțideχnǛces\\x99 oŜr n;Iot.Χ', 'RĻecaNɴȺllŵ@KϺş metric.', 'Getʶ theĥ nōŜ=ťumbȖeßrɈ Ƴo>ͣf ɾreÐqu˅iredȫ neżĐiϫƮghb̕ourʟs.\\n\\n \\n \\nƍArg°sɫ:Ə̅\\x87\\n   \\n  ϼ  ϡlÂaǄbeµls: ģDaΫt^aɿset laʓʺ\\x8aΞbels.', 'CoȆmƓpȁȦutŘe ̘ŷƄͽmϟe˃ʾ¸triɳϔc v˼ͿÐ3aluĜeġæΆ̓ƓȻ.\\n    \\n   \\n\\nArgs:ɽ#GvmMTSd\\n  Č̊ƾ̰ Ȋ ¬nearse\\u03a2tʯ_ǖs΅͗aƂϊmeϩ:PƂ čBinƩ̋aưƊrĊ¡yƁ ěɱla̵belϽsƕBĿȥʾ Ͳofæ něea͖reνθϼsɫt͗φ neiΎgɤh͵bţo˳ur͠sƹ ŜeqƇΘŦuώa˪È̍²l ¤tώsϿΧo 1 ifƧfŅ cla͠\\x8ess̿É is equ[ϸâl Ȳto the qõuerî7£yŽî.ί\\n\\n    ėônearƟestϭŻ_\\x9d\\u0381ɧscores: SiϺͫmilaȑritǕyϊ scorɯesȭ of Únea̕reΒ\\x85ʜst ̺ƖΩ´ÔʰneiƄǫ͙ÍghbouǲſrȨs.̮\\n \\n ϩś   ˛class_sizϏÌĢ̏es: Clʍǖass sƾizͷe foɗr ǤèaƱch ρȎËelement.\\n\\x87  ǵØ [ positőͽive_scores: Ì˝Sñimilȃa\\xad\\x95ri̤tãyĄ scoɹƄ˝res ̢of eļ˝lemʑˤʍkent˄͛s wϷi~tȧhͺ̐Ύ [the ʭʑsa\\x82mˋήe6 clϞŸasȒs.\\n   \\n #t\\n  ̦  c>oΈ\\x96ŝΒįnfiF¬de˗yncǬeƚŸs (oǰżΐ͂pƄtiǉŉȯn\\x9eaʦlȧİ)Q:ǼG˖ ȂǶCɚonfidenI\\u0380ȶǲce ƚfor żeac§h͇ elǓeQmċenȕt ɑof thμ;e batcɡhȐȵ̎ ė͒Ϯ̻wǿ\\u0380itWh ́shapͽe (B\\x92).Ô\\\\\\n \\n\\nįȶRɷetˇʖurns:\\nŦ ǅL˿  à ƕǤMetrƮ˺ϱicΣ ƾ\\x82ɧțÅÿɋvaȁ\\u0381ˬlue.', 'WŪhe˅thʀer mÈeĕtđϛȀrȺÏic ƱŤreeqRuiÕ˷reǁs\\u0378 co˫«nfiȓdĜencˍes͖Ǻ or not«\\u0381.', 'EárroǾ˭@rϊű\\x99ʶ-ƨvºeͯřsħus-ǈR\\x90ejϗecĤϨ϶t-́Curvʤeɍư baʽˡ\\\\sǢed Εỏn RecJƟalkl@K Òʽme̠tƝǶr\\xad˕ic.', \"Can't compute ERC without confidences.\", 'WhɛˁŅether meƾtĮriʒcʣɨ ±̐6rĶequiύres poɀɹʨͩsç˦itive ϰ˹s˯cȆûores\\x9f orǩ not.', 'Comp0ute ǅmƈʡéaximǝu̙m accuraV\\x8bc!yȹʺͰ \\x99fǼor R¸@ˍ1ğɾ pŨreḋėicytĝio\\x96n froǙmƛ coɫnfidence.,\\n  \\n     #rtv\\n\\nNOêT¹ţE: ƻǱD̹e͐cȡɀisÀi©soƟnȵɫ¥ thƊr<eŉs̃hǫ˚ɬoȜld \\xadisƸ aÏdjʪ͒uďsteΝʶd[ξd usϨing\\x9f̪ tes̏tṣetȣV.Ǻ̜\\x8cŤʚ', 'Whµ˔eɂȑǐïμth,ň˥er ̌˗ìm͎etÃricϋΠΡ Óˑ̥rŒͤǺǟeqpu̓irȞe̖ţs cͥoƪn̞fŬidɋenǨcϹes Ȱoɥr noæ°tiʲ.', \"ʐCǊƼ̿ouɋmƩ̀put`ƽƜͿƽe ŷʑͪƨM\\x85AǬǁP\\x8f@ĸ̫\\x94R.\\n\\nArg͠ϴɉ̿¤s:Ŀ\\n \\n    nɵeȽ\\x7faresƗƚt\\x8b[ʵ_ƺősame: ɋMaõt˔¦˴chźʺiQng labelsƅ for nλeʮʈa˘Ʉre˜˫õsʹɳt̐Ĉ̢Ƃ ŃnzǅeiƎ}ghbǲȇouͺrƒŖsʗĖ ˴ʁϥ\\u0380wǲith shǪap·ȎðΞée (B\\u038d, ʮͻ§RL˜)ȩÖΤäǁ.ǈ\\nϡ  ϗϸ   ő  ͘ɚ M)łǓ͏͋at`cʿÏhesǰ ǪΖȦaʀ¦χroϧǳľeξ coω˳ded wĝitƧh ȟ1 aĺɃInd2łʜ mʞis\\u0381ma̙tcÇęhċes ûwitϳhʳɧƥ 0.\\nĭ  hƦT  ȹ¿nea˰ƁʓʾȖrest_ȵ\\\\s̨corɢ̀es: ȧ(uÛî͚nέíÜυuseǢʮȢʡdǃˍø) ¾ScΩʧofr˃͟eˤ ×Efoƣ͜rʉǄʑĊ eȸÆacθôh nΪeiŶǚʵghbŘouƷ\\u0379rɁ˱ ŃŪÕΌwiĤṯŪhrǅ shapͦe (\\u0381\\x96̼B̽ɟȨU,ʐˇȶ ̪RˎCÝ}).\\n\\n   \\n \\n    \\n>· ϴ   nuȀm,_nΧβeȗarest: ΉņˡΩΒNϞuŭmberĢ ̃ofʮ ɔË͆neaļȍ?res·tȑ ¹ƉneigÑhbīțouπȗɶr̈́Ƽs ͉fÓʌęȪ\\x8eʟ͙orΨ geȳa̴cΤĲ͝ϛǓhɠʡ ele0ŰΜʶmeΘŬnt o͒ƴf tɯhʺeŪª Ϗbatɢch ̖ʁ¬wi˳tβΌȟˉ ɸshņapǈ̩eÛ\\u0379 ÿ%«(ŗǣB).\\n Ŏ  ΐ ʩclass_sΉ7ŶͲ¤izǏes: (ǣɘunŭƎusθeldŲ) ˉǄşNuȁmȞ|ρź̓ɠber ʤōoǀ˭f eleθlǜmƲeɕÍntȲ,W\\x99ǹs yi̊2ntɭǙ tɗhÍʰe clǘass foöɘ̈́ƇϹÔĐ̕r eωςach eɚlreme̊ntχ of ˮthe bãatǠchØ.\\nŝ  ʭČ  pϚ\\x8d·͒ȗoƩsĐųÈit˶ŔǊ͆iȫŸvŞe_score͋ϻs: SΕiΖźmi'lariťty ςȀFθĈsƍc͆orʨesŕ of ͇¾PeϪleʱŰmeʝånts wiχαtËιmh įɭthƩe sUėaÃĤɏɘme clasŉĊɎsϥͳϥϬˠ.ƍ-ϡʏőȇò\\n  ſω  coȖnǥfΗiɳdЀɯeϋǽºnceͧsΫĶǫ (ØopŽtʣ£ioːnal˭)Ϻ: Conˍ\\x92fȦiμ\\x92ͽde˫nǏ̵ϟĺce\\x82 ʁɍfĚorʼ ʒκeƢaŒcʓͰh ʉ®̚el}˼e͘˞͋K\\x89ʖ˙˃ǥʇm˵e̘nt ɂỏf Ϣthe öƢbatcέḩ ͯėʞwiͩʀ˹͌Ȭthɒʽ shȿϵʅ̓aÁṕʣĦǜIe+õ (ƭB\\xad).\", 'ERƮƧˋĳC curğvƱGe for ʯǱMAP@Rƍ mΤʣeʿtric3.', \"CoΪƳmp̕uʡ+t'e MAP@Rj̜ ERCČƟ>ǥ.\\n   \\nś̆ɒ&\\n\\nAƄr\\u03a2ɳgs:\\n    neȋͻarØʜ˖esϯt_sȜöaĉ̥Ċme:ŭ ȅ˺ŤϸľʹMΙaɞƦtϘch¹in̈́Ȩ̇g labϬe̕ŘʴlΘƽs ffor n\\x8dearesətϤɦǮ neê͐ighłbours Ɖwi˓̆th shͺap\\xadeò Ȋą̖(B,Όϔ̫ ǜR,ɻ) .\\n    \\n    #YziS\\n \\náȽ ɋ \\u0382  § ͭ   łĴ$Match¿esŵ areȪ co÷ŋ͈Ŭ̪˕ded& with% 1ɰ ƻaʚn2d ̒mƝư˾ǴΣiɡsmatÔcåšΦhesƚ ʋwiƫŧtǅhƵ Ɵ̵0ɘ.\\n    ͇\\x80n˅ețǗaFresʰt_sɈcoǕreʜƀ¸Ǟs:ɞ \\x84(unuǭ0sGŏɣeȎ\\x9fϲˎd})ťɻ SαŰϰcoʶϾreͭηğϪɐ ̇foϖÛrΑ ˂úeacœháɞ̹ˣƀĆ ne˘\\x88ĴigƊhbouǔr wŌFitΛh sɠh͍ape (Bɪ,ĚÓǵȶ͌ Ūķk{HR\\x85).ɰ#JMDlmQjtUwXvbEp\\n8˭Ĭ    numaĠ_nô\\x8ceǖaresƋt:u NȃumʻberϚ ȁͥo͊O\\x85÷f ĨnɌoÚeȧresχȑt ̘ʘnei\\x91ΏghboěùĐrĔsd forΌ Ƈeaɟ\\x7f̫ch\\u038dμ eǼleλmšeãȶnt oİͻ\\x86Ȇfʼ t̹he˱ bϓ´aÂtcŻΥ̮hȾ with sʶhapeI (B˲).\\nθͦʀ    clĶ̴ass_s9iz͏ẻs:ͱͱ ɂE{ǋs(uànusζMedȺǍƕ)ˌ\\x89 ͈NΰuÒmǖberˉ ofĩŚjʄǯ Źe͖lÚemζenŒts i˽ªn ϐtʭ̰Ųheƫ Úclass f oǑsrʝ Ŷǿeacôhʩ ά»eǬleͪźmσȯxen\\x85tĀŤ ǆofÑ th\\u03a2e bʆatcʔhЀ.\\n˱   \\x83 p(ositiϋ\\x90ve_ɶ¨Ǥscoźrģes͙: SiĽʞmÂilarʊiǀty Ć\\x81scäorľĊ\\u0383es oϰf elU˗ƧżveŞǬm˫ʬτen˝t̀ͳzsȲǄř \\x8fwith \\x9cɹthe sÄ˸aƍͳəmeƍưϜɰ Ģc͠ĺƄΈǗlüass.\\nϒ  ɘ(  confidencesáß (˯opʁt>iođnaǙɉl):ʒ ĥ΅CƖǩ˂o;nfi̔Ͻ͝ϔdenϸc̭Ϟe f×Ǐor ȞeachΫͿγ űeͅŅlǶemeƱŵ͓ŇÛ»ĂnDhɢWtf ĳŚof theņɄ bŉ6ŞaΞřtch wϺ̮iǊtǢh̖̿?ǵĒ ǈůsĞhaOpʷʣåe \\x94(BĠ̂˜)\\x84ªΧ.ú̝\", \"Can't compute ERC without confidences.\", 'recall', 'erc-recall@1', 'confidence-accuracy', 'mapr', 'erc-mapr', 'mapr-ms', 'torch', 'torch', 'backend', 'broadcast_backend', 'metrics', 'prefetch_factor', 'recall_k_values', '  Ϳ  ˳  Ǿ\\x8cȇ2  ɐ´n  ϊ ȁɓ   ʲ ', 'broadcast_backend', 'torch', 'torch', 'numpy', 'Unknown broadcast backend: {}.', 'Number of nearest neighbours is too large: {} for batch size {}.', 'backend', 'metrics', 'metrics', 'recall', 'recall_k_values', '{}@{}', '\\x98FindŘ nωƝeÐaːȝreİΔs̴t n\\x9eeõighboȴurŽ»˯s fŐo̕r eaʯcŠͫøƱh eƎDlľeǘmǺÏeˍnt͘ oĀfƲʏ ƾȳūthe ̢bƷatϹch.\\n˪\\nStagƙe Â1. Find êeͲ¬ɲˡl`ú˘emenͲʞːts ȃϞÇcl˃ose tƞȢ͌oŶÐǑ quϞeʊrẏŞ ɱbUĉy LɅ2̶ƕ. N͇eare˟stϤ ̝nŐeigǷhb͐˜ourȜs aręşe ɩ̍sƶȶńñeʂažȋΗrΌcƞh_e¯d\\n   \\nfor eŰ̓aÆctƿhǗŰ ɡdiʅȎstʉrįƜīϢi\\xadͬbŎu\\u0383Αɹɬátĝi̸on m˹oĺd˒eƉʑ͑ ºʈinǙͥdȚepe͵ndentƶlƚÀyã˅ʞʐz|ɋ¦ƤϤ\\x9eɢ ¿(iʌn ϭˢmuɏϓŹ6lti-϶mƙĸ˕oŊdö̕ǣal Ϟâ̻ʹɡϵseʠt̋C¬òup)͕ǷΞ.Ȫ\\nStage 2. R̾8e͞m\\u0381oǩĩÅȕƤvďɄeɠʐ dupȑõlic5atQ́şţe4˔ķs M˨ca͌usΩeý̥d ͱb«y crŝȈÜŗyµ\\x89oˠsêʫs-Ζmodalźũ ˛Ίm̃inin9\\u0382șǈgȨǵ ťĆϣŗiȣn\\x84÷ st΅a¾ʌ͎Ĺōge ƸΎ1Ðŧ˔.ɒƁ\\n \\nStĿag¦ȧeƣȒ@̯ 3ϤĲͤȀ. ResceoΊ\\x81ļɿrŞeɇ Ʀneaͭreɤst̙ ΈnºeigțhbouĪrϦs u͚sƐιingÊ sʉÍɭcƯʓoǋ£ÍrƃeЀr.ǧ', 'prefetch_factor', 'broadcast_backend', '     ʏ η@  ǉ p   ΰ   ̝˺', 'Expected parameters matrix.', 'Batch size mismatch between labels and parameters.', 'broadcast_backend'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <6x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'ClassDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': [\"ύTŗƮr\\x86aÜnsfɲorm that uskes :py:fƤuncα:`~λet-na.analysiìs.outɎ9liʈseðr Ǟs.median_ou̜t˼lie̟rs.getλ_anoɫmalies_medianÚ`Ť t̜o find anomaĥ϶ȩlΣieùˊŶs ȝƹǐinɳ data.\\n\\nW\\u03a2aϔrninæg\\nƹ---ñΡ-ɱ-Φ--\\nThis trɸansf˛o¼rmȟ can #su(ffe̯r ĳfʉǂr͔om looζk-ahead bias. Fo˔r trɷʳ\\x98ansforƔminΊg dĊataƝ ĖĘat some ͙timestamp\\nit usºes inˬformatŴ¸ionʗ fromU ˚the ẅholȭŖɗe tra͕Ưi'n partü.ɬ\", 'Calɜl |:py:ɬλfuncn:`~ͽēetκʤna.aȬnal͔ysis̥.oƥutlierrʯȵĞs.mediaˏn_outlieǁrʒs.ʂg͵e}ÝtˎƔ_ƣːȥaͺn\\x83omɻaŇlies_mʩeǄd͜ian` fƪuncoBtionǺ wǎȍƉitȭŢh sweơlf paɼʛraĀmetǭıers.ʤ\\n\\nPŏͷɽaraʰȘmetνers\\n-ȎĚ--ʳ--º---Â-ξ-|ķ˽ě\\næżIˑtƟ*ĕɰƊs:\\nˉ    Ʒdʻ͍\\x95ƆataƣsetƝ tĚƋo pͫʢ>ǘEroc!essY\\n¼\\n\\x84ǏReturnϐʈǧȤɲs\\n-±-̪----ͦ-\\n:\\n Ñ Ȼ ϰ dicȸƑëtÀ ofĒ\\x9e˫ oʰuɹtliǝers in fço\\x9frȓŁhmʷat{ĸĸ \\x8eđ̾>{sĒegment:ń [ouθt͡Ȕ>ʖliͶerĖsϿ_Ƀ©\"ʙtϜimôÕ͝estĒamǪps]ψ}̍', 'ȯȜTransform tϖƚhat usʡe˺sʻ̓ :˻py:ƏĤf\\x8dunc:`p³~Ġeʎtna.a°ǯnγaléœysǂisʬ.outlǸiers.ƋǺȇìdensýɫity_Ĝo̯uƒtliΡ˓Ϣerŝ.ge_¢̲tˣ_ĈaSnomaɯ̻lieËs_density` \\x9atǫİoϋ fin·d ɑaυʽʕn̡omalies iϹƦn daȜtaƠ.\\n\\nƈψWarnƓingơ\\n---Σ̊-ğ---\\nThis tra\\x91n\\x87sɚƔ\\x94form´ caŘn suȂfˉfer ŧȦΠfrŹom lookΗǢ-aheaɎad biŊas. ËϙɜȒForȀ>ʾ tǋɻraȎnsfĜĮorming daɑt˪͊ʹa ^Ƶaėt;Ʈ ʨsomNe tiƚmestaŅΓFmpª\\n˺i\\x9et ͠usʴeΖƨs iξnΦfoɵrmöaʪt1ȇioͬnΥəϒ fromƲ thʊeμȎč wholeƲŌ ΫĨǯt϶raǐn˛ parϥȾt.õ', 'Transform that useLs ͘:Ȍpy:f̋unc:`Ό~etnůa.anǂal²yßsis.oϬ˭utlΣiers.ΈǘpϸɶrÜedi˟\\xadction_interɏvɫaœˏl_oͰuĘtulieǣrƺs.geítǂ̡ʯ_ϙŋųanîomͲaȵlͯȋies_preæƨγĲdicʖtˣion_ȕɈintervʥal` to fƷind anÓomal\\x9dies ɱinϴ data.', 'ProphetModel', 'SARIMAXModel', 'ŭƺͣCallɁ :pyǶG:funƪņċǹ)ĔcƮ:Ƥ`V~κetnɫƢa.aΣɞǪÕȿnÿa˜l˙yȫĿsisȾ.ÑÔo\"ýuõtlJɄǂierβsĘΝļǾ6.pʹ\\x7freƏ:ǥdiνHĉcɬtiɌĝȗon_úint1eȹͭrvŘaČͻtΖl_oŅutliersǧ̋˟ģZ˨)˦.ʦgϕébt_ano̎mŌħdϵ\\x92al͆io͌eŬƸȜs_pƳrŰeFdiǩ¥ƈBctɊΝŒ¯i7̞ȍM}ΑʁüoƧn\\u038b_˓ʐϭͽɎiŖnter̞ɽƖ/čvalļ` fˡůʴnctƘio\\x9cæ\\u0382Ān wæiŜth seʆ̠ǶͭlͿf ͍parςaaƵmeʡœte^Ϊrs.\\n\\nϧ̽ŭPa̓raǂˡÇmƠeǓtersȭ\\nĂ---υ--(-Ǳ̱ɸē/ɑ-ƹ-î-\\x9cϷ-ɀ\\n͔tŝ̉̂ŭs:\\nʱ  ƅό Ȯǣzĳ ɝǏ\\u0379ͽ\\x95ƀ§\\'data̔ʖ˧set toĪ ͝pΏ̏r¯oc\\x8e͂ŋ;essü\\n\\nRäet̗Ĳuųrğns\\n-ʫƓʟ---ʡ---\\x97ȴ\\n:\\n   JŢȗƙ éǢdiȀ9ct ϥoáf ÿϛūou̕\\x8bˮtőlieϴrsd ƾin f\\u0381ʨ2ʕʦormat ɬΣǰ&ǀ˸{sɵegmȩnŚȤt: ǳΪ[á\\x9a˫ouĮtlieǷœrēsǮ_ktϻime̦stɐamps]ϖ}ˣƜɅ', 'MedianOutliersTransform', 'DensityOutliersTransform', 'PredictionIntervalOutliersTransform'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'ClassDef': <1x1 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 1 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['Tȼ(eɉs̮t metʒ<riçs +iŮnɓ ˿̧simp̞leτ́ ϮcÞzaseͮsĎv.', 'fpr', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <18x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 18 stored elements in Compressed Sparse Row format>, 'ClassDef': <6x6 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 6 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['CoƺmėpĔļare M̫tˮǂw-Ĭoϗ em͋beddings u̡sinȌgǅ ͚siƙmilaȚ÷rĘȬiηty\\u038b based on ȪeşuͻclUʎĭ̶ǂideƛǮan̓ diɍsZtașn\\u0378Ϧce.ϰĄ\\n\\nAΆ͈űrgòs:\\n    ?õdÁiȎsɓtr̿iͳbut&η˘iĎoϔn: DĴistǮribʍuʮŃȬtionōw «ucsȐ̅ǆe]dƼΨ in\\x8e tȦhχe m{ɮo͋dÉel.\\n\\nξˍÛInϽΧÆǔp˪uɿvts:͡Ι͆\\n̵ĸȱ  ͅĪʆ  -ΆűT ÅparŤametZerǤsÉƶ%!1ȟ: ÙF\\x94ir͏å͢stŗ ǄgΛĜʃroupʋÇȠ ŚofǏ Ȁdis͚Ρg~ʘCt̒rib̹ļutŒioŸns wͿiǅt9h shea϶Ȉŭ\\x95pe ˼\\u0382(.Ù.., ˌKϜß).\\n\\x94 ǳ  ĥ -\\x91 p̨arametOƊersë2:ωΑ Seconͺʾd ˭group˸ of èdȠistρʒribˌutiŭʄoͥnĩs ųΟΜwȷǅiṭh sʎh\\x83ape υ(υ̻Ό͑Á...Πǌ˔ʤ, K).Ͻ\\n\\n͓<OǸuʵtputs :ƞ\\n N   ˧Ϛ-Ƀ s̘wΠ̲cores´:5ɏʢͮ ƐķɮSimilaòʚηűritŞuťiƜʂɐesĲϋË with ˒shape ɽ˴̉(ƴ..ƛ.ȝ)¦ň.', 'ǭϼD   ώ  ʝǵɊƏ°    ', 'Coǰm\\x82pare tw˵o ĞeʀñmbeddiǷɐngsɐ using dͩot p̫roǎducta.\\n\\nA³rƲºg_s:\\nQ  ēζ ˪ distribžution: Distributioɍn-ƨ usedĞ̉ ¸in the mǉϠƇ˝odš5e\\x9al.\\nŅ\\n\\u0381ЀInŸpǉutϗȯsɅ:\\n ´   - paͫramet¡ȴµerύs1˾:ǉ Firstθ΅ groupˍǍư ȩoƿøfH distributiāons withH shaÃpe (.ʠ.., K).\\n    - pȏarame/tersʣ2: S\\x7feɠcond Ȁégroupέ of dʓist̨ΜribuŝtiŊoɁns withK īshape (..., \\x8cKȹ).\\n\\nʒOuϮtώputsÞ:\\n    - scores:Ϊ Similar\\x7fitieʎsƯ with shδape (...).', 'Compute useful statistics for logging.\\n\\nReturns:\\n    Dictionary with floating-point statistics valueͧs.', '̅Ceom˙pŻaɳϫre( ʅɧtwϓȀ\\xa0to ±embeʆddύi<nĀgsʓ\\x80 usíǶnˊg exÁpͣ=ļȭectǾ1eɡɚdϝù ̆@ȄcǸosɥiýne simil½ƄÖ̃ΜÑʐaĎwɥ0ÂrϹͩi¥tyƚΕ.4Ɲ\\n\\n\\x84Args:\\nĺ υ Ͻ  ˻αdisǠ̾ǶƲtϠrĹÃiãbu\\x8eß͌st7ion:@Ǝʉ ɽDȺ\\x89÷˿i&sűtr¥ƴibu¼tʖiǱo˾n u\\x8cs˼ŀedŃɓ̙ in ɀthe ¥modeʠlύϸ.\\n&\\nʈInɪpʩuts:ʻʢ\\n   \\x93 -Ɓ pa˒̆Ϥr&amêȇϾe̛̓Τµtɺers1:Ƣ ƖFirstť: Ň¹grȱϋouÓpƽʯ oŴf d˲istÍribÜʷuɱtoions w̱ƒithλΰ˺sɩ̩\\x88ÖϿǢ\\x7fȥ shaʨpǃe (ē..˴.,ɃŐɟ ͣ+K)įƤýȸƾˣļ.ć\\n Ƭ ÈʔƼGĿ ;\\u0381 ȴ-¨ paramȹďeˉtȜeȰrsǈ2ˠœŜ: SeǞcɿ\\x81on¨Ǆd ðr͛\\u0383group ǧoρřf disr ͝φtͳʸ˹ȨriˠbuġɟtǼ̀ions̝ʕƞ ȗåįwith ςĆɫsfh̏apeƂÍ \\u038dɷM(..Ĉɻʇ., ͳKΙ).\\nΎ\\nΌOut˭.puɰ̰ʩȌ¨ʶts:ɾƾτ\\n    - ȂͲscϲoĄʭrʉe̒ʓ͇\\\\s: ƥS\\x9cˤi̩˴˛milͣarʩˍitϵ\\x88ieǝs \\x9d͛Ʌwithĵ Χɴsɂhapͮe ·Ƣ(...)Ńɮζʊ˭Ȯ.', '    h ͢ Ɏʭ   ĬǺ  ', 'Compute ȹuse̅fulϾƓb˥ staϋtiŹšstic̄sˡ for± ΆloȪggćiĪnųg.\\n\\nQReturÊns:ƻæǣ\\n    Dic̆ti\\x89onary͔ˍ withâ fÀlo\\x97ătinåg-ṕoint stͻa͒̋ßtisticsʝðª valuȠǐes.', ' ɬ ɢ ', ' ', \"Compar\\x90ƻeɓ two ˑe\\u0379mbǋeddings usðiȫnǀge exipeǬctatiƭon ofϙ L2 sυiΦgmošid wÓƢ\\u0379ϕɣiʧtƯζh ÊβtͽɅra͉inɍŠ´Ja˷N̙bƭlǩőĄe scʭϱaοliˎěe ņa\\u0378nd ʃbǉi̖aɹs.\\n\\nSʬcϭϘƭorer Ħis Ǳuͱ˛ʈsedÛ ˚bš͚Åϟyƙ8ɷ HIͦBǤǾǮ: h\\u038bɧtϯtpǂsΎõȬIʘ:ƀǢ/̞έ/a˝ȗʂ˼rȽxǏiŢ-ƎʒƄv.orgʀ/͊˅̬ɐpɵd̈Ŀf/1˨νş8̥10.Ļ00\\x80319¦.pͣdf\\n\\nAϚrgs:Ɗ¨σ\\nɜ,y  à ŕϙ ƚd˧Ǔɻϒi'strŉ\\x9ei̠butiŗ˝o|ŴǑn: DistrʉiΊŕbutēioȱn ǘƂseʫȦȦd in¥Ϥ tχh̜eľµTȉ modÈePˏïlɋ.\\n\\nƽ̐Inputˌ̕sϞ͊̄:\\n Ď ħυ  Ǆ- ΆparǜάamUetʽ˽e¦rs1ɯ̂ϩ:̏ First ζgro͠\\xadÖ\\x9cup of di˱strŘi\\x83bƄͦutΏionsÀ witΣʯh shape (¥..̈́.êċ,ϲ ƞK).Ȏ͗\\nζ˯Ⱥ ˍ  ˋ υ϶ʹ-Ϫ p̿aͶ˼ram̫et˺ers21ˏ̰: SeƔÃcoSϿndœ groϚup ofĐǧʽ dʲidʊs˰tmriǈbóƹϧuŹtiɍŏonsΞ ÿwʔit«˾Ôh ϑ˕ǝsïhaîΗpϗĴe (I..ǣ., KξãΎ̗¯˘).\\n\\nOuʾtputɦsɏˆƊ:̳\\n    -, sç3orʊesŃʎ: ȃSŔ̩ïΪiƴm˿ǂilariti$eϱœs witϼ·ƙ\\u038dhĲ sνϧhɻvä́pȶe ɢ(...).\", 'CompuŨtΊe useŲfuʼl sϫtϻΝʻatist\\x96ics Ƴfor ƅĦlǋogg˓iüngͽ1.\\nû˧\\nƼRetɦuƶrnĂs:\\n̂ Ύ ë Ȓ DiΛcǂņtioĚna˺rĀy wiωtcƆ̶ψhé floaãʝtοiǸngǐɢ-pϟȝointôɯT ɽsϼtaǟ́tisͪtĺiɉcsĘ vçalueĳ\\x88s.̀\\x9a', 'scorer_scale', 'scorer_bias', '\\x98 '], 'from': [], 'import': []}\n",
      "{'FunctionDef': <8x8 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 8 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['          ·  ̳ ξ', '2020-01-01', '2020-05-01', 'timestamp', 'segment', 'target', 'D', 'Check that͙ all ήthe series are diviƈdeýd to the clusterĐ\\x8fs saccording to mu\\n #LujxUg\\n(inƿ c\\x8case of number of clusters isß equal tγo num.beÃr ͵of different mus).', 'cluster', 'expected_mean', 'cluster', 'expected_mean', 'min', 'max', 'mean', 'min', 'max', 'mean', 'max', 'ϰChΠeck thảt dtwŻ ƋƐ πɵ̪clΪu\\u0382steͪȦring w˳Ț@orĵkJs.Ċ', 'cluster', 'cluster', 'target', 'clustering,n_clusters', 'clustering,n_clusters', 'Distance matrix is not built!', 'clustering', 'Test that HierarchicalClustering raise error when calling fit_predict without building clustering algorithm.', 'Clustering algorithm is not built!', 'clustering', 'Test \\x83that ƤHiera¨rcʉhicalŊC\\u038dʒluϬsɬǬνteĿr&iˈͩng ´rʿaiśƾe errorǵϸÆ w̽ͅheŕͶn ̃calli̢̓bˎngͻ gäzet_centro|ids ǓwitGΗhoȏut ͇beÒing ɉfitÏ\\u0379.ɵ', 'HierarchicalClustering is not fitted!', 'clustering'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <29x27 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 29 stored elements in Compressed Sparse Row format>, 'ClassDef': <3x3 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 3 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': ['separate', 'norm', 'default', 'scl', 'separate', 'invlin', 'default', 'dim', 'k', 'parametrization', 'max_logk', 'logiv_type', 'dim', \"Compɲut\\x8de pr\\u03a2oduct of two densiļties.\\n\\n \\n\\nRϹeturnsȯ:\\n  \\n  TĒύuple ofŁSŖ new5 d̸sistϴȃˡr\\u03a2ibˬutioɼΤn cvlaĠ\\xadss 9andrːΝØ it's pªaramˢeters.Ɍ\", 'dim', 'ĕʮWhe˟ǲwϳίth˜ʜΘƈ͡ºeλΆrʭ disʤtrǴTibutionȠ ˦has͈ buĲϣΊìlȢtˆŁi͈n confiΥȺddeù¼nce eϢĲsti̕m˱vatɷio,̥nΤ ɨoȡϫrğƈ \\u0381noǆƜt.ȡ', 'Sa˯mple Ĕfrêom di\\x84ɹstribuƳtionɞs.#TuZjbiIAXelHExpSD\\n\\nArgs:ų͔˦ʍ\\nȘ   ͼ par\\u0378ameteìrs: ÏϒDi˫st̡ribution pͧZarafmãǐetersǗ ϒw̦i˶tƻh ɈǼʍshŚapǫe (..., K).\\n   \\n ò ʿʒ  size̝: Samǵple ͥʛsˍize (oȀuǍϐĠr̋tpİǺutƧ εsήha¬pe ƀʠwiχtho}əut Ą\\x94d͆imension). ħParameters Ųmust be broadcasƖtabʲl͐e ͩto̦ thˈe gɠʳiĥȢvenʎ siͣze.\\n   Ñ, ˘Iʱf not pɸroviΡdeúd,Ă ou͈tͦƨpu%\\x7ft shΙape willƣ be\\x99ȯ ʐc˕onŰËsi\\x90stÑent wiˉ\\x85th pʎarameƟte̵rsΕ.\\n\\nReturns:\\n  \\n   \\n  Tup\\u038dle of:\\n ƻ Τ ƭ  ͡  ɇηŭ: -ʷΚ ͼSamples wɽilth shape ǿǂ(ď..., D).\\n   \\n   \\n \\n Ǉ     -b ¿Meaǈɷns with shape͉˂ (ʻ...).̕', '$Loːgçɒarʨithϱm ͺoΕf the unǾitƖΜ ǶspheɤȡŐreλ ϫarea.', 'dim', 'Eɷxtract͔ loŉƒg˳ ˜ϋpr̅foȗbs̰,ǔ ̋m\\\\eans Ǟńan\\x8fd˼ ĴinvǍKe͘;rs˻e kɎ hf²r˼om paàrameterŐs.', 'Wrong number of parameters: {} != {}.', 'dim', 'k', 'k', 'k', 'k', \"CǃͅomģpƎuteʴ ΒuseƼfulƯ statϔÏis˳tłiźcs foοΧrȫ lµɐo΄gʄgiƕng̾.͜\\nȯ\\nĞdAͶŰrʧgÇs:Ă\\n   \\n   \\n \\nɥúƒkα  ʥφparamŚɳetώ˵ers˘º: DistɌribÿuƁƭκt+ǮɈʝiĆon pˇ'ǐ̒aʧrǩameȹƆt\\u0381erͻsLδ ˿wWʋ\\xa0iȼϲþth\\u0378 shaɗpùˆ\\u0379eʶǿαǾǑ (.ōŌ.ȻĊ.,ɜɵä ̟žƉǇK̑Z).Ńơ7\\n\\nRϤʈetiuȥrns:źɐ\\n \\nĴ  ίǿ¢  ǕDiȁȴ͢ct˱\\u0382io˿˃nćσarƢy ĒwiɅth ̓f̨loaɾti˘ng-Ĥɿ\\x98pT¨oiɅnt sptaĎ¥ɊϘː8tΒň\\x8dϱˌis~tȴicŰs œŭvalȕğuŗesˉ.\", 'vmf_sqrt_inv_k/mean', 'vmf_sqrt_inv_k/std', 'Nƴuǋ\\u0381mbǁer of Ǻʱd̨ϊȎistàνΊ˄riÄbuĿtion parˎϞaū%meute̷rs.Ƶ', 'dim', 'k', '˱ŸRƘ̙etãurnsϼ diϣNc\\x9dt wi3̽\\x95thbÞ Ɣʐdis͝ĔϋtribΗution ̟parɝameųqters.Ŗ', 'log_probs', 'mean', 'k', 'dim', 'k', 'Whˎ͍Ѐɪǌeʶ̓t̘heŷψÛ\\u0380rϙ dE^istri#bʲ͙uti\\x9aon ɱ`is on sphĠ̖Ŧe̮ȵreͣŜ oˣrĺƉ˟ ǰR\\u0383^n.ͮ', 'ComÎpȫute L˙og Mutual Likelihoodǌ ScĤore (ˍMLS) fo,ǼǢrÔ ̰paȌ˄ȇiŪrs of\\x9f ɷdistϽrŘibut{ions.\\n\\n\\n\\n   \\n̒A:rgsǓǼ:̈#ZMwpi\\n   \\n \\n  ǹøϢ  Ŕ˅parameteǝrs1: Di̢ſßstribuʩt9ǿion paramΔ\\u038dźuet\\\\ers with˷ sh1a˘pe (..., KΝΎ).ͳ\\n\\n  Ŀ  paramet̳le͂rs2: DistɥributiΚon parƙamºeters with shēape (...,Ŧϩ K)ò.\\n\\n   \\n \\nRƛψeturnϨs΅:\\nǓ   ̋ 0MLS scǻores \\x83wϼith sˤhape ǰ(.ϯ..).', 'dim', 'dim', 'Feature space must have dimension >= 2, got {}.', 'dim', 'k', 'k', 'Unknow type of k parametrization: {}.', 'k', 'k', 'max_logk', 'max_logk', 'parametrization', 'logiv_type', 'GeΒǗtƖî coT»Ǉnfi¹ų¸deçnceŒ ȋscore for eϮach elemϭ̦ŖĨʙeđǫʮ\\'nŒtΣ ÏZ/ƚĵáȟζϲoȬfϜ \\x84˭th e bΔa½˪tchƧ̝.ϯʁ\\n²\\n̦Args:Ɍ|\\u038d\\n \\nˋ  pŞaËraŎmete˪ǁrϻ̈́s: Distͷɉ\\x85r\"ȯiƾˡblΠťutɧioǂnʊŗǰ ŘpaárίˀameÂters with sϿhapɧe (Ǘͩ.̳..,Ŵ ƵKˏϵ)ȑʖΞÛ.\\n\\u03a2\\n\\nReturns:ΦĲ\\n ͵ ƙ̓  ɮλC̹o8ǠnfiʘdeŎnces witƽh sh͢Ċaƭĺɦʳ$pʐe˶ (.\\x8eξˣ..).', 'k', 'k', 'All k must be equal to {} for fixed k parametrization', 'k', 'k', 'k', 'Returns vvector from parameters dict.', 'log_probs', 'mean', 'k', 'Expected dict with keys {}.', 'k', 'log_probs', 'mean', 'ʁG¢3ăet̳ɨ modŶ̀eͷsƩ oΙf distri˝buϒtǁiÉ˖ons.\\n \\n   #PtklFRDzp\\nȠ\\n   \\n̪Argsʌ:ʾ\\n  ɴ  pTaraǎίmǇeyςȺter̜s: Distriˋbuti\\x7foơn parċȧþ̙ameters͘ wi4tøh shĞapeįćΜ (ϣŃ..., ΎKƲ).Πϓ\\n\\nÉǙRetu̦rnŝ{͍s:\\n Ɔ   Ō̰TupõleĽ|ɗ ȻΚofİ mod0e loʁg prob\\u0383abÛilities ¸ɪwξith sǲhapeȵ ǘ(.·ϕ=.., Cϡ) ä́nd modÆ\"es witŔCh ïύsŪēρhȭaƴpe (.ʡ.ǿ.Ř, C, DϷÏ).', 'ǠP\\x9croĥjǢǌect poi͖gntȁs ɺ®to sȨ͔řʄɁ˲pόʇˣ̗herÛƮÁe.', \"ǜC˜ompute log IúV ɿć̍̂us÷ingƿ 'MǀSCL\\x8a impŻleͫméen͛tatio˥n8.\", 'ɡˬϝDiffer˶ÀevπnΞtΟίSƵiǎableȵ ćlo̜͟[ȒΌÜÆϸgarȭithʩϡm oɝf mʄʰodif5ĥi@ed̞Ğ BγǐeδsͺsʐelB ʠfĂumnͤcʣtionžΕ ofŀ͠ theɖĠȯ fϟʸirs˭řˊtµ\\x9bΒ ŨQkíiĸɬnd˩̂.ÿě#RKQoUzTWy\\n\\x85ʑ\\něIƳʒƟΠnteϢƨàrnal\\x9e ǋʽcoΔmputaʜcȒ̯tiɄons aς̲re˞ donʂeǮɵĬ iUƅɮn\\x9dϽ ˲dou͎ble prˬȽe\\x95̲âɰƩ,ci˲͆s϶ioǥnï.\\nȴ\\n͟Inp`uƗts:\\n  -Ǡɯ vʚ: S̽Ƨ̻̓cχ̆ala΄ȵπrɢ orderʀ.§ āŢOnǾ\\x93lÜ˰ˍ̲ȵyʦ ȟn¹ʞonƎ\\x8d-͊neg\\x97aĩ\\x85tͪivêϖ͑eÚʵϦ ¡Πv̔σ0aluϷʿeƑ˖Ǆs Ō(¾>=3 0) arŠϼe suʧ̐p+poß̠ΟṟtedϚ.ĳ\\n   Ż P-Ơ\\x9e zȕ:ψˍĽ ϛAA\\x8erg¡ϸ˰Ȼuǫˉment̵ĠȗǬs ̲ˮt̝ȭens\\x98ξoʞrǓ.Ÿ ŁǷOȟ͟ǈ²nly ŜpoʯsĤ¢itive̸ ɾ͊vϠalueősīƻ Ľ̃ú(Ǯ̶> ŷǅ0)ğ arɕɁeÀÌ vsup7Ɇɖpo\\x8aǢrted˭\\x82.Ð̰ϗɷĢʯƉ\\n˵ʥ#SWF\\nOȿ̪̑ͺƯutιˆpơuϔƏtƨ΅ƽʡͶƼ{s:ŗ\\n Ɂ ϩ  - ]ɇLo˶gÎʷƌa̻ì̜̎ŇïriƉthmǞDˋŏ oÂşΙfȏɈėŨ mo\\x84ͷdkiĦfied̯ BLessǇel Ƅ=fϨðR̥uƐnšctʐiķon χrȳÖeΥ\\u0380sğulSȦȞȜǰtΙ tϏhĿe saǠʴmƉeˎȁ shaʆͳɩďːpʷe as ǥ`zçΎ`.ʹ', 'Ǭ     ί    ', 'Order must be number, got {}', 'Negative order.', 'Order must be number, got {}', 'Negative order: {}.'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <3x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'ClassDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'AsyncFunctionDef': [], 'String': [' ς ş ', '      ͔ǃ Ȳ  ț  ', ' Ñι΅ª̲  Ȅ   \\x7f   ', '__main__'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <18x18 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 18 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['%Y-%m-%dT%H-%M-%S', 'Test that LIocalFileLogƜger createξs subΗfoldϘer duƆring init.', 'endpoint_url', 'https://s3.example.com', 'aws_access_key_id', 'aws_secret_access_key', 'example', 'Environment variable `aws_access_key_id` should be specified', 'example', 'experiments_folder', 'example', 'example', 'keys', 'values', 'first', 'second', 'third', 'example', 'example', 'example', 'example.json', 'example.json', 'keys', 'values', '1', '2', '3', 'You should start experiment before', 'example', 'ÓTe\\x99s˸tƂ\\x9f̒ΰ Ȩ\\x93tʛŅhaʿt ɝ\\x96ΝċLoŰca̼ɺlǿƻFʗ̆γiĖ̪leLoggYer ȥsaϵvķ̔esͨʒ ta͠bl̔͗\\x81őe afΞĵteƃr Ȳ˦Yˈőˡȭĕstaɲr>˯tiūng\\x9b͗ thʸ̷Ŵʜe ̹eȆx\\x80peɡ˸rimÌent˓.', 'example', 'example', 'keys', 'values', 'first', 'second', 'third', 'example', 'example', 'example', 'example.csv', 'example.csv', \"Te\\xad̐st Ɓthat S3FÁçiɾlǹeLogger can't be ͫʚcreated without settοɨing« 'aw˞§s_smʺǌecreÖtŉ_Eacc̄eǮss_kʔȴeyɜü' envi϶ƶroʶnmenϊt variable.\", 'endpoint_url', 'https://s3.example.com', 'aws_access_key_id', 'example', 'aws_secret_access_key', 'Environment variable `aws_secret_access_key` should be specified', 'example', 'experiments_folder', 'keys', 'values', 'first', 'second', 'third', 'You should start experiment before', 'example', 'crossval', 'metrics.csv', 'forecast.csv', 'test.csv', 'metrics_summary.json', 'r', 'median', 'mean', 'std', 'percentile_5', 'percentile_25', 'percentile_75', 'percentile_95', 'key', 'value', 'config.json', 'TeĕãǦˠMŁ̯stɯ Ǽthϐ\\x84aǒt ƊLocς́alFi̚ˁleϓŴĆLoïgRļgeɛŗrϲ correctlϚyȰ ĿÝworȐͮks ʫin w]ithͦ \\x82sşt̘ackÍiƟng.ò̋ͽɥ', '1H', \"we've run one experiment\", 'crossval and crossval_results folders', 'crossval', 'crossval should have `n_folds` runs', \"ǆTe¤sƸt'˖ʴ t·*ǎh̺ľơő\\\\Ǧ©Ȟaƴtª L:ǹȴÀocaƄlF̸ilϊôeL%og͜gerj ͚corrɗƳeȯœctlΧyGk ʯσ\\x9f¦wϩ\\x80orõks iŰ\\x95n ϲ5witȠHhŐ ȻeAmʤYȐhƒpiriɣǖģcalˢϚ̫ ʝprediͶǍcui͢tionɓ ϞȤinteλrvals viȘ͞ϏűaƩϵ bͮ͆acɘktįʛeǩģst.\", '1H', 'prediction_interval', \"we've run one experiment\", 'crossval and crossval_results folders', 'crossval', 'crossval should have `n_folds` runs', 'endpoint_url', 'aws_access_key_id', 'example', 'aws_secret_access_key', 'example', 'Environment variable `endpoint_url` should be specified', 'example', 'experiments_folder', 'example', 'experiments_folder', 'keys', 'values', 'first', 'second', 'third', 'You should start experiment before', 'example', 'etna.loggers.S3FileLogger._check_bucket', 'etna.loggers.S3FileLogger._get_s3_client', 'Te˳st th˼̚ɬȑat ˙LoʕcǪalFɯ\\x8eile8LoggƯɌerδ crea˒te̞sí Şnew subfoldʕĘɟer according ʗto̸ 8the \\x90paraȥmeterǠsć.', 'test', '1', 'test', '1', \"TϥƷest t͡hat Sǳ3Fi̎leǄ̖Logg̾9e\\u0379r canō't ĲĖsav4̯Ƃ˯eΕ ta˩΅b̰leɽϼǚͮĨ \\x98ͻbef̺ore ͩǄŧΙŪstarting *theˑǱ expƋerimenw§t.Ϝ̓ȣϓ\", 'example', 'experiments_folder', 'keys', 'values', 'first', 'second', 'third', 'You should start experiment before', 'example', 'etna.loggers.S3FileLogger._check_bucket', 'etna.loggers.S3FileLogger._get_s3_client', \"Tɤestɹ tha-ʻt S3ȣFilƗϵʜeLogǛgeȎrſπ sȿaȥves̨ tableʙ cǄa΄fteºr st̡artinɤg ̱tɘhe ˰expχeriƴĞm¸ent.º\\n\\n    \\nThŅi˃s\\u0382 ʵCtest Ͼis œoptionaël and require˹ƗsǶ ̲envï̩ronmËent variable '̩ȕetnaȁ_tĐest_sȉʬ3_buckˈŢetM' to be˅ sϏġeǨtʪ.\", 'etna_test_s3_bucket', \"To perform this test you should set 'etna_test_s3_bucket' environment variable first\", 's3_logger_test', 'test_simple', '1', 'keys', 'values', 'first', 'second', 'third', 'example', 'Contents', 'Key', 'Key', '/', 'crossval_results', 'all', 'metrics.csv', 'segment', 'segment', 'segment', 'segment', 'forecast.csv', 'timestamp', 'timestamp', 'fold_number', 'segment', 'timestamp', 'fold_number', 'segment', 'target', 'target', 'fold_info.csv', 'train_start_time', 'train_end_time', 'test_start_time', 'test_end_time', 'metrics_summary.json', 'r', 'median', 'mean', 'std', 'percentile_5', 'percentile_25', 'percentile_75', 'percentile_95', 'aggregate_metrics', \"TTήe²͚ãsŤɩÕtŊĔ tåhačt Sɸõ3Fɲ˄°iǥlǦ΄eLi˩ogͯgeʔͺrǆ saveCs̅ dǿict afte̦r st3airti\\x86˲˻̸ng the ex±³ŰɰpeȽɨ³rʝimeĩʌ+̨nΣˊtĒ.Ïh#BCNPJUEzWiqVRSXsbLog\\n\\nTϻhiϘɸs ?̿\\x99ÎǛt7\\x99esʦtˀ isʗ˾ ǂ0opȂtiϋϑ\\x98ɣonϫ¾ˤaí˜ų̀ƈˉĸl žanďdŎ ȶȼrĒͦĿǱequπHireÐƄ˷s̬͝× e̅ϾnvʐüȨ\\u0379ir£OoȭnÕͭmenɬt uϛvǻariaϮbleʓŰ 'et\\x9fna_teɖº̸ʊsțˋ_s}3Ǎ_bu̺cĭĶϳkʂȃʉet'Ϊ ŖtƀȂoƘś Ĩbe sǁet.sȶ˄\", 'etna_test_s3_bucket', 's3_logger_test', 'test_simple', '1', 'keys', 'values', 'first', 'second', 'third', 'example', 'Contents', 'Key', 'Key', '/', 'r'], 'from': [], 'import': []}\n",
      "{'FunctionDef': <2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 2 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['ȴAdʸd loǦgʃͳ˅g͕iɢĲnøg fɫͶ¦˺orȅ methoQʎd oɷfǤǖ HtϔǓƪǓhe mÿoĢdʿͧel̞đζ.', 'function', 'line', 'name', '¢        ǀͨ       ', 'Calling method ', ' of '], 'from': [], 'import': []}\n",
      "{'FunctionDef': <5x5 sparse matrix of type '<class 'numpy.float64'>'\n",
      "\twith 5 stored elements in Compressed Sparse Row format>, 'ClassDef': [], 'AsyncFunctionDef': [], 'String': ['őGener̨͈aȬƵtʡe simɜpélǚeÉtɩ ǭd̪ata˫frƋameʤ σw˝țȿÃϩΟǐiůth! ^.multšɠiplʥČe źs%eLgments.', '2020-01-01', 'timestamp', 'segment', 'A', 'target', 'timestamp', 'segment', 'B', 'target', 'timestamp', 'segment', 'C', 'target', 'timestamp', 'segment', 'D', 'target', 'target', 'target', 'D', 'A', 'B', 'C', 'D', 'A', 'B', 'C', 'D', 'DistanceMatrix is not fitted!'], 'from': [], 'import': []}\n"
     ]
    }
   ],
   "source": [
    "for path in files:\n",
    "    with open(path, 'r') as file:\n",
    "        text = file.read()\n",
    "        c_text = clear_text(text)\n",
    "\n",
    "        if path.split('/')[-1] != '__init__.py':\n",
    "            files[path]['X_train_tf'] = to_vector([text])\n",
    "\n",
    "        for keyword in keywords:\n",
    "            files[path][keyword] += c_text.count(keyword)\n",
    "\n",
    "        try:\n",
    "            tree = ast.parse(text, type_comments=True, mode='exec')\n",
    "            func_lister = FuncLister()\n",
    "            func_lister.visit(tree)\n",
    "            files[path] |= func_lister.get_stats()\n",
    "        except SyntaxError:\n",
    "            pass\n",
    "            #print('SyntaxError, file_name =', path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_train_tf</th>\n",
       "      <th>False</th>\n",
       "      <th>class</th>\n",
       "      <th>from</th>\n",
       "      <th>or</th>\n",
       "      <th>None</th>\n",
       "      <th>continue</th>\n",
       "      <th>global</th>\n",
       "      <th>pass</th>\n",
       "      <th>True</th>\n",
       "      <th>...</th>\n",
       "      <th>finally</th>\n",
       "      <th>nonlocal</th>\n",
       "      <th>yield</th>\n",
       "      <th>break</th>\n",
       "      <th>for</th>\n",
       "      <th>not</th>\n",
       "      <th>FunctionDef</th>\n",
       "      <th>ClassDef</th>\n",
       "      <th>AsyncFunctionDef</th>\n",
       "      <th>String</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>./plagiat/files/multisim.py</th>\n",
       "      <td>(0, 0)\\t0.029160592175990215\\n  (0, 1)\\t0.02...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>(0, 2)\\t1.0\\n  (1, 1)\\t1.0\\n  (2, 0)\\t1.0</td>\n",
       "      <td>(0, 0)\\t1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Implementation of the Multi-similarity loss w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>./plagiat/files/test_stages.py</th>\n",
       "      <td>(0, 0)\\t0.03813157118703993\\n  (0, 1)\\t0.019...</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>[]</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>(0, 1)\\t1.0\\n  (1, 0)\\t1.0\\n  (2, 4)\\t1.0\\n ...</td>\n",
       "      <td>(0, 0)\\t1.0\\n  (1, 1)\\t1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[cmd, data, name, logger, config, train_root, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>./plagiat/files/test_log_transform.py</th>\n",
       "      <td>(0, 0)\\t0.12110096839533452\\n  (0, 1)\\t0.121...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>(0, 0)\\t1.0\\n  (1, 1)\\t1.0\\n  (2, 8)\\t1.0\\n ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Generate dataset with non-positive target., t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>./plagiat/files/test_catboost.py</th>\n",
       "      <td>(0, 0)\\t0.060314454884943684\\n  (0, 1)\\t0.02...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>4</td>\n",
       "      <td>(0, 6)\\t1.0\\n  (1, 7)\\t1.0\\n  (2, 0)\\t1.0\\n ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1d, target, catboostmodel, regressor_exog, fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>./plagiat/files/test_base_feature_selection_transform.py</th>\n",
       "      <td>(0, 0)\\t0.021266970502955673\\n  (0, 1)\\t0.04...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>(0, 0)\\t1.0\\n  (1, 1)\\t1.0\\n  (2, 3)\\t1.0\\n ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[features_to_use, expected_features, all, regr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>./plagiat/plagiat2/vmf.py</th>\n",
       "      <td>(0, 0)\\t0.018020374541359026\\n  (0, 1)\\t0.00...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>(0, 10)\\t1.0\\n  (1, 8)\\t1.0\\n  (2, 21)\\t1.0\\...</td>\n",
       "      <td>(0, 2)\\t1.0\\n  (1, 1)\\t1.0\\n  (2, 0)\\t1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[separate, norm, default, scl, separate, invli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>./plagiat/plagiat2/test_sampler.py</th>\n",
       "      <td>(0, 0)\\t0.142313613392964\\n  (0, 1)\\t0.03557...</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>[]</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>(0, 1)\\t1.0\\n  (2, 0)\\t1.0</td>\n",
       "      <td>(0, 1)\\t1.0\\n  (1, 0)\\t1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ ς ş ,       ͔ǃ Ȳ  ț  ,  Ñι΅ª̲  Ȅ      , __m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>./plagiat/plagiat2/test_file_logger.py</th>\n",
       "      <td>(0, 0)\\t0.03207089087717946\\n  (0, 1)\\t0.016...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>(0, 5)\\t1.0\\n  (1, 13)\\t1.0\\n  (2, 7)\\t1.0\\n...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[%Y-%m-%dT%H-%M-%S, Test that LIocalFileLogƜge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>./plagiat/plagiat2/decorators.py</th>\n",
       "      <td>(0, 0)\\t0.09759000729485333\\n  (0, 1)\\t0.390...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(0, 0)\\t1.0\\n  (1, 1)\\t1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ȴAdʸd loǦgʃͳ˅g͕iɢĲnøg fɫͶ¦˺orȅ methoQʎd oɷfǤǖ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>./plagiat/plagiat2/test_distance_matrix.py</th>\n",
       "      <td>(0, 0)\\t0.06674086442659999\\n  (0, 1)\\t0.033...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>(0, 0)\\t1.0\\n  (1, 4)\\t1.0\\n  (2, 3)\\t1.0\\n ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[őGener̨͈aȬƵtʡe simɜpélǚeÉtɩ ǭd̪ata˫frƋameʤ σw...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>918 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                           X_train_tf  \\\n",
       "./plagiat/files/multisim.py                           (0, 0)\\t0.029160592175990215\\n  (0, 1)\\t0.02...   \n",
       "./plagiat/files/test_stages.py                        (0, 0)\\t0.03813157118703993\\n  (0, 1)\\t0.019...   \n",
       "./plagiat/files/test_log_transform.py                 (0, 0)\\t0.12110096839533452\\n  (0, 1)\\t0.121...   \n",
       "./plagiat/files/test_catboost.py                      (0, 0)\\t0.060314454884943684\\n  (0, 1)\\t0.02...   \n",
       "./plagiat/files/test_base_feature_selection_tra...    (0, 0)\\t0.021266970502955673\\n  (0, 1)\\t0.04...   \n",
       "...                                                                                               ...   \n",
       "./plagiat/plagiat2/vmf.py                             (0, 0)\\t0.018020374541359026\\n  (0, 1)\\t0.00...   \n",
       "./plagiat/plagiat2/test_sampler.py                    (0, 0)\\t0.142313613392964\\n  (0, 1)\\t0.03557...   \n",
       "./plagiat/plagiat2/test_file_logger.py                (0, 0)\\t0.03207089087717946\\n  (0, 1)\\t0.016...   \n",
       "./plagiat/plagiat2/decorators.py                      (0, 0)\\t0.09759000729485333\\n  (0, 1)\\t0.390...   \n",
       "./plagiat/plagiat2/test_distance_matrix.py            (0, 0)\\t0.06674086442659999\\n  (0, 1)\\t0.033...   \n",
       "\n",
       "                                                   False class from   or None  \\\n",
       "./plagiat/files/multisim.py                            0     1   []   48    0   \n",
       "./plagiat/files/test_stages.py                         0     7   []   32    0   \n",
       "./plagiat/files/test_log_transform.py                  0     0   []   61    0   \n",
       "./plagiat/files/test_catboost.py                       0     0   []   66    0   \n",
       "./plagiat/files/test_base_feature_selection_tra...     0     0   []   74    0   \n",
       "...                                                  ...   ...  ...  ...  ...   \n",
       "./plagiat/plagiat2/vmf.py                              0     3   []  110    0   \n",
       "./plagiat/plagiat2/test_sampler.py                     0     8   []   20    0   \n",
       "./plagiat/plagiat2/test_file_logger.py                 0     0   []   89    0   \n",
       "./plagiat/plagiat2/decorators.py                       0     1   []    6    0   \n",
       "./plagiat/plagiat2/test_distance_matrix.py             0     0   []    9    0   \n",
       "\n",
       "                                                   continue global pass True  \\\n",
       "./plagiat/files/multisim.py                               2      0    0    0   \n",
       "./plagiat/files/test_stages.py                            1      0    0    0   \n",
       "./plagiat/files/test_log_transform.py                     0      0    0    0   \n",
       "./plagiat/files/test_catboost.py                          0      0    0    0   \n",
       "./plagiat/files/test_base_feature_selection_tra...        0      0    0    0   \n",
       "...                                                     ...    ...  ...  ...   \n",
       "./plagiat/plagiat2/vmf.py                                 0      0    0    0   \n",
       "./plagiat/plagiat2/test_sampler.py                        0      0    0    0   \n",
       "./plagiat/plagiat2/test_file_logger.py                    0      0    0    0   \n",
       "./plagiat/plagiat2/decorators.py                          0      0    0    0   \n",
       "./plagiat/plagiat2/test_distance_matrix.py                0      0    0    0   \n",
       "\n",
       "                                                    ... finally nonlocal  \\\n",
       "./plagiat/files/multisim.py                         ...       0        0   \n",
       "./plagiat/files/test_stages.py                      ...       0        0   \n",
       "./plagiat/files/test_log_transform.py               ...       0        0   \n",
       "./plagiat/files/test_catboost.py                    ...       0        0   \n",
       "./plagiat/files/test_base_feature_selection_tra...  ...       0        0   \n",
       "...                                                 ...     ...      ...   \n",
       "./plagiat/plagiat2/vmf.py                           ...       0        0   \n",
       "./plagiat/plagiat2/test_sampler.py                  ...       0        0   \n",
       "./plagiat/plagiat2/test_file_logger.py              ...       0        0   \n",
       "./plagiat/plagiat2/decorators.py                    ...       0        0   \n",
       "./plagiat/plagiat2/test_distance_matrix.py          ...       0        0   \n",
       "\n",
       "                                                   yield break for not  \\\n",
       "./plagiat/files/multisim.py                            0     0   4   0   \n",
       "./plagiat/files/test_stages.py                         0     1   7   5   \n",
       "./plagiat/files/test_log_transform.py                  0     0  48   1   \n",
       "./plagiat/files/test_catboost.py                       0     0  43   4   \n",
       "./plagiat/files/test_base_feature_selection_tra...     0     0  24   0   \n",
       "...                                                  ...   ...  ..  ..   \n",
       "./plagiat/plagiat2/vmf.py                              0     0  14   8   \n",
       "./plagiat/plagiat2/test_sampler.py                     0     0   9   0   \n",
       "./plagiat/plagiat2/test_file_logger.py                 0     0  27   0   \n",
       "./plagiat/plagiat2/decorators.py                       0     0   0   0   \n",
       "./plagiat/plagiat2/test_distance_matrix.py             0     0   0   1   \n",
       "\n",
       "                                                                                          FunctionDef  \\\n",
       "./plagiat/files/multisim.py                                 (0, 2)\\t1.0\\n  (1, 1)\\t1.0\\n  (2, 0)\\t1.0   \n",
       "./plagiat/files/test_stages.py                        (0, 1)\\t1.0\\n  (1, 0)\\t1.0\\n  (2, 4)\\t1.0\\n ...   \n",
       "./plagiat/files/test_log_transform.py                 (0, 0)\\t1.0\\n  (1, 1)\\t1.0\\n  (2, 8)\\t1.0\\n ...   \n",
       "./plagiat/files/test_catboost.py                      (0, 6)\\t1.0\\n  (1, 7)\\t1.0\\n  (2, 0)\\t1.0\\n ...   \n",
       "./plagiat/files/test_base_feature_selection_tra...    (0, 0)\\t1.0\\n  (1, 1)\\t1.0\\n  (2, 3)\\t1.0\\n ...   \n",
       "...                                                                                               ...   \n",
       "./plagiat/plagiat2/vmf.py                             (0, 10)\\t1.0\\n  (1, 8)\\t1.0\\n  (2, 21)\\t1.0\\...   \n",
       "./plagiat/plagiat2/test_sampler.py                                         (0, 1)\\t1.0\\n  (2, 0)\\t1.0   \n",
       "./plagiat/plagiat2/test_file_logger.py                (0, 5)\\t1.0\\n  (1, 13)\\t1.0\\n  (2, 7)\\t1.0\\n...   \n",
       "./plagiat/plagiat2/decorators.py                                           (0, 0)\\t1.0\\n  (1, 1)\\t1.0   \n",
       "./plagiat/plagiat2/test_distance_matrix.py            (0, 0)\\t1.0\\n  (1, 4)\\t1.0\\n  (2, 3)\\t1.0\\n ...   \n",
       "\n",
       "                                                                                       ClassDef  \\\n",
       "./plagiat/files/multisim.py                                                         (0, 0)\\t1.0   \n",
       "./plagiat/files/test_stages.py                                       (0, 0)\\t1.0\\n  (1, 1)\\t1.0   \n",
       "./plagiat/files/test_log_transform.py                                                        []   \n",
       "./plagiat/files/test_catboost.py                                                             []   \n",
       "./plagiat/files/test_base_feature_selection_tra...                                           []   \n",
       "...                                                                                         ...   \n",
       "./plagiat/plagiat2/vmf.py                             (0, 2)\\t1.0\\n  (1, 1)\\t1.0\\n  (2, 0)\\t1.0   \n",
       "./plagiat/plagiat2/test_sampler.py                                   (0, 1)\\t1.0\\n  (1, 0)\\t1.0   \n",
       "./plagiat/plagiat2/test_file_logger.py                                                       []   \n",
       "./plagiat/plagiat2/decorators.py                                                             []   \n",
       "./plagiat/plagiat2/test_distance_matrix.py                                                   []   \n",
       "\n",
       "                                                   AsyncFunctionDef  \\\n",
       "./plagiat/files/multisim.py                                      []   \n",
       "./plagiat/files/test_stages.py                                   []   \n",
       "./plagiat/files/test_log_transform.py                            []   \n",
       "./plagiat/files/test_catboost.py                                 []   \n",
       "./plagiat/files/test_base_feature_selection_tra...               []   \n",
       "...                                                             ...   \n",
       "./plagiat/plagiat2/vmf.py                                        []   \n",
       "./plagiat/plagiat2/test_sampler.py                               []   \n",
       "./plagiat/plagiat2/test_file_logger.py                           []   \n",
       "./plagiat/plagiat2/decorators.py                                 []   \n",
       "./plagiat/plagiat2/test_distance_matrix.py                       []   \n",
       "\n",
       "                                                                                               String  \n",
       "./plagiat/files/multisim.py                         [Implementation of the Multi-similarity loss w...  \n",
       "./plagiat/files/test_stages.py                      [cmd, data, name, logger, config, train_root, ...  \n",
       "./plagiat/files/test_log_transform.py               [Generate dataset with non-positive target., t...  \n",
       "./plagiat/files/test_catboost.py                    [1d, target, catboostmodel, regressor_exog, fe...  \n",
       "./plagiat/files/test_base_feature_selection_tra...  [features_to_use, expected_features, all, regr...  \n",
       "...                                                                                               ...  \n",
       "./plagiat/plagiat2/vmf.py                           [separate, norm, default, scl, separate, invli...  \n",
       "./plagiat/plagiat2/test_sampler.py                  [ ς ş ,       ͔ǃ Ȳ  ț  ,  Ñι΅ª̲  Ȅ      , __m...  \n",
       "./plagiat/plagiat2/test_file_logger.py              [%Y-%m-%dT%H-%M-%S, Test that LIocalFileLogƜge...  \n",
       "./plagiat/plagiat2/decorators.py                    [ȴAdʸd loǦgʃͳ˅g͕iɢĲnøg fɫͶ¦˺orȅ methoQʎd oɷfǤǖ...  \n",
       "./plagiat/plagiat2/test_distance_matrix.py          [őGener̨͈aȬƵtʡe simɜpélǚeÉtɩ ǭd̪ata˫frƋameʤ σw...  \n",
       "\n",
       "[918 rows x 40 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(files)\n",
    "\n",
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1 (v3.11.1:a7a450f84a, Dec  6 2022, 15:24:06) [Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
