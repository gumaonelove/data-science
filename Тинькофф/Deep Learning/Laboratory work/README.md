# Лабораторная курса Deep Learning

## Дедлайн: 25.12.2022 23:59 GMT

## Общее описание
Системы распознавания автомобильных номеров состоят из двух модулей: детекция и распознавание символов (Optical Character Recognition, OCR). Детектор выделяет прямоугольник с номером из изображения, а OCR конвертирует его в текст. Будем считать, что детектор уже реализован. В рамках проекта предлагается самостоятельно обучить модель OCR для автомобильных номеров.

**Пример входа:** 
![Автомобильный номер](https://algocode.ru/files/course_dlfall22/number.png)

**Пример выхода:** 皖AD16688

## Предлагаемая архитектура решения
Предлагается реализовать модель, состоящую из двух блоков: Fully-convolutional CNN (FCNN) и Bi-LSTM. На выходе предлагается использовать Cross-entropy или CTC-loss. 

Пример архитектуры:

![Архитектура](https://algocode.ru/files/course_dlfall22/architecture.png)

Не обязательно реализовывать такой подход. Любое решение с хорошим качеством распознавания подойдёт (residual networks, attention, трансформеры и др.). Главное ограничение – нельзя использовать предобученные веса модели.

## Корпус данных
Предлагается использовать корпус [CCPD2019](https://github.com/detectRecog/CCPD). Специально для участников курса DL мы выделили регионы интереса и распарсили метки из исходного корпуса. В test вошли изображения из CCPD-weather. Подготовленный корпус можно скачать по [ссылке](https://disk.yandex.ru/d/adjYzzNayB1pag).

## Что должна включать работа
Для сдачи проекта нужно подготовить ноутбук с решением. В каждом решении должны быть описанные ниже блоки.
1. **Подготовка данных.** Нужно реализовать класс данных (наследник torch.utils.data.Dataset). Класс должен считывать входные изображения и выделять метки из имён файлов. Для чтения изображений предлагается использовать библиотеку OpenCV (методы cv2.imread, cv2.resize и cv2.cvtColor). В базовом варианте достаточно загрузить тренировочную и тестовую части корпуса. Можно также отделить валидационный корпус от тренировочного. Также предлагается реализовать механизм аугментаций для повышения качества обучения.
2. **Создание и обучение модели.** Код модели должен быть реализован через слои стандартной библиотеки torch (torchvision.models и аналоги использовать нельзя). Поскольку число символов в номерах фиксировано, можно использовать обычный кросс-энтропийный критерий. Желающие могут использовать и CTC-loss. Цикл обучения можно реализовать самостоятельно или воспользоваться библиотеками PyTorch Lightning / Catalyst.
3. **Подсчет метрик.** Качество модели должно оцениваться по двум метрикам: accuracy и Character Error Rate (CER). Accuracy считает долю правильно распознанных номеров. CER оценивает число посимвольных ошибок. Можно реализовать метрики самостоятельно или взять готовые реализации из интернета.
4. **Анализ ошибок модели.** В этой секции нужно найти изображения из тестового корпуса, на которых модель ошибается сильнее всего (по loss или по CER). Предлагается выписать в ноутбук возможные причины появления этих ошибок и пути устранения.

## Оценка работы
Работа будет оцениваться по следующим критериям:
1. Качество кода
2. Качество реализованного подхода
3. Качество описания принимаемых решений и анализа ошибок
4. Финальные метрики

## Как сдавать работу
- Создайте новую ветку, которая будет называться `lab-<gh_handle>`. Выполняйте работу в ней.
- Пожалуйста, закоммитьте итоговый ноутбук еще и в виде pdf-ки (так вы сделаете проверяющим жизнь намного проще). То есть в итоге в вашей ветке должен лежать ipynb + pdf, их содержание должно совпадать.
- Когда доделаете работу, откройте PR с таким же названием, как и ветка.
