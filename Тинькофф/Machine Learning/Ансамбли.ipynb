{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "jSesEiLRkV2M"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import warnings\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as mse, r2_score\n",
    "from typing import Tuple\n",
    "from abc import ABC, abstractmethod\n",
    "from collections import deque\n",
    "from typing import Tuple\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Домашняя работа: ансамбли"
   ],
   "metadata": {
    "id": "MVTZmFccmyHP"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Эта домашняя работа является идейным продолжением предыдущей. В данной работе вам будет необходимо поэкспериментировать с различными методами ансамблирования и проверить, какие из них работают лучше. Пайплайн предобработки данных можно взять полностью из предыдущей работы.\n",
    "\n",
    "Требования к домашней работе:\n",
    "- Во всех графиках (если вы их строите) должны быть подписи через title, legend, etc.\n",
    "- Во время обучения моделей проверяйте, что у вас не текут данные. Обычно это позитивно влияет на качество модели на тесте, но негативно влияет на оценку 🌚\n",
    "- Если вы сдаете работу в Google Colaboratory, убедитесь, что ваша тетрадка доступна по ссылке. Если в итоге по каким-то причинам тетрадка не будет открываться у преподавателя, задание не будет засчитано\n",
    "- Использование мемов допускается. Если задания дались тяжело, можно дополнительно приложить какой-нибудь постироничный мем про ваши страдания во время выполнения данной домашней работы. За мемы с использованием нецензурной лексики баллы будут снижены."
   ],
   "metadata": {
    "id": "VE36FyB9m4Gp"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Загрузка и подготовка данных (1 балл)"
   ],
   "metadata": {
    "id": "_u-DyeiInWN2"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "В этой секции предлагается прогнать предобработку данных из прошлой тетрадки заново и сохранить получившийся датасет в формате csv.\n",
    "\n",
    "Если вы **не хотите заморачиваться**, то просто скопируйте код с предобработкой ниже.\n",
    "\n",
    "В противном случае в старой тетрадке:\n",
    "1. Отдельно выполните предобработку (`fit_transform`) тренировочной части данных\n",
    "2. Добавьте колонку `split` к датафрейму с обучающей выборкой, в этой колонке проставьте значение `train` для всех объектов\n",
    "3. Затем примените **только** предобработку (`transform`) к тестовой части данных\n",
    "4. Добавьте колонку `split` к тестовой выборке, в этой колонке проставьте значение `test` для всех объектов\n",
    "5. Объедините два датафрейма в один при помощи функции `pd.concat`\n",
    "6. Сохраните получившийся датафрейм при помощи функции `to_csv`, не забудьте передать аргумент `index=False`\n",
    "\n",
    "Получившийся файл сохраните отдельно и используйте в этой домашней работе. Для разбиения датасета на обучающую и тестовую части вместо функции `train_test_split` можете применять колонку `split`."
   ],
   "metadata": {
    "id": "kfY_eyP7nc3P"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "# !pip install gdown\n",
    "# !gdown 18PVwZWFbpRbEHW-Hc8R0DUTl9CF1aQa0 -O data.csv"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('data.csv').drop(columns=[\n",
    "    'product_name',\n",
    "    'index',\n",
    "    'uniq_id',\n",
    "    'customers_who_bought_this_item_also_bought',\n",
    "    'items_customers_buy_after_viewing_this_item',\n",
    "    'sellers',\n",
    "    'description', # text\n",
    "    'product_information', # text\n",
    "    'product_description', # text\n",
    "    'customer_questions_and_answers', # text\n",
    "    'customer_reviews', # text\n",
    "])"
   ],
   "metadata": {
    "id": "h7kSBxwxqBE9"
   },
   "execution_count": 41,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Посмотрим на данные"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "  manufacturer   price number_available_in_stock number_of_reviews  \\\n0       Hornby   £3.42                     5 new                15   \n1    FunkyBuys  £16.99                       NaN                 2   \n2          ccf   £9.99                     2 new                17   \n3       Hornby  £39.99                       NaN                 1   \n4       Hornby  £32.19                       NaN                 3   \n\n   number_of_answered_questions average_review_rating  \\\n0                           1.0    4.9 out of 5 stars   \n1                           1.0    4.5 out of 5 stars   \n2                           2.0    3.9 out of 5 stars   \n3                           2.0    5.0 out of 5 stars   \n4                           2.0    4.7 out of 5 stars   \n\n                    amazon_category_and_sub_category  \n0  Hobbies > Model Trains & Railway Sets > Rail V...  \n1  Hobbies > Model Trains & Railway Sets > Rail V...  \n2  Hobbies > Model Trains & Railway Sets > Rail V...  \n3  Hobbies > Model Trains & Railway Sets > Rail V...  \n4  Hobbies > Model Trains & Railway Sets > Rail V...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>manufacturer</th>\n      <th>price</th>\n      <th>number_available_in_stock</th>\n      <th>number_of_reviews</th>\n      <th>number_of_answered_questions</th>\n      <th>average_review_rating</th>\n      <th>amazon_category_and_sub_category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Hornby</td>\n      <td>£3.42</td>\n      <td>5 new</td>\n      <td>15</td>\n      <td>1.0</td>\n      <td>4.9 out of 5 stars</td>\n      <td>Hobbies &gt; Model Trains &amp; Railway Sets &gt; Rail V...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>FunkyBuys</td>\n      <td>£16.99</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>4.5 out of 5 stars</td>\n      <td>Hobbies &gt; Model Trains &amp; Railway Sets &gt; Rail V...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ccf</td>\n      <td>£9.99</td>\n      <td>2 new</td>\n      <td>17</td>\n      <td>2.0</td>\n      <td>3.9 out of 5 stars</td>\n      <td>Hobbies &gt; Model Trains &amp; Railway Sets &gt; Rail V...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Hornby</td>\n      <td>£39.99</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>2.0</td>\n      <td>5.0 out of 5 stars</td>\n      <td>Hobbies &gt; Model Trains &amp; Railway Sets &gt; Rail V...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Hornby</td>\n      <td>£32.19</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>2.0</td>\n      <td>4.7 out of 5 stars</td>\n      <td>Hobbies &gt; Model Trains &amp; Railway Sets &gt; Rail V...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Количество пропусков"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "manufacturer                           5\nprice                                  0\nnumber_available_in_stock           2211\nnumber_of_reviews                     15\nnumber_of_answered_questions         673\naverage_review_rating                 15\namazon_category_and_sub_category     550\ndtype: int64"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Процент пропусков"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "manufacturer                         0.058500\nprice                                0.000000\nnumber_available_in_stock           25.868726\nnumber_of_reviews                    0.175500\nnumber_of_answered_questions         7.874108\naverage_review_rating                0.175500\namazon_category_and_sub_category     6.435006\ndtype: float64"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum() / df.shape[0] * 100"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Заполнение пропусков\n",
    "**Поля**\n",
    "1. manufacturer - заполним \"unknown\" на следующем шаге и переведем в категориальный признак\n",
    "2. number_available_in_stock - количество_отвеченных_вопросов, заполним пропуски 0 на следующем шаге\n",
    "3. number_of_reviews - количество просмотров, заполним 0 на следующем шаге\n",
    "4. number_of_answered_questions - количество_отвеченных_вопросов, заполним 0 на следующем шаге\n",
    "5. average_review_rating - усреднение_просмотров_рейтинг, удалим строки с пропусков в данной колонке\n",
    "6. amazon_category_and_sub_category - амазон_категория_и_суб_категория, заполним \"unknown\" и переведем в категориальный\n",
    "\n",
    "Заполнение 0 или \"unknown\" происходит, потому что:\n",
    "* в количественных столбцах пропуски означают отсутствие данного признака, следовательно, можем использовать 0\n",
    "* в категориальных заполним константой \"unknown\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "df['manufacturer'] = df['manufacturer'].fillna(\"unknown\")\n",
    "df['number_available_in_stock'] = df['number_available_in_stock'].fillna(0)\n",
    "df['number_of_reviews'] = df['number_of_reviews'].fillna(0)\n",
    "df['number_of_answered_questions'] = df['number_of_answered_questions'].fillna(0)\n",
    "df['amazon_category_and_sub_category'] = df['amazon_category_and_sub_category'].fillna(\"unknown\")\n",
    "\n",
    "df = df.dropna()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Подготовка данных\n",
    "### Работа с числовыми данными\n",
    "Переведем price в числовой тип данных"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "df['price'] = df['price'].str.replace('£', '')\n",
    "df['price'] = df['price'].str.replace(',', '')\n",
    "df['price'] = df['price'].astype('float')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Переведем number_available_in_stock в числовой тип данных"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "df['number_available_in_stock'] = df['number_available_in_stock']\\\n",
    "    .replace('new', '', regex=True).replace('used', '', regex=True)\\\n",
    "    .replace('refurbished', '', regex=True).replace('collectible', '', regex=True).astype('uint8')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "change data type of number_of_reviews to int"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "df['number_of_reviews'] = df['number_of_reviews'].str.replace(',', '').astype('uint16')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "change data type of number_of_answered_questions to int"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "df['number_of_answered_questions'] = df['number_of_answered_questions'].astype('uint8')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "change data type of average_review_rating to float"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "df['average_review_rating'] = df['average_review_rating'].replace('out of 5 stars', '', regex=True).astype('float')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Работа с категориальными данными\n",
    "cтолбец manufacturer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "Oxford Diecast        152\nLEGO                  138\nDisney                136\nPlaymobil             117\nThe Puppet Company    102\n                     ... \nNoris                   1\nMammut                  1\nM Gordon & Sons         1\nStephens                1\nGreen Hornet            1\nName: manufacturer, Length: 2358, dtype: int64"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['manufacturer'].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2358 - количество уникальных значений, прямое кодирование (One-Hot Encoding, OHE) для данного столбца не подойдет,\n",
    "тк добавлять 2358 столбцов не целесообразно. Используем порядковое кодирование (Ordinal Encoding)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "encoder = OrdinalEncoder()\n",
    "\n",
    "df_new_ordinal = pd.DataFrame(encoder.fit_transform(df), columns=df.columns)\n",
    "\n",
    "df['manufacturer'] = df_new_ordinal['manufacturer'].astype('float')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "column amazon_category_and_sub_category"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "Die-Cast & Toy Vehicles > Toy Vehicles & Accessories > Scaled Models > Vehicles    784\nunknown                                                                            545\nFigures & Playsets > Science Fiction & Fantasy                                     359\nArts & Crafts > Children's Craft Kits > Bead Art & Jewellery-Making                340\nCharacters & Brands > Disney > Toys                                                292\n                                                                                  ... \nElectronic Toys > Kids Remote & App Controlled Toys                                  1\nCharacters & Brands > Harry Potter > Books > Stationery                              1\nGames > Casino Equipment > Game Sets > Roulette Sets                                 1\nGames > Casino Equipment > Game Layouts > Poker Layouts                              1\nGames > Drinking Games                                                               1\nName: amazon_category_and_sub_category, Length: 236, dtype: int64"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['amazon_category_and_sub_category'].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Разобьем данный столбец на 3 столбца (иерархия категорий)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "new_df = df['amazon_category_and_sub_category'].str.split('>', expand=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Закодируем каждый из полученных столбцов используя порядковое кодирование (Ordinal Encoding)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "encoder = OrdinalEncoder()\n",
    "\n",
    "df_new_ordinal = pd.DataFrame(encoder.fit_transform(new_df), columns=new_df.columns)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Добавим столбцы к исходному df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "df = df.drop(columns=['amazon_category_and_sub_category'])\n",
    "df = pd.concat([df, df_new_ordinal], axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Удалим оставшиеся пропуски"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Важно: во всех разделах ниже задачу регрессии важно оценивать не только при помощи `MSE`, но и при помощи `r2_score`. Если вы хотите перебрать какой-либо гиперпараметр, не забывайте оценивать то, насколько сильно переобучается модель и как меняется каждый из параметров в процессе обучения."
   ],
   "metadata": {
    "id": "XXUtaMSv5oGF"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "X, y = df.drop(columns=['price']), df.price\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=42)"
   ],
   "metadata": {
    "id": "0K3HJ_AqLg9i"
   },
   "execution_count": 59,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Нормализуем данные"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "#X_train = Normalizer().fit_transform(X_train)\n",
    "#X_test = Normalizer().fit_transform(X_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Стекинг (максимум 3 балла)"
   ],
   "metadata": {
    "id": "cO5VjK7kp_si"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Решите задачу, используя разные комбинации базовых моделей. В качестве базовой модели обязательно попробуйте линейную регрессию, дерево и SVM для регрессии.\n",
    "\n",
    "Какой набор моделей дает лучший результат? Попробуйте улучшить его, перебрав несколько гиперпараметров (как у базовой модели, так и у ансамбля)."
   ],
   "metadata": {
    "id": "sDbjOEre6Xst"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Простой стекинг своими руками (2 балла)"
   ],
   "metadata": {
    "id": "9HnkGgBpqfgI"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class StackingRegressionSolver:\n",
    "    def __init__(self, base_estimators: list, meta_estimator):\n",
    "        self._base_estimators = base_estimators\n",
    "        self._meta_estimator = meta_estimator\n",
    "\n",
    "    def _fit_base(self, X_train: pd.DataFrame, y_train: pd.Series) -> None:\n",
    "        for estimator in tqdm(self._base_estimators):\n",
    "            estimator.fit(X_train, y_train)\n",
    "\n",
    "    def _predict_base(self, X_train: pd.DataFrame) -> pd.DataFrame:\n",
    "        '''Размерность [k, N]'''\n",
    "        meta_features = []\n",
    "        for estimator in self._base_estimators:\n",
    "            meta_features.append(estimator.predict(X_train))\n",
    "        df = pd.DataFrame(meta_features)\n",
    "        return df.T # Размерность [N, k]\n",
    "\n",
    "    def fit(self, X_train: pd.DataFrame, y_train: pd.Series) -> None:\n",
    "        self._fit_base(X_train, y_train)\n",
    "        meta_features = self._predict_base(X_train)\n",
    "        assert meta_features.shape[0] == y_train.shape[0], 'Не совпадающие размерности'\n",
    "        self._meta_estimator.fit(meta_features, y_train)\n",
    "\n",
    "    def predict(self, X_test: pd.DataFrame) -> pd.Series:\n",
    "        meta_features = self._predict_base(X_test)\n",
    "        return self._meta_estimator.predict(meta_features)"
   ],
   "metadata": {
    "id": "in4yMYq1qVei"
   },
   "execution_count": 61,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "def get_score(y_pred, y_test, title='') -> None:\n",
    "    if title:\n",
    "        print(title)\n",
    "    print('mse =', round(mse(y_test, y_pred), 2))\n",
    "    print('r2_score =', round(r2_score(y_test, y_pred), 2))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Линейная регрессия"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse = 1516.25\n",
      "r2_score = 0.03\n"
     ]
    }
   ],
   "source": [
    "linear = LinearRegression(n_jobs=-1)\n",
    "linear.fit(X_train, y_train)\n",
    "y_pred = linear.predict(X_test)\n",
    "\n",
    "get_score(y_pred, y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Решающее дерево\n",
    "Возьмем гипер-параметры из 9 домашки,\n",
    "* max_depth = 6\n",
    "* min_samples_split = 99\n",
    "* min_samples_leaf = 5"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse = 1530.47\n",
      "r2_score = 0.02\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTreeRegressor(max_depth=6, min_samples_split=99, min_samples_leaf=5)\n",
    "tree.fit(X_train, y_train)\n",
    "y_pred = tree.predict(X_test)\n",
    "get_score(y_pred, y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Простое ансамблирование"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "class EnsembleTreeRegressor:\n",
    "    def __init__(self, num_trees=100, **model_kwargs):\n",
    "        self._samples_frac = 0.8\n",
    "        self._trees = [DecisionTreeRegressor(**model_kwargs) for _ in range(num_trees)]\n",
    "\n",
    "    def fit(self, x: pd.DataFrame, y: pd.Series):\n",
    "        for tree in self._trees:\n",
    "            tree_x = x.sample(frac=self._samples_frac, random_state=42)\n",
    "            tree_y = y[tree_x.index]\n",
    "            tree.fit(tree_x, tree_y)\n",
    "\n",
    "    def predict(self, x: pd.DataFrame):\n",
    "        # В качестве предсказания ансамбля будем выдавать усреднение предсказаний деревьев\n",
    "        tree_y_pred = np.zeros((x.shape[0]))\n",
    "        num_trees = 0\n",
    "        for tree in self._trees:\n",
    "            num_trees += 1\n",
    "            tree_y_pred += tree.predict(x)\n",
    "\n",
    "        return tree_y_pred / num_trees"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse = 1526.44\n",
      "r2_score = 0.02\n"
     ]
    }
   ],
   "source": [
    "ensemble = EnsembleTreeRegressor(max_depth=6, min_samples_split=99, min_samples_leaf=5)\n",
    "ensemble.fit(X_train, y_train)\n",
    "y_pred = ensemble.predict(X_test)\n",
    "\n",
    "get_score(y_pred, y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def step(meta_model, kwargs):\n",
    "    stacking_regressor = StackingRegressionSolver(\n",
    "        base_estimators=[\n",
    "            LinearRegression(n_jobs=-1), DecisionTreeRegressor(**kwargs),\n",
    "            SVR(), EnsembleTreeRegressor(**kwargs)\n",
    "        ],\n",
    "        meta_estimator=meta_model\n",
    "    )\n",
    "    stacking_regressor.fit(X_train, y_train)\n",
    "    y_pred = stacking_regressor.predict(pd.DataFrame(X_test))\n",
    "\n",
    "    get_score(y_pred, y_test, f'meta_model = {meta_model}, kwargs = {kwargs}')"
   ],
   "metadata": {
    "id": "OnrpvxiHccHL"
   },
   "execution_count": 67,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c24258351b7f4b99bc0f675868847614"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f6dd5e27d6e94bfc9e7bb65d97593eef"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta_model = LinearRegression(n_jobs=-1), kwargs = {}\n",
      "mse = 2887.59\n",
      "r2_score = -0.86\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4f779ce35a65477ab4454ec756453d77"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta_model = LinearRegression(n_jobs=-1), kwargs = {'max_depth': 6, 'min_samples_split': 99, 'min_samples_leaf': 5}\n",
      "mse = 1530.78\n",
      "r2_score = 0.02\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "34c8251856434e77b40f532a56e3c4f5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta_model = DecisionTreeRegressor(), kwargs = {}\n",
      "mse = 2927.86\n",
      "r2_score = -0.88\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "986ebb0992224cd6a3121b83727c9e17"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta_model = DecisionTreeRegressor(), kwargs = {'max_depth': 6, 'min_samples_split': 99, 'min_samples_leaf': 5}\n",
      "mse = 2732.32\n",
      "r2_score = -0.76\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2c9945cb531d46c3896fb09a8938534a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta_model = SVR(), kwargs = {}\n",
      "mse = 1832.58\n",
      "r2_score = -0.18\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a9e36b9b7cd844d0aa225c3782e6e6d2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta_model = SVR(), kwargs = {'max_depth': 6, 'min_samples_split': 99, 'min_samples_leaf': 5}\n",
      "mse = 1584.4\n",
      "r2_score = -0.02\n"
     ]
    }
   ],
   "source": [
    "params = {'max_depth':6, 'min_samples_split':99, 'min_samples_leaf':5}\n",
    "for meta in tqdm([LinearRegression(n_jobs=-1), DecisionTreeRegressor(), SVR()]):\n",
    "    step(meta, {})\n",
    "    step(meta, params)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Результаты с использованием нормализации признаков:**\n",
    "* meta_model = LinearRegression(), kwargs = {}\n",
    " mse = 2837.96 r2_score = -0.82\n",
    "* meta_model = LinearRegression(), kwargs = {'max_depth': 6, 'min_samples_split': 99, 'min_samples_leaf': 5}\n",
    " mse = 1631.62 r2_score = -0.05\n",
    "* meta_model = DecisionTreeRegressor(), kwargs = {}\n",
    " mse = 2930.63 r2_score = -0.88\n",
    "* meta_model = DecisionTreeRegressor(), kwargs = {'max_depth': 6, 'min_samples_split': 99, 'min_samples_leaf': 5}\n",
    " mse = 10046.93  r2_score = -5.46\n",
    "* meta_model = SVR(), kwargs = {}  mse = 1823.18\n",
    " r2_score = -0.17\n",
    "* meta_model = SVR(), kwargs = {'max_depth': 6, 'min_samples_split': 99, 'min_samples_leaf': 5}\n",
    " mse = 1593.39  r2_score = -0.02\n",
    "\n",
    "**Результаты без использования нормализации:**\n",
    "* meta_model = LinearRegression(), kwargs = {}\n",
    " mse = 2791.35 r2_score = -0.79\n",
    "* meta_model = LinearRegression(), kwargs = {'max_depth': 6, 'min_samples_split': 99, 'min_samples_leaf': 5}\n",
    " mse = 1530.78 r2_score = 0.02\n",
    "* meta_model = DecisionTreeRegressor(), kwargs = {}\n",
    " mse = 2958.28 r2_score = -0.9\n",
    "* meta_model = DecisionTreeRegressor(), kwargs = {'max_depth': 6, 'min_samples_split': 99, 'min_samples_leaf': 5}\n",
    " mse = 2789.74 r2_score = -0.79\n",
    "* meta_model = SVR(), kwargs = {}\n",
    " mse = 1837.1 r2_score = -0.18\n",
    "* meta_model = SVR(), kwargs = {'max_depth': 6, 'min_samples_split': 99, 'min_samples_leaf': 5}\n",
    " mse = 1584.4 r2_score = -0.02\n",
    "\n",
    "\n",
    "\"Наилучшие\" результаты показала (без нормализации признаков)\n",
    "meta_model = LinearRegression(), kwargs = {'max_depth': 6, 'min_samples_split': 99, 'min_samples_leaf': 5}\n",
    "mse = 1530.78 r2_score = 0.02"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Использование встроенной модели стекинга (0.5 балла)"
   ],
   "metadata": {
    "id": "tISuwHbhqjGN"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import StackingRegressor, RandomForestRegressor\n",
    "\n",
    "estimators = [\n",
    "    ('lr', LinearRegression(n_jobs=-1)),\n",
    "    ('svr', SVR()),\n",
    "    ('dtr', DecisionTreeRegressor(**params))\n",
    "]\n",
    "\n",
    "reg = StackingRegressor(\n",
    "    estimators=estimators,\n",
    "    final_estimator=RandomForestRegressor(n_estimators=10, random_state=42)\n",
    ")\n",
    "\n",
    "reg.fit(X_train, y_train)\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "get_score(y_pred, y_test)"
   ],
   "metadata": {
    "id": "PgHoaeW0nWGh"
   },
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse = 1961.62\n",
      "r2_score = -0.26\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Результаты встроенной модели оказались хуже, чем самописной"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Блендинг (0.5 балла)\n",
    "\n",
    "Реализуйте схему блендинга. Для этого разбейте **тестовую** выборку на *валидационную* и *тестовую* части, при необходимости также доработайте код класса `StackingRegressionSolver`. Используйте для обучения базовых моделей обучающую выборку, а для обучения метамодели - валидационную.\n",
    "\n",
    "Как изменилось качество? Как вы думаете, правдоподобнее ли выглядит такой результат?"
   ],
   "metadata": {
    "id": "_Y95u9XcqmeP"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "train, validate, test = np.split(df.sample(frac=1, random_state=42), [int(.6*len(df)), int(.8*len(df))])\n",
    "\n",
    "X_train, y_train = train.drop(columns=['price']), train.price\n",
    "X_validate, y_validate = validate.drop(columns=['price']), validate.price\n",
    "X_test, y_test = test.drop(columns=['price']), test.price"
   ],
   "metadata": {
    "id": "t6JPX4o4rBP1"
   },
   "execution_count": 70,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "class BlendingRegressionSolver:\n",
    "    def __init__(self, base_estimators: list, meta_estimator):\n",
    "        self._base_estimators = base_estimators\n",
    "        self._meta_estimator = meta_estimator\n",
    "\n",
    "    def _fit_base(self, X_train: pd.DataFrame, y_train: pd.Series) -> None:\n",
    "        for estimator in tqdm(self._base_estimators):\n",
    "            estimator.fit(X_train, y_train)\n",
    "\n",
    "    def _predict_base(self, X_valid: pd.DataFrame) -> pd.DataFrame:\n",
    "        '''Размерность [k, N]'''\n",
    "        meta_features = []\n",
    "        for estimator in self._base_estimators:\n",
    "            meta_features.append(estimator.predict(X_valid))\n",
    "        df = pd.DataFrame(meta_features)\n",
    "        return df.T # Размерность [N, k]\n",
    "\n",
    "    def fit(self, X_valid: pd.DataFrame, y_valid: pd.Series,\n",
    "            X_train: pd.DataFrame, y_train: pd.Series) -> None:\n",
    "        self._fit_base(X_train, y_train)\n",
    "        meta_features = self._predict_base(X_valid)\n",
    "        assert meta_features.shape[0] == y_valid.shape[0], 'Не совпадающие размерности'\n",
    "        self._meta_estimator.fit(meta_features, y_valid)\n",
    "\n",
    "    def predict(self, X_test: pd.DataFrame) -> pd.Series:\n",
    "        meta_features = self._predict_base(X_test)\n",
    "        return self._meta_estimator.predict(meta_features)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e4b41aa8115f4499b491c92b25302fd4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse = 1630.23\n",
      "r2_score = 0.02\n"
     ]
    }
   ],
   "source": [
    "blending_regressor = BlendingRegressionSolver(\n",
    "    base_estimators=[\n",
    "        LinearRegression(n_jobs=-1), DecisionTreeRegressor(**params),\n",
    "        SVR(), EnsembleTreeRegressor(**params)\n",
    "    ],\n",
    "    meta_estimator=LinearRegression(n_jobs=-1)\n",
    ")\n",
    "blending_regressor.fit(X_train, y_train, X_validate, y_validate)\n",
    "y_pred = blending_regressor.predict(pd.DataFrame(X_test))\n",
    "\n",
    "get_score(y_pred, y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Результаты Блендинга оказались лучше, чем результаты встроенной модели стекинга, но хуже самописной модели стэккинга.\n",
    "*Как изменилось качество?* Качество практически не изменилось\n",
    "*Как вы думаете, правдоподобнее ли выглядит такой результат?* Да, но меня пугает такая большая ошибка"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Бэггинг (максимум 3 балла)"
   ],
   "metadata": {
    "id": "bu3-DYDlqKhT"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "В этой секции аналогично нужно решить задачу при помощи бэггинга - сначала написанного самостоятельно, а затем взятого из sklearn."
   ],
   "metadata": {
    "id": "UIJY9_baafxr"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Бэггинг своими руками (2 балла)"
   ],
   "metadata": {
    "id": "cWrKsOxerRUC"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Решите задачу, используя в качестве базовой модели линейную регрессию, дерево и SVM. Какой из алгоритмов в качестве базовой модели дает лучший результат? Почему, как вы думаете?"
   ],
   "metadata": {
    "id": "frsguFTtawet"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class BaggingRegressionSolver:\n",
    "    def __init__(\n",
    "        self,\n",
    "        base_estimator_ctor,\n",
    "        max_samples: float = 1,\n",
    "        n_estimators: int = 100,\n",
    "        sample_random_state=42,\n",
    "        **model_kwargs\n",
    "    ):\n",
    "        if max_samples < 0 or max_samples > 1:\n",
    "            raise ValueError\n",
    "        self._estimators = [\n",
    "            base_estimator_ctor(**model_kwargs) for _ in range(n_estimators)\n",
    "        ]\n",
    "        self._max_samples = max_samples\n",
    "        self._random_state = sample_random_state\n",
    "\n",
    "    def _sample_data(self, X: pd.DataFrame, y: pd.Series) -> Tuple[pd.DataFrame, pd.Series]:\n",
    "        x_i = X.sample(frac=self._max_samples, random_state=self._random_state)\n",
    "        y_i = y.loc[x_i.index]\n",
    "        return x_i, y_i\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y: pd.Series):\n",
    "        for estimator in self._estimators:\n",
    "            x_i, y_i = self._sample_data(X, y)\n",
    "            estimator.fit(x_i, y_i)\n",
    "\n",
    "    def predict(self, X: pd.DataFrame) -> pd.Series:\n",
    "        y = []\n",
    "        for estimator in self._estimators:\n",
    "            y_pred = estimator.predict(X)\n",
    "            y.append(y_pred)\n",
    "        ser = pd.DataFrame(y)\n",
    "        return ser.mean()"
   ],
   "metadata": {
    "id": "M6TGRabcnSxG"
   },
   "execution_count": 73,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for meta in tqdm([LinearRegression, DecisionTreeRegressor, SVR]):\n",
    "    brs = BaggingRegressionSolver(base_estimator_ctor=meta)\n",
    "    brs.fit(X_train, y_train)\n",
    "    y_pred = brs.predict(X_test)\n",
    "\n",
    "    get_score(y_pred, y_test, f'model = {meta}')"
   ],
   "metadata": {
    "id": "R7E2FbSHa_Hf"
   },
   "execution_count": 74,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "53ed0063e0da40659a570689646f0e83"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model = <class 'sklearn.linear_model._base.LinearRegression'>\n",
      "mse = 1655.88\n",
      "r2_score = 0.01\n",
      "model = <class 'sklearn.tree._classes.DecisionTreeRegressor'>\n",
      "mse = 3890.4\n",
      "r2_score = -1.33\n",
      "model = <class 'sklearn.svm._classes.SVR'>\n",
      "mse = 1762.32\n",
      "r2_score = -0.06\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Использование встроенной модели бэггинга (1 балл)\n",
    "\n",
    "Решите задачу, используя:\n",
    "- `sklearn.ensemble.BaggingRegressor`. В качестве базовой модели попробуйте линейную регрессию, дерево и SVM\n",
    "- `sklearn.ensemble.RandomForestRegressor`\n",
    "\n",
    "Какая модель дает лучший результат? Попробуйте улучшить его, перебрав несколько гиперпараметров (как у базовой модели, так и у ансамбля).\n",
    "\n"
   ],
   "metadata": {
    "id": "jLVRU23TrTfj"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "for meta in tqdm([LinearRegression(), DecisionTreeRegressor(), SVR()]):\n",
    "    br = BaggingRegressor(base_estimator=meta)\n",
    "\n",
    "    br.fit(X_train, y_train)\n",
    "    y_pred = br.predict(X_test)\n",
    "\n",
    "    get_score(y_pred, y_test, f'model = {meta}, bagging = BaggingRegressor')"
   ],
   "metadata": {
    "id": "ugjjfpES2kk1"
   },
   "execution_count": 77,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "52d9fbbe18c84f5caf727bba09f96faf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model = LinearRegression(), bagging = BaggingRegressor\n",
      "mse = 1653.75\n",
      "r2_score = 0.01\n",
      "model = DecisionTreeRegressor(), bagging = BaggingRegressor\n",
      "mse = 2158.34\n",
      "r2_score = -0.29\n",
      "model = SVR(), bagging = BaggingRegressor\n",
      "mse = 1764.76\n",
      "r2_score = -0.06\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bagging = RandomForestRegressor\n",
      "mse = 2213.06\n",
      "r2_score = -0.33\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "br = RandomForestRegressor()\n",
    "\n",
    "br.fit(X_train, y_train)\n",
    "y_pred = br.predict(X_test)\n",
    "\n",
    "get_score(y_pred, y_test, 'bagging = RandomForestRegressor')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Бустинг (максимум 3 балла)"
   ],
   "metadata": {
    "id": "H-jNmNEEqMU6"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Бустинг своими руками (2 балла)\n",
    "\n",
    "Решите задачу при помощи алгоритма бустинга, используя в качестве базовой модели:\n",
    "- Линейную регрессию\n",
    "- Дерево\n",
    "- Случайный лес\n",
    "\n",
    "Какая модель дает лучший результат? Попробуйте улучшить его, перебрав несколько гиперпараметров (как у базовой модели, так и у ансамбля)."
   ],
   "metadata": {
    "id": "dd9LV-ot4cke"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "outputs": [],
   "source": [
    "class Loss(ABC):\n",
    "    \"\"\"\n",
    "    Базовый класс для функции потерь\n",
    "    \"\"\"\n",
    "    @abstractmethod\n",
    "    def forward(self, y_true: pd.Series, y_pred: pd.Series) -> float:\n",
    "        \"\"\"\n",
    "        Метод, вычисляющий значение функции потерь\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def backward(self, y_true: pd.Series, y_pred: pd.Series) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Метод, вычисляющий значение градиента функции потерь по предсказаниям модели\n",
    "        \"\"\"\n",
    "        pass"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "outputs": [],
   "source": [
    "class MSELoss(Loss):\n",
    "    def forward(self, y_pred: pd.Series, y_true: pd.Series) -> float:  # посчитаем значение ошибки\n",
    "        return ((y_pred - y_true) ** 2).mean()\n",
    "\n",
    "    def backward(self, y_pred: pd.Series, y_true: pd.Series) -> pd.Series:  # посчитаем производную по выходам модели\n",
    "        return y_true - y_pred"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class GradientBoostingRegressionSolver:\n",
    "    def __init__(\n",
    "        self,\n",
    "        base_estimator_ctor,\n",
    "        n_estimators: int = 10,\n",
    "        loss: Loss = MSELoss(),\n",
    "        learning_rate: float = 0.1,\n",
    "        early_stopping: int = 10,\n",
    "        **model_kwargs\n",
    "    ):\n",
    "        if early_stopping < 0:\n",
    "            raise ValueError\n",
    "\n",
    "        self._ctor = base_estimator_ctor\n",
    "        self._kwargs = model_kwargs\n",
    "        self._n_estimators = n_estimators\n",
    "        self._estimators = []\n",
    "        self._early_stopping = early_stopping\n",
    "        self._loss = loss\n",
    "        self._lr = learning_rate\n",
    "        self._random_state = 42\n",
    "\n",
    "    def _sample_data(self, X: pd.DataFrame, y: pd.Series, frac: float) -> Tuple[pd.DataFrame, pd.Series]:\n",
    "        x_sample = X.sample(frac=frac, random_state=self._random_state)\n",
    "        y_sample = y.loc[x_sample.index]\n",
    "        return x_sample, y_sample\n",
    "\n",
    "    def _split_data(\n",
    "            self, X: pd.DataFrame, y: pd.Series, val_size: float\n",
    "    ) -> Tuple[pd.DataFrame, pd.DataFrame, pd.Series, pd.Series]:\n",
    "        x_val, y_val = self._sample_data(X, y, val_size)\n",
    "        x_train, y_train = X[~X.index.isin(x_val.index)], y[~y.index.isin(y_val.index)]\n",
    "        return x_train, x_val, y_train, y_val\n",
    "\n",
    "    def predict(self, X: pd.DataFrame) -> pd.Series:\n",
    "        '''Прогоним данные, поступившие на вход, через все модели в ансамбле и сложим ответы '''\n",
    "        pred = map(lambda x: x.predict(X), self._estimators)\n",
    "        return sum(pred)\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y: pd.Series, val_size: float = 0.1):\n",
    "        '''Обучение'''\n",
    "        # Хотим получить валидационную выборку, не тратя на это время снаружи\n",
    "        x_train, x_val, y_train, y_val = self._split_data(X, y, val_size)\n",
    "        # Создадим и обучим базовую модель\n",
    "        base_estimator = DummyRegressor()\n",
    "        base_estimator.fit(x_train, y_train)\n",
    "        # Добавим базовую модель в список моделей\n",
    "        self._estimators.append(base_estimator)\n",
    "\n",
    "        # Посчитаем предсказания как на обучающей, так и на валидационной выборках\n",
    "        y_pred_train, y_pred_val = self.predict(x_train), self.predict(x_val)\n",
    "\n",
    "        # Посчитаем значение функции потерь для обучения и валидации\n",
    "        train_loss, val_loss = self._loss.forward(y_train, y_pred_train), self._loss.forward(y_val, y_pred_val)\n",
    "\n",
    "        # Посчитаем остатки, используя градиент функции потерь\n",
    "        residuals = - self._lr * self._loss.backward(y_train, y_pred_train)\n",
    "\n",
    "        print(f'train loss: {train_loss}, val loss: {val_loss}')\n",
    "\n",
    "        previous_val_loss, cnt = val_loss, 0\n",
    "        for i in range(self._n_estimators - 1):\n",
    "            # Создадим очередную модель\n",
    "            estimator = self._ctor(**self._kwargs)\n",
    "\n",
    "            # 1. Обучим её и добавим в список моделей\n",
    "\n",
    "            estimator.fit(x_train, residuals)\n",
    "            self._estimators.append(estimator)\n",
    "\n",
    "            # 2. Предскажем ВСЕМ ансамблем данные из обучающей выборки, то же самое сделаем для валидационной\n",
    "            y_pred_train, y_pred_val = self.predict(x_train), self.predict(x_val)\n",
    "\n",
    "            # 3. Посчитаем значения функции потерь (на обучении и валидации)\n",
    "            train_loss, val_loss = self._loss.forward(y_train, y_pred_train), self._loss.forward(y_val, y_pred_val)\n",
    "\n",
    "            # 4. Обновим остатки для обучающей выборки\n",
    "            cnt += 1\n",
    "            residuals = - self._lr * self._loss.backward(y_train, y_pred_train)\n",
    "\n",
    "            print(f'train loss: {train_loss}, val loss: {val_loss}')\n",
    "            # Если валидационный лосс несколько (self._early_stopping) шагов подряд не уменьшается, то остановим обучение\n",
    "\n",
    "            if cnt > self._early_stopping:\n",
    "                break"
   ],
   "metadata": {
    "id": "Sx68FEOxmxw1"
   },
   "execution_count": 172,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Вопросы на дополнительный балл:\n",
    "- *Почему градиент по ответам мы берем со знаком минус?* Вектор градиента направлен в сторону увеличения функции,\n",
    "мы используем знак минус что бы двигаться (в обратном направлении) к минимуму функции.\n",
    "- *Почему в обучении мы домножаем на `learning_rate`, а в предсказаниях этого не делаем?*\n",
    "learning_rate - шаг градиентного спуска, он выполняется на этапе обучения модели, мы умножаем на l_r вектор производных, на этапе предсказания в этом нет необходимости, тк моделька уже обучена, веса подобраны, градиентный спуск уже не выполняется"
   ],
   "metadata": {
    "id": "1_Fgwz-JfRw6"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "gbr = GradientBoostingRegressionSolver(LinearRegression, early_stopping=10)\n",
    "\n",
    "gbr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = gbr.predict(X_test)\n",
    "\n",
    "get_score(y_pred, y_test)"
   ],
   "metadata": {
    "id": "IWQSDxWoc2Xq"
   },
   "execution_count": 176,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 2659.39066204753, val loss: 1850.9158807243762\n",
      "train loss: 2650.796074752804, val loss: 1841.1717048106123\n",
      "train loss: 2643.8344590440793, val loss: 1833.1478086897025\n",
      "train loss: 2638.195550320011, val loss: 1826.530450564081\n",
      "train loss: 2633.628034253516, val loss: 1821.0641884414151\n",
      "train loss: 2629.92834623966, val loss: 1816.5409342852324\n",
      "train loss: 2626.9315989484307, val loss: 1812.7910747655812\n",
      "train loss: 2624.5042336425304, val loss: 1809.676267266842\n",
      "train loss: 2622.53806774476, val loss: 1807.0835940338145\n",
      "train loss: 2620.9454733675507, val loss: 1804.9208174719267\n",
      "mse = 1651.89\n",
      "r2_score = 0.01\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Catboost (1 балл)"
   ],
   "metadata": {
    "id": "Iul0dgvdqOIa"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Решите эту же задачу при помощи `catboost`, не перебирая гиперпараметры. Насколько лучше или хуже справился катбуст? В качестве эксперимента также попробуйте закинуть в него данные без предобработки (разумеется, выкинув ненужные колонки). Изменилось ли качество? Каким образом?"
   ],
   "metadata": {
    "id": "QIMRGkhP5KOk"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from catboost import CatBoostRegressor"
   ],
   "metadata": {
    "id": "e9ewnPfYqP5P"
   },
   "execution_count": 177,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## С использованием предобработанных данных"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.05298\n",
      "0:\tlearn: 50.5614111\ttotal: 1.86ms\tremaining: 1.86s\n",
      "300:\tlearn: 37.2372714\ttotal: 383ms\tremaining: 890ms\n",
      "600:\tlearn: 32.0892930\ttotal: 831ms\tremaining: 552ms\n",
      "900:\tlearn: 29.3498719\ttotal: 1.25s\tremaining: 137ms\n",
      "999:\tlearn: 28.5364375\ttotal: 1.36s\tremaining: 0us\n",
      "mse = 5754.71\n",
      "r2_score = -2.45\n"
     ]
    }
   ],
   "source": [
    "catboosting = CatBoostRegressor(random_state=42, metric_period=300)\n",
    "catboosting.fit(X_train, y_train)\n",
    "y_pred = catboosting.predict(X_test)\n",
    "\n",
    "get_score(y_pred, y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## С использованием необработанных данных"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv').drop(columns=[\n",
    "    'product_name',\n",
    "    'index',\n",
    "    'uniq_id',\n",
    "    'customers_who_bought_this_item_also_bought',\n",
    "    'items_customers_buy_after_viewing_this_item',\n",
    "    'sellers',\n",
    "    'description', # text\n",
    "    'product_information', # text\n",
    "    'product_description', # text\n",
    "    'customer_questions_and_answers', # text\n",
    "    'customer_reviews', # text\n",
    "])\n",
    "df['price'] = df['price'].str.replace('£', '')\n",
    "df['price'] = df['price'].str.replace(',', '')\n",
    "df['price'] = df['price'].astype('float')\n",
    "df = df.dropna()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "outputs": [],
   "source": [
    "X, y = df.drop(columns=['price']), df.price\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=42)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.05172\n",
      "0:\tlearn: 37.3666326\ttotal: 2.58ms\tremaining: 2.57s\n",
      "300:\tlearn: 29.3465994\ttotal: 853ms\tremaining: 1.98s\n",
      "600:\tlearn: 26.7843836\ttotal: 2.34s\tremaining: 1.55s\n",
      "900:\tlearn: 24.8630250\ttotal: 3.3s\tremaining: 363ms\n",
      "999:\tlearn: 24.4064804\ttotal: 3.66s\tremaining: 0us\n",
      "mse = 6325.02\n",
      "r2_score = -0.02\n"
     ]
    }
   ],
   "source": [
    "catboosting = CatBoostRegressor(\n",
    "    random_state=42,\n",
    "    metric_period=300,\n",
    "    cat_features=[\n",
    "        'manufacturer', 'number_available_in_stock', 'number_of_reviews',\n",
    "        'average_review_rating', 'amazon_category_and_sub_category'\n",
    "    ]\n",
    ")\n",
    "catboosting.fit(X_train, y_train)\n",
    "y_pred = catboosting.predict(X_test)\n",
    "\n",
    "get_score(y_pred, y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Результаты CatBoostRegressor для данных без предобработки оказались хуже, чем для предобработанных данных,\n",
    "также хочу заметить что в обоих случаях CatBoostRegressor работал с гиперпараетрами по умолчанию, и показал результаты хуже чем самописный бустинг"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "*Насколько лучше или хуже справился катбуст?* Катбуст справился хуже, я думаю это связвно с тем, что в самописном бустинге я использовал подобранные гиперпараметры (хочется в это верить)\n",
    "\n",
    "## Комментарий\n",
    "В любом случае результаты моделей полученные в этой домашке ужасные, r_2 ~ 2% такое я вижу в первый раз, я думаю что это связано с малым объёмом данных"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
