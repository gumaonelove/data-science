{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sZDTrjkL9LJx"
   },
   "source": [
    "# Лабораторная работа\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import warnings\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import pickle\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from catboost import CatBoostClassifier\n",
    "from collections import Counter\n",
    "from sentence_transformers import SentenceTransformer, util"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NPQTLpQKMllu"
   },
   "source": [
    "## 1 EDA\n",
    "Необходимо исследовать данные в предлагаемом Вам датасете. К исследованию данных относится анализ распределения значений в признаках, проверка скоррелированности признаков и т.д."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "KCm55dW18tHv"
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nYGKFSdS_Cr8"
   },
   "source": [
    "### 1.1. Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "f504WeNz_Ipy"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'houses_ads_popularity.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/jl/6gw5l36x7tv9jxp646h_lhn40000gn/T/ipykernel_2740/770110612.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mpandas\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0mdf\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'houses_ads_popularity.csv'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mindex_col\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'Id'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msep\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m','\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    309\u001B[0m                     \u001B[0mstacklevel\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstacklevel\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    310\u001B[0m                 )\n\u001B[0;32m--> 311\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    312\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    313\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mwrapper\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001B[0m in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001B[0m\n\u001B[1;32m    584\u001B[0m     \u001B[0mkwds\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkwds_defaults\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    585\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 586\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0m_read\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    587\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    588\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001B[0m in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    480\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    481\u001B[0m     \u001B[0;31m# Create the parser.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 482\u001B[0;31m     \u001B[0mparser\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mTextFileReader\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    483\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    484\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mchunksize\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0miterator\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[1;32m    809\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moptions\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"has_index_names\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mkwds\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"has_index_names\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    810\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 811\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_engine\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_make_engine\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mengine\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    812\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    813\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mclose\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001B[0m in \u001B[0;36m_make_engine\u001B[0;34m(self, engine)\u001B[0m\n\u001B[1;32m   1038\u001B[0m             )\n\u001B[1;32m   1039\u001B[0m         \u001B[0;31m# error: Too many arguments for \"ParserBase\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1040\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mmapping\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mengine\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moptions\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# type: ignore[call-arg]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1041\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1042\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_failover_to_python\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, src, **kwds)\u001B[0m\n\u001B[1;32m     49\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     50\u001B[0m         \u001B[0;31m# open handles\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 51\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_open_handles\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msrc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     52\u001B[0m         \u001B[0;32massert\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mhandles\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     53\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\u001B[0m in \u001B[0;36m_open_handles\u001B[0;34m(self, src, kwds)\u001B[0m\n\u001B[1;32m    220\u001B[0m         \u001B[0mLet\u001B[0m \u001B[0mthe\u001B[0m \u001B[0mreaders\u001B[0m \u001B[0mopen\u001B[0m \u001B[0mIOHandles\u001B[0m \u001B[0mafter\u001B[0m \u001B[0mthey\u001B[0m \u001B[0mare\u001B[0m \u001B[0mdone\u001B[0m \u001B[0;32mwith\u001B[0m \u001B[0mtheir\u001B[0m \u001B[0mpotential\u001B[0m \u001B[0mraises\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    221\u001B[0m         \"\"\"\n\u001B[0;32m--> 222\u001B[0;31m         self.handles = get_handle(\n\u001B[0m\u001B[1;32m    223\u001B[0m             \u001B[0msrc\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    224\u001B[0m             \u001B[0;34m\"r\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\u001B[0m in \u001B[0;36mget_handle\u001B[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[1;32m    700\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mioargs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mencoding\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0;34m\"b\"\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mioargs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmode\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    701\u001B[0m             \u001B[0;31m# Encoding\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 702\u001B[0;31m             handle = open(\n\u001B[0m\u001B[1;32m    703\u001B[0m                 \u001B[0mhandle\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    704\u001B[0m                 \u001B[0mioargs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmode\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'houses_ads_popularity.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('houses_ads_popularity.csv', index_col='Id', sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fiKGts2TA3Mw"
   },
   "source": [
    "### 1.2. Информация о DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hhG2q9-8M85s"
   },
   "source": [
    "#### 1.2.1. О столбцах и типах данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4sSlZmKmBFkT"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oHjd77TyBKmz"
   },
   "source": [
    "#### 1.2.2. Описание данных         \n",
    "* *bathrooms* - количество туалетных комнат      \n",
    "* *bedrooms* - количество спальных комнат\n",
    "* *building_id* - уникальный номер дома\n",
    "* *created* - дата создания объявления \n",
    "* *description* - описание\n",
    "* *display_address* - адрес расположения\n",
    "* *features* - особенности\n",
    "* *latitude* - широта\n",
    "* *listing_id* - идентификатор\n",
    "* *longitude* - долгота   \n",
    "* *manager_id* - идентификатор менеджера\n",
    "* *photos* - фотографии\n",
    "* *price* - цена\n",
    "* *street_address* - адрес по улице\n",
    "* *TARGET* - популярность обьвления"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s3SVTmKBCAJ_"
   },
   "source": [
    "#### 1.2.3. Первые 5 строк таблицы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GZ0MyUP4CA3U"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mOz5JWnxDFNJ"
   },
   "source": [
    "### 1.3. Гистограммы для всех столбцов таблицы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JVG0hR61DNOh"
   },
   "outputs": [],
   "source": [
    "df.hist(figsize=(10, 10))\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T7JcggNxFm86"
   },
   "source": [
    "Рассмотрим гистограму столбца цены отдельно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DvwFuGziEkCW"
   },
   "outputs": [],
   "source": [
    "df['price'].hist(bins=100, range=[1, 10**4])\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QKEeJge3Dd54"
   },
   "source": [
    "#### 1.3.1 Комментарий\n",
    "* *bathrooms* - большинство квартир имеют 1 туалетную комнату, данные имеют распредение Пуассона\n",
    "* *bedrooms* - распределение данных похоже на нормальное (судя по гистограмме)\n",
    "* *latitude* - большинство квартир расположены на одной широте\n",
    "* *longitude* - большинство квартир расположены на одной долготе\n",
    "* *price* - имеет нормальное распределение, внутри диапазона цены (1, 10^4), с левосторонней ассиметрией. В данных присутствуют выбросы, далее обработем их."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XVjuUIvlGJ-l"
   },
   "source": [
    "### 1.4. Корреляция в данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G53upsYaM4v9"
   },
   "source": [
    "#### 1.4.1. Матрица корреляции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zAL9jabYGPTW"
   },
   "outputs": [],
   "source": [
    "corr_matrix = df.corr()\n",
    "corr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UFANAiVLG08w"
   },
   "source": [
    "#### 1.4.2. Тепловая карта"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SBKneMyhG4kX"
   },
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(10, 10)})\n",
    "sns.heatmap(corr_matrix, annot=True)\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rMg0UUIZHUk6"
   },
   "source": [
    "* *bathrooms* и *bedrooms* коррелируют, их коэфицент 0.53\n",
    "* *longitude* и *latidude* линайно зависимы, коэфицент -0.99 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bjn19NYQ-hz6"
   },
   "source": [
    "## 2 Feature engineering\n",
    "Необходимо заполнить пропуски в данных, обработать категориальные признаки и т.д."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9WvfTe8wNnHe"
   },
   "source": [
    "### 2.1. Обработка пропусков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dyhWye8tN27P"
   },
   "source": [
    "#### 2.1.1. Количество пропусков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kyVZ1pNxN8jS"
   },
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SiRWo7_aOFNW"
   },
   "source": [
    "#### 2.1.2. Процент пропусков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UIBXQNmNOJrH"
   },
   "outputs": [],
   "source": [
    "df.isna().sum() / df.shape[0] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q3f28a8r20fl"
   },
   "source": [
    "#### 2.1.3. Заполнение пропусков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cujCVTwx2iNV"
   },
   "outputs": [],
   "source": [
    "df['description'] = df['description'].str.strip()\n",
    "df.loc[df['description'].isna() == True, 'description'] = 'None'\n",
    "df.loc[df['description'] == '', 'description'] = 'None'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wyfTnywWOUvM"
   },
   "source": [
    "Пропусков незначительное количетво, заполним пропуски в столбце \"description\" константой \"None\", квартиры без адреса по улице удалим"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VAOZDQHG2QOG"
   },
   "outputs": [],
   "source": [
    "df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Md0Tn2On3ArS"
   },
   "source": [
    "### 2.2. Изменение типов данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6q07EudV3uEP"
   },
   "source": [
    "#### 2.2.1. Численные"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "df['TARGET'].value_counts()"
   ],
   "metadata": {
    "id": "Kvhm-ShdviKp"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pqJnDB0t31Z8"
   },
   "outputs": [],
   "source": [
    "df['bathrooms'] = df['bathrooms'].astype('uint8')\n",
    "df['bedrooms'] = df['bedrooms'].astype('uint8')\n",
    "\n",
    "df['TARGET'] = df['TARGET'].replace('low', '0')\n",
    "df['TARGET'] = df['TARGET'].replace('medium', '1')\n",
    "df['TARGET'] = df['TARGET'].replace('high', '2')\n",
    "df['TARGET'] = df['TARGET'].astype('uint8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kft6Qd1S4J5W"
   },
   "source": [
    "#### 2.2.2. Временные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J6mlLGwQ4JQd"
   },
   "outputs": [],
   "source": [
    "df['created'] = pd.to_datetime(df['created'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7nim_iHv4-bB"
   },
   "source": [
    "#### 2.2.3. Категориальные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WRKmLrwP5R1r"
   },
   "outputs": [],
   "source": [
    "gl_obj = df.select_dtypes(include='object').copy()\n",
    "gl_obj.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ONieqoEb5XaB"
   },
   "source": [
    "Что бы оптимизировать память и вычисления, необходимо категоризировать данные, в которых менее половины уникальных значений, в нашем случаи это \n",
    "* *building_id* \n",
    "* *display_address*\n",
    "* *manager_id*\n",
    "* *street_address*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yz5y1vat5Ci6"
   },
   "outputs": [],
   "source": [
    "columns = ['building_id', 'display_address', 'manager_id', 'street_address']\n",
    "for column in columns:\n",
    "    labelencoder = LabelEncoder()\n",
    "    data_new = labelencoder.fit_transform(df[column].values)\n",
    "    df[column] = data_new\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dkWm0BptuMHs"
   },
   "source": [
    "#### 2.2.4. Фото\n",
    "Укажем колличество фотографий у лбьявления (количество элементов в массиве)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "622EgeOSuN48"
   },
   "outputs": [],
   "source": [
    "df.loc[df['photos'] == '[]', 'photos'] = ''\n",
    "df_photos = df['photos'].apply(lambda x: len(x.split(',')) if x != '' else 0)\n",
    "df['photos'] = df_photos"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "df['photos'] = df['photos'].astype('uint8')"
   ],
   "metadata": {
    "id": "-b3JzK3C29YL"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "imytXYIy6ykF"
   },
   "source": [
    "#### 2.2.5. Текстовые\n",
    "Текстовые поля описаний, закодируем слова в эмбэдинги, подробное использование тектовых фич будет в разделе 6. NLP"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "features = df['features'].str.lower().str.strip()\n",
    "features = features.apply(lambda row: row[1: -1].replace(\"'\", \"\").replace(',', ''))\n",
    "features.head()"
   ],
   "metadata": {
    "id": "gob6Ig0v8VQq"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['features'] = features"
   ],
   "metadata": {
    "id": "AqLG-4u_QYFc"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Очистим текст от html тэгов"
   ],
   "metadata": {
    "id": "71ThucI-4AZW"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def remove_html(row) -> list:\n",
    "  row = re.sub(r'(\\<(/?[^>]+)>)', '', row)\n",
    "  return row"
   ],
   "metadata": {
    "id": "trS0S_Id3RlY"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['description'] = df['description'].str.lower().str.strip()\n",
    "df['description'] = df['description'].apply(remove_html)"
   ],
   "metadata": {
    "id": "eahqRElkQYFd"
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hMQhmQSmvvpl"
   },
   "source": [
    "### 2.3. Обработка дубликатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4QUXrUZGvvDj"
   },
   "outputs": [],
   "source": [
    "df.drop(columns=['description', 'features']).duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "olaixxh_v6x1"
   },
   "source": [
    "Дубликаты не обнаружены"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.4. Добавление дополнительных фич"
   ],
   "metadata": {
    "collapsed": false,
    "id": "VhOvGttWQYFi"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Количество слов в описании и количество слов в features"
   ],
   "metadata": {
    "id": "aYRe4U366o63"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['description_count_words'] = df['description'].apply(lambda matrix: len(matrix))\n",
    "df['features_count_words'] = df['features'].apply(lambda matrix: len(matrix))\n",
    "\n",
    "df['features_count_words'] = df['features_count_words'].astype('uint16')\n",
    "df['description_count_words'] = df['description_count_words'].astype('uint16')"
   ],
   "metadata": {
    "id": "5plyveBbQYFi"
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "skcRGuZf-jV1"
   },
   "source": [
    "## 3 **Выбор целевой метрики**\n",
    "Необходимо выбрать метрику качества, которую вы будете оптимизировать. Для выбранной метрики необходимо написать пояснение. В этом задании нет единственного правильного ответа, однако за откровенно неадекватный выбор или слабую аргументацию будут снижаться баллы.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Самая популярная и самая не эффективная матрика качества для задач классификации это accuracy,\n",
    "она имеет право на существование только в случаи работы с классами имеющими равное количество экземпляров.\n",
    "\n",
    "Посмотрим на количество обьявлений (экземпляров) каждого класса"
   ],
   "metadata": {
    "collapsed": false,
    "id": "OBu5eR_RQYFi"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['TARGET'].value_counts()"
   ],
   "metadata": {
    "id": "NbgtRme4QYFj"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Процентное соотношение от общего количества"
   ],
   "metadata": {
    "collapsed": false,
    "id": "6FGInTSXQYFj"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['TARGET'].value_counts() / df.shape[0] * 100"
   ],
   "metadata": {
    "id": "lYa-mquwQYFj"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Классы не равные, следовательно, мы не можем использовать accuracy (не очень то и хотелось),\n",
    "рассмотрим другие метрики (имеющие право на существование):\n",
    "* **Precision** - точность\n",
    "* **Recall** - полнота\n",
    "\n",
    "Они зависят, в отличие от accuracy, от соотношения классов и потому применимы в условиях несбалансированных выборок.\n",
    "Будем использовать f1 меру (совокупность полноты и точности)"
   ],
   "metadata": {
    "collapsed": false,
    "id": "5_JmsvMjQYFn"
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gZ7eZU_k-kua"
   },
   "source": [
    "## 4 **Проведение экспериментов**\n",
    "Необходимо попробовать разные модели, изученные в рамках курса и оптимизировать ими выбранную вами целевую метрику. Решение, состоящее только из grid-search по гиперпараметрам Catboost, получает 0 баллов.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "В классах TARGET не равное количество элементов, будем обучаться на датасете с одинаковым количество объявлений каждого класса"
   ],
   "metadata": {
    "id": "rERRYOn87MXM"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "PS После тестирование оказалось что в случаи обучения на датасете с неравным количество обьявлений каждого класса, результаты оказались лучше чем на равно классовом. 0.73 прости 0.54"
   ],
   "metadata": {
    "id": "uK_VzPydFHu7"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#count = df.loc[df['TARGET'] == 2].shape[0]"
   ],
   "metadata": {
    "id": "OGSjUgCW73AL"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#df_0 = df.loc[df['TARGET'] == 0][:count]\n",
    "#df_1 = df.loc[df['TARGET'] == 1][:count]\n",
    "#df_2 = df.loc[df['TARGET'] == 2]"
   ],
   "metadata": {
    "id": "w8I0tGrQ7LWM"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#assert df_0.shape[0] == df_1.shape[0] == count, 'не равные размерности'"
   ],
   "metadata": {
    "id": "uYATii3m8ugi"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#normal_target_df = pd.concat([df_0, df_1, df_2])\n",
    "normal_target_df = df"
   ],
   "metadata": {
    "id": "kNeRx-jN9RSD"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_to_train = normal_target_df[\n",
    "    ['bathrooms', 'bedrooms', 'building_id', 'manager_id', 'photos', \n",
    "     'price', 'features_count_words', 'description_count_words']\n",
    "]\n",
    "df_to_train.head()"
   ],
   "metadata": {
    "id": "It5Fw5XHQYFo"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_to_train, normal_target_df['TARGET'], test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "id": "DYQ1KoMyQYFo"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Нормализация данных"
   ],
   "metadata": {
    "collapsed": false,
    "id": "nZRUYH3lQYFo"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "transformer = Normalizer().fit(X_train)\n",
    "X_train_normalize = transformer.transform(X_train)\n",
    "\n",
    "transformer = Normalizer().fit(X_test)\n",
    "X_test_normalize = transformer.transform(X_test)"
   ],
   "metadata": {
    "id": "XYBtlDLRQYFo"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_report_of_model(model, X_train, y_train, X_test) -> None:\n",
    "    '''\n",
    "    1) Обучаем полученную модель\n",
    "    2) Делаем предсказание\n",
    "    3) Считаем метрики\n",
    "    '''\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    print(report)"
   ],
   "metadata": {
    "id": "O6sViSHdQYFo"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.1. CatBoost"
   ],
   "metadata": {
    "collapsed": false,
    "id": "NTC-172LQYFp"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install catboost"
   ],
   "metadata": {
    "id": "GCoaSR2H9jTX"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "catboosting = CatBoostClassifier(metric_period=300)"
   ],
   "metadata": {
    "id": "v3Xk3SidQYFp"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4.1.1. Ненормализованные данные"
   ],
   "metadata": {
    "collapsed": false,
    "id": "InJoBTLCQYFp"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "get_report_of_model(catboosting, X_train, y_train, X_test)"
   ],
   "metadata": {
    "id": "f8YElbZhQYFp"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4.1.2. Нормализованные данные"
   ],
   "metadata": {
    "collapsed": false,
    "id": "MUHKANL_QYFp"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "get_report_of_model(catboosting, X_train_normalize, y_train, X_test_normalize)"
   ],
   "metadata": {
    "id": "KPlb66gzQYFq"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "После опытов проведенных ниже, хочу отметить что наилучший результат показал катбуст,\n",
    "Нормализованные данные в этом эксперименте показали результат хуже"
   ],
   "metadata": {
    "collapsed": false,
    "id": "PDGMDOr7QYFq"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.2. Метод К-ближайших соседей"
   ],
   "metadata": {
    "collapsed": false,
    "id": "qFj6SaZKQYFq"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nnn = KNeighborsClassifier(n_neighbors=3, n_jobs=-1)"
   ],
   "metadata": {
    "id": "pj00EymoQYFq"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4.2.1. Ненормализованные данные"
   ],
   "metadata": {
    "collapsed": false,
    "id": "TDu3VCkMQYFq"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "get_report_of_model(nnn, X_train, y_train, X_test)"
   ],
   "metadata": {
    "id": "dCSJz_X0QYFr"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4.2.2. Нормализованные данные"
   ],
   "metadata": {
    "collapsed": false,
    "id": "EDpaT1JNQYFr"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "get_report_of_model(nnn, X_train_normalize, y_train, X_test_normalize)"
   ],
   "metadata": {
    "id": "9y5B0wyBQYFr"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.3. Решающее дерево"
   ],
   "metadata": {
    "collapsed": false,
    "id": "qkwOck5TQYFr"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier(random_state=42)"
   ],
   "metadata": {
    "id": "dAMvaMNeQYFr"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4.3.1. Ненормализованные данные"
   ],
   "metadata": {
    "collapsed": false,
    "id": "Sh4v5FnXQYFs"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "get_report_of_model(dtc, X_train, y_train, X_test)"
   ],
   "metadata": {
    "id": "wShkF3zQQYFs"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4.3.2. Нормализованные данные"
   ],
   "metadata": {
    "collapsed": false,
    "id": "T6XRp7JcQYFs"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "get_report_of_model(dtc, X_train_normalize, y_train, X_test_normalize)"
   ],
   "metadata": {
    "id": "zEziD7tZQYFs"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.4. Наивный байесовский классификатор"
   ],
   "metadata": {
    "collapsed": false,
    "id": "Gl4Z0ELzQYFs"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gnb = GaussianNB()"
   ],
   "metadata": {
    "id": "nEYq4pEDQYFt"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4.4.1. Ненормализованные данные"
   ],
   "metadata": {
    "collapsed": false,
    "id": "JM8oiAoUQYFt"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "get_report_of_model(gnb, X_train, y_train, X_test)"
   ],
   "metadata": {
    "id": "Cz4HuEqjQYFt"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4.4.2. Нормализованные данные"
   ],
   "metadata": {
    "collapsed": false,
    "id": "ExABLLipQYFt"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "get_report_of_model(gnb, X_train_normalize, y_train, X_test_normalize)"
   ],
   "metadata": {
    "id": "UnTibaUtQYFt"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Самые плохие результаты"
   ],
   "metadata": {
    "collapsed": false,
    "id": "L4A87D9CQYFu"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.5. Линейный дискриминантный анализ"
   ],
   "metadata": {
    "collapsed": false,
    "id": "9MB27O7jQYFu"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lda = LinearDiscriminantAnalysis()"
   ],
   "metadata": {
    "id": "7dWoNiLhQYFu"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4.5.1. Ненормализованные данные"
   ],
   "metadata": {
    "collapsed": false,
    "id": "DrRF5MFEQYFu"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "get_report_of_model(lda, X_train, y_train, X_test)"
   ],
   "metadata": {
    "id": "Z8E41hMNQYFu"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4.5.2. Нормализованные данные"
   ],
   "metadata": {
    "collapsed": false,
    "id": "f2YYq2zMQYFu"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "get_report_of_model(lda, X_train_normalize, y_train, X_test_normalize)"
   ],
   "metadata": {
    "id": "ddwIwGLBQYFv"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.6. Метод опорных векторов"
   ],
   "metadata": {
    "collapsed": false,
    "id": "bItnGiG-QYFv"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "svc = svm.SVC()"
   ],
   "metadata": {
    "id": "53ivVS6qQYFv"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4.6.1. Ненормализованные данные"
   ],
   "metadata": {
    "collapsed": false,
    "id": "zp26fC8-QYFv"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "get_report_of_model(svc, X_train, y_train, X_test)"
   ],
   "metadata": {
    "id": "GnX2PrZTQYFv"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4.6.2. Нормализованные данные"
   ],
   "metadata": {
    "collapsed": false,
    "id": "XZdyeAWyQYFv"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "get_report_of_model(svc, X_train_normalize, y_train, X_test_normalize)"
   ],
   "metadata": {
    "id": "myt3DO_NQYFw"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.7. Multi-layer Perceptron (MLP)"
   ],
   "metadata": {
    "collapsed": false,
    "id": "wfYyDSFQQYFw"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mlp = MLPClassifier()"
   ],
   "metadata": {
    "id": "WHO7A5nGQYFw"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4.7.1. Ненормализованные данные"
   ],
   "metadata": {
    "collapsed": false,
    "id": "ZTvLiWmPQYFw"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "get_report_of_model(mlp, X_train, y_train, X_test)"
   ],
   "metadata": {
    "id": "f7NI7NttQYFw"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4.7.2. Нормализованные данные"
   ],
   "metadata": {
    "collapsed": false,
    "id": "mnlkk9RfQYFx"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "get_report_of_model(mlp, X_train_normalize, y_train, X_test_normalize)"
   ],
   "metadata": {
    "id": "Na_kpY8xQYFx"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Мы можем заметить что нормализованные данные в среднем показывают результаты такие же, как и нормализованные"
   ],
   "metadata": {
    "collapsed": false,
    "id": "ySACDxYuQYFx"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.7. Ансамбль деревьев\n",
    "Наилучший результат показало решающее дерево, попробуем использовать ансамбль"
   ],
   "metadata": {
    "collapsed": false,
    "id": "WdovpXrxQYFx"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4.7.1. Подбор гипер параметров"
   ],
   "metadata": {
    "collapsed": false,
    "id": "VVt1tSEbQYFy"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_fitting_curve(parameter: str, values: list, X_train, X_test, y_train, y_test):\n",
    "    train_curve = []\n",
    "    test_curve = []\n",
    "    for value in tqdm(values):\n",
    "        model = DecisionTreeClassifier(**{parameter: value})\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred_train, y_pred_test = model.predict(X_train), model.predict(X_test)\n",
    "        train_curve.append(f1_score(y_train, y_pred_train, average='weighted'))\n",
    "        test_curve.append(f1_score(y_test, y_pred_test, average='weighted'))\n",
    "    sns.lineplot(x=values, y=train_curve, label=\"Train\").set_title(parameter)\n",
    "    sns.lineplot(x=values, y=test_curve, label=\"Test\")"
   ],
   "metadata": {
    "id": "1BGJwVlnQYFy"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 4.7.1.1. Максимальня глубина"
   ],
   "metadata": {
    "collapsed": false,
    "id": "2r3t1p8HQYFy"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_fitting_curve('max_depth', np.arange(1, 20), X_train, X_test, y_train, y_test)"
   ],
   "metadata": {
    "id": "5djs0VJEQYFy"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Судя по графику max_depth = 6"
   ],
   "metadata": {
    "collapsed": false,
    "id": "2m71cArwQYFz"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 4.7.1.2. Минимальное количество образцов, необходимое для разделен"
   ],
   "metadata": {
    "collapsed": false,
    "id": "PYxRWtbiQYFz"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_fitting_curve('min_samples_split', np.arange(2, 800, 2), X_train, X_test, y_train, y_test)"
   ],
   "metadata": {
    "id": "luFi2hzBQYFz"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Судя по графику min_samples_split = 600\n"
   ],
   "metadata": {
    "collapsed": false,
    "id": "HjP_mhTdQYFz"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 4.7.1.3. Минимальное количество образцов, необходимое для нахождения в листовом узле"
   ],
   "metadata": {
    "collapsed": false,
    "id": "Qb-yjkzZQYFz"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_fitting_curve('min_samples_leaf', np.arange(1, 400), X_train, X_test, y_train, y_test)"
   ],
   "metadata": {
    "id": "vHz11TwGQYFz"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Судя по графику min_samples_leaf = 160"
   ],
   "metadata": {
    "collapsed": false,
    "id": "b5wYYlrQQYF0"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4.7.2. Ансамблирование"
   ],
   "metadata": {
    "collapsed": false,
    "id": "GnouPef6QYF0"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_fitting_curve(parameter: str, values: list, X_train, X_test, y_train, y_test, params: dict):\n",
    "    train_curve = []\n",
    "    test_curve = []\n",
    "    for value in tqdm(values):\n",
    "        params.update({parameter: value})\n",
    "        model = RandomForestClassifier(**params)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred_train, y_pred_test = model.predict(X_train), model.predict(X_test)\n",
    "        train_curve.append(f1_score(y_train, y_pred_train, average='weighted'))\n",
    "        test_curve.append(f1_score(y_test, y_pred_test, average='weighted'))\n",
    "    val, idx = min((val, idx) for (idx, val) in enumerate(test_curve))\n",
    "    sns.lineplot(x=values, y=train_curve, label=\"Train\").set_title(parameter)\n",
    "    sns.lineplot(x=values, y=test_curve, label=\"Test\")"
   ],
   "metadata": {
    "id": "std2J8H2QYF0"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 4.7.2.1. С использованием подобранных гиперпараметров"
   ],
   "metadata": {
    "collapsed": false,
    "id": "mbQz0ICTQYF0"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "params = {'max_depth':6, 'min_samples_split':600, 'min_samples_leaf':160}\n",
    "\n",
    "plot_fitting_curve('n_estimators', np.arange(1, 200), X_train, X_test, y_train, y_test, params)"
   ],
   "metadata": {
    "id": "A2mJTmEEQYF0"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Результаты оказались хуже, чем у модели без подобранных гипер параметров"
   ],
   "metadata": {
    "collapsed": false,
    "id": "vV9wo6QKQYF1"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 4.7.2.2. Без использования подобранных гиперпараметров"
   ],
   "metadata": {
    "collapsed": false,
    "id": "AEdaLHDBQYF1"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "params = {}\n",
    "\n",
    "plot_fitting_curve('n_estimators', np.arange(1, 20), X_train, X_test, y_train, y_test, params)"
   ],
   "metadata": {
    "id": "uo-Ln2l1QYF1"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Судя по графику n_estimators = 30, f1=0.7, эти результаты получены при использовании данных для обучения с разных колличеством обьектов каждого класса"
   ],
   "metadata": {
    "collapsed": false,
    "id": "Ss1DbPAKQYF2"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4.7.2. Бустинг"
   ],
   "metadata": {
    "collapsed": false,
    "id": "2xgaW5guQYF2"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "modelClf = GradientBoostingClassifier()\n",
    "\n",
    "modelClf.fit(X_train, y_train)\n",
    "print(modelClf.score(X_test, y_test))"
   ],
   "metadata": {
    "id": "6W3ncU0cQYF2"
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lKNAInMx-mLq"
   },
   "source": [
    "## 5 **Анализ ошибок модели**\n",
    "Необходимо взять несколько примеров из тестовой части датасета, на которых модель дала неправильный ответ, и попытаться проанализировать их, найти закономерности, полученные выводы проверить на других примерах."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.1. Используемая модель"
   ],
   "metadata": {
    "id": "T4-JxfRq9wGN"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=30)\n",
    "\n",
    "get_report_of_model(model, X_train, y_train, X_test)"
   ],
   "metadata": {
    "id": "UYfmscUZQYF2"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Наилучшие результаты из всех эксперементов"
   ],
   "metadata": {
    "collapsed": false,
    "id": "g22y38dbQYF2"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.2. ДатаФрэйм на котором модель давала не правильные ответы"
   ],
   "metadata": {
    "id": "lztQ8UzA95Dv"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ],
   "metadata": {
    "id": "md2VsosJQYF3"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "error_matrix = []\n",
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i] != y_test.to_list()[i]:\n",
    "        row = [*list(X_test.to_numpy())[i], y_pred[i], y_test.to_list()[i]]\n",
    "        error_matrix.append(row)"
   ],
   "metadata": {
    "id": "fH2ldRRqQYF3"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "error_df = pd.DataFrame(\n",
    "    data=error_matrix,\n",
    "    columns=['bathrooms', 'bedrooms', 'building_id', 'manager_id', 'photos', \n",
    "     'price', 'features_count_words', 'description_count_words', 'y_pred', 'y_test']\n",
    ")"
   ],
   "metadata": {
    "id": "YwBn1wZxQYF3"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "error_df.head()"
   ],
   "metadata": {
    "id": "7JEtm35XQYF3"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.3. Корреляция"
   ],
   "metadata": {
    "id": "PF3N8GI2-Lmb"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 5.3.1. Матрица корреляции"
   ],
   "metadata": {
    "id": "ucIv3VaP-cZD"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "corr_matrix = error_df.corr()\n",
    "corr_matrix"
   ],
   "metadata": {
    "id": "FKIKHFno-g3C"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 5.3.2. Тепловая карта"
   ],
   "metadata": {
    "id": "j1E2oXzx-qAN"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "sns.set(rc={'figure.figsize':(10, 10)})\n",
    "sns.heatmap(corr_matrix, annot=True)\n",
    "None"
   ],
   "metadata": {
    "id": "VQ9JMhf5-zxt"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "y_pred имеет коэффицент корреляции с price = -0.19 (наибольший), в то время как y_test с price = -0.018. можно сделать вывод что модель нашла зависимости между ценой и популярнстью на тренировочном датасете, но на тестовом этой зависимости нет. \n",
    "\n",
    "Так же относительно высокий коэффицент y_pred и building_id, но на тестовой выборке этой зависимости нет. "
   ],
   "metadata": {
    "id": "nuDIUE9E_CW5"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6 NLP\n"
   ],
   "metadata": {
    "id": "oCIJOzidVYQH"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6.1. Подготовим датасет"
   ],
   "metadata": {
    "id": "_iLLUMG2Bym-"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "df = df.drop_duplicates('description')"
   ],
   "metadata": {
    "id": "RWutfPuA1-nz"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Удалим дубликаты"
   ],
   "metadata": {
    "id": "3d91ikdHB3uV"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "df['description'].unique().shape"
   ],
   "metadata": {
    "id": "JaruvKgezi5X"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Получим текста (description)"
   ],
   "metadata": {
    "id": "XunJIP5JCMBh"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "dd = Counter(df['description'].values)\n",
    "\n",
    "arr = []\n",
    "for k, v in dd.items():\n",
    "    arr.append((k, v))\n",
    "sort_arr = sorted(arr, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "desc = df['description'].values"
   ],
   "metadata": {
    "id": "fpHcAQil0ood"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6.2. Работа с нейросетью"
   ],
   "metadata": {
    "id": "LzIReVvECSay"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 6.2.1. Сделаем эмбэдинги"
   ],
   "metadata": {
    "id": "wMdjYR3UCXSo"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install sentence-transformers"
   ],
   "metadata": {
    "id": "mdFFP8lNZHm2"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model = SentenceTransformer('all-mpnet-base-v2')"
   ],
   "metadata": {
    "id": "1E2yzdU3ZGn2"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class DescDataset(Dataset):\n",
    "    def __init__(self, embs, df):\n",
    "        self.embs = embs\n",
    "        self.df = df\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "      \n",
    "    def __getitem__(self, idx):\n",
    "        embs = self.embs[idx]\n",
    "        trg = self.df['TARGET'].values[idx]\n",
    "        return torch.FloatTensor(embs), torch.LongTensor([trg])"
   ],
   "metadata": {
    "id": "aazJyPMXZ_mf"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2)"
   ],
   "metadata": {
    "id": "D7UtuGNHbvcO"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "device = torch.device('cuda')\n",
    "model = model.to(device)"
   ],
   "metadata": {
    "id": "s6cEqFswcQL8"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "all_embs = model.encode(df['description'].values)"
   ],
   "metadata": {
    "id": "sFJcBODHheYi"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Считать ранее сохраненные эмбэдинги"
   ],
   "metadata": {
    "id": "TQ8f2Ps3Ci21"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#all_embs = pickle.load(open('embs1.pkl', 'rb'))"
   ],
   "metadata": {
    "id": "W4v8vndXj02Q"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Сохранить эмбэдинги"
   ],
   "metadata": {
    "id": "gKiDVooOCoBN"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "pickle.dump(all_embs, open('embs1.pkl', 'wb'))"
   ],
   "metadata": {
    "id": "rj4MJotIjYFN"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "all_embs.shape"
   ],
   "metadata": {
    "id": "4zP4SdvcjS29"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_dataset = DescDataset(all_embs, train_df)\n",
    "test_dataset = DescDataset(all_embs, test_df)"
   ],
   "metadata": {
    "id": "hytqRdBXb8i7"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def make_weights_for_balanced_classes(images, nclasses):                        \n",
    "    count = [0] * nclasses                                                      \n",
    "    for item in images:                                                         \n",
    "        count[item[1]] += 1                                                     \n",
    "    weight_per_class = [0.] * nclasses                                      \n",
    "    N = float(sum(count))                                                   \n",
    "    for i in range(nclasses):                                                   \n",
    "        weight_per_class[i] = N/float(count[i])                                 \n",
    "    weight = [0] * len(images)                                              \n",
    "    for idx, val in enumerate(images):                                          \n",
    "        weight[idx] = weight_per_class[val[1]]                                  \n",
    "    return weight         "
   ],
   "metadata": {
    "id": "eLlFbVzhubnb"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Сохраним веса"
   ],
   "metadata": {
    "id": "eQsFLcRWCvtl"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "weights = make_weights_for_balanced_classes(train_dataset, 3)                                                                \n",
    "weights = torch.DoubleTensor(weights)                                       \n",
    "sampler = torch.utils.data.sampler.WeightedRandomSampler(weights, len(weights))"
   ],
   "metadata": {
    "id": "1YJYMKlwubfA"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "trainloader = DataLoader(train_dataset, batch_size=256, sampler=sampler)\n",
    "testloader = DataLoader(test_dataset, batch_size=256, shuffle=False)"
   ],
   "metadata": {
    "id": "OFS1_js6bbu5"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Самописная сеть классификатор"
   ],
   "metadata": {
    "id": "N97YKY56CyJH"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "head = nn.Sequential(\n",
    "    nn.Linear(768, 1536),\n",
    "    nn.BatchNorm1d(1536),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(1536, 1536),\n",
    "    nn.BatchNorm1d(1536),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(1536, 1536),\n",
    "    nn.BatchNorm1d(1536),\n",
    "    \n",
    "    nn.Linear(1536, 3),\n",
    ").to(device)\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.m = []\n",
    "        sh = 768\n",
    "        for i in range(50):\n",
    "            self.m.append(nn.Sequential(\n",
    "                nn.Linear(sh, sh * 2),\n",
    "                nn.BatchNorm1d(sh * 2),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.2),\n",
    "                nn.Linear(sh * 2, sh - 15),\n",
    "                nn.BatchNorm1d(sh - 15),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.2),\n",
    "            ))\n",
    "\n",
    "            sh -= 15\n",
    "        \n",
    "        self.m = nn.Sequential(*self.m)\n",
    "        self.l = nn.Linear(18, 3)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.m(x)\n",
    "        x = self.l(x)\n",
    "        return F.sigmoid(x)\n"
   ],
   "metadata": {
    "id": "8Azqwi5Qcvg6"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "head = Model().to(device)"
   ],
   "metadata": {
    "id": "Ib8L4I9CpzS-"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.AdamW(head.parameters(), lr=1e-4)\n",
    "shed = torch.optim.lr_scheduler.StepLR(opt, 10, 0.1)"
   ],
   "metadata": {
    "id": "_hhnuX5neUQ-"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 6.2.2. Обучение нейросети"
   ],
   "metadata": {
    "id": "iOPn8a8OC9Hv"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "for epoch in trange(100):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for i, batch in enumerate(trainloader):\n",
    "        x, y = map(lambda x: x.to(device), batch)\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        y_pred = head(x)\n",
    "        loss = criterion(y_pred, y.squeeze(1))\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    \n",
    "    train_loss /= len(trainloader)\n",
    "    \n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "\n",
    "    Y = []\n",
    "    Y_PREDS = []\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(testloader):\n",
    "            x, y = map(lambda x: x.to(device), batch)\n",
    "            \n",
    "            y_pred = head(x)\n",
    "            loss = criterion(y_pred, y.squeeze(1))\n",
    "\n",
    "            test_loss += loss.item()\n",
    "\n",
    "\n",
    "            Y.append(y)\n",
    "            Y_PREDS.append(torch.argmax(torch.softmax(y_pred, dim=1), dim=1))\n",
    "\n",
    "\n",
    "    test_loss /= len(testloader)\n",
    "    Y = torch.cat(Y, dim=0)\n",
    "    Y_PREDS = torch.cat(Y_PREDS, dim=0)\n",
    "\n",
    "    #print(f'Epoch: {epoch} \\t\\t TrainLoss: {train_loss} \\t\\t TestLoss: {test_loss}')\n",
    "    #print(classification_report(Y.cpu().detach().numpy(), Y_PREDS.cpu().detach().numpy()))"
   ],
   "metadata": {
    "id": "k9kfx9HZd8zD"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "Y = []\n",
    "Y_PREDS = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, batch in tqdm(enumerate(testloader), total=len(testloader)):\n",
    "        x, y = map(lambda x: x.to(device), batch)\n",
    "        y_pred = head(x)\n",
    "        Y.append(y)\n",
    "        Y_PREDS.append(torch.argmax(torch.softmax(y_pred, dim=1), dim=1))"
   ],
   "metadata": {
    "id": "MFZsOx6UkjUC"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "Y = torch.cat(Y, dim=0)\n",
    "Y_PREDS = torch.cat(Y_PREDS, dim=0)"
   ],
   "metadata": {
    "id": "7kSIK8EAk9Dz"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "Y_PREDS.unique()"
   ],
   "metadata": {
    "id": "aqck9pXgq46D"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 6.2.3. Результаты обучения"
   ],
   "metadata": {
    "id": "c_WsKqBODFpy"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(classification_report(Y.cpu().detach().numpy(), Y_PREDS.cpu().detach().numpy()))"
   ],
   "metadata": {
    "id": "vrq3ATgomu54"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6.3. Комментарий\n",
    "\n",
    "Нейросеть переобучилась, результаты оказались хуже, у наилучшей модели (лес)"
   ],
   "metadata": {
    "id": "wTDTUqCcDSzx"
   }
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "private_outputs": true,
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
